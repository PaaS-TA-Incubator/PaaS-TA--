var result_scholar_list = [
	{
		"ID": 1,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한남대학교 대학원",
		"TITLE": "빅데이터 플랫폼을 활용한 公共圖書館 빅데이터 分析 硏究 :A big data analysis for public libraries utilizing big data platform : a case study of Daejeon Hanbat Library ",
		"AUTHOR": "온정미",
		"REGION": "대전",
		"PROFESSOR": "한남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박성희 참고문헌: p. 65-69",
		"STORE_LOCATION": "한남대학교 도서관",
		"ABSTRACT": "본 논문의 연구목적은 2016년 1월 1일부터 서비스하기 시작한 공공도서관 빅데이터 플랫폼 구축 현황과 사례를 통하여 도서관 빅데이터 분석의 중요성을 인식시키고, 도서관 빅데이터 플랫폼 구축 데이터를 활용하여 한밭도서관 업무에 적용할 수 있는 공공서비스 및 시행정책을 도출하는 것이다. 연구내용 및 방법은 1) 도서관 빅데이터 플랫폼을 활용한 사례도서관의 빅데이터 활용 유형분석 및 시행정책을 살펴보고 2) 공공도서관 빅데이터 플랫폼에서 제공하는 장서현황, 회원현황, 대출현황 등의 빅데이터 분석결과를 토대로 한밭도서관에서 접목 가능한 활용서비스를 적용하여 도서관 수서정책 개선, 독서문화 프로그램 운영 개발, 장서 활성화 방안 도출 등 업무의 효율성 향상 가능성을 검증하였다. 3) 좀 더 유용한 데이터 결과를 도출하기 위해 ‘도서관 빅데이터의 효율적 분석 방법론(안)’을 제안하고,이를 적용하고자 추가로 분석도구 툴 및 알파 데이터를 활용하여 분산분석 및 회귀분석을 수행하였다. 4) 이상의 세 과정에서 나타난 도서관 빅데이터 플랫폼 활용의 한계점과 개선방안을 도출함으로써 도서관 빅데이터 플랫폼 서비스 확장 개발 필요성을 인식시키고, 향후 도서관 정보서비스에 효과적인 빅데이터 활용의 연구 방향을 제언하였다. 구체적인 활용 및 적용하기에는 도서관계 빅데이터 플랫폼이 초기단계이지만 도서관 빅데이터 분석에 대한 관심제고와 도서관 업무에 대한 다각적인 적용으로 스마트한 업무를 수행할 필요가 있다. 도서관 빅데이터의 개발·확장을 통해 과학적인 분석데이터를 근거로 이용자가 만족하는 서비스를 제공하고, 변화하는 도서관 환경에 적극적으로 대처하여 앞으로 더욱 진일보한 도서관으로 발전시켜 나가기를 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 2,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경기대학교 서비스경영전문대학원",
		"TITLE": "지식정보 자산인 빅데이터(Big Data) 활용에 관한 연구 :데이터 연구자(Data Researchers)의 관점에서 본 사례분석의 시사점 ",
		"AUTHOR": "김선영",
		"REGION": "서울",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수:엄길청 참고문헌 : p.79-84",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "과일을 파는 상점에서는 사과, 배, 감 등을 한군데 섞어놓고 팔지 않는다. 사과는 사과끼리 배는 배끼리 같은 종류별로 나누어 진열한다. 뿐만 아니라 동일한 종류의 과일이라도 크기별로 분류한다. 심지어 신선도(新鮮度)에 따라 구분하기도 한다. 일상생활에서 복잡한 문제에 마주치게 될 때, 그 현안을 여러 각도에서 분류와 재분류 해보면 그 실체를 정확하게 파악하는데 도움이 된다. 고대 그리스의 철학자 아리스토텔레스는 학문을 이론학(theoretike episteme : 자연학, 수학, 형이상학), 실천학(praktike episteme : 정치학, 윤리학, 경제학), 제작학(poietike episteme : 수사학, 사학) 으로 분류했다. 그가 이 처럼 학문을 분류했던 이유는 나름대로 체계를 세워 분류함으로서 세상을 보다 종합적이고 통합적으로 이해하려고 했기 때문이다. 2008년 세계적인 금융위기 이후 빅데이터(Big Data)라는 단어가 봇물을 이루고 있다. 빅데이터`라는 시대적인 빅이슈(Big Issue)를 정확하게 파악하는 방법 중 하나는 지금까지 이루어진 빅데이터 분석사례들을 ‘다양한 각도’에서 분류해보는 것이다. 본 연구는 그 ‘다양한 각도’ 중 한 가지 관점을 통해, 선행된 빅데이터 분석사례들을 분류했다, 그 목적은 첫째, 빅데이터 선행분석결과들을 체계적으로 보여줌으로서 빅데이터 분석을 시도하려는 당사자들에게 정확한 목표와 방향을 제시 하려는 것이며, 둘째, 빅데이터 분석을 도입하고 싶어도 그럴만한 자원을 보유하고 있지 못한 기업이나 단체에게 체계적으로 분류된 선행 분석결과들을 이용(利用) 또는 원용(遠用) 할 수 있게 하려는 것이다. 그 방법론으로서 빅데이터 생성과 제공의 의도성(意圖性)에 따라 쓰레기통 모델, 라이프메트릭스 모델, 소셜메트릭스 모델, 크라우드 소싱모델 등 총 4개의 모델로 분류하여 연구를 진행했다. 연구를 통해 소개된 각 모델들을 정리해본 결과 가장 큰 특징은 다음과 같다. 메트릭스 모델 분석의 경우 첫째, 우리나라에서는 메트릭스 모델, 쇼셜메트릭스 모델, 크라우드소싱 모델에 의한 분석은 거의 찾아볼 수 없었고 쓰레기통 모델분석이 주류를 이루고 있다. 이것은 처음부터 빅데이터를 분석할 목적으로 자료를 생성하고 축적하지 않았음을 보여주고 있다. 둘째, 서울시가 교통사고를 분석할 때 자신이 갖고 있는 행정데이터 뿐만이 아니라 기상청, SKT, 교통안전공단 등 외부자료를 적극적으로 활용함으로서 입체적인 분석을 시행할 수 있었다. 이는 빅데이터를 분석할 때 데이터를 공유하면 시너지효과를 얻을 수 있음을 보여준 사례로 평가된다. 셋째, 외국의 경우 쓰레기통 모델분석 분야에 데이터를 사고파는 데이터중개업이라는 새로운 직군(職群)을 출현시켰다. 라이프메트릭스 모델의 경우에는 종업원 또는 고객에게 센서 등 웨어러블 기기를 착용시키는 의도적이고 노골적인 자료수집 행위가 수반된다. 이는 자칫 잘못하면 피실험자 집단인 종업원과 고객들을 통제하려는 목적으로 이해될 수 있다. 그러나 쓰레기통모델에서는 발견할 수 없는 획기적인 결과들이 도출될 가능성이 높다. 쇼셜메트릭스 모델의 경우 피실험자집단의 규모가 라이프메트릭스 모델 보다는 큰 단위로 이루어고 있으며, 데이터를 수집하는 장비로 스마트폰이 많이 이용된다. 이는 스마트폰의 기능이 다양해지고 보급률이 높아질수록 더 정교하고 다양한 데이터들을 수집할 수 있기 때문에 특정한 지역 또는 국민전체를 긍정적으로 변화시킬 수 있을 것으로 기대된다. 라이프메트릭스 모델이나 쇼셜메트릭스 모델 모두 센서산업과 센서운용(運用)업 이라는 새로운 직업을 탄생시켰다. 크라우드소싱 모델의 경우 피실험자가 자발적으로 데이터를 제공한다는 점에서 라이프메트릭스 모델이나 쇼셜메트릭스 모델에서 문제가 될 수 있는 개인의 프라이버시 침해 논란으로 부터 자유스럽다. 정부나 지방자치단체는 민간에서처럼 국민이나 시민들에게 센서를 부착케 하거나 스마트폰에 앱을 깔아 실시간으로 데이터를 수집하기는 어렵다. 따라서 정부가 에너지절약이나 전염병예방 등 캠페인성 정책을 수행할 경우 크라우드 소싱 방법을 택한다면 국민들의 자발적인 참여를 통해 정책의 효과를 배가 시킬 수 있을 것으로 기대된다. 빅데이터의 유형을 위의 4개 모델로 분류하여 분석한 연구의 총합적인 결론은 아래와 같이 여섯 가지이다. 첫째, 빅데이터는 사회적 자산으로 평가 될 수 있다. 둘째, 빅데이터는 공유할수록 가치가 커진다. 셋째, 빅데이터분석을 시도하기 전에 정확한 목표설정이 필요하다. 넷째, 빅데이터분석에 내부 자료에만 의존해서는 안 된다. 다섯째, 센서를 이용한 새로운 빅데이터 생산도 필요하다. 여섯째, 타인의 빅데이터 분석결과를 이용하는 것도 한 가지 방법이다.",
		"KEYWORD": "데이터리서처,데이터연구자,빅데이터,사례분석"
	},
	{
		"ID": 3,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "사용자 경험(UX)향상을 위한 빅데이터 활용 스마트폰 헬스케어 디자인 기획 모델 연구 =(A)study on model of smart phone health care design planning using big data for enhancement in UX ",
		"AUTHOR": "오인균",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정석길 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "현재의 사회, 경제 트렌드에서 가장 중요한 키워드는 경험(Experience)이며, 디자인에서도 이와 같은 시대적 배경의 영향을 받아서 사용자 경험(UX)이 중요한 요소가 되었다. 하지만 사용자 경험(UX)은 사용자의 감성, 기억, 상상력 등이 종합되어서 표출되는 것으로 그것을 찾아내는 것은 어렵다. 빅데이터(Big Data)는 이러한 문제를 해결할 솔루션으로 관심을 받고 있다. 빅데이터는 그동안 분석을 하지 못했던 대용량의 데이터를 수집하고 분석할 수 있는 기술이자 시스템이다. 우리는 빅데이터 기술을 활용하여 방대한 데이터를 분석하고 그 결과로 사용자의 행동과 감정을 예측(Forecast)할 수 있게 되었다. 현재 마케팅, 정보시스템 분야를 중심으로 적용되고 있으며, 디자인 분야에서도 빅데이터에 많은 관심을 가지고 있다. 본 연구는 이와 같은 시대적 배경을 바탕으로 사용자 경험(UX)향상을 위해서 빅데이터 기술을 스마트폰 헬스케어 디자인 기획 단계에 활용한 모델을 제안하였다. 이러한 연구의 진행을 위해서 문헌연구방법, 통합연구(정량조사, 정성조사)방법 그리고 타당성 검증을 적용하였다. 문헌연구결과 디자인 분야에서의 빅데이터 적용 사례와 스마트폰 헬스케어에서의 빅데이터와 사용자 경험(UX)적용 사례를 구체적으로 알 수 있었다. 통합연구결과 디자이너들의 빅데이터 이해도는 높으며, 디자인 업무에 빅데이터 활용의 필요성에 동의하고 있는 것으로 조사되었다. 또한 디자이너들은 빅데이터 활용이 적합한 디자인 분야로 디자인 기획업무와 사용자 경험(UX)관련 업무를 선정하였다. 문헌연구와 통합연구 결과를 바탕으로 본 연구자는 빅데이터 활용 스마트폰 헬스케어 디자인 기획 모델을 제안을 하였다. 본 모델은 물리적 시스템과 공존하고, 총 4단계의 프로세스(① Health-care UX Strategy → ② Health-care UX Big Data Analysis → ③ Health-care UX Concept Making→ ④ Evaluation)를 기본으로 6개의 루트(Route)를 지니고 있다. 모델 구축 이후 실제 업무 적용에 대한 타당성을 검증을 진행하였으며, 설문평가와 인터뷰 평가로 나누어서 진행하였다. 검증결과 평가자들은 본 모델이 디자인 기획 업무에 적용이 타당하다는 결론을 지었다. 이와 같은 빅데이터 활용 스마트폰 헬스케어 디자인 기획 모델은 기존의 일반적 디자인 기획 모델과 달리 빅데이터 활용을 통해 사용자 경험(UX) 정보를 실시간으로 수집과 분석할 수 있다는 것과 다양한 시각화 요소를 첨가하여 효과적인 의사결정을 내릴 수 있게 한 것이 장점이다. 그리고 연구 결과는 빅데이터 활용의 토대를 마련하였으며, 도입을 위한 기업들에게 가이드라인을 제시하였다는 데 그 의의가 있다. 그리고 이와 같은 연구가 디자인 분야에서 초기인 빅데이터 활용의 기초 연구가 되어서 향후에 다양한 연구가 지속되길 희망한다.",
		"KEYWORD": null
	},
	{
		"ID": 4,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "광운대학교 대학원",
		"TITLE": "개인정보 비식별화 기술 적용수준이 빅데이터 이용활성화 의도에 미치는 영향 :(The)effects of applying personal information de-identification technology on intention to use big data :빅데이터 공급자와 수요자 관점 =big data providers and consumers perspectives ",
		"AUTHOR": "양현철",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김신곤 참고문헌 수록",
		"STORE_LOCATION": "광운대학교 중앙도서관",
		"ABSTRACT": "빅데이터의 본격적인 활용 증가로 인해 개인정보의 침해위험은 빅데이터 공급자와 수요자 모두에게 심각한 문제를 야기할 수 있다. 미래 성장동력으로 추진되는 빅데이터 산업의 경쟁력 강화는 자칫 통제적이고 권력적인 빅브라더 기술로 전락할 수 있기에 본 논문은 개인정보의 보호기반에서 빅데이터의 활용성을 극대화할 수 있는 방안으로 개인정보 비식별화 기술을 적용할 것을 제안하고 있다. 본 연구는 비식별화 기술을 적용함으로써 빅데이터의 이용활성화와 개인정보의 보호 사이에서 조화로운 균형점을 찾고자 하였다.. 이를 위하여 개인정보 비식별화 기술 적용수준과 빅데이터 이용활성화에 관한 연구모형 및 가설을 도출한 후 실증분석을 통해 규명함으로써, 개인정보 비식별화 기술을 활용한 빅데이터의 이용활성화의 이론적 기반을 마련하는데 주안점을 두고 있다.본 연구는 빅데이터 이용활성화를 위하여 개인정보 비식별화 기술의 효과적인 적용에 대한 실증연구를 수행하였다. 기존의 이론적 모형을 기반으로 실증모형을 개발하기 위해, Davis의 기술수용모델(TAM)과 Laufer의 프라이버시 계산이론(Privacy Calculus)을 기본모형으로 채택하였다. 또한 본 연구는 개인정보 비식별화 기술의 성숙도(비식별화 기법, 프라이버시 모델)에 따른 비식별화 기술의 적용수준에 따라 빅데이터의 이용활성화 의도에 긍정적이고 차별적인 영향을 준다는 것을 밝혀냈다는 것에 중요한 의의가 있다. 본 연구를 통해 개인정보 비식별화 기술 적용수준이 이용활성화 의도에 어떤 영향을 미치는지 실증분석을 통하여 다음과 같은 결과를 도출할 수 있었다.첫 번째, 빅데이터 환경에서 개인정보 비식별화 기술 적용수준이 높을수록 빅데이터의 유용성, 사용용이성, 업무기술적합성, 개인정보 침해위험 방지가 효과적이었다. 특히, 빅데이터의 유용성, 업무기술적합성, 개인정보 침해위험 방지는 빅데이터 이용활성화 의도에 긍정적 역할을 수행하는 것으로 밝혀졌다. 이를 통해 빅데이터 환경에서 개인정보 비식별화 기술은 빅데이터의 활용과 개인정보의 보호 모두에서 실효성이 있는 것이 밝혀짐으로써 빅데이터 활성화 정책수립에 있어서 비식별화 기술의 적용을 적극적으로 활용할 필요가 있다.두 번째, 빅데이터의 공급자와 수요자 모두에게 비식별화 기술 적용수준이 사용용이성, 업무기술적합성, 개인정보 침해위험 방지에 긍정적인 역할을 한다고 인식되어 있으며 특히, 빅데이터의 유용성과 이용활성화 의도에 있어서 공급자 보다 수요자가 그 영향과 필요를 상대적으로 더 크게 지각하고 있었다. 이를 통해 빅데이터 수요자가 공급자 보다 비식별화 기술에 대한 활용성과 안전성의 중요도를 더 높게 인식하고 있음을 확인할 수 있었다. 세 번째, 국내 개인정보 법제의 엄격한 환경은 빅데이터의 활용과 개인정보의 보호라는 상반된 논리에서 절충점을 찾기가 어려운데, 개인정보 비식별화 기술은 상호 균형점과 활용점을 제시하고 있기에 해당기술에 대한 제도기반과 적용기준을 마련할 필요가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 5,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "비즈니스 인텔리전스 데이터 특성에 따른 빅데이터 배치 전략 연구 =(A)study of big data placement strategy based on the characteristics of business intelligence data ",
		"AUTHOR": "정두영",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 논문은 저작권에 의해 보호받습니다. 지도교수:최종무 참고문헌(60-61장)수롣",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "오늘날 빅데이터 분석은 성공적인 비즈니스를 위한 필수 요소가 되고 있다. 고객의 요구는 더욱더 복잡해지고 있으며 기업의 환경과 업무는 특화되고 세분화 되어가고 있다. 데이터의 증가 속도는 더욱 빨라졌으며 비즈니스 프로세스는 더욱 복잡하고 다변화 되었다. 이러한 비즈니스 환경 속에서 의사결정은 정확히 처리된 정보를 바탕으로 적시에 이루어져야 한다. 기업은 데이터에 대한 관리와 분석의 중요성을 인식하였고 빅데이터를 처리할 수 있는 새로운 아키텍처를 요구하고 있다. 여기서 중요한 것은 IT서비스 자체뿐만 아니라 IT서비스로부터 얻을 수 있는 가치와 도출된 의미에 중점을 두어야 한다는 것이다. 빅데이터 기술은 크게 분석 기술과 인프라 기술로 나누어 볼 수 있다. 이러한 기술 중 도입비용에 대부분을 차지하는 인프라 솔루션의 도입방안에 대해 사례를 통해 분석하였다. RDBMS, Hadoop, NoSQL, In-memory DBMS 와 같은 다양한 솔루션들이 기업과 현장에서 효과적으로 사용 되고 있으며 성능, 확장성, 비용 등의 측면에서 다양한 장단점이 나타난다. 특히 Hadoop과 NoSQL 은 빅데이터를 다루는데 있어 효과적인 솔루션으로 부각 되고 있다. RDBMS 는 안정성과 활용도 측면에서 큰 이점을 가지고 있다. In-memory DBMS는 key-value 방식의 처리시 응답지연을 보이는 문제가 있으나 실시간 처리가 요구되는 영역에서는 속도측면에서 가장 적합하다. 하지만 가격 면에 있어서 달러당 저장 용량은 Hadoop과 NoSQL 이 가장 우수한 솔루션으로 볼 수 있다. 본 논문에서는 각 솔루션의 장단점에 대한 분석을 바탕으로 데이터의 특성에 따라 솔루션을 통합적용 할 수 있는 새로운 접근방법을 제시하였다. 제안의 목적은 ROI를 최적화하는 방향으로 접근하였다. 우선BI에서 관리 되고 있는 데이터를 사용빈도와 규모 등의 특성에 따라 분류하였다. 데이터 처리의 병목현상(Bottle neck)은 데이터의 변환단계인Transformation 단계에서 주로 발생하는 것을 고려하여 사용 빈도가 높은 Data Mart 및 Transformation영역을 In-memory DBMS영역에 배치하였다. BI의 특성인 비휘발성을 고려하여 활용도가 낮고 History성격의 데이터는 상대적으로 저가의 NoSQL에 저장하고 일부 영역에 대해서는 기존 BI영역을 유지하도록 했다. 기존 BI시스템 전체를 In-memory DBMS기반의 BI시스템으로 전환하게 되면 M+사이즈의 도입이 필요하지만 도출된 방법에 따라 솔루션을 배치하게 되면 4단계 아래인 XS사이즈의 도입이 가능하다. 이는 도입비용의 60% 이상이 절감될 수 있음을 보여준다.",
		"KEYWORD": null
	},
	{
		"ID": 6,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "빅데이터 활용을 위한 데이터 수집 도구 평가에 관한 연구 =(A)study on the evaluation of data collection tools for big data utilization ",
		"AUTHOR": "한수현",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 논문은 저작권에 의해 보호받습니다. 지도교수:유해영 참고문헌 : 30-31 장.",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "The Realized information with the widespread use of computers and Internet produced 1.8ZB data information by accelerating the production data facing the data explosive in phenomena in 2011. The amount of data produced from all over the world to take advantage of the available storage capacity in excess of the data flood era was initiated and, in the future, the data is exponentially increasing, as early as in 2020 will be 50 times the current explosion. The scale of big data are vast and big data(Volume), and the variety of data (Variety). And also, the big data has the characteristics that need to resolve in a timely manner data(Velocity) as the result, it should be able to create new value. Big data is a common database to overcome the limitations of store, manage, and analyze. It also contains web, images, videos, social network services, including both structured and unstructured data and, require real-time processing in analysis and forecasting on demand. We need to efficiently collecting data first and store management in order to take advantage of big data. You can find the solution of social problems through the analysis of the data collected, which unearthed a prediction for the future. So you can be sure that the ability to collect large amounts of data(Big data) is important. The big data platform based on Hadoop becomes factual standard(de facto). There are a variety of tools for data collection and the actual global companies also operated various collection tools to select and fit for the purpose of applying the big data platform. Hadoop-based big data platform is built upon a variety of data collection tool operated by the user on the purpose of the tool allows you to select a data collection tool for the evaluation of offers through this paper model. In this paper through the study of big data and understand the big data-collection tools, assessment by identifying in advance the model features the introduction of new technologies to meet the purpose of the user is expected to build big data platform.",
		"KEYWORD": null
	},
	{
		"ID": 7,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "공공분야에서의 빅데이터(Big Data) 활용이 업무성과에 미치는 영향에 관한 연구 ",
		"AUTHOR": "황대욱",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박희준",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 8,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "빅 데이터(Big Data) 도입의도에 미치는 영향요인에 관한 연구 =(An)empirical study on the influencing factors for big data intented adoption ",
		"AUTHOR": "가회광",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진수 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "Solving the various problems that the corporation confronts needs to be effectively solved to survive in the global environment. The big-data is being perceived as a tool to solve corporate problems effectively and improve competitiveness with the various problem solving ability and predictive ability which the existing IT system did not have. The big-data is called the `crude oil` of the 21st century and it is expected that the type of corporation and organization which deduct strategic value through big-data possessed by the corporation and apply this to the business properly will be able to obtain competitive superiority. The reason why the big data is in the limelight is because while the conventional IT technology has been falling behind much in its possibility level, the big data has gone beyond the technological possibility and has the advantage of being utilized to create new values such as business optimization and new business creation through analysis of big data. The big data was actively produced in order to perceive the high strategic value possessed by the big data and to utilize the big data strategically based on the global initiative corporations. However, since the big data has been introduced too hastily without considering the strategic value deduction and achievement obtained through the big data, there are difficulties in the strategic value deduction and data utilization that can be gained through big data. According to the survey result of 1,800 IT professionals from 18 countries world wide, the percentage of the corporation where the big data is being utilized well was only 28%, and many of them responded that they are having difficulties in strategic value deduction and operation through big data. The strategic value should be deducted and environment phases like corporate internal and external related regulations and systems should be considered in order to introduce big data, but these factors were not well being reflected. The cause of the failure turned out to be that the big data was introduced by way of the IT trend and surrounding environment, but it was introduced hastily in the situation where the introduction condition was not well arranged. The strategic value which can be obtained through big data should be clearly comprehended and systematic environment analysis is very important about applicability in order to introduce successful big data, but since the corporations are considering only partial achievements and technological phases that can be obtained through big data, the successful introduction is not being made. Study which considers the strategic value and introduction condition is needed for the corporations which consider introduction of big data, but the current big data related researches focus only on the concept of the big data, study on the strategic value, study on the technology and conceptual study on the introduction and vitalization, and thus the study which can provided guideline for the big data introduction by corporations insufficient. To cope with this situation, this study has intended to comprehend the effect elements which affect the introduction of big data, and analyze these empirically and propose the guideline for the introduction of big data which is theoretically reasonable and practically useful. For this, the elements which can affect the introduction intention of big data were deducted by reviewing the information system`s successful factors, strategic value perception factors, considering factors for the information system introduction environment and big data related literature in order to comprehend the effect factors when the corporations introduce big data and structured questionnaire was developed. After that, the questionnaire and the statistical analysis were performed with the people in charge of the big data inside the corporations as objects. According to the statistical analysis, it was shown that the strategic value perception factor and the inside-industry environmental factors affected positively the introduction intention of big data. The theoretical, practical and political implications deducted from the study result is as follows. The frist theoretical implication is that this study has proposed theoretically effect factors which affect the introduction intention of big data by reviewing the strategic value perception and environmental factors and big data related precedent studies and proposed the variables and measurement items which were analyzed empirically and verified. This study has meaning in that it has measured the influence of each variable on the introduction intention by verifying the relationship between the independent variables and the dependent variables through structural equation model. Second, this study has defined the independent variable(strategic value perception, environment), dependent variable(introduction intention) and regulatory variable(type of business and corporate size) about big data introduction intention and has arranged theoretical base in studying big data related field empirically afterwards by developing measurement items which has obtained credibility and validity. Third, by verifying the strategic value perception factors and the significance about environmental factors proposed in the conventional precedent studies, this study will be able to give aid to the afterwards empirical study about effect factors on big data introduction. The operational implications are as follows. First, this study has arranged the empirical study base about big data field by investigating the cause and effect relationship about the influence of the strategic value perception factor and environmental factor on the introduction intention and proposing the measurement items which has obtained the justice, credibility and validity etc. Second, this study has proposed the study result that the strategic value perception factor affects positively the big data introduction intention and it has meaning in that the importance of the strategic value perception has been presented. Third, the study has proposed that the corporation which introduces big data should consider the big data introduction through precise analysis about industry`s internal environment. Fourth, this study has proposed the point that the size and type of business of the corresponding corporation should be considered in introducing the big data by presenting the difference of the effect factors of big data introduction depending on the size and type of business of the corporation. The political implications are as follows. First, variety of utilization of big data is needed. The strategic value that big data has can be accessed in various ways in the product, service field, productivity field, decision making field etc and can be utilized in all the business fields based on that, but the parts that main domestic corporations are considering are limited to some parts of the products and service fields. Accordingly, in introducing big data, reviewing the phase about utilization in detail and design the big data system in a form which can maximize the utilization rate will be necessary. Second, the study is proposing the burden of the cost of the system introduction, difficulty in utilization in the system and lack of credibility in the supply corporations etc in the big data introduction phase by corporations. Since the world IT corporations are predominating the big data market, the big data introduction of domestic corporations can not but to be dependent on the foreign corporations. When considering that fact, that our country does not have global IT corporations even though it is world powerful IT country, the big data can be thought to be the chance to rear world level corporations. Accordingly, the government shall need to rear star corporations through active political support. Third, the corporations` internal and external professional manpower for the big data introduction and operation lacks. Big data is a system where how valuable data can be deducted utilizing data is more important than the system construction itself. For this, talent who are equipped with academic knowledge and experience in various fields like IT, statistics, strategy and management etc and manpower training should be implemented through systematic education for these talents. This study has arranged theoretical base for empirical studies about big data related fields by comprehending the main variables which affect the big data introduction intention and verifying them and is expected to be able to propose useful guideline for the corporations and policy developers who are considering big data introduction by analyzing empirically that theoretical base.",
		"KEYWORD": null
	},
	{
		"ID": 9,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "빅데이터 응용사례 분석을 통한 소스데이터 유형 분류 :(The)classification of source data types through the analysis of big data application cases :BI&A 응용분야와 U-City 서비스 분류체계를 중심으로 =focused on BI&A applications and u-city service categories ",
		"AUTHOR": "이현구",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 논문은 저작권에 의해 보호받습니다. 지도교수:오재인 참고문헌(p. 52-56)수록",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "최근 스마트 모바일 기기의 확산, 소셜네트워크 서비스의 활성화, 기업의 고객데이터 수집, 동영상 콘텐츠의 증가에 힘입어 정보의 양이 기하급수적으로 증가하고 있다. 이러한 빅데이터는 과거에는 별도로 보관 및 저장하지 않고 흘려버려지는 데이터들이었다. 하지만 지금은 분석기술의 발달, 저장매체 가격의 하락에 힘입어 이를 분석함으로써 비즈니스의 효율화, 개인맞춤화, 미래예측 등 비즈니스 부문의 혁신을 이루어낼 수 있음은 물론이다. 나아가 장기적으로는 지식기반 사회에서 일어나는 다양한 사회현상에 대한 통찰력, 대응력, 경쟁력, 창조력을 제공하고 있다. 본 연구의 목적은 빅데이터의 다양한 응용사례들을 BI&A 응용분야의 기준과 U-City 서비스 유형에 따라 분류하고 데이터의 특성을 분석함으로써 향후 다양한 분야에서의 빅데이터의 활용 및 발전방안 모색을 위한 시사점을 제시하는 것이다. 국내외 빅데이터로 소개된 사례를 조사하고 중복, 빅데이터와 무관한 사례를 제외한 58개 사례를 정리하였다. 관련연구의 문헌고찰을 통하여 BI&A의 5대 분류기준과 유비쿼터스도시건설등에관한법률 시행령 상의 10대 서비스 분류체계를 조합한 5x10 매트릭스 형태의 분류체계를 를 고안하였고 본 분류체계에 따라 데이터의 구조적?비구조적, 내부?외부 데이터의 특성을 분석하였다.",
		"KEYWORD": null
	},
	{
		"ID": 10,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "개인정보보호와 빅데이터 산업의 균형발전을 위한 법정책적 개선방안 연구 =(A)study on legal and policy improvements personal information protection and big data industry for the balanced development ",
		"AUTHOR": "김선남",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:정준현 참고문헌 : p.75-80",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "IT 기술의 발전과 스마트기기의 보급은 우리가 생활하는 환경을 편리하게 변화시켰으며, 특히 생활 속에 일반화된 스마트폰, 테블릿PC 등을 활용하여 다양한 데이터들을 생성하였다. 또한 데이터들의 누적 데이터 수는 기하급수적으로 매년 증가하였으며, 기업들은 이러한 데이터들을 활용하여 새로운 가치를 창출하기 시작하였다. 그러나 빅데이터의 활용은 국민들에게 수요에 맞는 서비스를 제공하면서 삶의 질을 향상시켰지만, 반대로 빅데이터를 사용함에 있어 개인의 정보를 사용하기 때문에 개개인의 사적 영역을 침해하는 문제가 발생하였다. 이에 미래창조과학부와 방송통신위원회는 2013년 12월 18일에 ‘빅데이터 개인정보보호 가이드라인(안)’을 제시하여 개인정보를 보호함과 동시에 빅데이터 산업의 진흥을 함께 발전시키고자 하였다. 하지만 12조항으로 구성된 초기‘가이드라인(안)’에서는 공개된 개인정보 또는 이용내역정보를 수집, 조합, 분석, 처리 및 관리 중 정보주체의 ‘개인정보 자기결정권’을 무력화 시키거나 심각한 프라이버시 침해를 야기할 수 있는 내용들이 포함되어 있어 시민단체들의 강력한 반발이 있었다. 이후 추가적인 수정을 통해 ‘빅데이터 개인정보보호 가이드라인’이 시행되었지만 실제 가이드라인을 적용함에 있어 보호대상인 개인정보 정의가 불명확하며, 현실적이지 못한 사전동의(Opt-in) 원칙은 빅데이터 활성화 방안에 큰 걸림돌이 되었다. 또한 최종 수정된 빅데이터 가이드라인에서 가장 핵심적인‘비식별화’의 경우 정의가 모호하게 표현되어 있어 활성화 방안에 적용하기에는 어려운 상황이다. 이러한 문제점을 보완하기 위하여 다음과 같은 방안을 제시하였다. 우선 첫 번째로는 개인정보의 분류기준을 명확하게 정의하고자 하였다. 현재 「개인정보보호법」제2조 정의규정의 경우, 다른 정보와 쉽게 결합하여 알아볼 수 있는 정보는 개인정보라고 포괄적으로 보고 있어 쉽게 정보를 사용하기 힘든 구조이다. 이러한 문제점을 개선하기 위하여 개인정보 분류기준표를 작성하였으며, 개인정보 등급을 4단계로 구분하고 민감도 지수를 상, 중, 하 단계로 구분하였다. 각 단계별로 정리된 내용을 통해 사용자들이 어느 단계까지 사용할 수 있는지 쉽게 파악할 수 있도록 정리하였다. 두 번째로는 사전동의(Opt-in)에서 유연하게 대응할 수 있는 사후동의(Opt-out) 원칙을 도입하고자 하였다. 다른 국가들과 비교하여 빠르게 빅데이터 시장을 선점한 미국의 사례를 들었으며, 활용 절차에서 안전하고 정당할 경우 사전동의(Opt-in)와 사후동의(Opt-out)을 복합적으로 사용하여 수집, 이용, 공개를 완화하고자 하였다. 마지막으로 모호하게 표현된 ‘비식별화’의 경우 수집, 저장, 분석, 이용·제공, 파기단계 총 5단계로 분류하였으며, 각 단계별로 기술적·절차적 사항을 제시하였다. 또한 빅데이터 개인정보보호 가이드라인의 모호성을 해소하기 위하여 기존 일반법과 개별법들과의 연계된 합리적인 처리 프로세스를 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 11,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "자원기반관점에서 빅데이터 사용의도에 영향을 미치는 요인에 관한 연구 =A study on the factors that influence the intention to use big data from the perspective of the resource based theory ",
		"AUTHOR": "윤수영",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:오재인 참고문헌 : p.89-103",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "빅데이터가 기업에서 지속적으로 중요한 이슈가 되는 것은 이미 보유하고 있는 방대한 양의 데이터를 누가 먼저 가치있게 분석하느냐에 따라 향후 기업의 성패를 가늠할 수 있는 상황에 직면해 있기 때문이다. 최근 많은 기업들은 빅데이터 분석을 통한 새로운 통찰력을 확보하고 있다. 빅데이터가 전세계적인 트랜드로 부각될 시점부터, 대기업, 정부부처 그리고 공공기관 중심으로 빅데이터 활용이 활성화되고 있으며, 기업에서는 신제품 또는 서비스 개발을 위한 빅데이터 활용에 많은 관심을 기울이고 있는 추세이다. 빅데이터 기술과 관련한 연구는 기술동향, 사례연구 그리고 아키텍쳐 연구 등이 활성화 되고 있으나, 빅데이터를 기업이 도입하여 성과를 창출하기 위한 주요한 요인들을 분석한 연구는 아직 미비한 실정이다. 또한, 빅데이터 관련 연구는 지속적으로 이루어지고 있으나 기업이 실질적으로 빅데이터를 활용함에 있어 성과를 창출할 수 있는 기업의 주요 자원 및 역량에 대한 연구는 미비한 실정이다. 본 연구의 목적은 자원기반관점 이론을 활용하여 빅데이터 사용을 위한 기업의 핵심자원 및 역량을 도출하여, 빅데이터 사용의도에 어떠한 영향을 미치는지 분석하는 것이다. 본 연구는 빅데이터 사용의도에 영향을 주는 요인들을 도출하기 위해 선행연구들을 고찰하여 연구모형을 개발하였다. SPSS 20을 사용하여 각 변수 별 기술통계량 조사와 탐색적 요인분석을 실시하였고, SmartPLS 3.0을 사용하여 확인적 요인분석, 가설검정 그리고 매개효과 분석을 실시하였다. 본 연구모형의 적합도는 구조방정식모형을 사용하여 검정하여 적합한 것으로 나타났다. 가설 검정 결과 기술적자원에서는 보안성만 매개변수에 긍정적인 영향을 미쳤으며, 인적자원에서는 IT스킬은 모두 기각되었고, 지식공유는 지식역량에만 유의한 영향을 미쳤으며, 과업기술적합성은 매개변수 모두 긍정적인 영향을 미치는 것으로 나타났다. 조직자원은 교육 및 훈련은 지식역량에만 긍정적인 영향을 미쳤으며, 데이터 의사결정 문화는 지식역량, 데이터활용성 모두 긍정적인 영향을 미치는 것으로 나타났다. 본 연구는 자원기반관점 이론을 이용하여, 빅데이터 사용의도에 대해 분석하였다. 또한, 기업이 관심을 가지고 있는 빅데이터의 실질적인 활용을 위한 기업의 주요 자원 및 역량의 중요성을 업계에 전파하고, 관련 연구의 중요성을 학계에 제시하였다는 점에서 그 의미가 있다고 할 수 있을 것이다. 주제어: 빅데이터, 사용의도, 자원기반관점 이론, 데이터활용성, 지식역량",
		"KEYWORD": null
	},
	{
		"ID": 12,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "빅데이터 활용과 개인정보보호체계의 재구축을 위한 헌법적 고찰 =A constitutional study on the use of big data and reconstruction of personal information protection system ",
		"AUTHOR": "김나루",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이욱한 참고문헌: p. 310-342",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "빅데이터는 다양하고 방대한 양의 데이터뿐만 아니라 그 데이터의 가치 있는 활용을 위한 분석 기술 및 관련된 모든 과정을 의미하며, 국가의 경쟁력을 좌우하는 제4차 산업혁명의 핵심요소이다. 이러한 빅데이터를 활용함에 있어 개인정보는 빅데이터의 주요자원이다. 그런데 개인정보의 이용은 개인정보의 보호를 경시한다는 인식과 동일시되어, 개인정보의 이용을 토대로 하는 빅데이터 활용을 부정적으로 보는 경향이 강하다. 그러나 빅데이터는 국가 시스템 전반을 향상시키고, 기업의 효율적 사업 운영을 가능하게 하여 사회·경제적 이익을 창출하는 동시에 개인정보 및 사생활의 침해라는 위험을 야기하는 양면성을 가지고 있다. 그렇기 때문에 이익은 극대화하고 위험은 최소화하는 노력을 병행하여야 빅데이터 활용이 효율적으로 이루어질 수 있다. 그러므로 이를 위해서는 빅데이터의 활용기반을 구축하는 동시에 더욱 심각해지는 개인정보 및 사생활 침해에 대응하는 개인정보보호 체계를 갖추어야 한다. 빅데이터 활용과 개인정보 보호는 모두 헌법에 근거를 두고 있으며, 그로 인한 기본권의 보장과 제한, 기본권 간의 충돌, 기본권과 헌법적 가치와의 충돌 문제는 조화롭게 해결되어야 한다. 이를 위해서는 개인정보보호 법제와 그 문제점을 고찰하는 것은 필수적이다. 우리나라 개인정보보호 법제는 빅데이터를 예상하고 확립된 것이 아니기 때문에 빅데이터 활용과 그로 인하여 더욱 심각해지는 개인정보 및 사생활 침해에 대하여 적절히 대응하지 못하고 있다. 본 논문에서는 빅데이터와 현행 개인정보보호 법제가 상충하는 다양한 측면에 대한 논의를 구체적으로 하고, 이를 해결하기 위한 대안을 모색하고자 하였다. 특히 개인정보의 개념, 목적명확성 및 정보수집최소화 원칙, 정보주체의 동의 방식, 익명화 또는 비식별화, 정보주체의 권리 측면에서 이들의 문제점을 살펴보고 그에 대한 개선방안을 고찰하였다. 개인정보보호법에는 개인정보를 ‘살아있는 개인에 관한 정보로서 성명, 주민등록번호 및 영상 등을 통하여 개인을 알아볼 수 있는 정보(개인식별정보)’와 ‘해당 정보만으로는 특정 개인을 알아볼 수 없더라도 다른 정보와 쉽게 결합하여 알아볼 수 있는 정보(개인식별가능정보)’로 정의하고 있다. 후자에 해당되는 개인정보는 빅데이터와의 관련성이 매우 크다. 왜냐하면 빅데이터는 다양한 정보 간의 결합을 기본으로 하고 있고, 이를 통하여 개인을 식별할 수 있게 되는 경우가 많기 때문이다. 그런데 개인식별가능정보에 해당하는 개인정보의 정의는 포괄적이고 모호하다. 그래서 빅데이터상에서 이용되는 정보의 많은 부분이 개인정보에 해당되어 빅데이터 활용에 상당한 제약이 따를 수 있다. 따라서 다른 정보와의 결합용이성 및 그로 인한 식별가능성은 제3자를 중심으로 판단하는 것이 아니라 개인정보처리자를 중심으로 판단하고, 이를 법률에 규정하여 해석의 모호함을 없애야 할 것이다. 또한 빅데이터상에서 개인식별가능정보와 비식별정보를 구분하는 데에 있어서 ‘쉽게 결합하여’의 의미가 이들의 경계를 확립하는 데에 중요한 기능을 하므로 그 의미가 구체화되어야 한다.",
		"KEYWORD": null
	},
	{
		"ID": 13,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "개혁확산관점에서 본 출판업계의 빅데이터 인식과 도입방안 연구 ",
		"AUTHOR": "안건태",
		"REGION": "서울",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수:송종길 참고문헌 : p.61-67",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "본 연구는 출판 산업의 빅데이터 도입 방안에 대해 개혁확산이론을 기준으로 혁신특성요인과 환경요인이 빅데이터 도입에 미치는 영향관계에 대한 문헌적 고찰 및 실증조사를 통해 국내 출판 산업의 빅데이터 도입 방안을 도모하는데 그 목적을 두고 있다. 연구 대상은 국내 출판 산업의 종사하고 있는 종사자들을 상대로 연구를 실시하였고, 시간적 범위는 2015년을 분석의 기준년도로 설정하였다. 설문지는 자기기입법으로 응답케 하는 설문지법을 사용하고, 회수된 설문지는 PC SPSS를 이용하여 분석하였다. 표본의 일반적인 특성을 파악하기 위하여 빈도분석을 실시하였고, 측정도구에 대한 신뢰도 및 타당성을 파악하기 위해 신뢰도분석과 타당성 검증을 실시하였다. 각각의 유형에 따른 세부항목들을 영역별로 분류하기 위하여 요인분석을 실시하였고, 각 요인들 간의 상관관계를 파악하기 위하여 상관관계 분석을 실시하였다. 분석결과, 첫째, 혁신특성요인 중 상대적이점이 빅데이터 도입에 가장 큰 영향을 미치는 것으로 나타났다. 출판 산업 종사자들은 빅데이터를 사용한 마케팅은 기존의 마케팅보다 활용하기 좋다고 생각하고 있었다. 또한 빅데이터를 사용한 마케팅의 효과에 대해서도 긍정적으로 바라보고 있었고, 출판 관계자들에게 평가가 좋은 마케팅기술로 나타났다. 둘째, 혁신특성요인 복잡성이 높을수록 사용하기에 어려운 부분이 높다고 판단할 수 있는데 빅데이터 기술에 대한 복잡함을 이야기하고 있었다. 상대적 이점을 통해 사용하고 싶은 마음은 있으나 빅데이터를 능숙하게 다루기 위해서는 많은 노력이 필요하다는 점을 볼 수 있다. 셋째, 적합성이 낮은 결과를 나타냈으므로 출판 산업에서 빅데이터 기술이 에 부적합하다는 것을 보여준다. 빅데이터 도입을 고려하고 있는 출판 기업은 빅 데이터 도입으로 얻을 수 있는 이점을 파악한 뒤 이전 마케팅 전략보다 투자 이상의 미래를 보고 진행을 해야 할 것이다. 또한 출판 산업 내부적인 환경에 대한 측면을 검토하고 도입해야 한다. 출판 산업에 빅데이터가 적합한지에 대해 살펴본 후 빅데이터 시스템 구축 시 출판시장에 맞는 데이터 수집을 반영하는 것이 필요하다. 본 연구는 출판 산업 발전을 위해 빅데이터 도입의도라는 실증적인 연구를 통해 출판 산업의 새로운 마케팅연구를 위한 기초자료로 제공했다는 점에 의의가 있다.",
		"KEYWORD": "개혁확산이론,빅데이터,출판"
	},
	{
		"ID": 14,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "빅데이터의 지식재산권 문제에 관한 연구 =Study on intellectual property issues of big data ",
		"AUTHOR": "이이삭",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 孫京漢 참고문헌: p. 161-170",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "디지털 생활 일상화에 따른 데이터 증가, 저장 및 관리 비용의 감소와 함께 데이터 처리 기술이 발전하면서 빅데이터 시대를 맞이하였다. 이제는 수많은 데이터 속의 패턴과 현상을 분석하여 미래를 예측하는 것이 가능해졌다. 빅데이터 시대는 데이터가 곧 경쟁력이다. 전 세계가 빅데이터 시대를 선도하기 위해 국가적으로, 기업적으로 다양한 노력을 하고 있다. 우리나라가 빅데이터 시대를 선도하기 위해서는 빅데이터와 관련된 법적 문제를 살펴보고, 빅데이터 활성화를 위한 법제도적 기반을 마련하는 것이 중요하다. 그러나 지금까지 법적 논의가 포괄적이고 깊이 있게 진행되진 않았다. 논의가 어느 정도 진행되어 가이드라인이나 법 제정과 같은 결과를 가져온 것은 개인정보와 공공데이터에 대한 것뿐이다. 빅데이터는 소재가 되는 데이터와 기술이 지식재산과 관련되어 있기 때문에, 지식재산권 문제에 대한 법적 논의와 검토가 중요하다. 이에 관하여 선행 연구가 없는 것은 아니나, 개인정보나 공공데이터에 대한 논의와 비교해본다면 많이 부족한 실정이다. 이에 본 연구는 빅데이터와 관련된 지식재산권 문제를 전반적으로 살펴보며 빅데이터 활성화와 지식재산권법적 기반 마련에 기여하고자 한다. 본 연구는 빅데이터의 지식재산권 문제를 살펴보기에 앞서 빅데이터의 기존 정의와 그 문제점을 살펴보고, 빅데이터를 재정의한다. 아직까지 빅데이터를 바라보는 시각차로 인하여 통일된 정의가 없다. 빅데이터가 무엇인지 정확히 정의내리지 못했기에 그에 대한 논의도 제한적일 수밖에 없었다고 생각된다. 선행 연구를 살펴보면 빅데이터를 단순히 데이터의 크기로 파악하거나, 기술·분석적으로 바라보는 것이 대부분이었다. 하지만 빅데이터의 본질을 고려할 때, 데이터를 이용하여 의사결정에 유용한 결과를 제공하는 전체적인 과정으로 빅데이터를 정의하는 것이 바람직하다고 생각된다. 본 연구에서는 이와 같은 정의에 맞추어 빅데이터의 과정을 세분화해보고, 빅데이터 활용에서 발생하는 지식재산권 침해문제, 빅데이터를 이용한 지식재산권 보호 가능성, 빅데이터 활용에 대한 지식재산권으로서의 보호 가능성을 살펴보고자 한다.",
		"KEYWORD": "빅데이터,빅데이터 관련 법적 문제,빅데이터 활용,지식재산권 보호,지식재산권 침해"
	},
	{
		"ID": 15,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "빅데이터 환경에서 개인정보 보호에 관한 헌법적 연구 ",
		"AUTHOR": "정한신",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 김배원 참고문헌: p. 259-272",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "Big data is now part of every sector and function of the global economy. Big Data, which arises as new growth power, contributes to promote public interest or to reinforce competitive power of industry. Big Data provides positive aspects such as efficiency, convenience and new utility creation. However Big Data brings about various new problem such as infringement on personal information. The misuse of personal information(unrestricted collection, combination, profiling etc.) is at risk for development into the big brother. Big Data is highly likely to infringe on privacy and personal rights. The right to informational self-determination is the individual right to control the circulation of personal information. This right and personal information protection laws are personal information protection system. But this system is not fully functional in the big data environment. So there have been international efforts to solve this problem. The EU’s Proposed General Data Protection Regulation(2012), the Consumer Privacy Bill of Rights of US, ICDPPC’s profiling principles and Japan’s Personal Information Protection Act are worthy of notice. This thesis suggests constitutional and legislative ideas to protect personal information in the big data environment. First, the `responsibilities` of government and personal information manager should be emphasized. Second, the re-organization of the concepts of `personal information` and `the right to informational self-determination` is necessary. Also new rights to protect personal information should be adopted. So `re-constitution of right to consent` and adoption of `right to be forgotten`, `right to data portability`, `right to reject profiling` are necessary. Third, Korean Personal Information Protection Act(PIPA) must be reformed or revised to introduce Do-Not-Track, Privacy by Design, Privacy by Default, Differential Privacy and so on. And PIPA must be revised to reinforce the functions of Personal Information Protection Committee and to adopt Personal Information Impact Assessment in private sector.",
		"KEYWORD": "Big Data,개인정보 보호,빅데이터"
	},
	{
		"ID": 16,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한성대학교 대학원",
		"TITLE": "글로벌 온라인 비즈니스를 위한 빅데이터 활용에 대한 연구 :(A)study of using big data for global online business :전자 무역을 중심으로 =focusing on e-trade ",
		"AUTHOR": "이철웅",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조세홍",
		"STORE_LOCATION": "한성대학교 도서관",
		"ABSTRACT": "정보기술과 하드웨어 기기의 발달은 정보화 사회를 가속화 시켰으며 이에 따라 IT패러다임의 변화를 가져오게 되었다. PC시대, 인터넷시대, 모바일시대, 스마트시대로 이어지는 패러다임의 변화는 데이터의 생성과 확산 그리고 사용을 급격하게 증가시켰다. 데이터가 기하급수적으로 증가하되 되면서 기존의 데이터의 개념을 넘어선 방대한 양의 대이터로 대표되는 데이터를 빅데이터라 부르기 시작하였으며 이 데이터를 가치 있게 활용할 수 있는 분석 방법과 기술들이 많은 관심을 받고 있다. 언제, 어느 곳에서든 사람이 존재하는 곳에서는 데이터가 생성되며 공유되고 확산되고 있다. 이러한 데이터들 중에서 가치 있는 데이터를 수집하여 유용하게 사용할 수 있을 것이라는 기대를 가지고 많은 기업, 국가, 기관에서 필요하고 중요한 데이터를 자산화 하기 위하여 많은 노력을 하고 있다. 하지만 데이터의 텍스트 및 문서, 통화기록, 대규모의 전자상거래 목록 등의 수많은 데이터 중에서 가치 있는 데이터는 소수에 불과하다. 모든 기업이 보유한 빅데이터를 누가 먼저 그 가치를 추출해 내느냐에 따라 기업의 성패를 가늠할 상황에 직면해 있는 지금 대용량 데이터를 분석하여 의미 있는 데이터로 발전하는 기술이 필요하다. 따라서, 빅데이터 분석기술과 적용모델의 연구를 통하여 빅데이터를 효과적으로 활용할 필요성이 있다. 이에 본 논문에서는 다양한 산업 분야 중에서 데이터의 신뢰도와 중요성의 비중이 높고 효과적인 적용이 용이한 전자무역 분야를 선정하여 빅데이터를 효과적으로 전자무역에 적용하기 위하여 빅데이터의 개념 및 특징과 분석 기술 및 현황 조사, 빅데이터의 활용모델 등을 조사한다. 또한, 전자무역 환경에 대한 현황 조사 및 분석을 통하여 빅데이터를 환경과 조건에 맞게 효과적으로 적용할 수 있도록 제안하였으며 빅데이터의 개념과 구성요소, 특징을 파악하고 빅데이터를 분석하기 위한 데이터 마이닝 등의 기술 현황, 기술적용사례 그리고 빅데이터의 적용사례 등을 조사하였다. 본 논문은 전자무역의 배경, 개념 그리고 특징을 파악하고 전자무역 시스템을 분석하여 빅데이터 분석모델과의 결합 가능성에 대하여 연구하는데 목적이 있으며 효율적인 활용방안을 제시하였으며 이러한 자료들을 바탕으로 빅데이터를 활용한 모든 프로세스가 단일화 된 전자무역 시스템 모델을 구축할 수 있었다.",
		"KEYWORD": "데이터마이닝,빅데이터,온라인비즈니스,전자무역,전자상거래"
	},
	{
		"ID": 17,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 예술대학원",
		"TITLE": "콘텐츠산업분야 빅데이터 서비스플랫폼 구축모델 =(A)study on public big data service platform model for content industry ",
		"AUTHOR": "김선영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 권병웅 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 연구주제는 콘텐츠산업분야 빅데이터의 공공재적 가치창출과 빅데이터 활용 촉진을 위해서 다룬 ‘빅데이터 상용서비스 플랫폼 구축모델’이다. 연구방법은 공공부문이 빅데이터와 콘텐츠산업의 접목을 위해 어떤 역할을 해야 하는지에 관한 접근방법론으로 복잡계이론(Complex Theory)의 행위자기반모형을 통해 최소행위단위와 양질전화의 집합적 단위의 관계를 살폈다. 즉, 행위자기반모형의 최소행위단위가 복잡계의 국지상호작용(Local Interactions)을 통해 집합체적인 성질이 일어남에 착안하여 논지를 전개하였다. 연구과정은 2010년부터 현재까지 빅데이터의 개념과 기능, 학술적 이론과 사회적 쟁점, 빅데이터 기술유형과 적용사례, 국내외 연구동향을 살펴보았고, 빅데이터 서비스 적용영역인 국내외를 망라하되, 공공부문에 집중하여 고찰하였다. 기존 빅데이터의 주요 개념과 속성은 거대한 크기, 다양한 형태, 빠른 생성·유통·이용 속도 등 3V(Volume, Variety, Velocity)이자, 데이터 처리의 복잡성(Complexity), 가치(Value), 정확성(Veracity)을 갖춘 3V1C 혹은 4V로 평가된다. 즉, 기존 빅데이터는 기술적, 가치론적으로 그 개념이 규정되어 왔다. 그러나 본고에서는 빅데이터가 경제적인 측면 뿐 아니라 정치·사회·문화 등 전방위적 인사이트(insight)를 제공한다는 측면에서 빅데이터를 현 사회발전단계의 표상(表象)이자 메타포(metaphor)로 인지하고 그 구축모델을 모색하였다. 연구결과, 공공부문 빅데이터 상용서비스 구축모델로서 콘텐츠빅데이터마트(Content Bigdata Mart, CBM)와 빅데이터웨어하우스(Content Big data Warehouse, CBW)를 제시하였다. 본고에서 제시한 콘텐츠빅데이터마트는 빅데이터의 수요공급시스템을 구축키 위한 하위 콘텐츠산업별 빅데이터 플랫폼이자 인프라이다. 이 플랫폼은 지역단위 공공부문이 영세 콘텐츠기업들에게 분석서비스 등 빅데이터의 인사이트를 무료 또는 저렴한 비용으로 제공함을 전제한다. 또한 콘텐츠빅데이터웨어하우스는 하위 콘텐츠산업간 빅데이터의 융합이 필요할 때 기능하는 매쉬업(mash-up) 시스템이다. 이는 지방정부가 운영하는 CBM과 달리 CBW는 중앙정부가 주도하는 것이 적절함을 전제한다. 구축모델의 실현방안으로 각 광역지자체는 콘텐츠 하위산업별 콘텐츠빅데이터마트를 각 지역에 구축하고, 중앙정부는 각 지역의 콘텐츠부문의 융합과 해외, 대기업, 국가 차원의 공공데이터를 공급하게 된다. 즉, 중앙과 지방의 역할정립을 통해 통합관리 플랫폼 기능을 담당해야 하는 모델이다. 콘텐츠빅데이터마트와 빅데이터웨어하우스는 클라우드 소싱을 통해 사회적 집단지성을 창출하는 빅데이터 플랫폼으로서 기능하게 된다. 이 플랫폼은 콘텐츠산업의 새로운 지원체계 마련과 건전한 지식정보 생태계 구축을 위해 기여할 것이다. 현 단계에서는 빅데이터의 콘텐츠산업 적용모델 개발과 구축이 시급한 공공의 선결과제이다. 키워드: 빅데이터, 콘텐츠산업, 콘텐츠빅데이터마트, 빅데이터 플랫폼, 공공데이터",
		"KEYWORD": null
	},
	{
		"ID": 18,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "도시계획 수립시 시민 맞춤형 빅데이터 활용에 관한 연구 =(A)study on the utilization big data for the citizen-oriented service in the urban planning ",
		"AUTHOR": "김태형",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김도년 참고문헌 : p. 141-160",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "도시계획에 있어서 시민은 언제나 가장 먼저 고려되어야 할 존재였다. 도시에서부터 국가에 이르는 도시기본계획은 지방 정부의 정책에서부터 가깝게는 시민 개개인의 생활양식에 이르기까지 광범위한 영향력을 행사해왔다. 과거에는 도시계획을 수립하는 과정에서 일반시민은 의견도 제시하거나 의사 결정 과정에 영향을 줄 수 없는 수동적인 의미의 소비자로만 존재하였다. 그러나 최근의 도시계획은 도시 사회 패러다임의 변화로 말미암아 공급자 중심의 계획에서 벗어나 수요자 중심의 참여·합의·결정·집행을 중시하는 계획으로 빠르게 전환되고 있다. 정보통신기술의 발달로 시민의 의사를 묻고 그들의 요구사항을 반영하는 창구가 다변화됨에 따라, 시민 지향적 행정의 변화도 자연스럽게 모색되었다. 시민을 ‘고객’으로 생각하여 행정 대상이 되는 시민(고객)의 만족을 극대화하기 위한 형태로 서비스들이 변화되고 있는 현실에서, 시민에 대한 전반적인 재고도 절실해졌다. 시민에 대한 행정적 태도 변화와 함께 중요한 것은 데이터에 대한 기술 및 사회환경의 변화이다. 유래없을 정도로 데이터가 폭발적으로 유통되는 현대사회에서 데이터를 어떻게 다루고 처리하느냐는 모두의 관심사이자 현안이다. 본 연구에서는 데이터를 단순히 자료에만 머무르게 하는 것이 아니라 시민의 욕구를 반영한 자료로서 시민을 유형화하고 그를 통해 맞춤형 행정 서비스로 나아가야 하는 것이 그 핵심이며 , 데이터를 기반으로 객관적이고 과학적인 접근방식을 통해 도시 운영 및 사회 현안에 대응하여 더 나은 미래사회로의 방향을 모색한다는 관점에서 빅데이터 분석 활용의 가능성을 논의하였다. 연구 결과, 빅데이터의 활용은 의사결정과정에서 수요자의 역할을 크게 증대시키며 객관화된 데이터의 활용은 의사결정과정의 초기 단계인 대안의 탐색에 있어 보다 다양한 원천이 활용할 수 있다는 점을 모색하였고, 도시 환경에서 발생하는 문제를 해결하기 위하여 다양한 분야의 데이터를 활용·분석함으로써 가치 있는 정보로 추출하고 생성된 지식을 바탕으로 능동적인 대응과 미래 변화를 예측하기 위한 방법론으로서 데이터의 활용 가능성을 제시하였다. 향후 정책의사결정자 및 관련 산업 종사자들에게 빅데이터는 도시계획수립에서 보다 개선된 결과를 얻고 생산성을 높이기 위한 수단으로, 시민의 욕구를 보다 적극적으로 파악함으로써 객관적 혹은 보완적 측면의 효율적인 역할을 기대해 본다.",
		"KEYWORD": "도시계획수립,빅데이터(Big Data),시민 맞춤형,유형화,의사결정"
	},
	{
		"ID": 19,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "업무-기술적합에 따른 빅데이터 분석기술이 기대성과에 미치는 영향 :혁신확산이론을 중심으로 ",
		"AUTHOR": "김이환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박주석 경희대학교 논문은 저작권에 의해 보호받습니다. 참고문헌: p. 129-160",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "기업들은 IT 기술의 보급으로 새로운 비즈니스를 구축할 수 있는 기회는 물론이며, 시장환경의 변화에 적극적인 대응을 위해서 새로운 IT 기술에 대한 수용을 적극적으로 실시하고 있다. 포춘(Fortune) 500대 기업의 90%가 빠른 시일 내에 빅데이터(Big Data) 관련 프로젝트를 추진할 계획이며, 전 세계적으로 주요 기업의 25%가 빅데이터 관련 투자를 진행을 완료했다고 밝히고 있다. 빅데이터의 사용과 활용 방법을 통하여 의사결정의 적시성과 효과성을 높이고 나아가 의사결정을 위한 기반을 마련할 수 있으며, 내부 역량 향상, 업무 자동화 및 중복 데이터 제거, 프로세스의 안정화 등 생산성 향상을 기대할 수 있다고 한다. 이에 본 연구에서는 아래와 같은 연구의 목적을 제시하고, 이를 검증해 보고자 한다. 이에 본 연구에서는 실증분석을 통해 빅데이터 인식 연구, 기술수용연구, 업무-기술적합연구 그리고 개인의 혁신 성향에 따라 빅데이터 수용에 대한 특성 측정 연구를 통해 다음과 같은 연구 목적을 달성하고 자 한다. 첫째, 혁신확산이론(Innovation Diffusion Theory)에 대한 선행연구 고찰을 통해 빅데이터 분석기술의 혁신확산 과정을 측정할 수 있는 연구모형을 도출 하고자 한다. 둘째, 혁신확산이론에서의 수용자의 혁신성향에 따른 빅데이터 분석기술 인식요인이 개인의 기대성과에 미치는 영향에 대해 알아보고 자 한다. 셋째, 빅데이터 분석기술의 인식요인이 업무-기술 적합성의 정도에 따라서 기대성과에 미치는 영향에 대해 알아보고자 한다. 넷째, 빅데이터 분석기술의 인식요인을 기술수용연구(Technology Acceptance Research), 업무-기술 적합성 연구(Task-Technology Fit Research), 혁신확산 연구(Innovation Diffusion Research)를 통해 기술 수용에 대한 연구모형을 도출해 보고자 한다. 본 연구를 통하여 국내 기업의 빅데이터 분석기술에 대한 인식요인 도출 및 검증과 향후 빅데이터 분석기술을 도입하고자 하는 기업들에게 기여할 수 있는 효과적인 활용방안을 제시하고 자 한다. 기업 경영을 효율적으로 지원하기 위해서 많은 기업들이 다양한 유형의 IT기술을 도입·운영하고 있다. 최근에는 기업을 둘러싼 환경 변화에 즉각적인 대응을 위해서 빅데이터 분석기술을 수용하고 있거나 수용하기 위하여 IT에 투자를 많이 하고 있다. 빅데이터에 대한 사회적 관심에 비해 이를 제대로 활용하고 성과를 본 기업들에 대한 사례는 많이 알려져 있지 않다. 하지만, 무분별한 빅데이터 분석기술은 오히려 해가 될 수 있다. 이에, 빅데이터 분석기술의 도입을 위하여 사전에 업무에 빅데이터 분석기술의 도입이 적합한지와 기술 사용자의 혁신의지 고취 통하여 기업에 적합한 기술의 수용 및 활용 여부가 필요 할 것으로 판단된다. 빅데이터는 기업에 있어서 새로운 정보시스템의 도입이 아니다. 기업이 기존에 보유하고 있는 데이터와 세상에 존재하고 있는 다양하고 방대한 데이터 들 속에서 기업에게 필요한 진정한 가치를 찾는 것이며, 빅데이터를 분석할 수 있는 능력을 갖춘 기업이 급변하는 경영환경 속에서 경쟁우위를 갖게 될 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 20,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서강대학교 언론대학원",
		"TITLE": "빅 데이터 분석 시스템의 수용성 연구 :광고 전문가를 대상으로 ",
		"AUTHOR": "유정근",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김충현 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "The advent of big data in marketing and advertising has made its industry to face a challenge in adoption of the Big Data Analytics System. The industry recognizes its usefulness and powerful analytic ability, however, the users of the system still in the middle of confusion in adoption in several reasons. The current study explores the possibility of adoption of the analytics system by advertising experts by a survey of 189 employees. The findings from the survey includes that the benefits from the analytics system of ‘more accurate understanding of consumer’ was recognized all employees regardless of its ranks and positions. The benefits of macro-perspectives from the system were well recognized by high-ranked employees while more-detailed benefits from the system were adopted by middle and low-ranked employees. As expected, employees who are involved with planning and whose task is related with big data analytics system are more likely to adopt the system. Furthermore, the current study demonstrates that the adoption of analytics system is primarily determined by the levels of knowledge of the employees in big data analytics system while the benefits and usefulness of the systems in his/her tasks are less deterministic. The implications for future research and management are explained and discussed along with its limitations.",
		"KEYWORD": null
	},
	{
		"ID": 21,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "행정서비스의 빅데이터 활용에 영향을 미치는 요인에 관한 연구 =(An)empirical study on the influencing factors for the utilization of big data in the administrative service ",
		"AUTHOR": "이병도",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "Big Data is one of many IT technical skills, which has been receiving the most attention in various fields, such as academia, government and industry. However, most organizations are promoting the hasty adoption without considering various relevant factors in order to follow the IT trend for Big data, or due to the difficulties in utilizing Big Data, such as lack of proper technical capabilities or of proper understanding of the concept. So, The purpose of this doctoral dissertation is to determine the overall factor to consider using of Big Data technology in administrative services and provide the parsimonious utilization model of Big Data for practitioners who have difficulties in Big Data technology. This doctoral dissertation is to provide the factors for utilization of Big Data in four criteria based on the TOE framework and Big Data 3V model: technology, organization, environment and data. In the experiment for this doctoral dissertation, the researchers conducted a sample survey to the experts involved in the Big Data projects in administrative services domain. The results show that the utilization of Big Data significantly depends on Big Data external strategy, Big Data volume, Big Data infrastructure technologies. The implications of this doctoral dissertation provide theoretical foundation for the study of Big Data, and are expected to contribute to the practical evaluation and improvement in Big Data projects for administrative services.",
		"KEYWORD": "빅데이터,행정서비스,활용요인"
	},
	{
		"ID": 22,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "한신대학교 대학원",
		"TITLE": "기업의 빅데이터 활용 유형별 적용 방안 및 효과 분석 =(A)case study on application methods and effects based on the type of big data at corporations ",
		"AUTHOR": "이재성",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 홍성찬",
		"STORE_LOCATION": "한신대학교 장공도서관,한신대학교 중앙도서관",
		"ABSTRACT": "지난 수년 간 스마트폰과 같은 스마트 기기의 빠른 확산과 함께 인터넷과 소셜네트워크서비스(SNS, Social network Service) 등 소셜 미디어가 급성장함에 따라 개인정보와 소비패턴, 위치정보 등이 포함된 가치 있는 데이터가 매 순간 엄청난 양으로 생성되고 있으며, 사물간통신(M2M, Machine to Machine)과 사물인터넷(IoT, Internet of Things) 등이 활성화되면서 IT 및 생산 인프라 자체도 다량의 데이터를 직접 생성하기 시작했다. 점점 복잡해지고 리스크가 난무하는 최근 사회적, 경제적 환경에서 실시간 빅데이터 처리를 가능하게 하는 대규모 데이터 수집/관리/처리/분석 기술의 발전은 정부와 기업이 시장에 보다 효과적으로 대응할 수 있는 통찰력과 가치를 제공해주기 시작했다. 실제로 구글, 페이스북, 아마존, 야후 등의 소셜 미디어나 인터넷 업체들이 빅데이터 기반의 소셜 분석 효과를 입증하면서 많은 기업이 빅데이터에 주목하고, 빅데이터 기반의 새로운 비즈니스 모델 발굴을 추진하면서 빅데이터 시장 성장이 본격화되고 있다. 그렇지만 현재 기업과 일반대중의 관심을 받고 있는 것은 소셜 미디어에서 생산되는 소셜 데이터를 중심으로 한 비정형 빅데이터다. 물론, 새롭게 생성되고 유통되는 방대한 양의 데이터 즉, 빅데이터의 상당수는 비정형 데이터로 전체 데이터 양의 약 80%에 달하고 있는 것은 사실이지만, 일반 기업의 경우 이러한 비정형 데이터 중심의 빅데이터 만으로는 실제적인 가치를 확인할 수 있는 활용 방안이 그리 크지 않은 상황이다. 또한, 지금까지 이루어진 빅데이터 관련 연구를 살펴보면, 주로 활용 가능성을 타진하는 단일 사례 연구나, 빅데이터를 저장, 처리 및 분석하는 특정 기술에 한정된 것이 대부분이고 데이터의 유형, 즉, 정형 및 비정형 데이터의 빅데이터로서 적용에 대한 사례와 그 차이, 빅데이터 특성에 따른 활용 효과 등에 대한 연구는 부족한 실정이다. 본 연구는 기업에서 활용할 수 있는 빅데이터의 대표적 유형인 정형 데이터와 비정형 데이터, 더 나아가 정형 및 비정형 데이터의 결합을 통한 적용 사례를 비교 고찰함으로써 데이터의 유형에 따른 적용 영역과 적용 효과의 차이를 연구하였다. 이를 위하여 대표적인 비정형 데이터라 할 수 있는 소셜 미디어의 데이터를 수집, 분석하여 마케팅에 활용하는 사례, 정형 데이터 중에서 빅데이터에 해당하는 결산 데이터를 활용하는 사례, 정형 및 비정형 데이터를 결합하여 활용한 대리점 이상 거래 감지에 대한 사례를 비교 연구 하였다. 이 사례들을 통해 단일 기업 내에서도 데이터의 원천 및 유형, 담당하는 업무의 형태, 적용 기술 등에 따라 빅데이터가 활용되는 양상이 달랐다. 이러한 양상에도 불구하고 기업이 원하는 가치와 인사이트를 제공해 줄 수 있음을 알게 되었다. 사례 연구로 이루어진 빅데이터 활용 예는 신문이나 잡지에서 가볍게 다루어지는 것 외에 학문적 접근으로 연구된 것이 거의 없고 특히 민간 기업의 활용 사례를 연구 대상으로 한 것은 더욱 찾아보기 어렵고, 또한 학문적 주제로서 초기 연구에서는 다수 샘플에 의한 실증적 연구보다는 다양한 사례 분석을 통한 함의 축적이 더욱 필요하며 중요하다는 점에서 본 연구의 의의가 있다. 이러한 본 연구의 결과들이 종합되어 향후 국내 기업의 각종 의사결정이 데이터와 분석에 의한 보다 스마트한 의사결정이 되고, 이러한 의사결정들을 바탕으로 국내 기업의 경쟁력이 높아져 글로벌 시장에서 외국 기업들과 당당하게 겨루는 초석이 되었으면 하는 바람이다.",
		"KEYWORD": "비정형 빅데이터,빅데이터,정형 빅데이터,하둡"
	},
	{
		"ID": 23,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숙명여자대학교 교육대학원",
		"TITLE": "스마트교육의 현황 및 빅데이터 기반 스마트교육의 활용방안 =(The)current status of smart education and the application prospects of big data based smart education ",
		"AUTHOR": "송윤정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이기용 참고문헌: p. 59-60",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "정보화 사회가 급속도로 가속화되고 스마트 기기 보급률이 크게 높아지면서 그에 따른 데이터의 양도 크게 증가하였다. 소셜 네트워크 서비스와 스마트 기기의 보급 증가로 인한 데이터의 기하급수적인 증가는 소위 빅데이터의 시대를 열었다. 빅데이터의 활용은 오늘날 사회 전반에 걸쳐 정보 운용의 핵심으로, 교육에서도 빅데이터를 활용한 스마트교육에 대한 요구가 급증하고 있다. 빅데이터를 활용한 스마트교육은 개인의 적성과 능력에 맞게 교육 콘텐츠를 선택하는 등 다양한 응용이 가능하다. 본 논문에서는 현재까지 알려진 다양한 빅데이터 관련 기술들을 살펴보고, 그로부터 빅데이터에 기반한 스마트교육의 활용방안을 제안한다. 교사와 다수 학생으로 구성된 수업에서 학생의 개별 수준에 맞추어 개별화된 학습을 하는 것은 어려운 일이지만, 빅데이터에 기반한 스마트교육을 활용하면 교사는 개별 학생의 학습수준과 학습성취도에 따라 개별화된 학습을 제공할 수 있고 그로 인해 교육의 성과를 크게 높일 수 있다. 본 논문에서는 빅데이터 기반 스마트교육의 활용방안으로 크게 다섯 가지를 제안하고, 각 방안에 활용될 수 있는 빅데이터 기술과 그의 기대효과를 제시한다. 첫째는 학생들의 학습 데이터에 기반한 학생 진로 상담이다. 학생들의 개별 학습 데이터, 학업성취 데이터, 형성평가 데이터 등을 수집하고 이로부터 개인별로 취약하거나 강한 과목 등을 파악하여 학생의 진로 선택에 도움이 되는 정보를 제공한다. 둘째는 학생의 온라인 학습효과 분석이다. 학생들의 온라인 학습 시스템 사용 이력과 성적 데이터를 분석하여 학생들의 개별적인 온라인 학습효과를 파악하고, 그를 바탕으로 바람직한 온라인 학습 방법을 제시한다. 셋째는 학생들의 성적변화 패턴분석에 따른 학습지도이다. 학생의 초·중·고 과목별, 학기별 성적을 분석하여 학생의 성적변화 패턴을 파악하고 그로부터 학생의 성적을 향상시킬 수 있는 학습방안을 제시한다. 넷째는 학생들의 학교 홈페이지 활용과 학교생활에 대한 영향분석이다. 학생들의 학교 홈페이지 또는 소셜 네트워크 서비스 사용에 관한 데이터를 수집하고, 그로부터 학생의 고민, 교우관계 등에 관한 정보를 추출하여 학생의 학교생활 관련 상담에 활용한다. 다섯째는 교사의 담당 학습 성적 향상을 위한 학급데이터 분석이다. 학급의 출결상황, 과제제출, 학생성적 등의 데이터를 분석하고 이를 성적이 높은 학급의 데이터 패턴과 비교함으로써 교사가 학급의 문제점을 파악하고 맞춤형 교육을 할 수 있도록 도와준다. 본 논문에서 제안한 빅데이터 기반의 스마트교육 활용방안을 통해 학생에게 데이터에 기반한 정확하고 개별적인 맞춤형 교육을 제공할 수 있으며, 이로 인해 학생들의 학업 성취도 및 교사의 교육 효과를 크게 높일 수 있으리라 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 24,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "혁신기술로서의 빅데이터 국내 기술수용 초기 특성 연구 ",
		"AUTHOR": "김정선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박영일 참고문헌: p. 121-139",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "Big Data is the topic in the ICT market both in the inside and outside of Korea. But it is hard to find research that systematically deals with Big Data technology acceptance. Presently, the market of Korean Big Data technology is in the initial stage, so it is absolutely needed to study technology acceptance. It is because in the initial market, the spread of new technology will exhibit very different aspects afterwards correspondingly to the characteristics of technology acceptance. The purpose and significance of this study are as follows: first of all, the researcher aims to suggest an integrated study model to examine Big Data technology acceptance. For this, the study took the technology acceptance model (TAM) as its central frame to utilize innovation diffusion theory and task-technology fit theory integratively and verified its appropriateness to connect the established variable with the TAM. And through this, it will be possible to provide positive data systematically with which we can understand the current status of the initial market of Big Data technology in Korea. There are materials about the actual status of inducing Big Data technology into companies according to the purpose of each research institute; however, there is no large-scale positive research about Big Data technology acceptance in Korean companies for academic purpose. Next, regulating variables applied at the application of the TAM were extended for the purpose of technology acceptance and as the areas of tasks for application. Through this, when applying the TAM for Big Data technology, the researcher applied dual perspectives from the aspects of ‘technology users’ and ‘technology utilizers’ according to the purpose of acceptance. With this viewpoint, the author attempted to understand difference in the paths of the study model regarding task areas related with technology acceptance. ",
		"KEYWORD": null
	},
	{
		"ID": 25,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인천대학교 정보기술대학원",
		"TITLE": "매트릭스 분석을 이용한 빅데이터 공백기술 확보 방안 :(A)study for finding an undeveloped technology using matrix map in big data :미국등록특허를 중심으로 =focusing on the U.S patent registration ",
		"AUTHOR": "배준현",
		"REGION": "인천",
		"PROFESSOR": "지도교수:최진탁",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "빅 데이터는 다각적으로 변화하는 시장 동향과 소비 경향에 따른 대규모의 정형, 비정형 데이터를 신속하게 분석하여 사용자에게 맞춤형 정보를 제공할 수 있으므로 종래에 없던 새로운 비즈니스 모델을 만들 수 있으며 미래 서비스 분야에서 공용 기반 기술로 활용이 가능하므로 그에 따른 경제적 성장과 일자리 창출에 거대한 파급효과가 기대되는 차세대 경제 성장동력 중 하나이다. 이와 같이 빅데이터가 산업과 경제에 큰 여파를 미칠 수 있는 기술로 인식되면서 세계의 선진국과 유수한 기업들이 관련 기술에 대한 연구가 활발하게 진행되고 있으나 관련 기술에 대한 개발 현황에 대해서는 막연하게 추측만 하고 있는 실정이다. 이를 위하여 현재까지 빅데이터 관련 기술의 분야별 기술개발의 추이와 발전현황을 파악하여 관련 기술의 중복 개발을 막는 한편, 향후 관련기술의 연구개발 시 인적, 물적 자원을 효과적으로 투자함으로서 국제적 경쟁력을 갖출 수 있도록 지원하는 R&D 방향의 제시가 절실한 시점이다. 따라서 빅데이터 관련 특허를 국가별, 주요출원인별, 연도별, 점유율 등으로 정량적인 분석을 수행함으로서 관련 기술의 분야별 개발 현황과 발전 상황을 파악하고 관련 특허의 IPC 매트릭스 맵을 통한 세부적인 공백기술을 도출하는 한편 공백기술에 따른 빅데이터 기술의 체계적인 R&D 방향을 지원할 수 있는 방안을 제시한다.",
		"KEYWORD": "공백기술,국제특허분류,매트릭스,빅데이터,특허동향"
	},
	{
		"ID": 26,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "IPA기법을 활용한 제조분야의 빅데이터 수용도 분석 =Acceptance analysis for big data in manufacturing using IPA :IT분야 제조A社 중심 ",
		"AUTHOR": "주혁",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김윤배 참고문헌 : p. 68-70",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "계측, 센서, 정보기술의 발달로 인하여 다양한 분야에서 다양하게 많은 데이터가 쏟아져 나오고 있다. 경영환경의 변화 속도가 빨라지고 복잡도가 높아질수록 미래를 예측하는 역량이 중요해지고 있으며 이는 경쟁자들과 차별화를 이루는 요소로 나타나고 있다. 특히 전자, 반도체,디스플레이 등 제조업의 발달과 IT기술이 발전으로 제조공정에서 생성되는 데이터의 양이 기하급수적으로 늘고 있다. 과거부터 공정관리(MES), 공급망 관리(SCM)를 통해 지속적으로 데이터를 확보하여 왔지만, 근래에 센서기술의 발달과 데이터분석의 성장, 사물인터넷과 기계의 융합으로 데이터가 급증하고 있다. 본 연구에서는 국내 전자부품 기업의 설비와 공정의 각 계층별 전문가를 대상으로 제조 분야에서 발생하는 설비와 공정의 센서, 영상데이터를 빅 데이터로 활용하기 위해 개선되어야 할 속성들에 대해 설문하였고, 이 데이터를 IPA기법을 활용하여 분석하여 직급별과 빅 데이터의 인지 유무별로 빅데이터에 대한 수용도를 분석하였다.",
		"KEYWORD": "빅데이터,생산 효율화,설비 데이터,센서,제조 공정,지능형 제조"
	},
	{
		"ID": 27,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "기업의 빅데이터 활용 수준 진단지표 개발 연구 =(A)study on the development of indicator for the level diagnosis of big data-utilizing companies ",
		"AUTHOR": "추동균",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한창희 권두 국문요지, 권말 Abstract 수록 부록 수록 참고문헌: p. 55-57",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 급속도로 발전한 IT기술과 스마트폰 보급에 따른 SNS의 활성화로 수많은 데이터가 생성되고 소비되며 축적되고 있는 상황이다. 때문에 종래에 없었던 엄청난 데이터를 수집, 분석하고 유의미한 정보를 확보하는 것이 중요하게 되었다. 그리고 이러한 데이터 활용에 대한 노력이 전 세계적인 트렌드로 형성되었고 이른바 ‘빅데이터(Big data)’ 라는 용어가 생겨나면서 새로운 비즈니스의 원천으로 각광받고 있다. 빅데이터는 분명 새로운 고객을 창출하고 비즈니스를 다각화 할 수 있는 기회를 제공해 줄 수 있기에, 여러 기업들이 빅데이터 활용을 하기 위한 투자와 노력을 하고 있다. 하지만 빅데이터는 최근에 생겨난 용어로 개념이 생소하고 추상적일 수 있어 기업의 활용에 어려운 부분이 있다. 때문에 빅데이터를 단순한 트렌드로 인식하여 도입하거나 활용 하는 것을 지양해야 할 것이다. 또한 빅데이터 활용을 위한 기술, 인프라, 인력은 각 기업마다 다를 것이다. 그러므로 각 기업이 빅데이터를 활용할 수 있는 수준이 어느 정도 인지 자사의 현황을 파악하는 것이 선행되어야 할 것이다. 이에 따라 본 연구에서는 기존 문헌연구를 통해 빅데이터 활용을 위한 성공요인을 도출하고, 도출된 성공요인을 통해 기업의 빅데이터 활용 수준을 측정할 수 있는 진단지표를 개발하였다. 또한 개발된 진단지표를 통해 실제 기업을 진단하는 사례연구를 진행함으로써 기업이 향후 빅데이터를 활용하는 전략에 반영 할 수 있는 계기를 마련하였다.",
		"KEYWORD": "경영정책"
	},
	{
		"ID": 28,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "단국대학교 경영대학원",
		"TITLE": "정보자산 빅데이터의 서비스기대가 이용의도에 미치는 영향 :(The)effects of service expectation of the information asset big-data on the use intention :e-Commerce 유용성의 조절효과를 중심으로 =focusing in the moderating effects of e-commerce usefulness ",
		"AUTHOR": "염수환",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수:김영국 참고문헌 : 55-63장",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "인터넷의 생활화에 이은 모바일 디바이스의 대중화 등의 확대로 인해 사람들이 이용하는 미디어와 커뮤니케이션의 영역이 확장되고 있다. 그 결과 엄청난 양의 정보가 생산 및 관리되고 있으며 이를 통한 효율적인 경영전략수립에 중요성이 대두대고 있다. 이런 흐름을 바탕으로 세계적으로 빅데이터에 대한 관심이 고조되고 있으며, 빅데이터를 활용한 분석방법 및 영향에 대한 연구가 늘어나는 등 빅데이터에 대한 중요성이 알려지고 있다. 이러한 사회적 흐름을 바탕으로 학계 및 여러 실무 영역에서 빅데이터 분석에 대한 중요성이 강조되고 있으며, 기업의 향후 생존 전략에 있어서 빅데이터 분석은 필수적인 활용 대상으로 인정받고 있다. 또한 기업뿐만 아니라 국가의 공공부문이나 교육, 복지, 과학, 의료 등 수많은 분야에서도 활용의 가치가 높아가고 있다. 하지만 지금까지 빅데이터의 활용에 대해서는 여러 연구들이 진행되고 있으나 합의점을 찾기에는 연구가 부족한 실정이다. 빅데이터는 미래예측에 대한 측면에서 과거의 방대한 자료로부터 규칙성을 분석하고 미래의 결과를 예측할 수 있어 목적을 달성하기 위한 예측기법으로 크게 활용된다. 나아가 빅데이터는 매우 다양한 학문 영역에서 큰 영향을 미치고 있다. 이와같이 매우 다양한 학문영역에서 다루어지고 있는 주제이다 보니, 각 영역별로 연구가 상이하며 특히 사회과학분야에서의 빅데이터 활용에 대한 연구는 전무한 실정이라고 볼 수 있다. 그러나 이러한 빅데이터에 대한 관심이 전사회적인 인식의 변화로 이루어지며 사용자 및 소비자들로 하여금 빅데이터의 중요성과 효과성에 대한 인식 자체가 결국 기업이나 대상에 대한 평가가 이루어질 것으로 예상해 볼 수 있다. 이러한 문제인식을 가지고 본 연구에서는 빅데이터의 서비스 기대가 이용의도에 미치는 영향에서 e-commerce 유용성의 조절효과를 분석하였다. e-commerce의 유용성을 품질인식, 서비스, 편의성으로 분류하고 각 차원이 빅데이터 서비스 기대와 이용의도 간 관계에서 어떻게 역할을 하는지를 비교 분석하였다. 실증분석에는 e-commerce를 이용해본 사용자들을 대상으로 설문조사를 통한 결과를 가지고 요인분석, 타당성 분석, 회귀분석 등을 시행하였다. 분석결과 빅데이터 서비스기대가 이용의도에 유의한 정(+)의 영향을 미치는 것으로 확인되었으며, 서비스 기대와 이용의도 간 관계에서 e-commerce의 구성요인 중 품질인식과 서비스가 조절역할을 하는 것으로 나타났다. 이러한 연구 결과는 e-commerce의 유용성에 따라 빅데이터 서비스 기대가 이용의도에 미치는 영향이 다르다는 것을 확인해 주는 가운데, 사용자들은 e-commerce의 품질인식이나 서비스에 대한 평가가 높다면, 낮은 서비스기대에도 불구하고 이용의도를 높일 수 있다는 점을 밝혔다는 데에 실증결과의 의의가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 29,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한양사이버대학교 경영대학원",
		"TITLE": "빅데이터 기술에 기반한 그린IT 분류체계 수립 및 그린IT 활성화를 위한 전략적 과제 연구 :Classifying green IT based on big data technology and developing strategies for vitalizing green IT :비즈니스 활성화와 정책수립 관점 =focused on policymaking for vitalizing business ",
		"AUTHOR": "백현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박선경",
		"STORE_LOCATION": "한양사이버대학교",
		"ABSTRACT": "Recently, the information technology (IT) is significantly developed and plays an important role in many areas. When IT is applied to solve energy and environmental issues and to help the sustainable development of human beings, it is called as “Green IT”. Green IT was often classified into two categories: one is Green IT 1.0 and the other is Green IT 2.0. Green IT 1.0, also called as Green of IT, implies the IT that is used to improve the efficiency of the energy or to solve the environmental problems caused by the IT itself. Whereas, Green IT 2.0 also called as Green by IT, means the IT that helps enhancing sustainability for all areas of business. Though Green IT 2.0 can be useful in many areas of business, up until now, policies related with Green IT 2.0 are limited partly because it encompasses too large scope to focus on a certain purpose. The goal of this study is to reclassify Green IT to increase the usage of it through establishing policies linked with Green IT. Green IT is reclassified into four categories based on the usage of big data technology: green IT by environmental big data green IT by bio big data, green IT by things big data and green IT by human big data. Projects with a high priority were investigated for each categories of green IT and this investigation performed using Delphi method. Results indicated that developing environmental data integration and sharing system, pollution prevention and surveillance system, and human diseases prevention system are among the high priority needed for green IT by environmental big data. In addition, developing health insurance review & assessment service, hospital diagnosis, treatment integration and sharing system, natural language diagnosis through NLP(Natural Language Processing) technology and utilization system are among high priority for green IT by bio big data. Furthermore, developing data security technology, policies associated with M2M(Machine to Machine), and energy consumption monitoring system are highly prioritized for green IT by things big data. Finally, strengthening national security through analyzing human crime data, establishing process and counter plan for national disaster using SNS(Social Networking Services) data, developing sharing and utilizing system of security and traffic data using public data like national emergency management agency are highly prioritized for green IT by human big data. The result of this study can be used to develop policies that are needed to be developed in many areas of business using green IT. The policies based on this study can help develop green IT as well.",
		"KEYWORD": "그린IT,델파이기법,빅데이터"
	},
	{
		"ID": 30,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "경성대학교 교육대학원",
		"TITLE": "빅 데이터 처리기법을 이용한 청소년 폭력성 감지 시스템 ",
		"AUTHOR": "임윤지",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 김영택 교수님",
		"STORE_LOCATION": "경성대학교 도서관",
		"ABSTRACT": "The main points of this paper are two folds and the first one is to implement the open sources concerning big-data to create some feasible applications on any social development, secondly, the experimental study on the specific field of educational problem solving matters, specially with some prevention of violence at the school environments by using those big- data techniques. The experimentation has been done through the word-count mechanism by using Hadoop system which is implementing Map-Reducing methods. And the results show the effective key-value mapping concerning those aggressive notations which was sent to other students on any social network system.",
		"KEYWORD": "빅 데이터"
	},
	{
		"ID": 31,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "경성대학교 교육대학원",
		"TITLE": "빅 데이터처리를 활용한 학력 분포 분석 시스템 ",
		"AUTHOR": "손남주",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 김영택 교수님",
		"STORE_LOCATION": "경성대학교 도서관",
		"ABSTRACT": "This paper aims at the effective implementations with those current national educational problem solving methodologies which are big headaches socially in terms of some efficiency concerns these days. The implementation has been studied through the big-data analysis technique based on Hadoop open source which is using the Map-Reducing mechanism on the distributed parallel processing platform. The results show the partially effective experimental student records which are displaying some word counted grade point records by sorted queries according to the required analysis directions. This result reveals that the big-data analysis could be used to implement some educational problem solving purposes easily and effectively.",
		"KEYWORD": "빅데이터,워드카운터"
	},
	{
		"ID": 32,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국교통대학교 대학원",
		"TITLE": "빅데이터를 활용한 마케팅 전략 실행의 실제에 관한 연구 =Applications of big data in marketing strategies and executions ",
		"AUTHOR": "송민석",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 정기만",
		"STORE_LOCATION": "한국교통대학교 중앙도서관",
		"ABSTRACT": "본 연구는 빅데이터를 활용한 마케팅 전략 실행의 실제에 관한 연구이다. 정보화시대를 맞이하여 최근 세계경제는 디지털 시대에 맞는 경제발전에 관심을 보이고 있으며, 많은 양의 정보가 생산되고 관리됨으로써 정보의 분석과 활용이 중요한 가치로 강조되고 있다. 요즘 새롭게 등장한 ‘빅데이터(Big Data)’의 중요성이 부각되고 있는 가운데, 빅데이터는 미래 국가의 경쟁력을 좌우하는 핵심 자원으로 대두되고 있으며, 기업뿐만 아니라 국가의 공공부문에서도 활용의 가치가 높아 가고 있다. 또한 빅데이터를 정확히 이해하고 분석하여 효과적으로 활용하기 위한 전략수립과 대책을 체계적으로 확립할 필요성이 있다. 빅데이터 마케팅의 효율성을 높이기위해서는 충분한 데이터를 고객으로부터 직접 수집하여 분석하고 관리할 수 있어야 한다. 빅데이터의 활용분야는 공공, 과학, 의료, 도소매, 제조, 정보통신 등 여러 분야에 해당되며 빅데이터의 분석과 활용은 충분한 시간과 투자가 필요하다. 빅데이터 마케팅은 정부의 정책과 기업에 밀접한 관계를 갖고 있기 때문에 적극적인 의지로 체계적이고 조직적인 구조를 만드는 데 앞장서고 적극적인 지원을 해야 그 효과를 볼 수 있다. 따라서 본 연구는 빅데이터와 관련된 현황을 살펴보고, 마케팅 분야에서의 빅데이터 활용 사례를 공공 부문과 민간 부문으로 나누어 살펴봄으로써 마케팅 전략 수립과 실행에서의 시사점을 도출하고자 한다. 또한 이러한 시사점에 대한 충분한 검토와 대비가 이루어진다면 고객관계관리(CRM), 소셜고객관계관리(SCRM), SNS 마케팅을 포함한 각종 마케팅 전략의 실행에서 커다란 성과를 기대할 수 있을 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 33,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "순천대학교 대학원",
		"TITLE": "빅데이터 플랫폼 기반 온실 통합 관제 시스템에 대한 연구 =(A)study on the greenhouse integrated control system based on big data platform ",
		"AUTHOR": "황정환",
		"REGION": "전라남도",
		"PROFESSOR": "지도교수: 여현",
		"STORE_LOCATION": "순천대학교 도서관",
		"ABSTRACT": "As ICT convergence technology has been applied to current controlled horticulture, a lot of data has accumulated. But because existing systems process data in a single server, it’s hard to process massive data. Also, a new data processing technique is needed to process unstructured data, such as images, texts, and massive data. In this thesis, we propose an integrated control system for a greenhouse that can make it possible to effectively collect and save massive data created in a controlled horticulture and can offer a big data service, such as prediction of agricultural environment change, automatic measurement of growth, development, and production forecasts through processing and analysis of collected data. The proposed system consists of a greenhouse embedded server, a big data middleware server, and a web application server. A greenhouse embedded server performs the functions of environment sensor for data collection, the greenhouse facilities for environmental control of the greenhouse, data processing and transfer, local monitoring and control. A big data middleware server saves processed data to Hadoop file system periodically, classifies saved data and gives big data service through classification of saved data in real time and arrangement processing. web application server offers greenhouse control and related services to users. In this thesis, the system is established to process big data related to controlled horticulture and materialized integrated control applications for the green house and producer(user) application to make it possible to monitor a real time integrated greenhouse environment, control integrated greenhouse environment, monitor integrated production and analyze production efficiency. Also, a data processing test and environment control test in terms of energy efficiency were proceeded to evaluate the performance of the suggested system. As a result, a Hadoop distributed system can process massive data faster than existing systems and more energy efficient control for greenhouse environment is possible.",
		"KEYWORD": null
	},
	{
		"ID": 34,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "순천대학교 산업대학원",
		"TITLE": "싱글보드 컴퓨터 기반 빅데이터 처리 환경 시스템 구축 =(The)establish of big-data processing environment system based on single-board computer ",
		"AUTHOR": "조민희",
		"REGION": "전라남도",
		"PROFESSOR": "지도교수: 김원중",
		"STORE_LOCATION": "순천대학교 도서관",
		"ABSTRACT": "To establish a parallel distributed processing environment system for big data processing, it is necessary to connect multiple computers as nodes through network equipment or create multiple virtual hosts in a computer with high performance to build a clouding environment. In this sense, establishing a big data system is not easy, requires complicated system architecture, and follows many restrictions in terms of cost. To solve the problems, this thesis proposed a single board computer based Big Data Processing Environment System (BiDaPES or BDPS). The BDPS is the big data processing based environment where big data related works are easily performed at a low cost. In the future, it is expected that the BDPS developed in this study will effectively be used for beginners of big data processing and for educational fields and practice. With the use of five single board computers, the hardware of the BDPS proposed in this thesis was comprised of one internet gateway, three data nodes, and one name node. As the software for big data processing, Hadoop Distributed File System and MapReduce based on Hadoop framework, and MapReduce, and base systems necessary to analyze and practice big data, such as HBase, Hive, Flume, Pig, and Zookeeper, were used. Through the single board computers, it was found that they worked well.",
		"KEYWORD": null
	},
	{
		"ID": 35,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "빅데이터 역량 평가를 위한 참조모델 및 수준진단시스템 개발 =(An)assessment system for evaluating big data capability based on a reference model ",
		"AUTHOR": "천민경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 백동현",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "매일 약 2.5퀸틸리온(quintillion) 바이트에 이르는 데이터가 디지털 생성원 한명에게서 발생하고, 페타(Peta) 바이트에서 제타(Zeta) 바이트 규모에 이르는 데이터가 각 산업 및 기업에 축적되고 있다. 이러한 축적된 데이터를 합리적인 비용과 기술로 처리 할 수 있는 빅데이터는 데이터 폭증 시대를 대처할 기업의 필수불가결한 경쟁력이다. 빅데이터는 기업과 정부의 인식을 변화시키고 있다. 급변하는 환경 속에서 실시간으로 쏟아져 나오는 데이터 처리를 위해 기존의 시각에서 벗어나 빅데이터를 위한 기술, 전문 인력, 인프라 등 더욱 확장된 영역으로 투자 범위를 넓혀가고 있고 국가 경쟁력의 일환으로써 사업을 진행하고 있다. 특히 미국 등 해외 선진국을 필두로 빅데이터를 활용하여 성공을 거둔 사례가 계속 이어지고 있다. 하지만 우리나라는 빅데이터 후발 주자로써 빅데이터 활용에 대한 필요성을 인식하고 있는 정도로 아직 도입 초기 단계이다. 공공기관과 대기업의 경우 빅데이터를 활용하려는 움직임을 보이고 있지만 사회 전반적으로 빅데이터에 대한 인식이 추상적이며 막연하다. 빅데이터 도입 성공 사례와 도입 전략에 대한 체계적인 방법 역시 선진국에 비해 현저히 부족한 실정이다. 본 연구는 이러한 상황에서 우리나라 기업이 빅데이터를 활용하려면 어떠한 역량을 갖추어야 것인가, 빅데이터를 수용 및 활용하려면 어떠한 요소가 필요할 것인가에 대한 의문을 바탕으로 시작되었다. 따라서 본 연구에서는 빅데이터에 대한 이론적 고찰과 함께 기업이 빅데이터를 도입하는 데 있어 필요한 빅데이터 역량을 평가할 수 있는 참조모델과 이를 기반으로 한 수준진단시스템을 개발하여 빅데이터 도입 및 운영 전략을 수립할 수 있는 전 단계의 발판을 마련하고자 하였다. 본 연구를 위하여 해외의 기존 성숙도 모델과 역량 모델, 빅데이터 수준진단모델을 바탕으로 각 모델의 구성 요소를 종합하여 평가영역 내 요소들을 도출하였고 이를 통해 참조모델의 성숙도 단계와 평가영역을 분류하였다. 수준진단시스템은 참조모델을 바탕으로 진단 항목이 설계되었으며 이를 통해 기업은 영역별 자신의 빅데이터 성숙도 단계를 확인할 수 있고 제시되는 진단 결과, 개선사항, 시사점을 통하여 구체적인 역량 파악 및 보완이 가능할 것으로 기대된다. 또한 향후 빅데이터 활용도가 역시 높아질 것이라 예상된다.",
		"KEYWORD": "빅데이터(Big Data),성숙도 모델,수준진단시스템,역량 모델,참조모델"
	},
	{
		"ID": 36,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "딥러닝(Deep Learning)을 활용한 이미지 빅데이터(Big Data) 분석 연구 ",
		"AUTHOR": "김윤진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이용구 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "Big data is a set of all types including bulk of structured and unstructured data, which means extracting value from data by saving, managing and analyzing collected data. In order to express and use big data as valuable information, big data analysis methodology including data mining method suited to big data is needed. When analyzing unstructured image data of big data, it is often called image mining by applying data mining method. Image mining is a process finding meaningful information in image big data. Image mining means extracting an image similar to an image given from many images, so is also called Content-Based Image Retrieval. The purpose of image mining is to discover image pattern with important meaning in given image dataset. In this paper, we focus on the method for improving the classification accuracy of large-capacity image data. In order to classify the image data, Kohonen self-organizing map and two-step feedforward network of artificial neural network are suggested, which can be regarded as microcosm of the deep neural network among the deep learning algorithms. It is confirmed that classification accuracy of the suggested method can be higher than classification accuracy of existing research. Keywords: Big Data, Data Mining, Image Mining, Deep Learning, Kohonen Self-Organizing Map, two-layer feedforward network",
		"KEYWORD": null
	},
	{
		"ID": 37,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "청주대학교 대학원",
		"TITLE": "빅데이터 선호도 분석 에이전트 시스템 설계에 관한 연구 :(A)study on the design of preference analysis agent system based on big data :트위터 중심으로 =focused on Twitter ",
		"AUTHOR": "손성일",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 박찬곤",
		"STORE_LOCATION": "청주대학교 도서관",
		"ABSTRACT": "This paper has suggested that it efficiently analyse a massive Big Data on twitter through users` emotional perspective with Sensibility Analysis and improve the Preference about users` feedback adding weight on Sensibility Analysis. There are some issues on the earlier study on Sensibility Analysis to classify users` feedback as positive/negative because it has had big and rough particle of Sensibility and evaluate emotional elements such as slang, new words, emoticons and idiomatic expressions frequently used on SNS(Social Network Services). This paper has improved precision of Sensibility Decision and recall using Sensibility Dictionary specified Sensibility polarity based on the level of Sensibility and given importance to Sensibility Decision populating slang, new words, emoticons and idiomatic expressions not exist in the system dictionary and context using conjunctive adverbs fixed in Korean characteristics which are free to the word order. It also recognize sensibility words such as TF(Term Frequency), RT(Retweet), Follower which are weighting factors of preference and has increased reliability of preference analysis considering weight on `a very emotional tweet`, `a recognised tweet from users` and `a tweeter influencer` A lot of investment is being made on public services and private services for Big Data analysis in many different fields, it will grow and apply in various fields beyond information technology. But further studies should be carried out on Korean characteristics, the difficulty of natural language processing because of the free expression on tweeting in spoken language, sensibility dictionary Design applicable to various keywords, the classification between influencers and tweeter users.",
		"KEYWORD": "빅데이터,선호도 분석"
	},
	{
		"ID": 38,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 신문방송대학원",
		"TITLE": "빅데이터 환경에서 인포그래픽(infographic) 뉴스 기사가 수용자의 정보수용에 미치는 영향 ",
		"AUTHOR": "김진환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이민규",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "빅데이터에 대한 관심이 증가하는 저널리즘 환경에서 인포그래픽을 통한 데이터 시각화는 새롭게 등장한 비즈니스 모델이라고 볼 수 있다. 인포그래픽은 단순히 주목을 받기 위해 사용되기보다 데이터를 효율적으로 분석하여 이해하기 쉽고, 신속하게 메시지를 전달할 수 있는 핵심 도구로 국내 언론 및 해외 언론사에서 사용되고 있다. 선행연구들을 살펴보면 대부분 인포그래픽의 구성요소와 가독성 등에 집중하고 있으며, 신문 기사 유형에 따른 인포그래픽에 대한 연구는 찾아보기 힘든 실정이다. 따라서 본 연구는 빅데이터를 활용한 인포그래픽 뉴스 기사가 수용자의 정보수용에 미치는 영향을 살펴보았다. 그리고 인포그래픽을 활용한 뉴스의 시각화 효과가 수용자의 기저율정보 수용에 미치는 영향력에 대해서 분석을 진행하였다. 본 연구의 진행은 텍스트로만 구성된 기사와 텍스트와 인포그래픽이 혼합되어 구성된 기사, 인포그래픽으로만 구성된 기사를 제작하여 일반인 250명을 대상으로 실험 연구와 설문을 진행하였다. 수집된 설문 자료는 SPSS SPSSWIN 18.0 프로그램을 이용하여 분석을 진행하였고, 인포그래픽을 통한 뉴스 기사가 주목도, 정보전달, 이해도, 기억력에 미치는 영향에 대한 차이를 살펴보고 연구가설을 검증하기 위해 분산분석(One-way ANOVA)과 scheffe test를 실시하였다. 또한 기저율정보에 대한 응답자의 정답률 분석은 χ²-test을 활용하여 검증을 진행하였다. 연구의 결과는 텍스트와 인포그래픽이 혼합되어 구성된 뉴스 기사가 가장 긍정적인 영향을 주고 있는 것으로 나타났다. 구체적으로 텍스트와 인포그래픽이 함께 구성된 뉴스기사가 텍스트 뉴스와 인포그래픽 뉴스보다 수용자의 ‘주목도’, ‘정보전달력’, ‘이해도’, ‘기억력’에 높게 나타나고 있음을 나타났다. 또한 기저율정보의 수용에서도 텍스트와 인포그래픽이 함께 구성된 뉴스 기사가 가장 효과적임을 알 수 있다. 본 연구는 뉴스 기사의 정보전달 효과를 파악하기 위하여 실증적 연구를 통 인포그래픽의 활용이 효과적인 정보전달의 도구로 유용하다는 시사점을 제공하였다. 급변하는 저널리즘 환경에서 빅데이터의 등장과 데이터 분석기술의 발전으로 인하여 새롭게 등장한 인포그래픽에 대한 수용자의 정보수용을 파악하였다는데 의의가 있을 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 39,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "주가지수 예측을 위한 뉴스 빅데이터 오피니언마이닝 모형 =News big data opinion mining model for predicting KOSPI movement ",
		"AUTHOR": "김유신",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 鄭勝列 참고문헌: p.72-78",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "The digital revolution has rapidly changed the way we live. A huge amount of digital data is created from every aspect of our daily lives due to the development of the IT technology, advent of the Internet, and proliferation of the mobile environment that is represented by the smart-phone. The large quantity of digital data created is called “big data” and much interest is given to its use. Although data accumulation is easier than ever, the question of changing the data into useful information through manipulation, processing, and analysis remains a difficult one to solve. In particular, the need to identify and make use of one’s opinions, feelings, interests, preferences, expectations, and complaints is rising because informal text data on the Internet, and via mobile communication and SNS, explosively reflects them directly and indirectly. However, detailed research results are not yet satisfactory due to the difficulty in analyzing and identifying what the data means. This is due to the diversity of analysis techniques that is organized according to the data source, type, contents, and various characteristics of the language. It is also a fact that technology and the ideas to make the most of this data are not yet advanced enough. The news we watch every day is one example of informal data. Tens of thousands of news reports are created and digitalized every day, then distributed throughout the world. In that sense, news is the typical information text that makes up “big data” because its output is so enormous. The massive amount of news produced affects politics, economy, society, and is closely related to the stock price, which is the core index of economic activities. As a result, it is believed that the news has a close relationship with the stock price, and one can expect to find an investment opportunity and make a profit. Ultimately, we can predict the stock price and expect to create economic benefits if we can distinguish between favorable and unfavorable factors by properly analyzing the news. Therefore, many studies over the years have proved that the news is closely related to the stock price, and that the stock price fluctuates as a result of the news. Studies also have been conducted to forecast the stock price using the news based on this relationship between the news and stock price. However, past research targeted a particular kind of news or the news in a particular area. As a result, immediate reflection and analysis was insufficient as in the real world a massive amount of news is created and dispersed in real time every day. Also, recent research using machine learning has been limited by the fact that personal judgment acts in forecasting the stock price of a particular company or identifying the sentiment polarity of the glossary for news text analysis. This study presented an intelligent investment decision-making model based on opinion mining that extract opinions about stock price index increase/decrease, by taking massive news data as the “big data” composed of the informal text, scrapping and parsing the news automatically, and tagging the emotional word. In addition, the subject-oriented sentiment dictionary for the stock domain, not the general purpose sentiment dictionary, was directly implemented and applied by the prototype experiment for sentiment polarity tagging to analyze the informal text data. Afterwards, two spots with similar media characteristics were selected for the experiment, and the accuracy of stock price index increase/decrease was compared through learning and verification data split test. The data (July 2011 to September 2011) for the study(Kim, 2012) using the general purpose sentiment dictionary was used for mutual comparison when conducting the prototype experiment that built up and verified the subject-oriented sentiment direction of the stock domain. The experiment results confirmed the importance of the subject-oriented sentiment dictionary, which identifies the news opinion index by demonstrating high forecast efficiency compared to the general purpose sentiment dictionary in the particular threshold value section when attempting to forecast the stock price without data split. In addition, a prediction capability similar to the general purpose sentiment direction was demonstrated in the verification data set for the learning/verification data split experiment that was attempted to resolve the over-fitting problem. Therefore, it was found that the accuracy of stock price increase/decrease could be improved sufficiently if the optimized condition, opinion, and threshold value can be extracted from the learning data. The experiment was conducted for 80,000 news items about two companies, M and H, which were posted on the Stock section of the Naver portal site from January 2011 to December 2011. Company M, a relatively new online media company specialist, claims that they are more specialized in the stock exchange area, whereas Company H is a leading media company in the economy that was established with the motto of a “global comprehensive economic media company.” These two media companies have contrasting media characteristics. Consequently, the results of the experiment are different to some extent. In conclusion, Company M’s news opinion has shown a higher level of stock price prediction as well as in the quality of predictability in both the learning and verification data sets. On the other hand, it was found that analyzing two media company’s news as a single data set produced a poorer result than individual analysis because two lots of opinions are mixed. In the end, there was some difference in forecast accuracy and quality in the two media outlets, but the price index of stocks could be estimated using news opinion. It was also found that the opinion index and optimal threshold value learned through opinion mining can be useful in forecasting the actual increase/decrease of the stock price inde",
		"KEYWORD": null
	},
	{
		"ID": 40,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 도시과학대학원",
		"TITLE": "빅 데이터 기반의 재난정보관리 방안 =(The)management of disaster information based on big data ",
		"AUTHOR": "신자행",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤명오",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "최근 전 세계적으로 엄청난 규모의 자연재해와 더불어 인적·사회적 재난이 폭발적으로 증가하고 있고 그 빈도와 강도에 있어서도 과거보다 강력해지고 있다. 따라서 재난관리의 패러다임도 과거의 재난복구의 측면에서 벗어나 재난 대비의 필요성이 지속적으로 제기되고 있어, 빅 데이터의 활용을 통한 재난 대비를 위한 새로운 재난정보관리 전략이 요구되고 있다. 본 연구에서는 재난 관련 빅 데이터 활용에 대한 문헌조사과 사례연구, 재난관리정보시스템 운영 및 실태조사를 통해 효율적인 빅 데이터를 활용한 방안을 제시하고자 하였다. 연구결과 재난관련 빅 데이터의 실증적 연구 부족과 데이터의 규모에만 관심이 집중된 반면 데이터에서 의미를 찾아내는 분석기술에 대해서는 충분한 논의가 부족했던 것으로 파악 되었다. 효율적인 빅 데이터 기반의 재난정보관리 방안을 위해, 국가재난관리정보시스템의 현황과 재난관련 빅 데이터 활용실태 및 문제점, 빅 데이터의 수집, 처리, 저장, 보안관리, 분석, 제공·이용 활용절차방안을 제시하였으며, 재난관련 빅 데이터 프로세스 설계와 빅 데이터의 화재·구조·구급분야 활용 방안, 재난관리 단계·유형별 활용 방안을 제시하였다.",
		"KEYWORD": "국가재난관리정보시스템,빅 데이터,재난정보관리"
	},
	{
		"ID": 41,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "순천대학교 대학원",
		"TITLE": "빅데이터 마이닝 기반의 하이브리드 머신러닝 방법에 관한 연구 =A novel on hybrid machine learning method based on big data mining ",
		"AUTHOR": "정세훈",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 42,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅데이터 시대의 개인정보 제공에 영향을 미치는 프라이버시 요인 연구 =(An)empirical study on privacy factors affecting provision of personal information in the big data era ",
		"AUTHOR": "민현홍",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한경석",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "Recently, the appearance of Big Data has been drawing great attention from managerial scholars and journals worldwide such as Harvard Business Review, New York Times, etc. It is also considered as the most attractive industry in the 21st century. The main stream in the appearance of Big Data era is the extension of the Social Network Services(SNS) and the popularity of smart devices extensively. The Big Data industry, however, is not the leakage form of large amount of information but the technique itself is based on information leakage. Through smart devices or social network services, information is automatically collected and the leakage, hence, begins to appear. The Big Data era appeared and has been receiving lots of appreciation due to its economic, social, and political values that it offers. Along with the development of open sources, not only large enterprises but also small and medium enterprises collect personal data, analysis and, hence, generate such an economic values, which can be applied in the field of marketing. The popularity and accessibility of Big Data has turned out to be a new mainstream. It can be said that anyone can easily collect and analyze Big Data from a particular website, that leads to the popularity of the surveillance techniques. In foreign countries, there has been a budding industry in accordance with the individual`s social control and surveillance issues. This raises many researches and discussion, also in Korea. However, the domestic researches are still insufficient and lacking in almost all areas. Unlike the prior studies of privacy, this research focuses on the privacy of a so-called social Big Data, which is a transplanted form between Big Data and SNS. In the era of Big Data, anyone can encounter the risks and dangers related to the information leakage problem and the disclosure of personal information. The purpose of this research, therefore, is to provide a model, analyze and authenticate the associated issues. The research is divided into four sections. The previous studies indicated that individuals did not provide personal information which was considered as negative. In contrast, this study clarifies the Privacy Paradox of the individuals, even though still admits some factors like privacy risks, etc. The research has brought some following results. First, the hypothesis that people still provide personal information although they had been faced with privacy leakage(being hacked, for example) and acknowledge the risks, is proven. Second, the study has taken into consideration some factors, i.e. the public awareness of behavior provisions of personal information, policies, perceptions and issues relating to privacy, evaluating how these factors have affected individual risk perception and the corporate reputation. Third, some factors as perceived privacy risk about privacy and the business trust, and how they affect the provision of personal information are also being considered. Fourth, these following elements, i.e. gender, differences in age, the experience of personal information invasion, the usage level of SNS, have been assessed whether or not they act as the moderating factors of the research model. Among the independent factors, the most influential variable to the perception of personal risk ranges from privacy policy, experience of personal information invasion, and privacy awareness. The most effective factor to the corporate reputation also ranges from privacy policy, perceived value of information disclosure, and the privacy awareness. Besides, the experience of personal information invasion and the personal risk perceptions also affect the provision of personal information and there also has a paradox in it. The analysis indicates that there are differences between groups varying in gender, age, experience of personal information invasion, and the usage level of SNS.",
		"KEYWORD": null
	},
	{
		"ID": 43,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 대학원",
		"TITLE": "빅데이터 기반 추천시스템 구현을 위한 다중 프로파일 앙상블 기법 =(A)multimodal profile ensemble approach to development of recommender systems using big data ",
		"AUTHOR": "김민정",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 조윤호 참고문헌 수록",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "기존의 협업필터링 추천시스템 연구는 상품에 대한 고객의 평점(rating)이나 구매 여부 데이터로부터 하나의 프로파일을 생성하고 이를 기반으로 추천 성능을 향상시킬 수 있는 새로운 알고리즘을 개발하는 위주로 진행되어 왔다. 그러나 빅데이터 환경이 도래하면서 기업이 수집할 수 있는 고객 데이터가 풍부해지고 다양해짐에 따라, 보다 정확하게 고객의 선호도나 행태를 파악하는 것이 가능하게 되었고 이러한 데이터, 즉 퍼스널 빅데이터(personal big data)를 추천시스템에 활용하는 연구의 필요성이 대두되고 있다. 본 연구에서는 마케팅의 시장세분화 이론에 근거하여 퍼스널 빅데이터로부터 고객의 선호도나 행태를 다양한 관점에서 표현할 수 있는 5종의 다중 프로파일(multimodal profile)을 개발하고, 이를 활용하여 협업필터링 추천시스템의 성능을 개선하고자 한다. 제안하는 5종의 다중 프로파일은 프로파일 통합 유사도, 개별 프로파일 유사도 평균, 개별 프로파일 유사도 가중 평균이라는 세 가지 앙상블 기법을 통해 협업필터링의 이웃(neighborhood) 탐색과정에 적용된다. 실제 퍼스널 빅데이터에 본 연구에서 제안하는 방법론을 적용한 결과, 단일 프로파일을 사용하는 협업필터링 알고리즘보다 추천 성능이 개선되었으며 개별 프로파일 유사도 가중 평균 앙상블 기법이 가장 높은 추천 성능을 보여주었다. 본 연구는 빅데이터 환경에서 추천시스템을 개발하고자 할 때, 어떠한 정보를 이용하여 고객의 특성을 규명하는 프로파일을 만들고 이를 어떻게 결합하여 사용하는 것이 효과적인지 처음으로 제안하였다는 점에서 그 의의가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 44,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성신여자대학교 대학원",
		"TITLE": "빅데이터 환경 내 민감정보 및 개인정보 보호 방안 ",
		"AUTHOR": "김지영",
		"REGION": "서울",
		"PROFESSOR": "성신여자대학교 논문은 저작권에 의해 보호받습니다. 지도교수:홍승필 권말에 참고문헌 및 영문초록 수록",
		"STORE_LOCATION": "성신여자대학교 도서관",
		"ABSTRACT": "오늘날 빅데이터는 ICT 분야의 최대 이슈중 하나이다. 인터넷과 소셜미디어 등의 서비스 확산과 네트워크 기술의 진화 및 개인 스마트 기기의 발전에 따라 다양한 데이터가 기하급수적으로 증가하고 있다. 이러한 다양한 다량의 데이터를 수집하고 활용하는 범위 역시 넓어짐에 따라 빅데이터의 가치 또한 높아지고 있다. 다양한 종류의 대규모 데이터에 대한 생성, 수집, 분석, 표현을 그 특징으로 하는 빅데이터 기술의 발전은 다변화된 현대 사회를 더욱 정확하게 예측하여 효율적으로 작동케 하고 개인화된 현대 사회 구성원마다 맞춤형 정보를 제공, 관리, 분석 가능케 하며 과거에는 불가능했던 기술을 실현시키기도 한다. 이처럼 빅데이터는 긍정적인 측면을 가지지만, 개인이 원하지 아니하는 인격의 형성이나 개인에 대한 실시간의 감시를 비롯하여 향후의 행동방향에 대한 예측도 가능하게 하고, 조직의 민감정보 및 기밀정보를 유추 가능하게 되어 조직의 경제적 피해를 입힐 수 있는 동전의 양면성을 내포하고 있다. 본 연구에서는 빅데이터 환경 내 활용되는 “조직의 민감 정보” 및 “고객의 개인정보”를 보호할 수 있는 방안을 제시한다. 서론에서는 논문의 개요에 대해 간략하게 소개하고, 관련연구에서는 빅데이터의 개요 및 빅데이터 기술에 대해 설명하고 개인정보보호에 대해 소개한다. 그리고 빅데이터 환경 내 “조직의 민감정보” 및 “고객의 개인정보”를 활용하는 경우 발생 가능한 침해 위협을 도출하여 본 연구의 방향성에 대해 제시한다. 이를 기반으로 빅데이터 환경 내 “조직의 민감정보” 및 “개인정보”를 안전하게 활용할 수 있는 시큐어 빅데이터 시스템(Secure Big Data System)을 제안하고, 제시한 SBS의 실 환경 적용 가능성 검증을 위해 프로토타이핑을 보여준다. 후반부에서는 SBS 시스템의 분석 및 성능평가를 진행하였으며 향후 연구 방향에 대해 제시한다.",
		"KEYWORD": null
	},
	{
		"ID": 45,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "문화주도적 젠트리피케이션 현상에 의한 장소성 변화 연구 :(A)study on the change of sense of place due to the culture-led gentrification :홍대, 이태원, 신사동 지역에 대한 소셜미디어 빅데이터 분석을 중심으로 =focusing on the social media big data analysis about Hongdae, Itaewon, Shinsa area ",
		"AUTHOR": "황준기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 오동훈",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Desire for cultural consumption space which had begun in earnest in the 2000s became more pronounced with the development of the IT industry, globalization and the flow of information. In addition, there were animosity of the people about large-scale urban renewal. At the same time, interest in the `culture-led gentrification‘ phenomenon reactivating underdeveloped areas of downtown in a way that creates a unique atmosphere by cultural artists has been increased. Occurrence of cultural consumption spaces triggered by this gentrification keeps favorable function such as securement of diversity by providing new place for culture consumption. In addition, the penetration of large commercial capital had caused a surge in rents, lead to problems such as standardization, etc. due to the influx of large franchise stores. It leads the phenomenon that the initial features of the culture was transferred to a nearby low-rise residential area with cheap rents. Thus, the identity and sense of place of the cultural consumption spaces formed spontaneously have a great influence on sustainability of them. This study aims to identify the sense of place caused by culture-led gentrification by social media big data analysis. For this purpose, the study deals with two types of representative culture-led gentrification areas such as Hongdae, Itawon, Garosugil where the excessive commercialization has already occurred and such as Yeonnamdong, Serosugil, Gyeongridangil where the culture-led gentrification has just occurred. Basic information, character and history about the study area are examined through various reports, papers, articles and other printed materials. For the empirical analysis, social media big data analysis based on text mining was conducted The research results are as follows. First, excessive commercialization caused by the culture-led gentrification influences negative perceptions of visitors and inhabitants in case of existing hot place. On the contrary, new hot places turn up because of the atmosphere caused by the combination of physical condition like a alley and unique cultural character and sense of place from existing hot place. Thus, the excessive commercialization caused by the culture-led gentrification is the negative influence factor to deglamorize the existing hot place and warmth of alley is the positive influence factor to be fascinated. Secondly, negative awareness on culture-led gentrification place is different in different locality, culture. In case of Hongdae, disappeared artistic atmosphere is key factor and in case of Itawon, the problem of public safety is key factor. Finally, transplantation of cultural character of existing hot place is different in different locality. These results show that new hot places tend to be located on low-rise residental area with alley. The spread of gentrification is caused by not only cheap rents also atmosphere of warmth of low-rise residental area. And, the way to develope cultural heritage from existing hot place is different in different locality, culture. Therefore, regulation to prevent large scaled commercial facilities and buildings on low-rise residental area are required. To enhance current cultural character of new hot place and make up for existing hot place’s fault is a proper way to make complementary relation. And political perspective through the convergence of ordinary landscape and unique individuality of region is required.",
		"KEYWORD": "문화,빅데이터,소셜미디어,장소성,젠트리피케이션"
	},
	{
		"ID": 46,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "안양대학교 대학원",
		"TITLE": "SQL 기반 빅데이터 처리 플랫폼 설계 및 개발에 관한 연구 =(A)study on design & development of big data processing platform using SQL ",
		"AUTHOR": "김성숙",
		"REGION": "경기도",
		"PROFESSOR": "",
		"STORE_LOCATION": "안양대학교 도서관",
		"ABSTRACT": "Log data are useful media in tracking user’s reactions and finding his or hers meaningful activity patterns. Recently, log data that are being generated by many smart devices (e.g. Smart Phone, Smart TV, etc.) need a new processing method, because conventional relational database technology which is run on central processing platform is hard to deal large volume of data and the representation format of this big data are changing from formal to informal. In this thesis, therefore, Hadoop is adopted to provide the flexibility in gathering, saving, and analyzing big data for a log data analysis job. Hadoop consists of HDFS (Hadoop Distributed File System) and MapReduce framework that support massively parallel and distributed data processing mechanism. This means that conventional relational database system that relies on central processing platform is changed to the distributed processing platform such as Hadoop. At the same time, easy hardware performance upgradability and the modeling flexibility of data structure are obtained. However, it is still hard to implement MapReduce programming for analysis engineers by themselves and also difficult to schedule parallel-submitted jobs for them. To solve these problems, in this thesis, Hive that use conventional SQL script in big data query is used to provide SQL-like MapReduce programming environment. Also, to make a decision making process meaningful, data mining technologies is used in data analysis steps, and R, a popular data analysis tool, is linked with the result of a Hive query to visualize the analytic results. Various real users’ log data are used in the experiments. Through the usage histories of a smart device, the user experience can be tracked and also his or hers activity patterns can be visualized. According to these results, reconsideration of services on a smart device and new display design for the hardware can be derived. The contribution of this paper is that overcoming the difficulty of an analysis which is conducted using big data on the conventional relational database system. So the applicability of the proposed mechanism is high.",
		"KEYWORD": "SQL기반,개발,빅데이터,설계,연구,처리,플랫폼"
	},
	{
		"ID": 47,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "빅데이터 환경에서 메타DB 자동 매핑 알고리즘을 이용한 시각화 시스템 설계 및 구현 =Design and implementation of visualization system using meta DB automatic mapping algorithm in big data environment ",
		"AUTHOR": "권민",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 박석천",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "최근 빅데이터를 활용하기 위한 방안으로 데이터 시각화가 주목받고 있다. 이러한 데이터 시각화를 통해 빅데이터의 방대하고 불규칙적인 패턴을 직관적으로 파악하여 새로운 가치를 창출 할 수 있으나, 기존의 시각화 시스템은 시각화 대상이 되는 메타 DB의 관리가 비효율적이다. 뿐만 아니라, 시각화 처리 과정에서 시각화 작업의 산출물인 시각화 차트에 대한 데이터 갱신과 차트 종류의 수정이 신속하지 못한 문제점이 있다. 따라서 본 논문에서는 이와 같은 문제점을 해결하기 위하여 메타 DB 자동 매핑 알고리즘을 이용한 시각화 시스템을 제안하였다. 본 논문에서 제안하는 시스템을 설계하기 위하여 빅데이터와 시각화 처리기술에 대해 분석하고, 자동으로 쿼리를 생성하기 위한 데이터 가공 알고리즘을 설계하였다. 이 알고리즘을 통해 생성된 쿼리를 이용하여 호출된 메타 DB와 시각화 차트 구현 데이터를 자동으로 매핑하는 메타DB 자동 매핑 알고리즘을 설계하였다. 또한, XML로 생성되는 차트 구현 데이터를 JSON 형태로 변환하여 클라이언트 화면에 전송하는 데이터 컨버팅 알고리즘을 설계하였다. 본 논문에서 설계한 시스템을 구현하기 위하여 Window8기반 PC에서 JSP, Java, MS-SQL, HTML5 & CSS, Java Script를 사용하였으며, 시각화 차트를 구현하기 위해 시각화 오픈소스 라이브러리를 사용하여 구현하였다. 본 논문에서 구현한 시스템을 테스트하기 위하여 기존 시각화 시스템의 처리 단위별 평균 소요 시간을 측정하여 테스트를 진행하였다. 테스트 결과 제안시스템이 기존시스템에 비해 최소 0.254 초에서 최대 3.152초 시각화 처리속도가 감소하는 것을 확인하였으며, 제안하는 시스템이 보다 효율적임을 입증하였다.",
		"KEYWORD": null
	},
	{
		"ID": 48,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 대학원",
		"TITLE": "빅데이터 도입을 위한 데이터 품질관리의 경영성과 연구 :(A)business performance study of data quality management for big data adoption :기업의 데이터 품질관리 프로세스를 중심으로 =focused on corporate data quality management process ",
		"AUTHOR": "안희정",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김현수 참고문헌 수록",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "The purpose of this thesis is to offer the importance of data quality management to the corporation’s managers who want to enhance their value of business through adopting big data and suggest that focusing on successful factors of data quality management can solve one of the challenges of big data. Since the rapid development of information technology, there has been a quantitative expansion of data and developed technologies to process these gigantic, atypical data as well. Therefore, the number of corporations that want to adopt big data is increasing because successful data analysis can increase their competitiveness in the market. While the former researches on big data mostly dealt with the technological issues of big data and discussed on its potential value, the quality issues of big data was mostly neglected. However, increasing number of researches has brought up quality issues of big data these days as one of the challenges that one needs to address. Also, they also point out that there is a limit to obtain useful analysis results by using data that have been acquired from outside resources. There are also opinions that simply adopting the latest technologies or techniques is not the starting point of applying big data when we observe the fact that a lot of enterprises do not thoroughly analyze the existing data within the company. The writer also agrees with this opinion. Therefore, this research tries to explore the positive factors of successfully managing the enterprises’ data quality, which could be considered as the foundation of big data analysis and verifies the hypothesis that as the data quality management promotes data utilization for better business management and tactical decision-making, it brings positive effects on customer orientation and business performance. If the quality management of the data within the company affects the business performance positively, then one can assume that big data quality management will bring significant consequences in business performance. For this reason, different references about big data, data quality management, and business quality management have been researched. In addition, a research model has been investigated and analyzed through a survey to those managers and users who have some experience on processing information data and who understand the concept of data quality. The following paragraphs sum up the conclusion of this research. First, the causes that impact the data quality management have been researched. From the influential factors of data quality management such as data quality management recognition, management-level support, and management environment, data quality management recognition and management environment showed positive effects on data structure design management and database management while the hypothesis that data utilization management will give positive effects was dismissed. On the other hand, because the management-level support also showed positive effects on data utilization management, we can conclude that management-level support gives positive impacts on all of the data quality management activities. Regardless of the different data quality management types, overall, the management-level support showed the highest influential factor on data quality management, followed by data quality management recognition and business environment. Second, the observation on whether the data quality management promotes the use of data or not was made. Database management and data utilization management showed positive effects on data usage level but data structure design management did not show notable effect. This is because the quality of data structure design is more related with dealing with the efficiency of information system management rather than users’ convenience and accessibility. There is a direct relation between database management that provides stable data that the users need within the given time or data utilization management that directly conducts measuring data errors for improvement, and the increase of users’ data utilization level. Third, analysis on the effects of the data utilization level on non-financial business performance was made. The data utilization level showed positive results for customer-orientation, which also led to positive effects on the business performance. In addition, data utilization level positively affected the business performance directly even without mediating the customer-orientation factor. However, when breaking the down the correlation between them, data utilization level also had indirect effect to the business performance when the customer-orientation factor was included. Fourth, three different industries, manufacturing, finance and telco, and others have been categorized. The writer observed that different industries did not have any moderating effects on the research model. To analyze the cause for this reason, I have compared three different groups by conducting One Way ANOVA analysis. As a result, there was no difference in data quality management recognition among the groups but the other five variables such as; management class support, management environment, data structure design management, data utilization management, and business performance, all showed significant difference between the finance and telco industry and other industry groups. Data utilization level does not show notable difference among the industries because the survey items reveal that, generally, most of the industries stay at the level where they use their data directly with the business process and their data has not been analyzed thoroughly enough to affect their decision-making process. Lastly, through this research, I want to emphasis to those readers and business managers who are considering in adopting big data that rather than expecting positive features of big data by simply acquiring the external resource data like social data and investing on new technologies, they should examine their current data quality management system within the enterprise. Also, I suggest that if they prepare themselves to overcome current data quality issues, consequently, it will help them to effectively adopt and be able to manage big data successfully.",
		"KEYWORD": null
	},
	{
		"ID": 49,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 분석결과의 웹 3D가시화 도구 개발 =Development of a web 3D toolkit for visualizing big data analysis results ",
		"AUTHOR": "김진국",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 류관희 참고문헌: p.47-48",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "In order to get the insight in the big data where huge data are rapidly increasing, the insight which enables to recognize at a glance is required even though the analysis is important. To execute this role is big data visualization. Currently, numerous companies pay attention to big data visualization platform. As HTML5 technology is receiving the attention as new web interface technology and becomes a standard language which can be supported in PC or mobile devices, it has a big potential to be developed as web visualization platform. D3.js is a 2D visualization JavaScript library to correct the documents based on data and it gives the energy to visualize data analysis results using HTML5, SVG and CSS. D3.js has the linkage difficulty to database which stored the big data analysis results. In this thesis, we proposed a transformation process which extracts the data in a database and then transforms them into CSV or JSON in D3.js. Next, we proposed a 3D tookkit for visualizing big data analysis results, which is made by combining D3.js and X3Dom.js. X3Dom.js is a JavaScript rendering library which supports Extensible 3D(X3D) file format. We applied the proposed 3D visualization toolkit to visualize big data analysis results. The result shows the 3D visualization effects are better than the 2D visualization results using only D3.js.",
		"KEYWORD": "가시화,빅데이터"
	},
	{
		"ID": 50,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅데이터 기반의 인적자원개발 교육시스템 아키텍처 =A big data based education system architecture in human resource development ",
		"AUTHOR": "김용식",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신용태",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "기존의 이러닝 및 오프라인 교육에서는 시공간의 제약과 더불어 교육 데이터는 단지 시험 결과, 설문 결과 등을 위주로 수작업 기록 또는 광학 문자 판독기를 이용한 답안 작성이 이루어졌기 때문에 교육과정 및 학습활동에 대한 데이터는 대부분 저장되지 않았다. 그러나 인적자원개발(HRD: Human Resource Development) 시스템이 구축되고 스마트 교육환경이 도입되면서 모든 학습활동이 온라인상에서 진행되므로 학습활동과 관련된 데이터를 수집하기가 쉬워졌으며 개별화된 학습을 통해 학습자의 학업성취도를 향상하게 시키고 다양한 교육 데이터의 활용이 가능해졌다. 즉 인터넷, 모바일, 클라우드 기반의 스마트 교육 환경에서는 학습자와 강사의 학습 관련 활동정보 등이 대량의 디지털데이터로 축적되므로 이를 체계적으로 수집하고 분석하여 학습자에게 유용한 피드백 정보를 생성하고 교육 관련 정보로 활용할 수 있다. 수집된 방대한 교육 데이터는 빅데이터 전략을 통해 정형화된 학습정보뿐만 아니라 학습활동과 관련된 비정형의 교육 데이터를 종합적으로 이해하고 분석함으로써 학습자의 능력, 역량 등을 알아내고 이 정보를 토대로 개인별 맞춤형 학습을 제공함으로써 교육의 성과를 높일 수 있다. 특히 이러한 빅데이터를 HRD 교육시스템에 효과적으로 구축하게 되면, 학습에 다양한 이득효과를 얻을 수 있다. 학습자 측면에서는 학습 동기를 강화하거나 학습자의 학습 성과를 관찰하고 예측하는 잠재적인 문제를 조기에 발견하여 학습을 포기하지 않도록 하는데 응용될 수 있다. HRD 교육담당자 측면에서는 방대한 양의 학습데이터를 분석하여 학습의 지체요인을 밝혀내고 성공한 학습요인들을 시스템에 적용하여 개별 학습자들의 학업성취도를 향상하게 시킬 수 있다. 그러나 기존 기업의 HRD 교육시스템에서는 스마트폰, 태블릿과 같은 다양한 단말기를 활용한 스마트 교육 인프라의 활용이 대부분에서 미흡한 상태이며, 특히 빅데이터와 같은 최신 IT 기술을 활용하여 교육분야에서 실시간으로 조직 구성원의 다양한 학습요구를 분석하여 교육과정에 반영시킨 사례를 찾아보기 어렵다. 따라서 본 논문에서는 HRD 교육시스템에 빅데이터를 접목한 아키텍처를 제시하고, 개인학습에 있어 빅데이터 기술의 유효성을 검증하기 위해 HRD 교육담당자들을 대상으로 빅데이터 활용분야와 빅데이터 활용가치에 대해 설문 조사를 하고 그 결과를 분석하였다. 조사·분석된 결과를 토대로 빅데이터가 HRD 교육담당자는 물론, 기존에 알려진 학습효과를 높일 수 있는 다양한 방법들(교수법활용, 학습프로세스 개선, 콘텐츠 개발, 수준별 맞춤학습 제공 등)과 더불어 개인학습에 도움이 될 만한 충분한 가치가 있음을 확인했다.",
		"KEYWORD": "빅데이터,인적자원개발 교육시스템"
	},
	{
		"ID": 51,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "사회관계망 서비스 분석을 통한 효과적인 빅데이터 영향력자 활용 방안에 관한 연구 =A study on the effective utilization of big data influencer through the analysis of social network service ",
		"AUTHOR": "장준호",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정윤원",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 사회관계망 서비스의 활성화로 발생하는 대량의 소셜 빅데이터를 분석하여 리스크 관리, 마케팅자료, 사회현상 분석 등 다각적인 관점에서 관련연구가 이루어지고 있다. 본 논문에서는 소셜 빅데이터를 보유하고 있는 인스타그램, 페이스북과 같은 사회관계망 서비스 분석을 통하여 특정 분야의 영향력자를 팔로어의 반응지수를 이용하여 추출한다. 이후 키워드 분석을 통해 영향력자가 어떤 주제에 대해 어떠한 형태로 영향력을 행사할 수 있는지를 분석함으로써 효과적인 빅데이터 영향력자 활용 방안을 제시한다.",
		"KEYWORD": "HadoopECOSystem,SNS수집,WEB수집,빅데이터,사회관계망분석,영향력자 분석"
	},
	{
		"ID": 52,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인천대학교 문화대학원",
		"TITLE": "빅데이터 분석을 통한 문화마케팅 활성화 방안 :인천 펜타포트 락 페스티벌 중심으로 ",
		"AUTHOR": "이경아",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 권기영",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "1995년 지방자치가 시작됨에 따라 도시는 경쟁력 향상이라는 목표 하에 관광활성화를 꾀하고 고용창출을 위한 브랜드 전략을 더욱 강화하게 된다. 도시마케팅 차원에서 다양한 지역문화축제도 함께 증가하였는데, 한국관광공사의 <대한민국 구석구석> 의 축제·행사정보에 의하면, 올 한해 매달 평균 100개 이상의 축제가 개최되었으며 성수기인 가을에는 월 약 400개의 축제가 열렸을 정도였다. 그러나 이러한 지역축제의 증가추세에도 불구하고 축제의 지속력이나 자립성에 대해서는 회의적인 분위기이다. 본 연구는 이러한 배경에서 인천시의 대표유망축제로 손꼽이는 인천 송도 펜타포트 락 페스티벌을 표본으로 삼아, 인천시의 축제를 알리고 도시경쟁력을 증대시키기 위해 보다 효율적인 마케팅 접근법을 알아보았다. 현대 사회는 정보통신기술(ICT)의 발달로 대중들의 커뮤니케이션 방식이 다양화 되고 있다. 소통하는 채널은 물론이며, 그 양과 형태도 다양하게 펼쳐지고 있는데,이러한 방식으로 생성되는 데이터를 빅데이터라고 할 수 있다. 빅데이터가 가장 많이 생성되는 곳은 인터넷공간일 것이다. 이 인터넷 공간에서 대중들이 소통하는 방식은 다양한 소셜 미디어 즉, SNS(Social Network Service)를 통해서이므로, 이 속에서의 대중들의 커뮤니케이션의 흐름을 읽어내고자 하는 활동은 마케팅의 핵심요소 중에 하나라 할 수 있다. 현대에 있어 소셜 미디어의 활용은 더 이상 어려운 기술이 아니라 누구나 쉽게 사용할 수 있는 일상 커뮤니케이션의 한 도구이며 정보통신기술이 이러한 SNS속의 대중들의 커뮤니케이션 활동까지도 자세히 분석해 내는것을 가능하게 만들었다. 따라서 문화산업에서도 소셜 미디어 속의 대중의 흐름을 읽어 낼 수 있다면, 보다 다양한 발전전략 수립이 가능할 것이다. 빅데이터의 분석기술은 크게 데이터 마이닝 기술과 네트워크 분석 기능으로 나뉠 수 있으며, 본 연구에서는 네트워크 분석기법 중의 하나인 소셜 네트워크 분석기법(Social Network Analysis : SNA)을 사용하였다. 자료수집은 대표 소셜네트워크 서비스(Social Network Service : SNS)인 페이스북으로 한정하고, 시간상의 범위는, 인천 송도 펜타포트 락 페스티벌의 공식적인 페이스북 페이지가 적정한 연결망을 가지고 운영되기 시작한 2011년부터~2016년 까지 총 6년 동안의 축제기간(3일)을 데이터수집의 기준으로 잡았으며, 해당 기간 동안의 인천 송도 펜타포트 락 페스티벌과 그 계정에 연결된 대중들과의 네트워크 구조의 변화와 현상을 통해 향후 인천 펜타포트 락 페스티벌의 발전방향에 대한 시사점을 모색해 보았다. 구체적인 분석툴은 빅데이터 수집 및 시각화 처리 프로그램 중의 하나인 NodeXL(소셜네트워크 분석툴 중의 하나)을 활용하였으며, 밀도와 연결정도중심성, 근접중심성, 매개중심성 및 위세중심성을 분석함으로써 펜타포트 락 페스티벌의 경쟁력을 위한 현 상황을 진단해 보았다. 분석결과, 인천 송도 펜타포트 락 페스티벌 페이스북의 영향력은 관계망이 매우 견고히 맺어져 있어 락 페스티벌의 마니아층과 주변 관심자들에게 긍정적인 역할을 할 수 있는 토대가 되어있는 것으로 나타났다. 즉, 커뮤니케이션의 유기적 흐름의 척도가 될 수 있는 밀도가 해마다 증가되고 있어 소통이 원활하다는 것을 알 수 있었다. 그러나 각 중심성 분석에서 나타나는 영향력자 (노드/계정)들의 경우, 해마다 중복된 클러스트 안에 존재하지 않고 대부분 단절되고 있었다. 이는 소셜 마케팅이 제대로 이뤄지고 있지 않다는 것을 보여준다. 따라서 본 빅데이터 분석 결과를 토대로 전체적인 기획 측면과 각 중심성별 마케팅전략을 구체적으로 제시함으로써 빅데이터 분석의 효용성을 입증하였다.",
		"KEYWORD": "문화마케팅,빅데이터,소셜네트워크분석,인천 펜타포트 락 페스티벌"
	},
	{
		"ID": 53,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "인제대학교 대학원",
		"TITLE": "빅데이터 기반의 생체신호 분석 사례 및 연구 ",
		"AUTHOR": "박요셉",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 김희철",
		"STORE_LOCATION": "인제대학교 백인제기념도서관",
		"ABSTRACT": "빅데이터는 최근 우리사회의 산업, 과학, 예술분야에서 공공부문과 민간부문을 불문하고 모든 영역에 변화를 몰고 오고 있는 가장 주목받는 키워드(Key Word)이다. 빅데이터 기반의 서비스는 정치, 교통, 자연재해, 쇼핑, 고객관리, 의료, 기상정보 등의 다양한 분야에서 제공되고 있다. 특히 의료분야에서는 과거와 달리 병원이 아닌 일상생활에서 생체신호를 측정할 수 있는 웨어러블 디바이스의 등장으로 생체신호들이 기하급수적으로 생산되고 있다. 그로인해 생체신호는 빅데이터의 특징인 4V(Volume, Variety, Velocity, Value)의 요소를 가지게 되었으며 빅데이터 기반의 생체신호 분석이 필요하다. 하지만 아직까지 웨어러블 디바이스로 추출된 생체신호에 대한 빅데이터로서 연구는 활성화되지 않았다. 따라서 본 논문에서는 생체신호를 빅데이터 기반으로 분석하고 제공할 수 있는 서비스에 대한 연구를 제안한다. 제안하는 연구는 생체신호 데이터를 빅데이터 기반으로 분석하기 위한 프로세스를 제시하고 빅데이터 기반으로 제공할 수 있는 생체신호 서비스에 대해 연구한다. 적용사례로는 비교적 구하기 쉬운 스마트폰으로부터 추출 가능한 가속도데이터를 분석하고 가속도 기반의 빅데이터 서비스사례를 두어 연구를 검증한다.",
		"KEYWORD": "빅데이터,생체신호,웨어러블디바이스,웹서비스"
	},
	{
		"ID": 54,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2011",
		"UNIVERSITY": "경원대학교 소프트웨어대학원",
		"TITLE": "스마트혁명 시대 빅데이터 활용과 프라이버시 사이의 충돌에 관한 연구 ",
		"AUTHOR": "이용수",
		"REGION": "경기도",
		"PROFESSOR": "",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "스마트혁명시대 빅데이터 활용과 프라이버시 사이의 충돌에 관한 연구 이 용 수 경원대학교 소프트웨어대학원 전자거래학 전공 지도교수 양 영 규 사이버 공간의 국가 간 경계 부존재로 인한 각국과의 사법관할권 충돌과 글로벌 법익 침해자 응징의 실효성 담보의 어려움에 대해 논술하고 로렌스 레식 교수가 주장한 잠재적 모호성(Latent Ambiguity)의 발현으로 인한 법과 기술의 괴리, 법과 현실의 괴리를 인식하지 않고 만든 법과 정책은 국가·사회 발전을 저해하고 가치 버블과 과보호 같은 부작용을 가져 오는 문제점을 있음을 지적하고 몇 가지 사안에 대해 구체적 정책 제안을 하고 정책 방향 및 비전을 제시하였다. 아울러, 최근의 클라우드 서비스 확대를 기반으로 국가도 국민도 아닌 국가의 사법관할권을 초월해 존재하는 구글·애플 등 글로벌 빅브라더(Global Big Brother)가 정보화 시대 온갖 데이터를 장악하고 세상을 지배하려고 하고 있는 점에 대한 인식을 제고시키고 글로벌 빅브라더의 횡포에 휘둘리지 않도록 국가 차원의 빅데이터 확보와 데이터 주권 확보 방안을 고찰하였다. 국가는 국민 모두를 만족시키기 위해 끊임없이 노력하지만 모두를 항상 만족시키는 권력은 아니며 국가는 무한경쟁, 무법천지의 글로벌 환경에서 생존을 위해 끊임없이 선택과 결단을 요구 받고 있다는 점을 각인시키고 그 선택과 결단에 항상 모든 국민이 만족할 수 없다는 점을 결론적으로 강조하였다. 본 논문은 여러 가지 환경 변화를 있는 그대로 조명하고 논자의 관점에서 문제 제기와 해결책을 제안한 것이다. 그 제안은 이상적 일수도 있고 불완전한 것일 수도 있다. 하지만 현재 잘못된 것, 개선되어야 할 부분에 대한 나름의 해결책 제시를 위한 것으로 생각해 주면 좋겠다.",
		"KEYWORD": "Big Data,Black Swan,Cloud Revolution,Cyber Law,Data Mining,Data Sovereignty,Latent Ambiguity,Numerati,Privaqcy,Smart Revolution,Strategic Surprise,Trivergence,가치버블,개인정보,과보호,극단값,글로벌 빅브라더,뉴머리티,데이터마이닝,데이터주권,리틀브라더,블랙스완,빅데이터,빅브라더,사이버 로,삼중융합,스마트혁명,잠재적 모호성,전략적 기습,클라우드혁명,프라이버시,혁명융합"
	},
	{
		"ID": 55,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "클라우드 및 빅데이터 기반 침수 도로 탐색 시스템 개발 ",
		"AUTHOR": "송영미",
		"REGION": "부산",
		"PROFESSOR": "지도교수:김창수 참고문헌",
		"STORE_LOCATION": "부경대학교 도서관",
		"ABSTRACT": "Recently, although Korea having a distinct temperate seasonal climate natural disasters are increasing rapidly while extreme weather with the unstable weather events and subtropical characteristics such as heavy snow, earthquakes, hurricanes, occurs in urban and mountainous areas. Especially, local torrential rainfalls causes a flood of new types and results in a number of problems such as capital loss or injury to persons. In the present situation, the discussion with regard to disaster alerting and recovery systems for urban disaster has been made in several studies. In this paper, we conducted a study to develop roads flooded area flooding search system utilizing big data when flooding encountered. The data that needs to search for the road flooded area can be defined as a big data update even hundreds of thousands per day. When the emergency situation, road flooded area search system uses a distributed processing platform for rapid processing of big data. Big data collected in this study is social media data such as news, blogs and SNS, weather data provided by the National Weather Service, and the road link data. And database storing each data from the past to present in real time is analyzed by the distributed processing platform in order to searching road flooded area and extracted road flooded areas are given the degree of risk. Distributed processing platform is present in the cloud computing and extracted road flooded area can be provided to the client to obtain information about the actual road flooded area.",
		"KEYWORD": null
	},
	{
		"ID": 56,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅데이터 분석을 통한 전통마을 관광 개선 방안 =A plan for traditional village tourism improvement through big data analysis ",
		"AUTHOR": "정동현",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 신용태 참고문헌: p. 32",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "정보처리 기술의 발달과 활용 가능한 데이터의 급증에 따라 정치, 경제, 서비스 등 다양한 분야에 빅데이터를 활용한 연구가 큰 폭으로 증가하고 있다. 관광산업에서도 동일하게 발생하고 있다. 스마트 기기와 관광서비스 관련 플랫폼 등을 통해 관광객 관련 수요, 동기, 취향, 만족수준 등의 데이터들이 실시간 수집되고 있다. 수집된 데이터들로 인해 관광객의 동기, 행태 등을 분석이 가능해서 새로운 데이터들이 생산되고 있다. 또한 공공기관에서도 보유하고 있는 데이터를 보다 가치를 유발할 수 있는 분석을 시도하고자 하는 노력들도 진행되고 있다. 지역경제의 발전적인 정책을 여러 가지 방안을 가지고 추진하고 있는 정부는 지자체의 다양한 관광자원을 기반으로 관광객들이 좋아 할 수 있는 컨텐츠 개발을 통해 지역경제를 활성화 시키고자 노력하고 있다. 관광산업 활성화를 위하여 SNS(Social Network Service) 데이터와 공공기관이 보유하고 있는 데이터를 융합하여 어떻게 분석하면 보다 가치 있는 결과를 가져 올 수 있을까 하는 물음에서 시작되었다. 본 연구는 빅데이터 분석을 통해 전주 한옥마을에 2015년 1월부터 2015년 9월까지 약 10개월 동안 발생한 SNS 데이터를 활용하고, 해당 기간 동안 방문인구 정보, 관광시설 및 축제, 이벤트에서 발생되는 정보를 중심으로 연구하였다. 연구 결과, 한옥마을을 방문인구는 축제기간으로 인해 5월 방문이 전주시, 한옥마을 모두 가장 많았다. 상대적으로 방문인구가 적은 봄에는 가족단위 방문객을 여름에는 20대 젊은 층을 겨냥한 이벤트, 컨텐츠 확보가 필요하다. 전북지역 축제 기간보다 전주지역 축제 기간에 더 높은 관광객 증가율을 보이고 있다. 한옥마을 동선 확대를 위한 업종 다양화 및 컨텐츠 개발이 필요할 것으로 판단된다. 주차수급 분석을 통해 현재 주말만 운행 중인 셔틀버스를 휴가기간에 해당하는 평일에도 운행하고 5월 축제시기에는 주말에 확대 배차하여 운행을 추진할 필요가 있다. 일본인 관광객의 경우 역사/문화유적, 음식/미식탐방 등을 여행의 목적으로 둔 비율이 높았으며 중국인 관광객의 경우 ‘드라마 촬영지’ 등을 통한 홍보 및 고급여행상품개발(직장동료 또는 친구나 연인 타겟팅)이 관심이 높은 것으로 분석되었다. 미주지역의 관광객은 지역주민의 실상을 살필 수 있는 코스 개발(개별 관광객 타겟팅)이 필요한 것으로 분석되었다. 국내 지역관광 활성화의 빅데이터 활용 방안에 대한 민간 데이터와 공공데이터 빅데이터 분석을 통해 지역관광 활성화 방안을 제시하였다. 또한 최근 들어 대두되고 있는 관광 분야에 빅데이터 분석을 활용하여 효과적으로 전통마을 관광 활성화 방안을 제시하였다. 향후 연구에서는 지역관광의 이벤트 전문가와 빅데이터 등 정보처리 기술 전문가들의 다양한 생각을 통해 국가 관광자원의 경쟁력을 확보하기 위한 실제로 필요한 문제점이 무엇인지 또한 개선해야 할 것이 무엇인지를 연구가 필요하다.",
		"KEYWORD": "관광,분석,빅데이터,전통마을"
	},
	{
		"ID": 57,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "제조 생산라인 빅데이터 분석을 통한 기업 경쟁력 향상에 관한 연구 :A study on company competitiveness increase through big data analysis of product line : focused on improvement of product defective rate in electronic components manufacturing companies ",
		"AUTHOR": "김재중",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한경석",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "빅데이터 분야의 국내외 시장은 규모면에서 꾸준한 성장세를 보이고 있다. 빅데이터 분석 적용 대상에 있어서도 데이터나 정보 처리를 전문으로 하는 기관이나 기업에서 특수한 목적으로 사용하는 것이 대부분이었으나 지금은 전문 기업뿐만 아니라 일반 제조기업들도 그들이 생산해 내는 데이터를 기반으로 만들어지는 대량의 데이터를 분석하여 과거를 이해하고 현상을 파악하며 미래를 예측하려 하는 등 빅데이터의 활용 사례의 범위가 점점 확대되어 가고 있다. 이러한 사회적 추세는 빅데이터 분석 플랫폼의 저변확대와 상용화에 청신호로 작용되고 있다. 대기업에 비해 중소제조기업은 현장에서 만들어지는 데이터가 체계적으로 보관되어 있지 않은 경우도 많고, 또한 전문적인 데이터 분석시스템을 보유한 기업이 많지 않다. 보관하고 있는 데이터의 대부분도 수기로 작성된 데이터 또는 엑셀 문서로 보관되어 있는 상황이어서 정확한 데이터 분석에 의한 빠른 의사결정이 힘든 상황이다. 이로 인해서 불량요인이나 이상현상의 적시 파악이 힘들어지고 또한 공정별 가동률, 수율, 품질 등의 생산데이터 분석에 어려움을 격고 있다. 이를 해결하고자 정형 비정형 빅데이터를 효율적으로 분석 활용할 수 있는 빅데이터 분석 알고리즘을 구현하여 현장에서 비정형으로 기록되고 있는 정보들의 양식 패턴을 분석하고 정형화된 정보로 추출, 정제하여 분석에 활용할 수 있는 시스템을 구현함으로써 관련 산업계의 발전을 도모하고자 한다.",
		"KEYWORD": "빅데이터분석"
	},
	{
		"ID": 58,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "빅데이터 환경에서 PostgreSQL과 MongoDB의 데이터입출력 성능개선에 관한 연구 =(A)study on data input and output performance improvement of MongoDB ans PostgreSQL in the bigdata environment ",
		"AUTHOR": "정민규",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최용락",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "오늘날 데이터베이스 시스템은 비정형 데이터 시스템인 NoSQL로 프로젝트를 시작하거나, 현재 구축되어 있는 시스템들을 NoSQL로 변환하는 추세를 나타내고 있다. 그리고 기존에 사용해 왔던 관계형데이터베이스관리시스템은 소셜 네트워크의 발전과 다양한 모바일 기기의 대중화로 인해 발생되는 데이터 과다 현상을 처리하기에는 성능 문제가 대두되고 있다. 따라서, 본 연구에서는 관계형데이터베이스관리시스템을 NoSQL로 변환하려고 계획 중이거나, 새롭게 NoSQL을 활용하여 시스템 구축 프로젝트를 진행하려 할 때, 두 시스템들 간의 성능상의 차이가 있는지 여부를 확인하고 NoSQL로 진행 시 어떠한 설계로 진행을 하는 것이 보다 좋은 성능을 나타내는지에 대해 기술한다. 이를 통해 최근에 많이 사용 되고 있는 NoSQL의 올바른 사용에 대한 지침을 마련하고자 한다. 본 연구에서는 관계형데이터베이스관리시스템으로 PostgreSQL을 활용하고, NoSQL은 MongoDB를 활용하여 비교한다.",
		"KEYWORD": null
	},
	{
		"ID": 59,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "청주대학교 대학원",
		"TITLE": "빅데이터 처리를 위한 BI 모니터링 시스템에 관한 연구 :(A)study on the BI monitoring system for big data processing :SAP Bl를 중심으로 =focused on SAP BI ",
		"AUTHOR": "연제용",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 박찬곤",
		"STORE_LOCATION": "청주대학교 도서관",
		"ABSTRACT": "Modern societies produce a tremendous amount of data which has a strong effect on business administration. It also is used in the analysis of business administration and corporate adopts BI system to produce results of the various types of analysis. But it is difficult to guarantee consistency of the performance and the data depend on the time on BI system based upon OLAP. Therefore, this paper has designed and developed BI monitoring system that could monitor BI system based upon OLAP. BI monitoring system(BI-EMS) is able to monitor BI as software and BC as hardware both and it monitors three fields at a time, nine fields in total. First, Query Runtime Statistics monitor the result of analysis of OLAP system and produce Query Runtime, DB Access speeds, Data Extraction speeds, computing time of multi-dimensional results of the analysis, etc. Second, Data Load status monitors whether it is extracted from the source system to the target system. Third, Query Load Statistics monitor results of OLAP system such as Process Chain, Master Data, Transaction Data, etc Fourth, Database Statistics set the Database Statistics and monitor the time to the Database Statistics through monitoring physical storage space on the current system. Fifth, Workload Statistics monitor the status after populating data in BI that can monitor CPU time, average delayed time, average loading time, database queries(requests), GUI time, Rollup time, Rollout time, etc. Sixth, Operating System Monitor monitors Pick Time, usage rates and more details of CPU, Memory, Swap, Lan, etc. BI-EMS is applicable for other systems and a versatile GUI design including OLAP system. Further studies will be carried out on mobile and cross browsing.",
		"KEYWORD": "BI Monitoring,Monitoring,OLAP,Qeury Performance,SAP BI"
	},
	{
		"ID": 60,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한남대학교 대학원",
		"TITLE": "하둡을 이용한 빅데이터 분산 처리 환경의 보안 프레임워크 =(The)security framework of big data distributed processing environment using Hadoop ",
		"AUTHOR": "이재필",
		"REGION": "대전",
		"PROFESSOR": "한남대학교 논문은 저작권에 의해 보호받습니다. 지도교수:이재광 참고문헌: p.73-74",
		"STORE_LOCATION": "한남대학교 도서관",
		"ABSTRACT": "The service creation of the high value added is expected since IT including the improvement of quality of the life, medical cost down, and etc. technology is grafted with the development of ICT technology. While the internet utilization put through the smart mobile apparatus increases, it is numerous atypic data generated. This atypic data is collected, and we analyze and the storage is 3V form of the big data, as if importance of Value creation is emphasized in addition to the Velocity and Variety. around the globe, the concern about the wellness increases. and this area is expanded through the fusion between industrial fields contain and diverse the IT area. The Hadoop studied in this paper is the technology searching the way converting to the insight and value with amount of medical data increased a rapid development to be complicated. The security vulnerability of the wireless environment was solved between the smart mobile device and HIS. By using Hadoop, the security framework secrecy model in which the big data distributed processing is possible was presented. In the Hadoop, in order that the effort that it improved the treatment through the data analysis wide of the biometric information which the real-time is generated and it cuts down the medical cost was solved, the model applying the big data analysis and security based on the human body wireless network was presented. For this purpose, data transmission of the biometric information and query was converted from the smart mobile device in the form of SGM and HIGHT was applied. The encryption was applied in the environment of the low performance of the smart mobile device by transmitting to HIS. If Hadoop the biometric information big data analysis outcome is used, the diagnosis which is safe and exact can be rapidly dropt in the smart mobile device and HIS. Through this, we expect in establishing the foundation enhancing the convenience of the medical service and efficiency.",
		"KEYWORD": null
	},
	{
		"ID": 61,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "빅데이터 분석을 통한 물동량 분석 예측 모델에 관한 연구 :Developing estimation models for delivery quantity prediction analysis through big data analysis : based on the case of K company ",
		"AUTHOR": "이지홍",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진수 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 연구는 빅데이터를 제공하는 사업자가 빠르게 증가하고 있고, 최근 물류 업계는 빅데이터에 주목하는 것을 바탕으로 하여 물류에 신기술을 접목한 자원 운영의 효율화를 달성하고자 한다. 또한 빅데이터의 특징은 정형과 비정형 데이터의 정확한 분석을 통하여 결과를 활용하는데 있다. 최근 물류업에는 차량 정보, 위치정보, 온습도 정보 등 시스템과 데이터의 엄청난 이동을 하고 있으나 이런 비정형 데이터에 대한 수집 이후의 명확한 분석을 할 수 없었다. 빅데이터의 분석을 통해 SCM 상에서 일어나 일련의 데이타의 흐름을 비교 분석하여 물류 고유의 문제를 해결하고 고객의 트렌트 파악과 자원의 효율적 활용에 좋은 매개체가 되고 이것은 향후 고객 관리 및 마케팅 활동과 기업 내부 개선 활동에 영향을 주고 기업의 장기 수익 개선에 기여할 수 있다. 국내 선두 물류 회사인 K사의 230여개의 sub 터미널의 2013년 5월부터 2015년 6월까지의 데이타를 기초로 하여 수작업 및 경험적 판단에 의존한 배차 예측에서 sub 물동량 및 변수가 반영된 Data 기반의 배차로 개선하여 자원의 효율적 활용을 하고자 함에 의의가 있으며, 기본 데이터를 기준으로 마트를 구성하고, 각 서브의 물동량과 서브별 중요도에 따른 군집을 나누었다. 기존에 연구된 시계열 분석과 회귀분석을 통하여 기초 물동량을 분석 하였고, 물류의 특성을 가지는 변수를 추가하여 새로운 모델을 생성하여 예측 정확도를 높였으며, 시뮬레이션 학습을 통한 최적의 예측 모델을 도출 하였다. 물동량 예측을 통한 물류 예측은 자원의 효율적 사용과 물류 서비스 시장의 변화를 반영하며 수요변화에 대한 대응방법을 키울 수 있는 방법을 제안 하였다. 마지막으로 수요 예측은 월간 및 년간 예측을 통하여 물류 자원 확보와 수요변화에 따른 영업 경재력 강화 전략 수립에 대한 회사운영 활동의 의사결정과정에 사용할 수 있는 물동량 예측 방법을 제안 하였다.",
		"KEYWORD": null
	},
	{
		"ID": 62,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "건국대학교 정보통신대학원",
		"TITLE": "빅데이터 분석 사업의 정보시스템 감리에 대한 연구 =(A)study on the information system audit for bigdata analysis business ",
		"AUTHOR": "박성남",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 서희명",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "빅데이터 시대가 도래되면서 공공기관과 기업체에서 빅데이터의 활용성이 높아지고 수요도 증가하고 있는 반면 빅데이터분석 사업에 적용 할 수 있는 표준화된 감리 점검항목이 없어 빅데이터분석 사업을 감리 하기에 어려움이 있다. 시스템개발(SD)사업의 감리점검항목은 있지만 빅데이터분석 과정에서 나타나는 특성들을 효과적으로 점검하지 못하므로 빅데이터분석(BDA) 사업에 적용하기에 적합하지 않다. 위와 같은 배경을 고려하여 본 연구에서는 빅데이터 분석 사업를 감리 할 수 있는 빅데이터분석 감리 점검 프레임워크와 감리점검 항목을 도출 하였다. 우선 데이터베이스 진흥원에서 제공하는 빅데이터분석 전문가 가이드를 참조하여 빅데이터 분석 절차를 요건정의, 모델링, 시험, 전개 4단계로 구분하고 각 단계에서 해야 할 일에 대해 정의 하였다. 빅데이터 분석 절차와 같은 단계로 감리 점검 프레임워크와 감리점검 항목을 도출 하였다. 감리시점은 요건정의/모델링/시험/전개 4단계로 정의 하였고, 감리영역은 요건정의 시점과 모델링 시점에서는 데이터베이스/응용시스템으로, 시험 시점에서는 시험활동으로, 전개 시점에서는 운영준비 영역으로, 그리고 공통영역으로 품질보증활동을 정의하였다. 감리 점검 항목은 요건정의 시점에서는 9개의 점검항목과 세부점검항목, 모델링 시점에서는 9개의 점검항목과 세부점검항목, 시험 시점에서는 5개의 점검항목과 세부점검항목, 전개 시점에서는 5개의 점검항목과 세부점검항목을 도출 하였다. 본 연구에서 도출 된 빅데이터분석 감리 점검 항목에 대해 설문조사 방법으로 데이터분석전문가와 정보시스템감리원을 대상으로 필요성/ 적합성/충분성 3가지 항목으로 실효성 검증을 실시한 결과 필요성/적합성에 비해 충분성이 다소 낮은 평가를 받아 많은 경험을 토대로 세부 점검 항목 도출에 더 많은 연구가 더 필요하다.",
		"KEYWORD": "빅데이터 분석 감리,빅데이터 분석 방법론,빅데이터 분석 사업,빅데이터 분석 사업 감리,빅데이터 분석 절차"
	},
	{
		"ID": 63,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "빅데이터를 기반으로 하는 배제남용 행위의 위법성 판단기준 연구 :소비자 선택(Consumer Choice) 기준의 적용을 중심으로 ",
		"AUTHOR": "강정희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 홍대식 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "As society progresses more, new areas which was never considered as markets in the past, began to be included into market economy. In the industrial society price competition based on production and sale of goods was the central factor, but today non-price competition market is emerging as main stage. In recent years big data was the main issue of the digital economy. Development of information communication technology(ICT), increase of digital devices and enlargement of base of the internet of the things(IoT) and social networks made the types and amounts of produced or collected data grow rapidly. So it may be fairly said the competitiveness of digital economy depends on possession and practical use of data. Google and FaceBook are typical examples who developed new services and business models using big data in ICT ages. Because possession of massive amount of data and ability to analyze the data could help companies gain competitive superiority in market, cases often happen where companies use anti-competitive ways in order to gain data or they encroach on personal information. Especially blocking or disturbing the other businesses` accesses to data would have the effect of hindering the competition or excluding other rivals. However illegality determination of exclusionary abuse is mainly done with price or effectiveness approach, so we eventually face the problem, that illegality determination could not be easily done in non-price markets where arithmetical evaluations are hardly done. The authorities of the U.S. and Europe investigated the abusing of the market dominant position of Google, the representative global internet portal business. In the U.S. the investigation was over, which could not find any illegality but in Europe preliminary examination report which highly put suspicion of illegality of Google, was issued and the procedure is still on. Among the discussions related the authoritative investigation, it was never argued the normative analyzation about practical uses of data, which is the central competitive factor of the Internet platform business. I think it is all due to the absence of the measurement of illegality determination in the non-price competition market. The ultimate role of competition law would be supporting the market competition so that valuable choices could be given to consumers, and ensuring that the ranges of the choices will not be hampered or distorted by the anti-competitive practices. Choices should be include the timing of the supply, forms, shapes of goods or services as well as price, and the quality of choices should be determined with the various consumers` positions. In that case, consumers using the Internet platform services must be able to choose to pay money instead of their personal information for the services and use e-mail or search engines which have no online advertisements. If a company do not give consumers such rights to choose in order to gain profit by using the service users` data in other platform such as online advertisement, that must be considered in the illegality determination. In this paper, I introduce `consumer choice` and try to apply it to the competition law enforcement in the digital markets as a supplementary standard, in the cases where the illegality determination could hardly be done with only existing current price-effectiveness standard in the new areas such the Internet platform market based on big data. I cover the personal information encroachment issues caused by commercial exploitations of big data and the limitations of the existing current illegality determination standard related to exclusionary abuse conduct. And later I give legislative improvement proposal which can facilitate consumer choice standard with the existing current standard on the abuse of dominant position, by examining of consumer choice paradigm.",
		"KEYWORD": null
	},
	{
		"ID": 64,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅데이터 시대의 SNS 마케팅을 위한 타겟팅 최적화에 관한 연구 =(A)study on targeting optimization for SNS marketing in big data era ",
		"AUTHOR": "유성열",
		"REGION": "서울",
		"PROFESSOR": "지도교수:전문석",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 데이터의 범람과 더불어 빅데이터 시대가 도래 하면서 SNS라는 새로운 플랫폼을 마케팅에 활용하고자하는 기업들이 늘어나고 있다. 기업들은 이러한 SNS상의 데이터를 분석하고 이를 공개API를 통해 마케팅에서 활용할 수 있다. 하지만 SNS업체들은 과도한 트래픽 유발 및 보안상의 이유로 공개API의 사용을 제한하고 있다. 따라서 제한된 사용 횟수 안에서 효과적으로 공개API를 사용할 수 있는 타겟팅 최적화가 필요하다. 기존의 멀티캐스팅을 이용하면 이러한 타겟팅 최적화가 가능하지만 SNS의 특성을 반영한 것이 아니기 때문에 SNS마케팅에서 활용하는 데는 한계가 있을 수밖에 없다. 본 논문에서는 이러한 멀티캐스팅를 이용한 타겟팅 최적화의 한계를 보완하고 SNS의 특성을 보다 잘 활용할 수 있는 새로운 SNS마케팅을 위한 타겟팅 최적화를 제시한다. 최종 선정된 방안들이 여러 가지나왔음에도 선정기준이 존재하지 않는 멀티캐스팅을 단점을 보완하고, 트위터의 리트윗과 페이스북의 좋아요와 같은 재확산기능을 가지는 SNS의 특성을 반영하였다. 또한 메시지를 전달 받는 고객들의 확산 범위를 고려함으로써 최종적으로 보다 많은 인원들에게 메시지가 전파되도록 유도하였다. 고객프로파일링을 통해 선정된 캠페인 대상 고객 정보를 가지고, 멀티캐스팅을 이용한 타겟팅 최적화와 새롭게 제시된 SNS를 위한 타겟팅 최적화를 각각 실시해 보았다. 실험 결과 멀티캐스팅 기법을 이용한 타겟팅 최적화에 비해 새롭게 제시된 타겟팅 최적화를 이용할 경우, 상대적으로 수신율은 8% 높게 나타났고 확산범위는 약 8배가 더 많은 것을 확인하였다. SNS마케팅에서 제한된 전달횟수를 가지고 보다 많은 인원에게 마케팅 메시지를 전달하기 위해서는 타겟팅 최적화가 필요하며, 이러한 타겟팅 최적화는 SNS의 특성을 충분히 고려해야만 한다. 본 논문에서 제안한 SNS마케팅를 위한 타겟팅 최적화에서는 이러한 SNS의 제약사항 및 빠른 확산속도 등을 고려하여 수행되며, 이는 점차 수요가 늘어가고 있는 SNS마케팅 분야에서 효과적으로 활용할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 65,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "공공개방데이터 활용을 위한 빅데이터 기반의 소프트웨어 아키텍처 설계에 관한 연구 =(A)study on bigdata-based software architecture design for utilizing public open data ",
		"AUTHOR": "방승열",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김창재 참고문헌: p. 44-45",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "정부는 빅데이터를 기반으로 공공산업과 민간에 공공데이터를 적극적으로 공유 및 개방하여 국민에게 맞춤형 서비스 제공에 힘쓰고 있다. 또한, 공공데이터포털(data.go.kr)을 이용하여 Open API, 자료제공, 시각화 등을 통하여 국민에게 공공서비스를 제공하고 있다. 그러나 이러한 정부의 공공데이터와 빅데이터 개방 노력에도 불구하고 이를 분석 및 활용할 수 있는 아키텍처가 부족한 실정이다. 따라서 본 연구에서는 공공데이터 활용을 위한 빅데이터 기반의 소프트웨어 아키텍처 모델을 제안한다. 제시하는 빅데이터 기반의 소프트웨어 아키텍처는 서비스 설계, 업무요건 및 프로세스 정의, IT 시스템 개발의 절차로 설계하였다. 제시한 모델을 검증하기 위해 본 연구에서 제안한 모델을 적용하여 시나리오를 구현하였다. 본 연구를 통해 민간의 창의적인 아이디어를 결합하여 가치 있는 일자리 창출과 경제적인 부가가치 창출은 물론 새로운 서비스를 개발하여 대국민 서비스 및 경제 성장에 밑거름이 되기를 기대한다.",
		"KEYWORD": "공공데이터,빅데이터,소프트웨어아키텍처"
	},
	{
		"ID": 66,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 대학원",
		"TITLE": "클릭스트림 빅데이터 마이닝을 활용한 인터넷 사용자의 인구통계특성 예측 =Predicting Internet user`s demographics through clickstream big data mining ",
		"AUTHOR": "박지애",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 조윤호 참고문헌: p. 47-50",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "인구통계특성 정보는 디지털 마케팅의 핵심이라 할 수 있는 인터넷 사용자에 대한 타겟 마케팅 및 개인화된 광고를 위해 고려되는 가장 기초적이고 중요한 정보이다. 하지만 인터넷 사용자의 익명 활동 증가와 허위 기재된 설문 조사의 위험성으로 인해 인구통계특성 정보를 수집하는 일은 점차 어려워지고 있다. 반면, 인터넷 사용자의 온라인 활동을 기록한 클릭스트림 데이터는 해당 사용자의 인구통계특성 예측에 활용될 수 있다. 특히, 온라인 행위 특성 중 하나인 페이지뷰는 인터넷 사용자의 인구통계특성 예측에 있어서 중요한 요인이 된다. 본 연구에서는 기존 선행 연구를 토대로 클릭스트림 데이터 분석을 통해 인터넷 사용자의 온라인 행위 특성을 추출하고 이를 해당 사용자의 인구통계특성 예측에 사용한다. 또한, (1)의사결정나무를 이용한 변수축소, (2)주성분분석을 이용한 변수축소, (3)군집분석을 활용한 변수축소의 방법을 제안하고 실험에 적용함으로써 많은 설명변수를 이용하여 예측 모델 생성 시 발생하는 차원의 저주와 과적합 문제를 해결하고 예측 모델의 정확도를 높이고자 하였다. 실험 결과, 범주의 수가 많은 다분형 종속변수에 대한 예측 모델은 모든 설명변수를 사용하여 예측 모델을 생성했을 때보다 본 연구에서 제안한 변수축소 방법들을 적용했을 때 예측 모델에 대한 정확도가 높아짐을 알 수 있었다. 본 연구는 클릭스트림 분석을 통해 추출된 인터넷 사용자의 온라인 행위가 해당 사용자의 인구통계특성 예측에 활용 가능하며, 예측된 익명의 인터넷 사용자들에 대한 인구통계특성을 디지털 마케팅에 활용할 수 있다는데 의의가 있다. 또한, 어느 종속변수에 대해 어떤 변수축소 방법을 적용했을 때 예측 모델의 정확도가 가장 높은지를 확인하였다. 이는 추후 클릭스트림 분석을 활용하여 인구통계특성을 예측할 때, 본 연구에서 제안한 변수축소 방법들을 사용하여 보다 높은 정확도를 가지는 예측 모델을 생성할 수 있다는데 의의가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 67,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 도시과학대학원",
		"TITLE": "소셜네트워크 공간빅데이터를 이용한 활동기반 교통모형 분석자료 구축에 관한 연구 =(A)study on the data base construction for the operation of activity-based traffic model using spatial big data from social networking service ",
		"AUTHOR": "김승현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이승재",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "오늘날 인터넷 사용의 급격한 증가, 스마트폰 보급, SNS(Social Networking Service) 활성화 등과 같은 디지털 기술의 발전과 모바일 기기의 보급 등으로 인해 우리 주변에는 규모를 가늠할 수 없을 정도로 많은 정보와 데이터가 생산되는 ‘빅데이터(Big Data)’의 시대가 도래 했으며, 그 중요성이 날로 커지고 있다. 교통분야에서는 오랜시간동안 우세를 점하고 있었고 도시교통개발에 효과적인 추정 방법으로 여겨졌던 전통적인 통행기반교통모형(Trip-Based Model)인 4단계 교통수요추정법의 한계가 드러나고 있으며, 최근의 컴퓨터 기술의 빠른 성장에 힘입어 활동기반교통모형(Activity-Based Model)을 이용한 수요 추정 방법이 교통계획에 새로운 패러다임으로 떠오르고 있으며, 연구가 활발히 진행되고 있다. 교통은 사람이나 물류의 공간상의 시간적 이동을 의미한다고 봤을 때 공간데이터와 밀접한 관련이 있으며, 최근 급부상하고 있는 공간빅데이터(Spatial Big Data)와 접목될 수 있는 분야이다. 따라서 소셜네트워크 서비스(SNS)상의 공간빅데이터를 추출해 현재 사용되고 있는 통행기반교통모형(Trip-Based Model)의 특성과 비교?분석하고 나아가 활동기반교통모형(Activity-Based Model)의 분석자료를 구축하여 공간빅데이터와 활동기반교통모형을 접목시킨다면 매우 큰 가치가 있을 것으로 생각된다. 따라서, 공간정보를 포함하고 있는 SNS를 대상으로 시계열적 공간정보를 추출하고, 이를 현재 사용되고 있는 통행기반교통모형(Trip-Based Model)의 OD와 비교?분석하여 그 특성을 파악하고, 활동기반교통모형(Activity-Based Model)의 분석자료를 구축하여 교통시뮬레이션 프로그램을 이용해 시뮬레이션을 수행하였다. 연구결과 제도적 제약에도 불구하고 다수의 활동기반 교통모형 분석자료를 구축할 수 있었고, 교통수요추정 시뮬레이터인 MATSim을 성공적으로 실행할 수 있었다. 이번 연구로 인해 교통분야에 있어 빅데이터 활용의 기술적 한계를 극복할 수 있는 가능성을 확인하였고, 향후 발전방향을 모색하는 기회가 되었다.",
		"KEYWORD": "MATSim(Multi-Agent Transport Simulation),공간빅데이터(Spatial Big Data),빅데이터(Big Data),소셜네트워크 서비스(SNS) 분석,통행사슬(Trip chain),활동기반 교통모형(Activity- Based Model)"
	},
	{
		"ID": 68,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "빅데이터 마이닝에 의한 공시지가 민원의 시공간적 특성 분석 =Spatiotemporal characteristics analysis of complaints on officially assessed land price by big data mining ",
		"AUTHOR": "조태인",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 최병길",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "최근 다양한 분야에서 다량의 정형 및 비정형 자료, 즉 빅데이터를 분석하여 자료의 연관성을 규명하고 미래전략을 수립하는 방법이 활용되고 있다. 공시지가의 경우에도 지역적 및 시간적으로 다양하고 복잡한 민원이 제기되고 있어 빅데이터를 활용하여 이를 효과적으로 분석하고 관리하는 방법에 관한 연구가 필요하다. 이 연구의 목적은 빅데이터 마이닝에 의해서 공시지가 민원의 시공간적 특성 분석 방법을 정립하는 것이다. 특히 이 연구는 제도적인 측면보다는 공시지가 민원 발생의 시공간적 원인 분석에 주안점을 두고, 그 변화 추세를 모니터링 할 수 있는 표준화 모델을 정립하고자 하였다. 연구 수행을 위해서 빅데이터 마이닝에 의한 공시지가 민원의 시공간적 특성 분석 표준화 모델을 정립하였다. 그리고 시간과 공간적인 속성을 함께 포함하고 있는 2006년부터 2015년까지의 인천광역시 중구의 공시지가 민원자료 6,481건을 수집하고, 이것을 공간정보와 결합하여 공간 빅데이터 기반의 공시지가 민원정보 데이터베이스를 구축하였다. 텍스트 마이닝 방법을 이용하여 주요 키워드의 빈도를 분석하고, 소셜 네트워크 분석을 통해서 주요 키워드들의 상호 연관성을 파악하였다. 키워드 가중치를 산출하여 공시지가 민원발생 관심 키워드를 선정한 후, 국지적 자기상관의 지표인 G 통계량(Getis-Ord Gi*)을 적용한 핫스팟 분석을 통하여 시공간적 특성을 분석하였다. 연구 결과, 공시지가 민원의 특성은 시공간적으로 연계된 군집 형태를 형성하면서 변화하고 있음을 알 수 있었다. 텍스트 마이닝과 소셜 네트워크 분석 방법을 이용하여 자연어 기반의 공시지가 민원에 대한 발생 원인을 정량적으로 규명할 수 있음을 알 수 있었으며, 키워드 가중치인 단어 빈도(TF) 및 단어 빈도와 역문서 빈도의 조합값(TF-IDF)의 상대적인 차이가 있어 시공간적인 민원 특성을 분석하기 위한 주요 설명변수로 활용될 수 있음을 알 수 있었다.",
		"KEYWORD": "공시지가,민원,빅데이터 마이닝,소셜 네트워크 분석,시공간적 특성,텍스트 마이닝,핫스팟 분석"
	},
	{
		"ID": 69,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 관광대학원",
		"TITLE": "빅데이터 기반 레스토랑 평가 애플리케이션의 특성과 이용동기가 소비자 이용의도에 미치는 영향 =The effect of the intention of consumer use on characters and usage motivation of restaurants evaluation application based on big data ",
		"AUTHOR": "임영희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김홍범",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "새로운 기술의 등장은 사람들로 하여금 관심을 갖게 하는데, 그 기술이 보여주는 특성에 따라 주목을 받거나 혹은 외면당할 수 있으며 사람들이 그 기술을 받아들이는 능력 등 개인적 특성에 따라 활용 정도가 달라지고 어떤 용도로 그 기술을 사용하느냐에 따라 효능도 달라진다. 그러므로 본 연구에서는 새로운 기술인 빅데이터를 기반으로 하는 레스토랑 평가 애플리케이션의 기술적 특성과 그 기술을 받아들이는 사람들의 개인적 특성, 그리고 이용 동기에 대해 알아보고 이러한 새로운 기술이 사람들에게 유용한지, 그리고 다시 사용할 의도가 있는지를 연구하고자 하였다. 이러한 연구 목적을 달성하기 위하여 선행논문들을 통해 연구한 결과, 기술적 특성을 정보품질과 시스템 품질로 나누었고, 개인적 특성을 자기효능감, 개인혁신성, 지식으로 나누었으며, 이용동기를 사회적 동기, 기능적 동기 및 유희적 동기로 각각 분류하였다. 그리고 이러한 특징들이 지각된 유용성에 미치는 영향력과, 그것이 이용의도에 미치는 영향에 대해 연구하는 것으로 설계하였다. 본 연구를 위한 조사에서는 ‘레스토랑 평가 애플리케이션’을 사용한 경험이 있으며 레스토랑을 선택하고 결정할 수 있는 성인을 연구의 모집단으로 규정하였다. 그러나 만일 ‘레스토랑 평가 애플리케이션’을 사용한 경험이 없는 사람이라면 애플리케이션을 사용할 충분한 시간을 제공하고 필요에 따라서는 사용법도 알려주어 사용경험을 갖도록 한 후에 설문을 하도록 하였다. 애플리케이션 이용자들로부터 받은 설문지 중에 250명의 데이터를 유효표본으로 확보하였다. 직접 설문지를 배포하거나 구글 온라인 설문지를 통하여 2016년 9월 1일부터 2016년 9월 30일까지 1개월 간 조사를 실시하였다. 분석방법으로는 표본의 일반적 특성을 확인하기 위해 빈도분석을 실시하였으며, 측정변수의 기본적인 분석을 위하여 기술통계분석을 실시하였다. 또한 연구하고자 하는 개념들이 설문 응답자로부터 정확하고 일관되게 측정하기 위하여 신뢰도 분석, Cronbach’s α계수를 이용하여 측정하였다. 연구모형 및 가설을 검증하기에 앞서 확인적 요인분석과 상관관계분석을 실시하여 측정모형의 적합도를 평가하고 집중타당성, 판별타당성을 검증하였다. 그 다음으로 측정모형의 타당성을 거친 측정변수들의 공분산행렬을 토대로 구조방정식모형분석과 다중집단분석을 실시하여 잠재변수 간의 관계를 추정하고 가설을 검증하였다. 분석과정에 있어서 빈도분석, 기술통계분석, 신뢰도분석은 R Program을 사용하여 분석하였으며, 확인적 요인분석, 상관관계분석, 구조방정식 모형분석, 다중집단분석은 AMOS Ver. 22.0을 사용하여 분석하였다. 실증분석은 모두 유의수준 p<0.05에서 검증하였다. 본 연구에서 제시한 연구 문제에 대한 실증결과를 정리하면 다음과 같다. 첫째, 빅데이터를 기반으로 한 레스토랑 평가 애플리케이션에 대한 기술적 특성이 이용 의도에 영향을 미치는 기반은 어떠한 것들이 있는가? 이에 대한 연구 결과는 문헌 연구를 통해 도출한 두 가지 설명 요인, 시스템품질과 정보품질이었는데 이용의도에 미치는 인과관계에서 서로 다른 결과를 보여주었고 이들은 상호 독립적으로 의미 있는 설명 요소임을 입증하였다. 이 부분에서 특이한 점은 시스템품질이 지각된 유용성에 미치는 영향은 유의미한 것으로 나타나지 않았으나 정보품질이 지각된 유용성에 미치는 영향이 매우 큰 것으로 나타나 애플리케이션의 시스템품질에 상관없이 높은 정보품질은 애플리케이션에 대한 유용성과 이용 의도에 높은 영향을 줄 수 있다는 점이다. 이는 ‘레스토랑 평가 애플리케이션’의 이용자들은 ‘레스토랑 평가 애플리케이션’이 제공하는 정보의 정확도와 레스토랑에 대한 평점 및 정보의 일관성에 대해 매우 중요하게 생각하며 만족하고 있음을 반영한다. 둘째, 어떠한 개인적인 특성이 레스토랑 평가 애플리케이션의 이용 의도에 영향을 미치는가? 본 연구에서는 빅데이터와 SNS 마케팅에 관한 높은 지식을 가지고 있는 것이 빅데이터를 사용하는 애플리케이션을 이용하려는 의도에 긍정적인 영향을 미치는 강력한 요인으로 밝혀졌다. 이용 의도는 ‘지식’이라는 설명변수에 의해 직접적인 영향도 받고 지각된 용이성을 통하여 간접적으로 영향을 받아, 이는 평점에 대한 신뢰와 지식을 가지게 되면 애플리케이션을 더 믿고 사용하게 된다는 것을 의미한다. 셋째, 기존의 많은 연구들처럼 지각된 유용성은 이용의도에 정(+)의 영향을 준다. 이는 지각된 유용성으로 표현되는 편리성과 시간을 절약하게 해 주고 레스토랑과 메뉴를 선택하게 해 주는 변수들에 의해 레스토랑 추천을 원할 때 레스토랑 평가 애플리케이션을 이용 의도에 긍정적인 영향을 주게 됨을 실증하였다. 넷째, 레스토랑 평가 애플리케이션의 특성 요인들 중에서 정보품질, 지식, 기능적 동기 요인은 지각된 유용성에 정(+)의 영향을 주고 지각된 유용성은 이용의도에 정(+)의 영향을 미치고 있음을 밝혔다. 그리고 이들 중 정보품질과 지식 요인은 이용의도에 직접적인 정(+)의 영향이 주고 있는 것으로 밝혀져 지각된 유용성을 부분매개로 하여 이용의도에 영향을 미치고 있고, 기능적 동기 요인은 이용의도에 직접적인 영향을 미치고 있지 않으므로 지각된 유용성을 완전매개로 하여 이용의도에 영향을 미치고 있음을 알게 되었다. 마지막으로 응답자를 크게 IT관련 종사자와 타 직업군으로 분류를 하였는데 IT관련 종사자들은 시스템품질, 정보품질이 높으면 지각된 유용성도 높은 영향관계를 보여주었지만, 타 직업군은 정보품질에 대해서만 지각된 유용성에 정(+)의 영향을 주는 것으로 나타났다. 또한 IT관련 종사자는 유용성이 이용의도에 영향을 주지 않는 것으로 나타났으나 타 직업군은 유용성이 이용의도에 높은 영향을 보여주고 있음을 알게 되어, 직업군에 따라 확연한 차이를 보이고 있음을 알 수 있는 연구였다. 주요어: 빅데이터, 레스토랑 평가, 빅데이터 기반의 레스토랑 평가 애플리케이션, 지각된 유용성, 이용의도",
		"KEYWORD": null
	},
	{
		"ID": 70,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "Bankruptcy prediction modeling using qualitative information based on big data analytics =빅데이터 기반의 정성 정보를 활용한 부도예측모형의 구축 ",
		"AUTHOR": "조남옥",
		"REGION": "대한민국",
		"PROFESSOR": "지도교수: 신경식 Includes bibliographical references (p. 105-119)",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "기업의 부도 예측은 회계와 재무 분야에서 꾸준히 연구되고 있는 중요한 이슈이다. 전통적으로 부도 예측에 관한 연구는 주로 재무 변수를 중심으로 통계적 접근 방법 또는 인공지능 기법을 적용하여 모형 구축 기법 관점에서 모형의 성과를 높이는데 초점을 두어왔다. 그러나 재무비율과 같은 회계 정보는 재무제표 결산 시점과 신용평가 시점 간에 시차가 존재하고, 해당 산업의 경제적 상황과 같은 외부 환경적인 요소를 반영하기 어렵다는 한계점이 존재한다. 부도 예측을 위해 정량 정보인 재무 변수만을 이용하는 것에 한계가 있음에도 불구하고 정성 정보를 부도예측모형에 반영하기 위한 연구는 아직 미흡한 실정이다. 과거에는 다양한 정보 원천으로부터 정성 정보의 획득 및 처리가 가능한 기제가 정립되어 있지 않아 정성 정보의 활용이 제한적이었다. 최근에는 뉴스, 블로그, 소셜 네트워크 서비스(SNS) 등 웹상에서 수집 가능한 데이터의 양이 많아지고, 데이터의 유형이 비정형 텍스트인 데이터가 증가함에 따라 이를 분석할 수 있는 텍스트 마이닝 등의 빅데이터 분석 기법이 주목받고 있다. 이에 주가 예측 및 영화 수익 예측 등 경영 분야에 빅데이터 분석 기법을 적용하는 연구가 진행된 바 있다. 그러나 현재까지 웹상의 정성 정보를 활용하여 예측 모델링에 활용하기 위한 연구는 아직 초기 단계에 불과하며, 다양한 도메인에서 활용될 수 있도록 비정형 텍스트 데이터를 처리하기 위한 분석 방법론의 개발이 필요하다. 따라서 본 연구에서는 정량 정보를 이용한 기존의 부도예측모형의 예측 성과를 개선하기 위해 빅데이터 기반의 정성 정보를 결합한 부도예측모형을 제안하고자 한다. 부도예측을 위한 기본 모형을 구축하기 위해 기존의 많은 부도 예측과 관련된 연구에서 복잡한 비선형 패턴 분류 문제를 다루는데 우수한 성능을 보이는 것으로 검증된 인공신경망 기법을 사용하였다. 제안 방법의 성과는 정성 정보를 부도예측모형에 통합시키기에 적합한 정량 정보로 정보의 유형을 변환시키는 데 있다. 이에 본 연구에서는 정성 정보를 처리하기 위한 분석 기제로서 빅데이터 분석 기법 중 하나인 텍스트 마이닝을 활용하였다. 텍스트 데이터에 대한 감성 분석을 위해 형태소 분석 등 텍스트 데이터의 전처리 과정을 거쳐 경제 뉴스 기사 데이터로부터 도메인 중심의 감성 어휘를 추출하고, 각 어휘의 극성 및 감성 점수를 부여하였다. 또한, 단일 키워드 기반의 감성뿐만 아니라 경제 뉴스로부터 추출한 주요 토픽을 이용하여 부도예측모형에 토픽 기반의 감성을 반영하는 모형을 제시하였다. 본 연구의 실험 결과, 빅데이터 기반의 정성 정보를 전통적 부도예측모형의 입력 변수로 활용하는 것은 예측 성과를 높이는 데 효과적임을 입증하였다. 먼저, 경제 뉴스 기반으로 도출된 정성 정보인 감성 정보는 기업의 부도에 영향을 미치며, 특히 경제 상황에 대한 부정적 감정이 기업의 부도를 예측하는 데 예측 성과가 더 높은 것으로 나타났다. 또한, 경제 뉴스로부터 추출한 주요 토픽을 감성 정보로 변환하여 부도예측모형에 결합시킨 결과, 기존 부도예측모형의 성과를 개선하는 것으로 나타났다. 단일 키워드 기반의 감성 분석을 수행한 결과에 비해 경제 현상에 대한 해석이 용이하고, 별도의 감성 사전 구축 없이 이와 비슷한 수준의 예측 성과를 도출할 수 있었다. 본 연구는 경제 뉴스 기사로부터 추출한 정성 정보를 결합시킴으로써 부도예측모형에서 제한적으로 사용되고 있는 재무 변수 중심의 부도예측모형의 한계점을 보완한다는데 그 의의가 있다. 빅데이터 기반의 정성 정보를 활용함으로써 재무 변수에 비해 상대적으로 최신의 정보 및 해당 산업의 경제적 상황과 같은 외부 환경적 요인을 예측 모형에 반영할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 71,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국항공대학교 [항공·경영]대학원",
		"TITLE": "스마트 팩토리 구축을 위한 빅데이터 시스템 연구 =The research of big data system for smart factory ",
		"AUTHOR": "이유미",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이재환",
		"STORE_LOCATION": "한국항공대학교 도서관",
		"ABSTRACT": "본 논문에서는 제조현장의 자동화 시스템에서 설비가 동작 하는데이터를 분석하고 보다 효율적으로 관리할 수 있는 스마트 팩토리 구축에 관한 연구 결과에 대해 기술 하였다. 장비의 구동 시 생성되는 물리적 데이터를 ICT(Information and Communication Technology) 의 빅데이터 기술에 접목 하여 축적된 데이터를 바탕으로 신속하고 정확한 의사 결정을 가능하게 하는 것이 스마트 팩토리 구축의 목적이라 할 수 있다. 이에 본 논문에서는 현재 제조 현장에서 사용 되고 있는 제조 라인의 컨베이어 모터에 주목 하였다. 모터는 빈번하게 교체 되는 부품 중에 하나로서 모터 속도를 전기적 신호로 데이터화 하였다. 이 데이터는 빅데이터 클라우드에 전송 하였으며 데이터 베이스 구축과 데이터 분석을 통한 비 정상 운영 범위를 설정 하므로 비 정상적인 이벤트 상황에서 알람 발생을 가능 하도록 하였다. 최근 4차 산업을 시작으로 스마트 팩토리가 대두 되기 시작 하면서 공장내의 중요 자산이 작업자와 장비에서 데이터로 옮겨 지고 있다. 공장 내의 많은 물리적 데이터가 빅데이터에 저장된다면 데이터에 대한 용량, 장소 및 시간에 대한 제약을 받지 않을 것이다. 또한 취합된 데이터를 올바르게 분석하고 활용 할 경우 장비에 대한 예측이 가능 해 지고 운영 효율도 높아 질 것을 기대한다.",
		"KEYWORD": "빅데이터,스마트팩토리"
	},
	{
		"ID": 72,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "빅데이터 기반 시공간 센서 데이터 처리 시스템 =A big data based spatio-temporal sensor data processing system ",
		"AUTHOR": "김장수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이창훈",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "The application demand of spatio-temporal wireless sensor data due to the development of the computing related technology and the wireless sensor network is rapidly increasing. The spatio-temporal data collected in the sensor network can be used in various fields like environmental monitoring system, fire detection system, weather forecasting system and so on. Also the study on the query processing of these sensed data is actively being done. Among these query systems, there are Tiny DB and spatial TinyDB which were developed to process the query about the sensed data by the sensor node. But the existing query processing system does not support efficiently the spatio-temporal data type and the spatio-temporal operator to handle this kind of spatio-temporal data and there are some limits in the real time processing to deal with it efficiently, which are derived from the limited computing power resources of sensor node such as processor, memory and the battery. Due to this kind of problem, the existing study was focused on the area of the reduction of communication cost in the sensor network by reducing the communicaton bandwidth, saving the energy and reducing the use of flash memory. So the technology of in-network query processing to process the user query rather than the centralized query processing was mainly studied. The representative technology studied so far is routing protocol, query processing technique like joining strategy and data storing method such as local storage and data centric storage. The centralized query processing is the external processing way out of the network after collecting and saving the sensed data in the base station or sink node. The centralized data processing way can be preferred to the in-network processing for the complex query and big data analysis using the collected data. So in my thesis, I propose the combined way called hybrid way to meet these two needs. The way to improve the performance and efficiency in in-network processing was added to the existing query processing system to get the result of ad-hoc query efficiently as a front-end system and also I proposed the centralized processing system as a back-end system to get the result of complex query efficiently using the saved sensed data or historical data for the further big data analysis. I deployed and proposed the spatio-temporal data type and its operator in the existing spatial tinyDB for the efficient query by following the OGC(Open Geospatial Consortium) suggestion. Aso I proposed the input filtering module, memory sharing module to improve the performance of query in the front-end system. The back-end system to process the collected sensed data in a centralized way to overcome the limits of sensor node such as processor power, small memory and battery is also strongly needed for big data processing and analysis like regression analysis, correlation analysis, cluster analysis and time series analysis by distributing the sensed data and using the parallel processing. So in my thesis I proposed and implemented the Hadoop based sensor data processing system as a back-end system platform to address these kind of needs. The spatio-temporal data collecting from the various type of sensor node can be classified as a big data in the viewpoint of 3 characteristics of big data which are volume, velocity and variety, so the technology to process and analyse this big data is strongly needed. The process of big data is comprised of five steps which are the stage of aggregator, storage, processing, analysis and visualization and the big amount of data is handled at a time. At a glance, it looks like very simple but it requires high technology to go ahead for the in-depth analysis. So in this paper the Hadoop based back-end processing system supporting the distributed file system, parallel processing and the visualization processing using R program was introduced and suggested. The Hadoop based spatio-temporal sensor data processing system which is designed and implemented in this paper processes the big data through 5 steps consisting of aggregating, storing, processing, analysing and visualizing. The HDFS was adopted as a distributing file system and MapReduce was used to process the data parallely. And in the pre-refining stage of big data, the Pig and Hive which runs over the Hadoop was used and in the final stage the R program was used to analyse the big data and show the result visually. First in all, user defined spatio-temporal data type and its opertor was defined and used in the analysis step using R for the first time and the test result showed this proposed system can be useful in the various application.",
		"KEYWORD": "R,빅데이터,센서 데이터,시공간 데이터,하둡"
	},
	{
		"ID": 73,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 정보통신대학원",
		"TITLE": "빅데이터 기반의 자금세탁방지 시스템 연구 =(A)study on anti-money laundering system based on big data ",
		"AUTHOR": "김상완",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 함유근",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "빅데이터 시대가 도래 하면서 오늘날 기업은 단순히 많은 데이터를 보유하는 것은 의미가 없어지고 데이터가 조직의 목표에 부합하여 기업의 경쟁력을 높일 수 있도록 정보 시스템의 통합과 개선이 이루어지고 있다. 폭증하는 빅데이터를 바탕으로 신속한 의사결정과 비즈니스의 대응력을 높이기 위해 대/내외에 흩어져 있는 기업의 데이터에 대한 가치를 부여하고, 품질이 보장된 데이터를 새로운 비즈니스 기회와 다양한 부가가치 창출의 수단으로 활용 할 수 있지만 아직까지 국내 금융기관들의 빅데이터 적용 사례는 해외 사례와 다르게 소셜 네트워크 서비스를 활용한 평판 분석과 이상패턴 검출 정도로 미비하다. 본 논문은 타 산업에 비해 상대적으로 데이터 보유량이 많고 빅데이터 잠재가치가 높은 금융권에서 적용 가능한 빅데이터 기반 자금세탁방지 시스템에 대해 연구하였다. 아직 빅데이터를 활용한 자금세탁방지 시스템에 대한 연구사례를 찾을 수 없어 일부 카드사와 보험사가 이상패턴 검출과 부정사용 예방의 목적으로 빅데이터를 적용하고 있다는 점에 착안하여 빅데이터 사기방지 시스템을 연구 모델로 선정하였으며 기존의 사례를 바탕으로 자금세탁방지 업무에 적용 가능한 부분과 실제 어떠한 방법으로 시스템을 구축할 수 있을지 확인하고자 했다. 연구 결과 빅데이터를 활용한 자금세탁방지 시스템은 기존의 자금세탁방지 시스템에서 추가적으로 소셜 네트워크 서비스나 로그 파일 등의 다양한 데이터 소스를 수집하고 수집된 데이터를 바탕으로 일부가 아닌 전체 데이터를 대상으로 빠른 속도로 거래 모델의 검증과 빅데이터 분석이 가능하고 실제 자금세탁 업무에 활용이 가능하다. 빅데이터 기반 자금세탁방지 시스템은 비정형 데이터인 소셜 네트워크 서비스 데이터와 기존 거래나 고객정보를 통합하고 소셜 네트워크 분석 방법을 적용하여 고객확인 의무 기능, 빅데이터 분석 인프라를 이용하여 룰 모델이나 거래패턴 스코어링 모델을 빠르게 개발하고 검증하고 실시간으로 혐의 거래 적발이 가능한 실시간 자금세탁 거래 모니터링 기능, 다양한 데이터 소스로부터 링크 분석이 가능하도록 도와주는 빅데이터 시각화 분석 기능, 혐의 거래 조사 분석과정에서 발생하는 데이터들을 통합 관리하여 추후에 사례관리에 활용이 가능한 빅데이터 자금세탁 사례분석 기능, 최근 개인 정보 보호를 위해 영업점이나 조사 분석을 수행하는 내부 직원의 정보유출 이상 징후를 파악할 수 있는 빅데이터 통합 정보 보호 모니터링 기능 등의 목적으로 구축되어 활용될 수 있다. 아직까지 국내 뿐 만 아니라 해외에서도 빅데이터를 활용한 자금세탁방지 시스템의 사례에 대한 자료를 찾을 수가 없기 때문에 기존 자금세탁방지 시스템의 상세 기능을 파악하여 문제점을 도출했고 빅데이터를 통하여 해당 문제점을 개선할 수 있는 시스템 구축 방안을 제시 한 것으로 본 연구의 의의가 있다고 할 수 있다.",
		"KEYWORD": "금융 빅데이터,빅데이터,빅데이터 시각화 분석,빅데이터 실시간 거래 모니터링,빅데이터 정보 보호 모니터링,자금세탁방지 시스템"
	},
	{
		"ID": 74,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "상지대학교 대학원",
		"TITLE": "빅데이터와 융합한 웨어러블 디바이스 기반 예방의학에 관한 연구 =(A)study on wearable devices based preventive medicine fused with big-data ",
		"AUTHOR": "박현석",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 홍유식",
		"STORE_LOCATION": "상지대학교 학술정보원",
		"ABSTRACT": "의학기술 발달, 소득 증가 및 이로 인한 생활수준 향상 등으로 사회가 고령화 되면서 수명은 늘어나고 그와 더불어 질병에 노출되고 질병 치료를 위한 진료비가 급격히 늘어나고 있는 추세이다. 본 논문에서는 빅데이터와 융합한 웨어러블 디바이스 기반의 신체정보를 수집 분석하여 질병의 예방 및 초기 치료을 위한 시나리오 방안을 제시하고자 한다. 시나리오는 웹기반의 시나리오와 웨어러블 기기를 활용한 시나리오 2건, 총 3가지의 시나리오를 제시하며 향후 나아갈 방향을 제안하였다.",
		"KEYWORD": "빅데이터,시나리오,신체부착형 웨어러블,웨어러블"
	},
	{
		"ID": 75,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2012",
		"UNIVERSITY": "동국대학교 대학원",
		"TITLE": "Hyperstream: high performance parallel data processing system for big data =하이퍼스트림: 빅데이터 분석을 위한 고성능 병렬 처리 시스템 ",
		"AUTHOR": "조시원",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권에 의해 보호받습니다. 지도교수:이동욱",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "IT융합기술의 발달과 기술의 고도화로 축적되는 정보가 다양해지고 있다. 이러한 정보들은 비정형적이고 양이 급증하는 속성을 가지고 있어 ‘빅데이터(Big Data)’라고 불린다. 빅데이터는 기존의 관리, 분석 체계로 처리하기 어려운 막대한 양의 데이터로 최근에는 이러한 데이터를 처리하는 도구나 플랫폼, 분석 방법까지 포괄하는 용어로 불리고 있다. 빅데이터의 특징은 일반적으로 규모(Volume), 다양성(Variety), 속도(Velocity)로 나타난다. 빅데이터는 기존의 데이터와는 규모 면에서도 차이가 나지만, 데이터의 형태가 대부분 비정형화되어 있으며, 사용자의 다양한 심리와 요구사항 변화를 담고 있다. 나아가 사회 변화에 대한 정보도 포함하고 ㄴ있다. 데이터 분석은 연구 개발 및 기업 경쟁력 강화, 생산성 향상에 중요한 역할을 한다. 이러한 빅데이터를 어떻게 분석하고, 활용할 것인지에 대해서 관심이 집중되는 것은 당연하다. 빅데이터 분석에서는 효과적인 병렬 분산 알고리즘과 확장성과 성능을 만족하는 병렬 처리 시스템이 주요한 핵심이다. 본 논문에서는 GPGPU와 MapReduce 기반의 프레임워크인 HyperStream을 설계하고, 구현하였다. GPGPU는 컴퓨터 그래픽스를 위한 계산을 다루는 GPU를 사용하여 기존 CPU가 담당했던 응용 프로그램들의 계산을 수행하는 기술이다. MapReduce는 대용량의 정보검색을 위해 구글에 의해 개발된 분산 프로그래밍 프레임워크이며, 네트워크에 접속된 다수의 컴퓨터들을 통합하여 하나의 병렬 컴퓨팅 환경을 구축한 시스템 환경이다. HyperStream은 GPGPU 분야의 표준 라이브러리 OpenCL과 병렬 분산 처리에 사용되는 MPI 라이브러리를 이용하여 구현하였으며, 분산 파일 시스템과 분산 메모리 시스템을 지원한다. 또한, 본 논문에서는 HyperStream을 이용하여 분산병렬처리 기법을 적용한 한국어 형태소 분석기와 의미 관계 분석 모델을 제안한다. HyperStream을 이용한 한국어 형태소 분석기와 의미 관계 분석기를 구현하여, 대용량의 데이터를 분석하고, 그 성능을 확인하였다.",
		"KEYWORD": "Big Data,Parallel Data,Parallel Data Processing"
	},
	{
		"ID": 76,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "빅 데이터(Big Data)시대 소비자 개인정보 보호법제의 문제점과 개선방안에 관한 연구 =(A)study on consumer personal information in the era of big data :problems and potential remedies ",
		"AUTHOR": "최은진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신현윤",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Today, with development of Information Technology(IT) and the advent of smart mobile age, any member of the society can access to various services including shopping, education, finance, and communication, and it is available to deal with more works efficiently than in the past. Though smart devices have come in handy just shortly ago, the use of these devices makes computer always portable and use it anytime and anywhere by changing its user environment and culture completely. Popularization of smart device, the Internet of Things, Online to Offline(O2O) service, Near Field Communication(NFC), and Beacon service have enabled companies to use a variety of marketing strategies through application of them. Therefore, data, which was just collected or stored as information in the past, now pervades into our daily lives. With development of IT, means to collect personal information and to create new one become diverse and the amount of such data is also huge. The collected data is processed into a new information through storage, analysis and sharing with new values, and we call it `Big Data`. Big data, demonstrating its values of utilization as one of the `Top 10 core technologies of IT`, is now used effectively in various industrial areas as well as public sectors including medicine, education, election, counter-terrorism and cyber security. However, Big Data may infringe privacy personal information in a way that was unexpected in the past. In particular, because of the spread of personal portable smart devices today, such information saved in real-time may be leaked and this risk is becoming more significant. In addition, we barely recognize importance of its protection. Service providers usually do not seek consent from their users and to do so is difficult. Therefore, the existing legal principles on personal information are not sufficient to solve these problems. In such a situation, foreign countries put various efforts to protect personal information in this Big Data environment. For example, the Europe Union(EU) revised its General Data Protection Regulation and e-Privacy Directive to seek balance between strengthening information subject`s right and for utilizing Big Data, while the United States, in favor of autonomous regulations. The White House and Federal Trade Commission are leading efforts to protect privacy of consumers through policy-making. Japan, whose legal system is similar to Korea, is about to revise its personal information protection act to prepare for the Big Data environment. Accordingly, Korea should also prepare for infringement of various customer personal information and review whether proper legal and institutional instruments against infringement of customers` well-being in the age of Big Data are actually established. Then, Korea needs to make its effort to recover customers` rights and provide solutions to establish and maintain function of efficient market economy and balanced development of national economy.",
		"KEYWORD": "act on promotion of information and communications network utilization and information protection etc,big data,consumer protection,consumers` rights,opt-in,opt-out,personal data self-determination,personal information protection act,right to be forgotten and to erase,개인정보 자기결정권,개인정보보호법,빅 데이터,소비자보호,소비자주권,잊혀질 권리,정보통신망법"
	},
	{
		"ID": 77,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "사용자 의도 기반 정량적 빅데이터 시각화 가이드라인 시스템 =An user intention guiding system for a quantitative bigdata visualization ",
		"AUTHOR": "변정윤",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:박용범 참고문헌 : 65-67 장",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "기존의 다양한 데이터 시각화 툴에서 제공하는 차트 추천 방식은 사용자의 의도를 고려하지 않은 상태로 차트를 추천한다. 데이터 시각화 관련 지식이 부족한 사용자들은 시각화 설계 과정에서 자신의 기반 지식에 따라 차트를 선택하게 된다. 이러한 과정에서 사용자는 본래 표현하고자 했던 목적과 부합하지 않는 차트를 선택하게 되어 원하는 차트를 생성하기 위해 소모적인 과정을 반복하게 된다. 의도에 맞게 적절한 차트를 선택하는 작업은 사용자의 지식에 의존하므로, 이를 지원할 필요가 있다. 또한, 일부 시각화 툴에서는 세분화된 정량적 데이터 분류 체계를 따르지 않기 때문에 명확한 데이터 시각화가 이루어지지 않고 있다. 본 연구에서는 입력된 정량적 데이터를 정확하게 분류하고, 사용자 의도를 반영하여 효율적으로 차트를 추천하는 가이드라인을 제안한다. 사용자가 더욱 효율적으로 차트를 생성할 수 있도록 본 연구에서는 다음과 같은 방안을 제시하였다. 첫째, 입력된 정량적 데이터를 분석하여 알맞은 데이터 타입으로 분류하는 입력 데이터 분석 가이드라인을 생성하였다. 둘째, 분석된 데이터 타입과 사용자의 의도를 반영하여 차트를 추천하는 차트 추천 가이드라인을 생성하였다. 셋째, 입력 데이터 분석 가이드라인과 차트 추천 가이드라인을 구현하기 위해 오픈 소스 시각화 소프트웨어 RAW를 활용하여 사용자가 자신의 의도에 부합하는 차트를 생성할 수 있도록 지원하였다. 마지막으로, 사용자 평가를 통해 시각화 가이드라인 시스템의 유용성을 검증하였다. 결론적으로 차트 추천 가이드라인을 통해 차트 선택 과정에서 사용자의 의도에 부합하지 않는 차트를 배제함으로써, 사용자가 차트를 생성하는데 소요된 시간 및 차트 생성에 필요한 조작수가 감소하였음을 확인하였고 더욱 효과적이고 효율적으로 자신의 의도에 부합하는 차트를 생성하였음을 검증하였다.",
		"KEYWORD": null
	},
	{
		"ID": 78,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 테크노디자인전문대학원",
		"TITLE": "빅데이터를 활용한 광고 스토리텔링 연구 :A study of storytelling based on big data for advertisement : mainly, webdrama series storytelling ",
		"AUTHOR": "정한솔",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 전승규 참고문헌: p. 103-108",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "시간과 공간을 뛰어 넘어 광고 하고자 하는 브랜드와 소비자의 유기적인 관계를 가능하게 만드는 디지털은 상호작용적 구조를 가장 큰 특징으로 하고 있다. 이러한 상호작용적 과정 속에서 디지털은 미디어와 광고 콘텐츠를 결합하게 하여 예상하지 않았던 시너지 효과까지 창출하기도 한다. 또 디지털 미디어의 특성인 시간과 장소의 제약 없이 콘텐츠의 수용이 가능하다는 데에 주목하고 디지털 광고를 통해 엔터테인먼트와 정보들을 제공하는 동시에 제품이나 브랜드의 호기심을 불러일으키고자 의도하고 있다. 이러한 측면에서 디지털 엔터테인먼트 콘텐츠로서의 광고는 브랜드와 소비자들에게 있어 무한한 가능성을 가진 장이 되어줄 것으로 기대해 볼만하다. 하지만 소비자는 무수히 쏟아져 나오는 수많은 광고들에 대해서 회피하려는 무의식적 반발 심리가 크기 때문에 광고 콘텐츠를 거부감 없이 유희하면서 전달할 수 있는 새로운 방법에 대한 필요성이 대두되고 있다. 이러한 새로운 방법론으로써 광고의 엔터테인먼트 측면의 부각은 디지털 미디어의 상호작용적인 특성을 활용한 다양한 시도를 가능케 하고, 이에 광고 엔터테인먼트 콘텐츠의 개발과 새로운 미디어에서의 유희 요소 활용 가능성에 대한 고찰을 필요로 한다. 따라서 디지털은 광고를 소비할 수 있는 충분한 미디어 환경을 만들어 줘야 하며 다양한 광고유형과 스토리텔링의 방법을 제시하여야 한다. 즉 광고가 더 이상 정보전달에만 머물지 않고 그 이상의 가치를 가질 수 있어야 한다는 것이다. 이와 같은 측면에서 최근 디지털 광고의 다양한 유형 중 누구나 쉽게 접근 가능하면서 재미요소를 부여한 광고목적의 웹 드라마는 새로운 광고 콘텐츠로서 단연 주목을 받고 있다. 이러한 웹 드라마 스토리텔링의 다양한 방법 중 다양한 디지털 플랫폼 사용자 반응에서 추출된 빅데이터 분석결과를 바탕으로 한 스토리텔링 방법에 주목하고, 새로운 스토리텔링의 시도로써 연구하고자 한다. 현재 빅데이터에 관한 연구는 정형화된 다양한 분야에서 많은 적용과 연구가 이루지고 있지만 문화, 예술과 같이 비정형의 분야에서는 아직 연구가 미흡한 단계이다. 웹 드라마와 같은 엔터테인먼트 분야에서도 마찬가지이다. 하지만 광고를 목적으로 하는 마케팅에서는 이미 많은 연구가 이루어지고 있고 광고 콘텐츠 역시 마케팅의 일환으로 이루어지는 결과물임을 감안할 때 사용자의 반응으로 이루어진 빅데이터의 분석결과는 신뢰할 수 있다고 할 수 있으며, 이 추출 요소를 토대로 이루어진 스토리텔링은 소비자와의 상호작용성을 높이고 적극적인 참여와 반응을 이끌어낸다는 점에서 획기적이고 의미 있는 방법이라 할 수 있다. 이 연구는 지금까지 빅데이터와 광고, 광고와 엔터테인먼트 콘텐츠, 엔터테인먼트 콘텐츠와 스토리텔링처럼 필요에 의해 부분적으로 적용되는 과정을 전체적으로 융합하여 새로운 방법론을 제시한다는 점에서 연구의 의의가 있다고 할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 79,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "무용학의 지적 구조 분석 연구 :Intellectual structure analysis in Korean dance studies : focused on text mining based big data analytics ",
		"AUTHOR": "이정민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 전은자 부록: 무용학 지식 분류 목록 참고문헌: p. 221-230",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "Since 1945, dance studies has been adopted as an official subject in universities of Korea, and they have been positioned as the field of studies in the universities. The purpose of this study is to identify what intellectual structure of Korean dance studies have taken and how they changed from 1958 to 2016, and to determine the current intellectual structure of Korean dance studies systematically and visually. The data of dance studies have been produced through diverse research activities in dance field. I defined them as the text data contained in the original PDF titles, abstracts, and main texts of 20,776 cases of dance studies, written from 1958 to 2016. Also I defined the intellectual structure of dance studies as the information structure which is systematically classified according to relationships after determining the significant information extracted from the text of dance studies. The study has four stages according to text mining analysis: first, collecting data of dance studies and developing the big data database system, second, extracting information from them, third, classifying the information by subjects, fourth, visualizing the classified information. The results of this study are summarized as follows. First, of diverse methods for knowledge discovery, the text mining technique associated with the system development for big data analysis was confirmed as a useful method for identifying the intellectual structure of dance studies. Second, the morphemic analysis and frequency test of 20,776 cases of dance studies data created from 1958 to 2016 revealed 210,104 nouns, 1,184,379 proper nouns, etc. Third, the analysis of knowledge structure by time revealed that dance movement(Chumsaiwi) and exorism(Gut), perceived as important concepts in the initial dance studies, gradually decreased in importance. Fine arts had been perceived as important in the studies, but the concept of participation was perceived as more important than fine arts in 2011～2016. Education was perceived as a major function that dance could contribute to society. Also, recently, dance for elderly people was perceived as important. In addition, the Community dance, the Korean wave, social media, archive, and YouTube emerged as new knowledge information in recent dance studies, confirming that the social trend of IT and contents industries have had a influence on dance. Fourth, the extraction of relationship between the information of dance studies revealed that Muyong had strong relationship with stage arts and education. On the other hand, Chum had strong relationship with traditional arts and cultures. Dance had strong relationship with leisure activities and sports. Besides, 64 types of dance movements were derived as a result of the extraction of relationship. Fifth, the information of dance studies were classified by studies/research, culture arts, Muyong/Chum, figure, body, expression factors, institution/place, times/region. It also consisted of 8 top-category items, 62 medium-category items, and 3,103 low-category items as the form of hierarchical dictionary. In addition, regarding 3,173 items of the dictionary, 19,114 cases, 92% of 20,776 cases in dance studies had relational information. Sixth, in the semantic network of Muyong, Chum and dance, the centrality analysis confirmed that the key information was Muyong, fine arts, education, society, culture, body, expression, dance piece, and diversity in the knowledge structure of dance studies. In conclusion, research on Korean dance studies should try to establish the knowledge relations of dance as pop culture, sports, leisure activities as well as pure arts. In particular, the diversity of body expressions and the educational function of dance are perceived as important research themes, and thus, practice-based?movement-based?educational application-based research are deemed to continuously attract attention. This study is the first doctoral-degree thesis focusing on intellectual structure and big data analysis in the Korean dance field. It is also significant in that it presented the data analysis methodology applicable to the intellectual structure of dance and arts studies. Further studies will be conducted to establish the intellectual structure as well as the identity of dance studies in Korea.",
		"KEYWORD": "무용학,빅데이터,의미망,지적 구조,텍스트 마이닝"
	},
	{
		"ID": 80,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한국기술교육대학교 대학원",
		"TITLE": "빅 데이터 처리를 위한 맵리듀스 기반의 다중 중심점 클러스터링 기법 =(A)multi centroid set clustering method for processing big data based on MapReduce ",
		"AUTHOR": "강성민",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 민준기",
		"STORE_LOCATION": "한국기술교육대학교 도서관",
		"ABSTRACT": "데이터 수집 기술이 발달함에 따라서 데이터마이닝 분야에서 처리하는 데이터의 크기와 양이 빠르게 증가하고 있는 추세이다. 기존에 제안된 단일기기 환경의 알고리즘은 이러한 빅 데이터를 처리하는데 너무 많은 시간을 소요하기 때문에 새로운 방안들이 제시되고 있다. 그 중에서 분산 병렬 처리 프레임워크인 맵리듀스를 이용한 알고리즘들이 제안되고 있다. 본 논문에서는 맵리듀스를 이용한 k-Means 알고리즘 기반의 MCSK-Means (multi centroid set k-Means) 알고리즘을 제안한다. 기존의 k-Means 알고리즘은 클러스터의 개수 k만큼의 초기 중심점들을 무작 위로 생성한다. 이러한 특성 때문에 k-Means 알고리즘의 결과로 생성되는 클러스터들은 초기 중심점의 생성 위치에 따라서 크게 달라지며 클러 스터 정확도에 차이가 생기게 된다. 이는 곧 일정한 클러스터 정확도를 보장할 수 없는 단점이 된다. 이를 해결하기 위해서 본 논문에서 제안하는 알고리즘은 k개의 중심점 들로 이루어진 m개의 초기 중심점 집합들을 이용하여 기존의 k개만큼만 생성되는 초기 중심점의 의존도를 줄이고자 하였다. 각 중심점 집합들에 대해서 서로 영향을 주지 않고 독립적으로 k-Means 알고리즘을 입력된 데이터 집합에 대해서 수행하고 직접 계층 클러스터링 알고리즘을 적용하여 k개의 클러스터 중심점으로 수렴할 수 있도록 하였다. 생성된 k개의 중심점들은 기존의 무작위로 생성된 k-Means 알고리즘의 초기 중심점에 비해서 비교적 정확도가 높은 결과를 얻을 수 있도록 설정되고, 마지막으로 수렴된 k개의 중심점들을 이용하여 다시 k-Means 알고리즘을 수행하여 최종 결과를 얻도록 하였다. 제안 알고리즘의 효율성을 여러 환경의 실험을 통해서 입증할 수 있었고 맵리듀스 환경으로 개발하여 대용량 데이터에서도 비교적 빠른 시간에 수행이 가능함을 보였다.",
		"KEYWORD": "Big data,clustering,k-Means,MapReduce,맵리듀스,빅 데이터,클러스터링"
	},
	{
		"ID": 81,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "데이터사이언티스트의 역량과 빅데이터 분석성과의 PLS 경로모형분석 :PLS path modeling to investigate the relations between competencies of data scientist and big data analysis performance :Kaggle 플랫폼을 중심으로 =focused on Kaggle platform ",
		"AUTHOR": "한경진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조근태 부록 수록 참고문헌 : p. 44-48",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "인터넷이 도입된 이후 여러 정보 기술의 비약적인 발전이 있어왔다. 그중에 특히 최근 몇 년 동안은 폭발적인 데이터 양의 증가로 빅데이터(Big Data)가 정보 기술의 핵심 키워드가 되고 있다. 빅데이터란 Knox(2012)의 정의에 따르면 “3V를 갖는, 즉, 거대한 규모(Volume)와 다양한(Variety) 혙애의 데이터를 빠른 속도(Velocity)로 처리”를 의미한다. 이러한 변화에 따라 학술적으로도 빅데이터의 자원적인 측면, 그 자원을 활용하는 기술적인 측면에 관한 연구가 활발히 진행되고 있다. 하지만, 그 데이터를 저장하고 가공하는 주체인 데이터 사이언티스트에 관한 연구는 부족한 실정이다. 이에 본 논문에서는 빅데이터 성과를 높이는 데이터 사이언티스트의 역량에 관해 탐색한다. 본 연구의 목적은 데이터 사이언티스트의 역량을 기술, 경영 그리고 현업 영역으로 구분하여 각 요소가 빅데이터 분석성과에 미치는 영향에 대해 분석하는 것이다. 또한, 데이터 사이언티스트의 인구통계변수(연령, 전공, 국가 등)를 기준으로 조절효과를 분석한다. 이를 위해 자료수집으로 설문조사를 실시하였고, 분석방법으로는 요인분석과 부분최소제곱 구조방정식(PLS-SEM)을 사용하였다. 연구결과는 다음과 같다. 첫째, 데이터 사이언티스트의 탁월한 요소로는 머신러닝, 문제해결 및 경영분석, 우선적 개선 요소로는 시각화와 통계, 그리고 문제를 일으키는 요소로는 의사소통 및 협업으로 나타났다. 둘째, 조절효과를 분석한 결과 연령, 학력, 전공, 국가에서 집단별 차이가 있는 것이 확인되었다. 본 연구는 데이터 사이언티스트의 개별 역량과 성과 사이의 관계구조를 분석함으로써 해당 연구에 새로운 이론적 기초를 제공하고, 실용적으로는 데이터 사이언티스트가 필수적으로 갖추어야할 핵심역량의 우선도를 판별한다.",
		"KEYWORD": "PLS-SEM,SmartPLS,데이터 사이언티스트,빅데이터"
	},
	{
		"ID": 82,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 환경을 위한 HW 기반 개인정보 보호 기법 =HW based privacy protection techniques for big data environment ",
		"AUTHOR": "이대용",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 조완섭 참고문헌: p.41-43",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "After Web 2.0, bigdata processing platforms―Hadoop and NoSQL are in the spotlight due to the explosion of data. However, it is hard to store data securely in the platforms because there is a lack of data encryption function. In this study, we propose a universally applicable encryption system for big data platforms. This system is aimed at no additional changes to the client part of the system and is designed for the HBase. Features of the encryption system are as follows. First, the system uses a hardware equipment for more faster and safer encryption for big data. Second, we provide a double encryption technique for encryption of data and encryption of key at the same time. At this time, the key is a master key encryption of key at the same time. At this time, the key is a master key used to encrypt the data. Third, the data encryption is performed by a plug-in system which encrypts data in a database and the key encryption is performed by an API system which encrypts the key through another encryption server. At this point, the data encryption/decryption is performed by a column in order to reduce a CPU overhead caused by a cryptographic operation. Therefore, it is expected to contribute to the security improvement of big data platform.",
		"KEYWORD": null
	},
	{
		"ID": 83,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "전북대학교 대학원",
		"TITLE": "Grid-based join query algorithms for analyzing big data on MapReduce environment =맵리듀스 환경에서 빅데이터 분석을 위한 그리드 기반 조인 질의처리 알고리즘 ",
		"AUTHOR": "장미영",
		"REGION": "대한민국",
		"PROFESSOR": "지도교수: 장재우",
		"STORE_LOCATION": "전북대학교 중앙도서관",
		"ABSTRACT": "최근 정보 처리 및 통신 기술의 발전으로 위치 데이터, 병원 의료 정보 및 바이오 데이터 등 대용량 데이터가 생산되고 있다. 따라서 대용량 데이터를 효율적으로 활용하기 위해서는 클라우드 컴퓨팅 기반의 대용량 데이터 분산 처리 시스템에 대한 연구가 필수적이다. Apache 그룹에서 제안한 하둡(Hadoop) 맵리듀스(MapReduce)는 대용량 데이터 저장 및 처리를 위한 분산 데이터 관리 시스템으로써, 현재 아마존, 야후 등 글로벌 기업의 주요 프로젝트에 활용되고 있다. 그러나 기존 맵리듀스는 하나의 파일에서 데이터를 읽고 처리하도록 설계되었기 때문에, 빅데이터 분석에 필수적인 다수개의 파일 조인(Join) 연산을 처리하도록 설계하는 것이 필요하다. 한편, 기존 분석 질의처리 알고리즘은 크게 유사 조인(similarity join), k-최근접점 조인(k-nearest neighbor join), 스카이라인(skyline) 질의처리 알고리즘으로 분류된다. 첫째, 유사 질의처리 알고리즘은 미리 정의된 함수를 이용하여 데이터 간의 유사도를 측정하고, 사용자가 정의한 유사도 임계값 이상의 유사성을 지니는 모든 데이터 쌍을 탐색하는 기법이다. 그러나 기존 유사 조인 질의처리 알고리즘은 유사 데이터 클러스터 생성 시, 데이터 균등 분할을 보장하지 못하기 때문에 소수의 데이터 노드에 작업이 편중될 경우, 전체 질의처리 성능이 저하되는 문제점을 지닌다. 둘째, k-NN 조인 질의처리 알고리즘은 두 데이터 집합 R과 S를 기반으로 R의 모든 레코드에 대해 S의 데이터 중 가장 인접한 k개의 레코드를 탐색하는 알고리즘으로써, 대표적인 연구로는 보로노이 다이어그램 기반 k-NN 조인 질의처리 알고리즘이 존재한다. 그러나 해당 알고리즘은 데이터 업데이트에 따른 인덱스 구축 비용이 매우 크며, 보로노이 셀 정보를 저장하기 위해 사용하는 R-트리 또한 맵리듀스에서의 분산 병렬 처리에 적합한 구조를 제공하지 못하는 문제점을 지닌다. 마지막으로, 맵리듀스 기반 스카이라인 질의처리 알고리즘은 사용자가 관심을 가질 만한 데이터를 추출하기 위한 d 개의 데이터 판별 기준이 주어지면, d 차원의 데이터 영역에 속한 임의의 데이터 x가 다른 데이터 y보다 모든 차원에서 나쁘지 않고, 적어도 한 차원에서 우수한 데이터들의 집합을 탐색한다. 그러나 기존 맵리듀스 기반 스카이라인 질의 처리 기법은 데이터의 분포를 고려하지 않거나 차원에 독립적인 데이터 분포만을 고려하여 제안되었기 때문에, 다양한 데이터분포를 고려하지 못하는 문제점이 존재한다. 따라서, 본 논문에서는 효과적으로 대용량 데이터를 분석하기 위한 맵리듀스 기반 조인 질의처리 알고리즘을 제안한다. 첫째, 맵리듀스를 이용한 그리드 기반 유사 조인 질의처리 알고리즘을 제안한다. 제안하는 기법은 샘플 데이터간 거리 및 데이터 분포를 고려하여 그리드 분할을 수행하고, 각 차원별로 데이터 분포를 파악하여 가장 편중도가 낮은 축으로 분할을 수행한다. 따라서 각 클러스터별 데이터 수가 일정하게 분포되어 맵리듀스 작업 할당을 균등하게 하는 것이 가능하다. 둘째, 맵리듀스를 이용한 그리드 기반 인덱스 생성 및 k-NN 조인 질의 처리 알고리즘을 제안한다. 제안하는 후보 영역 탐색 알고리즘은 2단계 맵 단계에서 각 R 데이터에 대해 k-NN 객체가 존재할 가능성이 높은 S의 분할 영역을 후보영역으로 탐색하고, 해당 정보만을 리듀서에 전송함으로써 불필요한 k-NN 연산이 수행되는 것을 방지한다. 따라서, 불필요한 k-NN 탐색 시간이 크게 감소하는 장점을 지닌다. 마지막으로, 맵리듀스 환경에서 다중 필터링 기법을 사용한 스카이라인 병렬 처리 기법을 제안한다. 표본 데이터를 통해 분석한 다중 회귀 분석 결과를 기반으로 필터링 임계값을 분석하고, 스카이라인에 포함되지 않는 데이터를 필터링 한다. 아울러, 제안하는 부하 분산 기법을 통해 동일한 분할 영역 내에 존재하는 데이터를 동일한 맵에 할당함으로써 한 단계 맵리듀스 상에서 질의 처리를 수행할 수 있을 뿐만 아니라, 한 노드에 데이터가 편중되어 전체 질의 처리 수행 시간이 증가하는 문제점을 해결한다. 마지막으로, 성능평가를 통해 제안하는 조인 질의처리 알고리즘이 최근 연구보다 질의 처리 시간 및 데이터 분산 처리를 위한 클러스터 생성 측면에서 우수한 성능을 나타냄을 보인다.",
		"KEYWORD": "k-최근접점 조인 알고리즘,맵리듀스,빅데이터 분석,스카이라인 질의처리 알고리즘,유사 조인 알고리즘,조인 질의처리 알고리즘,하둡"
	},
	{
		"ID": 84,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 정경대학원",
		"TITLE": "빅데이터 기반 기술을 활용한 반도체 제조공정의 장비 센서 데이터 실시간 분석 방안 제안 :H사 사례에 기반하여 ",
		"AUTHOR": "권택수",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 이선로",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "big data,FDC,real-time anlaysis,semiconductor,반도체,빅데이터,실시간 분석"
	},
	{
		"ID": 85,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2012",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅데이터 분석 기반의 SNS 고객선정 프로파일링 모델에 대한 실증적 연구 =(An)empirical study of SNS customer targeting profiling model based on big data analysis ",
		"AUTHOR": "김종현",
		"REGION": "서울",
		"PROFESSOR": "지도교수 :이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "소셜 캠페인에서의 소셜미디어 분석은 SNS 키워드와 고객정보가 융합된 빅데이터 분석이 필요하다. 이에 따라 본 박사논문에서는 소셜미디어 데이터와 기존 고객정보를 융합하여 소셜미디어 고객 모델과 전체적인 분석 시스템구조를 제시하였다. 제시된 시스템구조는 마케팅 활용을 위한 구조로 고객중심의 통합 마트 구축, 기업의 CRM 인프라 활용, 소셜미디어를 직접 캠페인 채널로 활용하는 특징을 가지고 있다. SNS 고객은 1차적으로 기업의 회원이고, 2차적으로는 특정 관심 사항에 따른 그룹 멤버들이다. 비회원이라도 우리의 회원과 소셜네트워크로 연결되어 있다면, 마케팅 메시지를 타깃고객에게 전달할 수 있다. 소셜미디어의 불특정 고객을 기업 입장에서 성별, 연령대, 관심여부 등에 따라 선별하여 모아 둔다면 마케팅 활용 차원에서 가치가 높다. 소셜캠페인은 기본적으로 간접 캠페인 형태로 적정 회수 이내의 전달 범위를 고려하여야 하고, 한정된 대상의 중복 수신 문제를 가지고 있기 때문에 대상 고객에 대한 타깃팅 최적화가 필요하다. SNS 고객정보 프로파일링 모델에 대해서 실 데이터로 테스트를 하였는데, 속성이 없는 불특정 다수 고객의 79%에 대해 성별, 연령대를 추정하여 실제 고객 속성을 정확하게 판별해 내고 있다. 또한 SNS 고객성향 프로파일링 모델은 77%의 정확성을 보이고, 정확성을 높일 수 있는 보완 방안도 제시되었다. 따라서 SNS 고객 프로파일링 모델을 적용할 경우 SNS의 불특정 잠재고객의 속성이 정확히 파악되어, 이들 불특정 잠재고객을 캠페인 대상으로 활용할 수 있다.",
		"KEYWORD": "SNS 고객선정,빅데이터"
	},
	{
		"ID": 86,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "비정형 빅데이터 분석결과의 디자인씽킹을 통한 창의적 문제해결 :Creative problem solving using design thinking based on the result of informal bigdata analysis : focusing on online civil appeal in Yongin City ",
		"AUTHOR": "박병재",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:김태형 참고문헌 : 26-27 장",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "다양한 형태로 민원이 증가하고 있지만, 이를 담당하는 공무원과 처리할 시간이 부족한 것이 현실이다. 그래서 민원을 줄이고 향후 시정에 도움이 될 만한 키워드를 제공하고자 한다. 실제 용인시 최근 3년간 민원데이터를 분석하여 용인시의 문제점을 파악하고, 이를 해결할 수 있는 방안을 도출하였다. 이를 위해 하둡 플랫폼, 디자인 씽킹의 프로세스에 대한 이론을 고찰하였고, 이를 융합하는 새로운 프로세스를 제안하였다. 빅데이터 분석 단계로는 민원에 주목 > 민원데이터 추출 > 민원데이터 분석 > 년도별 키워드로 제안하여 시민의 니즈를 파악하였고, 인사이트 도출을 위한 예측 분석에서는 용인시의 매력적인 요소 > 분석을 통해 도출된 문제점과의 융합 > 혁신사례연구 > 아이디어 도출 및 방법 > 아이디어 평가 > 프로토타이핑 > 사례분석 단계로 구성하였다. 이를 통해 주요 이슈였던 공사, 아파트, 설치, 차량 문제를 해결하기 위해 교통 프리패스 카드 제공이라는 창의적 아이디어를 도출하였다. 물론, 어떤 기준으로 어느 지역에 이러한 서비스를 제공하느냐는 구체적인 문제가 남아있지만, 지금 이순간도 다양한 문제에 몸살을 앓고 있을 시민들에게 조금이나마 보탬이 될 수 있는 정책이 절실하다. 실제 용인시에 채택이 되어, 민원을 줄이고 향후 정책수립에 도움이 되길 기대해 보며, 다른 도시에서도 적용될 수 있도록 차후 연구에서 프로세스를 재정비 할 필요가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 87,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한국교통대학교 대학원",
		"TITLE": "SNS 빅데이터 분석을 이용한 화장품 마이크로타겟팅 시스템의 설계 및 구현 =Design and implementation of cosmetic micro-targeting system using SNS big-data analysis ",
		"AUTHOR": "송재오",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 이상문",
		"STORE_LOCATION": "한국교통대학교 중앙도서관",
		"ABSTRACT": "빅데이터가 ICT분야의 최신 트렌드로 소개된 이후 빅데이터 분석 결과를 활용한 기업의 경영활동에 대한 관심도 지속적으로 증가하고 있지만, 실제적으로 체감할 수 있는 보편화된 시스템은 아직 부족한 것이 현실이다. 본 연구에서는 일상 속에서 쉽게 접할 수 있는 SNS 라는 소셜 빅데이터를 분석 소스로 하여, 시장에서의 반응이 민감하고 보편화된 화장품 이라는 소비재 완제품을 분석 대상으로 화장품 제조?판매 관련 기업이 실제로 Micro-Targeting을 할 수 있도록 분석 결과 정보를 제공하는 시스템을 구현하여 중소기업에서도 빅데이터를 효과적으로 사용할 수 있는 모델을 제시하고 관련 서비스를 제공할 수 있는 시스템을 구현하는 것을 목적으로 한다. SNS에 존재하는 특정 제품과 브랜드 또는 기업에 대한 사용 후기, 평가, 의견, 느낌 등의 소비자 생각을 수집하여 기업에서 향후 신제품 개발이나 시장 진입 등의 경영활동에 활용할 수 있도록 SNS 빅데이터를 분석하고, 보다 소집단화 되고 개인화 되어가는 Micro-Trend 중심의 마케팅 활동을 할 수 있는 Micro-Targeting 정보를 제공한다. 본 논문에서는 데이터의 수집, 저장, 분석에 대한 내용을 다루고 있으며 관련 정보를 Excel 형태로 사용자에게 상세하게 제공하고 보다 쉽게 이해할 수 있도록 웹을 통한 시각화 방법도 제안한다. 또한, 빅데이터 시스템 인프라로 많이 사용되고 있는 Hadoop ECO System에의 의존도를 낮출 수 있도록 HDFS를 제외한 나머지 구성 모듈을 Python을 활용하여 직접 개발하거나 커스터마이징하여 사용하였다.",
		"KEYWORD": "Buzz,SNS,마이크로타겟팅,빅데이터,소셜"
	},
	{
		"ID": 88,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "사용자 트렌드 탐색을 위한 SNS 빅데이터 분석 방법론 :공간정보를 중심으로 ",
		"AUTHOR": "이일섭",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김경규",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "big data,LBS,SNS,spatial analysis,trend analysis,공간분석,빅데이터,트렌드분석,해쉬태그"
	},
	{
		"ID": 89,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "빅데이터 분석 기법을 활용한 군 입대 이슈 분석 ",
		"AUTHOR": "최명선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이정우",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "big data,military enlistment,network analysis,topic modeling,군 입대,네트워크 분석,빅데이터,토픽 모델링"
	},
	{
		"ID": 90,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "서울과학종합대학원대학교",
		"TITLE": "기업에서 빅데이터 활용에 미치는 요인과 빅데이터 전문조직의 운영전략 :의사결정나무 분석과 사례연구를 중심으로 ",
		"AUTHOR": "장동인",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 91,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "인천대학교 경영대학원",
		"TITLE": "빅데이터 분석을 통한 지방행정 예산집행 =Local government budget through big data analysis ",
		"AUTHOR": "이정재",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 이기동",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "중구의회의 의원이 되고서 중구의 예산을 파악하고 결산내역을 살펴보려고 하니 예산 결산의 내용파악이 제대로 되지 않아서 좀 더 과학적인 방법으로 예산을 파악하고 필요한 곳에 합리적으로 집행이 되어야겠다는 생각을 하게 되었다. 그래서 과거 5년간의 예산의 집행내역을 빅데이터를 통하여 분석하여서 미래에 중구의 필요한 예산을 크게 행정비 절감, 원도심 재개발과, 지역인프라구축, 새로운 프레임의 기업 인프라 구축, 보건환경, 관광활성화 등 5가지로 집행방향을 설정하였다. 중구의 개항시기인 1883년부터 현재까지의 역사와 경제상황, 주민의 삶의 형태를 개괄적으로 분석하였고, 중구청의 조직과 하는 일 향후 중구의 투자되어야 할 재정방향을 분석하였다. 연구를 통한 대안을 모색하여 연구결과로 일반행정 비용 등 고정비 지출은 최대한 줄이고 재개발과, 지역인프라구축, 새로운 프레임의 기업 인프라 구축, 보건환경개선과 관광활성화를 위한 문화와 예술에 중점 투자하여 중구지역의 균형 잡힌 발전방안을 제시하였다. 주제어 : 빅데이터, 예산분석, 발전방향 모색, 효율적 예산집행, 중구의 발전,",
		"KEYWORD": "빅 데이터"
	},
	{
		"ID": 92,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "기업내 데이터 과학자 양성을 위한 탐색적 연구 :ICT 기업 사례를 중심으로 ",
		"AUTHOR": "이석민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이정훈",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "최근 기업의 성장은 빅데이터 활용에 성패가 달렸다고 해도 과언이 아니다. 빅데이터를 활용하기 위해서는 데이터 과학자 확보가 필수적이다. 데이터 과학자는 데이터를 수집하고, 분석할 수 있는 형태로 가공하며, 분석을 통해 결과를 도출하고 이를 의사 결정자들에게 적절히 제시하고 설명할 수 있는 전문가들을 말한다. 그러나 데이터 과학자에 대한 수요가 높음에도 불구하고 데이터 과학자 양성이 일부 학계와 일부 대기업, IT 기업 위주 수행되고 있다. 데이터 과학자 양성을 위한 프로세스와 커리큘럼에 대한 막연함 때문에 데이터 과학자 양성에 본격적으로 나서지 않고 있다. 본 연구는 인터뷰 기반의 탐색적 연구를 수행하여 데이터 과학자의 필수 역량과 이를 확보하기 위한 사례 중심의 데이터 과학자 양성 촉진 및 저해 요인을 도출하고, 각 요인들의 인과관계와 영향을 분석하였다. 이를 위해 인과관계 다이어그램을 작성하여 핵심 이슈를 도출하고 그에 대한 대안을 제시하였다. 본 연구 결과를 통해 데이터 과학자 양성 과정 도입을 시도할 때 발생할 수 있는 부정적인 영향을 최소화하고, 긍정적인 효과를 최대화하여 향후 기업내에서 자체적으로 데이터 과학자 양성에 도움을 줄 수 있을 것으로 기대한다",
		"KEYWORD": "big data,casual diagram,data scientist,데이터 과학자,빅데이터,인과관계 다이어그램"
	},
	{
		"ID": 93,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "빅데이터 분석을 통한 성범죄 예방 예측 모형 연구 =(A)study on prevention prediction model of a sexual crime by big data analysis ",
		"AUTHOR": "전진호",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 정승렬 참고문헌: p. 93-105",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "최근 우리 사회에 만연해 있는 여성을 대상으로 한 강력범죄, 특히, 성범죄는 한 여성 개인의 문제를 넘어 남성혐오 사상으로까지 발전함으로서 남·여가 서로 반목하고 공격하는 등 우리 사회를 극심한 혼돈상태로 몰아넣고 있다. 이와 같은 사회질서를 혼란케하는 사회악인 성범죄를 감소시키기 위해 해당 기관 및 학계에서는 정책적 혹은 물리적 대안을 찾아가고 있는데 최신 IT 트랜드인 빅데이터도 이를 위한 하나의 방편으로 활발히 연구 중이며, 그중 감성분석이 대안이 될 수 있을 것이라 판단한다. 다만, 성범죄 예방을 위한 감성분석을 위해서 가장 우선되어야 할 것이 감성사전 구축인데 현재는 이에 대한 연구가 전무한 실정이며, 성범죄의 심리학을 근거한 시도는 더더욱 없었던 것이 사실이다. 본 논문은 이에 착안하여 일반인들의 감성과 성범죄자 및 피해자의 감성이 확연히 다를 것이라 생각하고 성범죄와 관련된 문헌연구를 하였으며, 문헌연구를 토대로 성범죄의 감성을 가해자 및 피해자 입장에서 정리하여 감성단어에 적용하고 감성사전을 구축하여 이를 SNS 데이터(인터넷 사건사고 텍스트 및 트위터 텍스트)를 대상으로 실험하는 성범죄 예방모델을 연구하였다. 예상한 바와 같이 성범죄의 키워드인 성폭행, 강간, 성매매, 성희롱, 성추행 등의 단어로 수집한 비정형 텍스트 데이터를 성범죄 심리에 적용하여 감성사전과 일반 심리 감성사전으로 비교분석한 결과 그 차이가 현저함을 확인할 수 있었으며, 아울러 실험을 위해 설계된 모델을 현실에 적용하여 성범죄를 예측할 수 있는 방안을 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 94,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "RHive를 활용한 빅데이터 분석 연구 =(A)study for bigdata analysis using RHive system ",
		"AUTHOR": "이창훈",
		"REGION": "경기도",
		"PROFESSOR": "",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "하둡은 데이터 시대의 등장과 함께 나타났으며, 대용량 데이터의 분산처리를 위한 신뢰할 수 있으며 확장 가능한 처리에 기반을 둔 효율적인 소프트웨어 프레임워크이다. 하지만 기본으로 제공되는 분석기기법이 존재하지 않아 분석가들이 사용하기가 어렵다. R 프로그래밍 언어는 계산과 그래픽을 위한 프로그래밍 언어이자 소프트웨어 환경이다. R은 통계 소프트웨어 개발과 자료 분석에 널리 사용되고 있으며, 패키지 개발이 용이하여 통계학자들 사이에서 통계 소프트웨어 개발에 많이 쓰이고 있다. 반면, 대용량 데이터의 처리 문제와 데이터처리의 스케일에 관한 어려움이 있다. 본 논문에서는 이 두 가지 빅데이터 기술을 충족시키는 RHive를 사용하여 하둡의 장점인 분산처리방식과 R프로그래밍의 장점인 계산과 그래픽을 위한 프로그래밍언어를 사용하여, 빅데이터를 분석 하였다. 분산 파일 시스템과 하둡에서 데이터를 분산 처리하기 위한 맵리듀스와 Hive를 사용하고 데이터 분석을 위한 통계 및 그래픽스를 지원하는 자유 소프트웨어 환경인 R을 이용하여 현재 사회에서 대두되고 있는 문제인 청소년의 자살생각의 원인에 대한 여러 요소들의 관계를 파악하여 대한민국 청소년의 자살을 예방할 수 있도록 청소년 자살을 예측하는데 목적을 두고 실시하였다. 그 결과, 청소년의 식습관, 비만, 폭력, 음주, 흡연, 성 행태, 성별의 위험요인에 근거한 자살생각 정도를 파악하여 대한민국 청소년의 자살을 예방할 수 있도록 청소년 자살 예측 시스템의 제안이 가능하였다. 본 논문의 분석 기법은 정형화된 빅데이터를 기반으로 기존의 분석시스템보다 더 발전하여 비정형화된 빅데이터에서도 적합한 분석방법과 모형을 결정 가능할 것이라 사료되었으며, 원인파악을 통한 사회문제 해결의 한 방법을 제시할 수 있을 것으로 판단된다.",
		"KEYWORD": null
	},
	{
		"ID": 95,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "Hadoop Ecosystem 환경에서 사용자 친화적 빅데이터 관리 =User-friendly management of big data in Hadoop ecosystem framework ",
		"AUTHOR": "이재경",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 김경창 참고문헌: 장 33-34",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "Big data, with the rapid growth of SNS data and the ever increasing number of cell phones, has received considerable attention since 2012. Currently, the advancement of Internet of Things (IoT) and sensor network technology has led to the rapid increase in data and hence its attention. The growth in the big data market has also led to the active research in Hadoop framework. In particular, the active research on a variety of eco-systems has led to the expansion of data collected from just text-based data to include images and videos. The increase in the complexity of the Hadoop distributed file system has resulted in the need for new technology to manage files. The Hadoop Distributed File System has the same file information (i.e. metadata) as the Linux file system. This means that for all files, the user must memorize detailed file information just by looking at the file name or check by opening the file every time. In this thesis, in order to solve the above problems, we propose to store the metadata of the files for the original Hadoop distributed file system in Mysql, to provide a file management technique through user-friendly metadata. Experiments were conducted to find the difference in performance between the original Hadoop and Hadoop linked with Mysql. Experiment results show that there is no performance difference between the two systems. We also propose a user-friendly meta-data in RDF format for flexible storage of various file information. Lastly, by implementing a simple Web application for managing Hadoop distributed file system, we show the usage of the user-friendly management of Hadoop distributed file system.",
		"KEYWORD": null
	},
	{
		"ID": 96,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "3D big data visual analytics for brand personality :빅데이터 기반의 3차원 브랜드개성 시각화 분석방법 개발 :the continuous simulation model based on 3D finite element method =3차원 유한요소법을 이용한 연속예측모델 분석 ",
		"AUTHOR": "SanghunSul",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 97,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "전북대학교 대학원",
		"TITLE": "Big data analysis using experimental optimization, data mining, and decision marking methodology =실험적 최적화와 데이터마이닝, 의사결정론을 활용한 빅데이터 분석 ",
		"AUTHOR": "NitaSolehati",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 98,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "서강대학교 경영전문대학원",
		"TITLE": "빅데이터 기반 스토리 마이닝을 활용한 소비자의 친환경제품 구매 연구 =(An)empirical study on consumer`s choice of eco-friendly products using story mining based on big data ",
		"AUTHOR": "임미선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진화 참고문헌:p. 78-88",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "According to the survey on consumer awareness on the environment and eco-friendly products, a relatively large number of consumers, 60% of respondents, do not purchase eco-friendly products, while they are conscious of the importance of environmental impacts of products. The objective of this study is to increase purchase intention on eco-friendly products of this consumer group by building cognitive map on eco-friendly consumption of the consumers based on social big data analysis, which can supplement existing consumer survey method. The results of text analysis of social media showed that the key words related to eco-friendly products were identified as `child`, `material`, `natural`, `various`, `nature`, and `certification`. In addition, the core key words linking `eco-friendly products` to `purchase` were found to be `price`, `size`, `design`, `material`, `natural`, `child`, and `brand`. Based on the findings, quasi-experiment was conducted in order to verify the effectiveness of messages and images, which were developed using story mining technique, entailing the key words linking eco-friendly products to purchase - `price`, `size`, `design`, `material`, `natural`, `child`, and `brand`. The result of quasi-experiment showed that the types of messages(logic/general/social story) on eco-friendly products had varying impacts on consumers’ choice on eco-friendly products, and social story messages were more effective in inducing eco-friendly consumption compare to logic and general messages. In addition, consumers’ choices on eco-friendly products varied according to the types of images(logic/general/social story), and social story images were more effective in stimulating purchase of eco-friendly products compare to logic and general images.",
		"KEYWORD": null
	},
	{
		"ID": 99,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "사물인터넷 환경에서 빅데이터 기반의 IoT 이상 데이터 식별 및 장애 탐지 시스템 설계 ",
		"AUTHOR": "나성일",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 34",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "최근 사물인터넷(IoT : Internet of Things)의 등장과 다양한 스마트 서비스 환경으로의 변화는 사용자의 상태나 주변 기기의 정보를 실시간으로 수집하고 분석하기 위해 빅데이터 분석 플랫폼 연계 구조로 변화되고 있다. 수집된 데이터는 사용자나 주변의 상태를 분석하여 서비스 상태를 최상으로 유지하면서 기계의 고장이나 오류에 대한 빠른 진단을 위해 인공지능 기술을 함께 적용하고 있다. 이렇게 사물인터넷은 환경이 빠르게 변화되면서 플랫폼 구조가 복잡해지고 실시간으로 정확한 분석과 성능을 유지하기 위한 융합 기술을 적극적으로 도입하고 있다. 사물인터넷은 이러한 변화의 가운데서 다양한 센서를 하나로 연결하여 데이터를 수집하는 초연결 환경을 구축하고 있다. 이 과정에서 다양한 스마트 장치와 연결되면서 여러 가지 문제들이 발견되고 있다. 예를 들면, 센서의 해킹이나 보안 등과 같은 문제로 인해 장치가 제어되지 않거나 사용자의 개인정보가 유출되는 경우가 있다. 그렇기 때문에 지속적인 연결을 위해 센서의 이상 상태를 탐지하거나 예측하는 것이 중요하다. 특히 센서 데이터는 실시간성이 보장되어야 하고 안정적인 스마트 서비스를 위해 실시간 모니터링 환경이 요구된다. 그리고 이 데이터를 통합하고 이상 상태를 판단하는 기계학습 기반의 이상 탐지 모델이 요구된다. 그럼으로써 사용자의 상황이나 장치의 상태가 정확하게 판단되어 정확한 서비스와 연결성을 보장할 수 있다. 본 연구는 수집된 센서의 이상탐지를 위해 빅데이터 기반의 IoT 이상데이터 식별 및 장애 탐지 시스템을 제안한다. 제안한 시스템은 센서의 이상탐지를 빠르게 처리하기 위해 기계학습 기반의 장애 탐지 모델을 적용하였다. 또한 기계학습의 성능 개선하기 위해 하이퍼파라미터 최적화와 함께 잘 정제된 데이터를 이용하여 기계학습을 수행하였다. 그 결과, 전처리되지 않은 데이터를 이용한 기계학습보다 정확한 이상탐지와 함께 학습 성능도 더 우수한 결과를 확인하였다.",
		"KEYWORD": "빅데이터분석,사물인터넷,스마트서비스,이상탐지,장애예측"
	},
	{
		"ID": 100,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "국가 차원의 빅데이터 활성화를 위한 개인정보 관련 정책의 개선안 고찰 ",
		"AUTHOR": "신지윤",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Utilizing Korea’s open data and national policy established based on it is still at a ground level when comparing the specification and accuracy of implementing the open data into national policy in developed countries like US and Europe. To thoroughly look into and find the problems of current personal information protection act and policies that restrict many companies and business operators, an in-depth interview was conducted with a specialist. From the findings of the interview, this study proposes two improvements that contribute to activating open data at national level. First, is to determine the accurate range of personal data protection. To do so, five new categories of standards were developed: whether 1) the information is unique identifier and has duplicate data, 2) the identifier is issued by the host, 3) the information is utilizable with only a single information, 4) the identifier takes a part in providing the information, 5) the identifier is aware of information being collected. The purpose of using newly categorized standards of information is to omit unnecessary non-identifier process and allowing private enterprise to actively use the resident registry number system that gives an opportunity of securing global-level data analytic competitiveness. Second is to enforce the security of information that needs protection by developing principles and guidelines of information and/or data handling processes. Especially the objective of this is to encourage the interaction between the government sector and private enterprise by the country regularly asks the private enterprise standard data. From this, Korea is expected to become the leader of the Fourth Industrial Revolution that adequately adopts people’s life into developing realistic welfare policies in the future.",
		"KEYWORD": "Big Data activation,personal information policy,personal information protection act,standards of personal information category,개인정보 보호정책,개인정보 분류기준,개인정보 처리방침,국가 오픈데이터,빅데이터 활성화"
	},
	{
		"ID": 101,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "스마트 교육 분야의 빅데이터 활용 전략에 관한 연구 :데이터 분석 중심으로 ",
		"AUTHOR": "김은주",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임춘성",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "본 연구는 우리나라에서 활발히 추진되고 있는 스마트 교육 환경에서 빅데이터 기술을 활용하여 스마트 교육이 지향하는 목표를 효과적으로 달성하기 위한 방안과 전략을 제시하는 것을 그 목표로 했다. 스마트 교육 환경에서 빅데이터의 활용 영역은 개인별 맞춤형 교육을 구축하고, 다양한 교육 빅데이터 분석을 통해 얻어지는 지식과 지혜를 통해 교육 전략을 수립하고 평가하며, 평가에 기초하여 수립된 전략의 대안을 검증하여 다시 학습 활동과 교육 전략에 적용하는 피드백 과정으로 설명했다. 이를 위해 본 연구에서는 교육 데이터 마이닝과 학습 애널리틱스의 방법을 교육 빅데이터를 분석하고 활용하는 방법으로 제시하였으며, 실제 교육 데이터를 활용하여 데이터 마이닝 분석을 수행함으로써 그 가치를 입증하였다. 끝으로 스마트 교육 환경에서 빅데이터를 활용하기 위한 요구 사항과 위험 요인을 고려함으로써, 학습자에게 가치를 제공해야 하며 학습 영향 요인을 발견해야 하는 등의 활용 전략을 제시하였다.",
		"KEYWORD": "big data,data mining,educational strategy,learning analytics,smart education,교육 전략,데이터 마이닝,빅데이터,스마트 교육,학습 애널리틱스"
	},
	{
		"ID": 102,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "남서울대학교 대학원",
		"TITLE": "빅데이터와 GIS를 활용한 범죄취약지 추출 =Extraction of crime vulnerable areas using big data and GIS ",
		"AUTHOR": "신민규",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 김의명",
		"STORE_LOCATION": "남서울대학교 도서관",
		"ABSTRACT": "2005년부터 2014년 경찰청 자료에 의하면 지난 10년간 범죄는 꾸준히 증가하고 있으며, 높은 비율을 차지하는 도로에서 일어나는 강력범죄 또한 줄어들지 않고 있다. 하지만 범죄 발생 위치정보를 제공하는 해외와 다르게 우리나라는『공공기관의 정보공개에 관한 법률』 제9조(비공개 대상 정보)에 따라 부동산 가치 하락 및 사생활 침해 논란 등으로 범죄정보의 제공이 원천적으로 제한되고 있기 때문에 범죄관련 연구는 행정구역 단위의 분석에서 그치는 실정이다. 이에 본 연구는 환경설계를 통한 범죄예방(CPTED : Crime Prevention Through Environment Design)를 이용하여 물리적·공간적 측면에서 활용 가능한 공간정보와 통계정보 그리고 빅데이터를 통해 수집한 민원정보를 활용하여 범죄발생 위치정보를 직접적으로 활용하지 않고 범죄발생에 취약한 지역을 추출하는 기법을 제시하였다. 범죄에 취약한 지역을 찾는 측면에서 실제 거주하는 주민들이 두려움을 느끼는 수요 측면과 공간적으로 범죄에 취약한 공급 측면을 고려한 종합한 범죄취약지를 추출하였다. 공급 측면은 범죄에 취약한 물리적 환경요인을 기반으로 공간정보의 기하학적 특성을 이용하여 범죄취약지를 추출하는 과정으로 진행하였다. 선정된 물리적 환경요인은 시야각도, 도로폭, 도로포장재질, 주변 건물 종류이며, 속성정보에 따라 위험점수로 등급화를 하였다. 각 요인에 대한 가중치를 적용하고자, 5대 범죄(살인, 강도, 강간, 절도, 폭력)와 환경요인간의 회귀분석을 수행하여 인과관계를 확인하였으며, 결과를 토대로 5대 범죄별 범죄취약지를 추출하였다. 수요 측면의 범죄취약지 추출은 비정형 빅데이터인 민원정보를 이용하였으며, 민원정보에서 안전시설물의 설치에 대한 요구사항과 안전시설물 설치현황을 비교하여, 안전시설물 사각지대를 추출하는 과정으로 진행하였다. 크롤링을 통해 민원정보를 수집하고, 안전시설물 설치와 관련되어 있으며 위치정보를 포함하고 있는 민원정보만을 추출하여 공간정보로 변환하였다. 공간정보로 변환한 민원정보를 가지고 공간통계분석 중 하나인 핫스팟 분석을 수행하여 안전시설물 설치에 대한 수요가 밀집한 지역을 추출하였으며, 실제 설치된 안전시설물에 대한 버퍼분석 결과와 비교하여 안전 시설물 사각지대의 추출하였다. 수요-공급 측면의 범죄취약지를 활용하여 종합적인 범죄취약지를 추출하고, 안전시설물 설치현황과 설치요구에 대한 불일치율을 분석하였다. 종합적인 측면에서 공간적·물리적으로 취약하면서, 많은 주민들이 두려움을 느끼는 지역을 추출하였다. 본 연구의 결과 물리적 환경요인과 5대 범죄 정보간의 회귀분석을 수행하여 인과관계를 확립하고, 이를 적용하여 보다 객관적인 결과를 가지는 범죄 유형별 범죄취약지 추출 방법론을 제시하였다. 또한 실제 거주하는 주민들의 요구사항이 포함되어있는 민원정보와 안전시설물 위치정보를 이용하여, 안전시설물 사각지대 추출 방법론을 제시하였다. 이를 통해 현장조사 없이도 수요-공급을 반영한 범죄에 취약한 지역을 효율적으로 찾을 수 있을 것으로 사료된다. 핵심용어 : 범죄취약지, 환경설계를 통한 범죄예방, 5대 범죄, 회귀분석, 빅데이터, 안전시설물 사각지대",
		"KEYWORD": null
	},
	{
		"ID": 103,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "빅데이터 분석을 통한 사용자 관점의 이슈 클러스터링 =User-perspective issue clustering using big data analysis ",
		"AUTHOR": "김지은",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김남규 국문 또는 영문 초록 수록 참고문헌: p. 29-32",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "급증하는 빅 데이터 분석은 웹 3.0과 스마트 기기의 보편화에 대응하기 위한 기업의 경영 의사결정에서 중요한 역할을 수행하고 있다. 최근에 축적되는 데이터는 사용자의 실생활과 밀접한 연관성을 갖는 경우가 많아 그 활용도가 높아지는 추세이다. 또한, 비정형 텍스트 데이터에 대한 분석을 통해 관심 제품, 고객 선호, 잠재적 구매의사와 같은 유용한 정보를 획득할 수 있기 때문에 많은 기업과 기관에서 연구와 투자가 진행되고 있고, 이를 위한 토픽분석이 상당한 주목을 받고 있다. 하지만 기존에 수행된 비정형 텍스트 자료의 분석은 토픽분석을 통해 도출된 결과가 토픽 과잉이나 토픽 과소로 적정 정보를 제공하지 못하는 한계를 보이고 있다. 본 연구에서는 고객의 실제 관심 분야를 파악할 수 있는 방안을 제시하였다. 또한 토픽 분석을 통해 각 문서의 주제를 도출하고 도출된 주제를 다시 동시 방문자 관점에서 군집화함으로써, 고객 관점에서 의미가 있는 상위 수준의 새로운 테마를 발굴하기 위한 방법론을 제안하였다. 연구의 특징은 유사주제 중심의 군집화라는 기존 연구와는 달리 사용자 관점의 관심주제 중심 군집화라 할 수 있다. 기존 비정형 뉴스 분석에 사용된 어휘출현 빈도와 연관관계에 기반한 유사 주제 분석의 한계를 해소하기 위해 관련 주제 중심으로 클러스터링하여 토픽 분석의 성과를 개선하는 방법론을 제시한다. 사용자 관점의 이슈 군집화 과정은 크롤링, 토픽 분석, 액세스 패턴 분석, 네트워크 병합, 네트워크 변환 및 군집화와 같은 여섯 가지 주요 단계로 구성되어있다. 이를 위해 텍스트 마이닝과 소셜 네트워크 분석 기법을 활용한 비정형 텍스트를 기반으로 한 빅데이터의 활용 방법을 모색하였다. 제안 방법론의 실무 적용 가능성을 평가하기 위해, 국내 최대 포털 뉴스 사이트의 방문자 2,177명의 1년간 방문 기록과 뉴스기사 대한 분석을 수행하고 그 결과를 요약하여 제시하였다. 제안된 방법론은 기업의 마케팅이나 트렌드 분석, 상품개발과 같은 다양한 수요에 맞게 포괄적으로 사용될 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 104,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "국방대학교 국방관리대학원",
		"TITLE": "국방분야 빅데이터 활용방안 연구 =(A)study on a way to facilitate the usage of big data in the defense area ",
		"AUTHOR": "김각규",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 105,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "빅데이터?환경에서의?개인정보?활용에?대한?소비자인식 ",
		"AUTHOR": "김인혜",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 106,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "빅데이터 분석을 위한 IT 아키텍처 구현에 관한 연구 =Information technology architecture implementation for big data analysis ",
		"AUTHOR": "마민철",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 107,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "Hadoop 프레임워크에서 효율적인 빅데이터 검색을 위한 전략 =(A)strategy for efficient retrieval of big data in hadoop framework ",
		"AUTHOR": "백우현",
		"REGION": "서울",
		"PROFESSOR": "국·영문 초록 수록 지도교수 : 김경창 참고문헌 : p. 31-32",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "개인 디지털 기기의 보급으로 하루에도 수많은 데이터가 생성되고, 유통된다. 시간이 갈수록 유통되는 데이터는 점차 증가하게 되었고, 이를 분석하고 처리하고자 하는 시도가 활발히 이루어지게 되었다. 이러한 연구는 Big Data 분석 연구라 불리며 현재 데이터베이스 및 데이터마이닝 분야에서 가장 활발히 연구되는 주제이다. 특히 대량의 데이터를 분석하고 처리하는 기술과, 이를 실생활에 접목하는 기술이 집중적으로 연구되고 있다. Big Data 분석 연구에서 가장 널리 사용되는 시스템은 Hadoop이다. Hadoop은 데이터를 분산해서 저장하는 HDFS와 데이터를 병렬로 처리하는 Map-Reduce로 이루어져 있다. 즉 Hadoop에서 데이터를 분석하기 위해서는 데이터가 HDFS에 저장되어 있어야 한다. 하지만 시간이 흐를수록 저장하고 관리해야 할 데이터의 양은 증가할 것이고, 이를 효과적으로 관리하기 위한 Hadoop의 기반 기술은 기존 File System보다 상대적으로 부족하다. 한 가지 예로 Hadoop은 HDFS 내에 저장된 File에 대한 검색 기능을 제공하고 있지 않다. 그렇기 때문에 Hadoop 클러스터를 관리하는 관리자나 Map-Reduce 개발자는 HDFS에 저장된 모든 File에 대한 정보를 알고 있어야 한다. 하지만 데이터의 양이 늘어날 경우 이 모든 File들을 기억할 수 없기 때문에 데이터의 관리 측면에서 문제가 발생할 수 있다. 본 논문에서는 저장된 File을 검색하지 못하는 Hadoop의 한계를 극복하고자 효율적인 검색 전략을 제시한다. Hadoop에 저장된 File에 대한 새로운 metadata를 설계 하고 이를 MySQL을 활용하여 구현한다. 구현한 metadata를 활용하여 효율적인 검색을 시도하고 이에 대한 기능을 평가한다.",
		"KEYWORD": null
	},
	{
		"ID": 108,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 교육대학원",
		"TITLE": "DACUM 기법을 활용한 빅데이터 직무능력모형 개발 ",
		"AUTHOR": "송현민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현철 DACUM = Developing A Curriculum 참고문헌: p. 105",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "본 논문의 목적은 현업에서 요구하는 체계화된 빅데이터 직무별 교육 프로그램 개발을 위해, 직무 및 역량에 대한 분석을 토대로 빅데이터 직무능력모형을 개발하는 것이었다. 이를 위해 직무분석방법 중 하나인 DACUM(Development A Curriculum) 기법을 활용하여 현업 종사자들의 직무를 분석하고, 직무분석 결과에 의거하여 빅데이터 직무능력모형을 개발하였다. 그 결과, 빅데이터 직무능력의 정의와 직무영역 및 각 직무에 대한 정의를 기술한 이후 총 5개의 핵심능력단위, 21개의 능력단위, 64개의 능력단위요소를 도출하여 구체화 하였다. 또한 능력단위요소별 세부적인 수행준거, 지식, 기술, 태도와 적용범위 및 작업상황을 명확히 기술하여 직무별 교육 프로그램 개발을 위해 필요한 기초작업을 정립할 수 있었다.",
		"KEYWORD": "DACUM,빅데이터,직무능력모형,직무분석"
	},
	{
		"ID": 109,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 부동산대학원",
		"TITLE": "부동산학 세부 학문영역으로서의 빅데이터 분석 :Big data analysis as the detailed scientific field of real estate studies :효용성 검증 및 커리큘럼 작성을 중심으로 =focused on the testing of efficiency and the preparation of the curriculum ",
		"AUTHOR": "우제택",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신 승 우",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "급변하는 현대사회에서 부동산학의 관한 연구는 아직 일반적으로 받아들여지는 합의는 존재하지 않는다. 기존의 연구는 주로 무엇을 가르쳐야 하느냐(Teaching Curriculum)와 혹은 어떻게 접근해야 하느냐 (Approach)의 문제로 집약되어 논의되어 왔다. 따라서 교과목에 관한 논의도 부동산 금융접근법(Common financial management approach)와 학제적 접근법(Multi-disciplinary approach)로 구분된다 (Jayantha and Chiang, 2012).고 볼 수 있다. 본 연구는 교과목에 관한 논의의 연장선상에서 출발하였고 부동산학은 순수이론적인 학문과 달리 현실의 문제를 다루는 면에서, 교과목을 편성하는 경우, 학생들과 업계의 관점을 충실히 반영하여 편성하여왔다 연구의 목적은, 현재 부동산업계 뿐만 아니라 새로운 시대 상황으로서의 ‘빅데이터’ 현상이 전반에 미치는 영향을 조사하며, 이어서 빅데이터 분석, 응용 관련 내용을 부동산학의 교과목으로 채택하는 것이 적절할 것인가를 통계적으로 검증하며, 빅데이터 관련 과목을 부동산학의 교과목으로 도입하는 것이 적절한 경우, 이를 기존 전공별로 추가하는 것과 새로운 전공으로 독립시켜 집약적으로 강의하는 방법의 장단점을 연구하였다 이러한 연구와 변화를 통하여 시대적 흐름을 인식하고 수용, 발전하며 세계일류를 지향하고 도약하는 건국대학교 부동산대학원의 발전적인 학문연구로서의 방향에서 가치를 갖게 되는데 유용하게 이용될 것이다.",
		"KEYWORD": "빅데이터분석,빅데이터응용,정부 3.0"
	},
	{
		"ID": 110,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "R을 이용한 빅데이터 분석 :데이터의 다차원 처리 및 시각화 ",
		"AUTHOR": "서유형",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이은경 참고문헌: p. 41",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "빅데이터는 그 잠재력과 활용 가능성 때문에 현재 거의 모든 산업에서 주목하고 있는 새로운 가치이며, 동시에 정보 기술 산업 분야에서 가장 활발히 개발되고 있는 새로운 기술이다. 기존에 없던 새로운 데이터라기보다는, 그 동안 축적되면서 양이 많아지고 종류가 다양해진 데이터를 좀 더 잘 활용해 보겠다는 새로운 관점이라고도 할 수 있다. 빅데이터 분석에 대한 수요는 늘어가지만, 고난도의 분석을 빅데이터에 적용하기 위해 필요한 인프라를 구축하는 것은 쉽지 않다. 이에 따라 요즈음 학교나 기업에서의 빅데이터에 관한 연구는 대부분 새로운 인프라와 새로운 방법론을 탐구하거나, 이를 특정 산업 분야에 적용하는 것들이다. 그런데 기존에 데이터 분석에서 사용되던 방법들을 인프라가 구축되지 않은 상태에서 빅데이터에 적용하는 고된 작업으로 인해 이미 많은 데이터 분석가들이 어려움을 겪고 있으나, 이에 관련된 연구는 찾아보기 힘들다. 이에 따라 새로운 인프라의 구축 없이 기본적인 인프라 상에서 빅데이터 분석을 어떻게 할 수 있을지를 주제로 진행되었다. 본 논문에는 빅데이터의 개념과 현황, 처리 기술, 분석 기법, 시각화 툴 등을 소개하고, 실제 자료인 다차원의 대용량 공간데이터를 싱글 코어 상의 R 프로그램 하나로 분석하려 할 때 부딪히는 문제점과 이를 해결해 나가는 과정을 기술하였다. 당면하는 문제점들은 사소하고 간단히 해결할 수 있는 문제점들처럼 보일 수 있으나, 데이터 분석에서 자주 접하게 되는 일반적인 상황이며 분석 진행에 큰 걸림돌이 되며 때로는 매우 치명적인 문제점이 될 수도 있다. 본 논문에서 제시하는 해결 방안들은 대부분 단순하고 일반적인 기법들이지만, 일반적으로 사용되는 목적과는 다른 새로운 관점으로 문제점을 해결하는 데에 사용하였기 때문에, 비슷한 문제에 부딪힌 데이터 분석가들에게 도움이 될 수 있을 것이다. 자료 구축 과정에서 NetCDF4 형식의 다차원 데이터를 R에서 분석이 가능하도록 구조를 변경하고, 다차원 문제에 대해 각 차원에 맞게 축소, 분리, 공간적 특성을 고려한 추정 등의 방법으로 차원을 축소하였으며, 차원을 축소함으로써 잃을 수 있는 정보들은 다양한 시각화 기법을 통해 탐색하였다. 또한 차원이 축소된 데이터에 여러 변환 방법을 시도하였으며, 선형 회귀, 로버스트 회귀(Robust Regression), 랜덤 포레스트(Random Forests), 변화도 부스팅(Gradient Boosting Machine), 일반화 가법 모형(Generalized additive model) 등의 다양한 통계모형을 적합시켜 최적 조절모수를 찾고 각 모형의 예측력을 비교하였다.",
		"KEYWORD": null
	},
	{
		"ID": 111,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "빅데이터 환경에서 정보주권의 의미 분석과 법적 대응 =Semantic analysis on information sovereignty and its legal countermeasure in the big data environment ",
		"AUTHOR": "이희옥",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 황성기 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 83-90",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "국문초록 빅데이터가 개인의 삶과 기업의 경쟁력을 향상시키고 국가의 제4차 산업혁명의 원천이 될 것이라는 전망속에 오늘날 빅데이터는 지능정보사회의 기반이 되는 핵심요소로 여겨진다. 빅데이터를 선점하는 것은 기업과 국가의 미래 경쟁력을 좌우할 만큼 중요하다. 오늘날 빅데이터를 가장 많이 보유하는 자는 단연 전세계를 대상으로 검색서비스를 제공하는 구글, 페이스북과 같은 미국의 글로벌 기업들이다. 이들의 빅데이터 독점을 의식한 유럽연합, 프랑스, 한국, 중국 등 각국이 자국민과 자국의 정보데이터 보호에 나선바, 정보주권은 이러한 개별국가의 인터넷공간에 대한 통제에 관한 논의이다. 이 논문은 빅데이터를 둘러싸고 개인, 기업, 국가의 이해관계가 엇갈리면서 나타난 법적 문제들을 바탕으로 지금까지 논의된 정보주권의 의미를 정리하고, 법적 관점으로서의 정보주권개념의 의미를 분석하는 것을 목적으로 한다. 아울러 이의 분석을 토대로 빅데이터 환경에서 국가의 역할과 내용을 모색한다. 여기서 정보주권의 의미에 관한 논의가 필요한 이유는, 정보주권개념의 진정한 의미를 파악하는 것이 정보주권 실현을 위한 기본전제가 되기 때문이다. 연구결과 정보주권은 법적 개념 이라기보다는 정보주체의 자기정보에 대한 주체성을 강조하는 개념으로 해석되었다. 또한 법적 관점으로서 정보주권의 의미를 분석한바, 정보주권의 주체는 빅데이터의 활용과 보호 측면에서 각각 개인과 기업, 그리고 자국민과 자국산업을 보호하는 입장에서 국가로 구분할 수 있었다. 빅데이터 환경에서는 정보주체가 누구냐에 따라서 정보주권의 내용도 다르게 이해되었다. 특히 정보주체가 개인인 경우, 빅데이터는 기존 개인정보 보호법제가 규율하는 개인정보보다 넓은 의미의 정보를 대상으로 한다. 이에 빅데이터는 정보의 성격 및 처리단계에 따라 구분되어 보호되어야하고, 정보의 처리, 이동, 유통, 안전한 보관 등을 보호내용에 포함시켜야 함을 논증하였다. 각각의 정보주체 입장에서 정보주권의 의미를 살펴본 결과, 빅데이터 환경에서는 빅데이터 기술이 복잡성만큼이나 정보주체들 간의 법익도 첨예하게 충돌하는 것을 알 수 있었다. 빅데이터 환경에서 충돌하는 법익을 조정하고 인터넷공간의 질서를 유지하는 조정자로서 국가의 역할은 헌법규정과 국가의 기본권보호의무에서 찾을 수 있다. 한편 최근 빅데이터환경에서는 인터넷공간을 운영하는 기업의 영향력이 점점 더 커져가고 있다. 이러한 현상은 지능정보화사회가 고도화될수록 심화될 것이다. 이에 국가는 빅데이터에 대응한 법제를 마련하는 과정에서 기업의 참여를 통한 자발적 협력을 이끌어 낼 방안을 강구할 필요가 있다. 마찬가지로 거대 글로벌 기업에 대응해서도 영향력 있는 이해관계자들과의 공조를 통해서 우리의 이해를 국제사회에 반영할 수 있을 것이다.",
		"KEYWORD": "법학"
	},
	{
		"ID": 112,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "MapReduce 기법을 이용한 전자책 빅데이터 처리 =Big data processing with MapReduce for E-book ",
		"AUTHOR": "홍태호",
		"REGION": "서울",
		"PROFESSOR": "지도교수:이용우",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "컴퓨터의 발달에 힘입어 현재 전자책이 많은 각광을 받고 있으며, 최근에는 스마트폰의 발전 및 보급 확산으로 전자책의 활용에 대한 관심도가 급증하고 있다. 이러한 전자책에서, jpg 또는 pdf 등과 같은 이미지 파일로 된 디지털 도서를 대상으로 할 때, 책의 내용에 대한 단어 검색이 불가능하다. 본 연구에서는 위와 같은 이미지 파일로 된 전자책을 Google의 Tesseract OCR 기술을 이용하여 검색이 가능한 텍스트 파일로 변환하여, 원하는 단어 검색이 가능하도록 하였다. 이러한 단어 검색이 가능한 전자책을 제작하기 위해 XML 기반의 텍스트 파일 포맷인 EPUB을 사용하였다. EPUB은 IDPF (International Digital Publishing Forum)에서 지정한 전자책 국제표준방식으로 대부분의 전자책 기기에서 이용가능하다. 본 연구에서는 이미지 파일을 텍스트 포맷의 EPUB으로 변환하여 원하는 단어 검색을 가능하게 하는 일을 수행하였다. 그러나 EPUB으로 변환이 필요한 이미지 형태의 전자책은 지속적으로 방대한 양이 생산되고 있다. 이러한 전자책 빅 데이터의 변환 작업을 일반적인 개인용 컴퓨터에서 처리한다면, 그 변환 작업에 많은 시간이 소요되거나 처리가 불가능 할 수도 있다. 따라서 MapReduce 모델을 사용하는 클러스터 시스템을 이용하여, 변환 작업이 가능하게 하고, 그에 따른 처리 시간도 줄이는 방안을 연구하였다. 본 연구에서는, EPUB으로 변환을 위해, 분산 지원 컴퓨팅 프레임워크인 Hadoop 기반의 전자책 변환 시스템을 개발하였다. 2TB 이하의 이미지 파일을 처리할 때, 15개의 노드 클러스터 시스템을 사용할 경우, 빠르게 변환작업이 완료될 수 있도록 시스템을 설계 및 구현하여, 시스템의 성능을 평가한 결과를 본 논문에 제시하였다. 본 연구에서 소개하는 Hadoop 기반의 전자책 변환 시스템은 만족할 만한 전자책 변환 속도를 보여주는 것을 확인할 수 있다.",
		"KEYWORD": "E-book,EPUB,Hadoop,MapReduce,빅 데이터,인터넷,전자책"
	},
	{
		"ID": 113,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "인제대학교 대학원",
		"TITLE": "빅 데이터 기반의 생체신호 분석 플랫폼 개발 ",
		"AUTHOR": "고동희",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 김희철",
		"STORE_LOCATION": "인제대학교 백인제기념도서관",
		"ABSTRACT": "웨어러블테크 융합산업은 인간중심적 감성이 결합된 인문-기술의 융합분야로 IT 및 타 산업 경쟁력 강화의 핵심으로 등장하였다. 이에 따라 의류분야도 u-healthcare 라는 영역으로 많은 새로운 기술들을 시도하고 있다. 최근에는 복지에 대한 수요가 확대되고 경제 수준 및 생활수준의 향상과 인구 고령화, 만성퇴행성 질환에 따라 의료비용의 급격한 증가로 인해 ‘질병에 따른 치료 중심’에서 ‘예방 및 건강관리 중심’으로 그 중요성이 부각되면서 개인의 건강상태를 언제 어디서나 관리 할 수 있는 u-healthcare에 대한 관심도가 높아졌다. 이러한 패러다임의 변화에 따라 u-healthcare 시스템에 생체신호를 이용하여 데이터를 저장하고 저장된 데이터를 분석 및 처리 등의 기술과 접목시켜야 한다. 생체신호란 인체에서 발생되는 신호에 대하여 디바이스를 통해 측정될 수 있는 모든 정보를 말하는데, 단지 측정하는 것에 그치지 않고 측정된 데이터 수집을 통하여 사용자의 건강상태를 확인하고 관리 할 수 있다. 하지만 심전도나 호흡 등과 같이 연속적으로 유입되는 생체신호는 비정형 데이터로서 가공되지 않은 원 데이터이며, 그 양(Volume)이 거대하여 빅 데이터로 분류하여 처리해야 한다. 본 논문에서는 선형구조를 가진 거대한 양의 생체데이터인 심전도(ECG) 데이터를 빅 데이터로 정의하며, 이를 분석하고 서비스하기 위한 플랫폼 개발 연구를 제안한다. 제안하는 연구는 5분단위로 측정되어 HDFS (Hadoop Distributed File System)에 파일로 저장되는 심전도 신호는, 주요 신호인 P파, QRS파, T파 중 R peak 값을 검출하고, R-R interval을 이용하여 HRV (Heart Rate Variability), SDNN (Standard Deviation of N-N Interval), LF (Low Frequency), HF(High Frequency) 등의 특징 값을 추출한다. 가속도 신호는 칼로리(Calorie), 걸음수(Steps), 거리(Distance) 등의 특징 값을 추출하며, 이렇게 추출되는 데이터는 정의가 가능한 의미 있는 정형데이터로써 하둡의 대표적인 데이터 웨어하우스(Data Wearhouse)인 아파치 하이브(Apache Hive)를 통하여 분석하는 연구를 진행한다.",
		"KEYWORD": "빅데이터,생체신호,웨어러블,하이브,헬스케어"
	},
	{
		"ID": 114,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "비정형 데이터의 의미 확장과 그래프 모델링을 이용한 개선된 소셜 빅데이터 분석 시스템 =Improved social big data analysis system on semantic-expansion of unstructured data and graph modeling ",
		"AUTHOR": "최승진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한상용 중앙대학교 논문은 저작권에 의해 보호받습니다 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "As the Internet becomes more widespread, social big data, which contains a lot of information such as personal opinions, emotions and social phenomena, is worth analyzing itself. However, these data is difficult to analyze because of their volume, velocity and variety (3V). In addition, in the case of domain-specific data, it is very difficult to analyze data without domain expertise. To solve these social big data problem, various analysis techniques such as machine learning, text mining and social network analysis were studied. Since the various relationships that can occur in real world can be defined by the graph structure, many analysis techniques were used in this structure based on graph theory. However, a huge portion of social big data is unstructured text data. This unstructured data is hard to analyze. Unstructured text data is much more important because it takes up a large portion of social media and contains more information than the size of other unstructured data such as images and movie. In this paper, improved social big data analysis system on semantic-expansion of unstructured data and graph modeling, which collects data from social media and formalizes the data with the concept of seed context. The seed context is auxiliary input that can formalize data without domain-expert knowledge. Using the graph model, the proposed method to model the data as graphical structure and to be applied to various applications has been explained. Finally, proposed methods compare with previous research through the experiment The results of this study can be used in various fields such as information retrieval system, curating system, and recommendation system, and it will be able to simplify the analysis and application of social big data of complex process.",
		"KEYWORD": "그래프 이론,분석 시스템,비정형 데이터,소셜 빅데이터,의미 확장"
	},
	{
		"ID": 115,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 기술로 분석한 북한의 언론 발표 =Analysing media announcement of North Korea by big data technology ",
		"AUTHOR": "이세학",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.99-100",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "We analyzed North Korea’s medias such as statements, reports, interviews, press conferences which were announced in 1996 to 2015 from official institution of North Korea by using big data technology. Since most of the data has unstructured format, preprocessing of the data for structurization should be done before the analysis. A relational database has been used for storing the preprocessed, structured data. First, a dictionary which classifies the keywords in the media has been constructed and used for the follow-up analysis. Then a multidimensional analysis for the statements has been done for extracting useful insights from the database. Multidimensional analysis is useful for driving various insights in diverse aspects of the data such as time, countries, and keyword categories. Finally, text mining and visualization technology have been applied to the data for finding more deeper insights from the data. Keywords: News data, Multidimensional analysis, Text mining, Visualization",
		"KEYWORD": "다차원분석"
	},
	{
		"ID": 116,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "정보화 정책 이슈의 확산 과정에 관한 연구 :소셜텍스트 빅데이터 분석을 중심으로 ",
		"AUTHOR": "최홍규",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김성태 참고문헌(p. 137-159)과 부록수록",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "본 연구는 우리나라 정책적 상황에서 정보화 정책 이슈가 확산되는 과정에 관해 조명하였다. 우리나라에서 정보화 정책은 정보통신기술 보급의 촉진에 기여해왔는데, 그 형성과정으로 보면 하향식 정책형성 모델의 특징을 보인다고 할 수 있다. 하향식의 정보화 정책형성 모델에서는 공중을 통해 논의될 수 있는 정책 키워드를 이미 정부가 설정하여 전달하고 온?오프라인의 논의공간을 통해 그것이 공중의제화되어 정책의제로 정착하는 단계를 거치게 된다. 본 연구는 정부에 의해 정책이 확산 단계를 거친 후, 2차 사회적 확산단계에서 공중의제가 형성되고 정부의제로 안착되는 단계를 중점적으로 살펴본 것이다. 연구는 정보화 정책관련 키워드를 토대로 소셜텍스트 확산 양상 및 유형, 그리고 이와 관련된 정책 대응 사례를 살펴보는 방식으로 구성되었다. 소셜텍스트 확산 양상의 분석을 위해 2010년 11월부터 2013년 10월까지 뉴스섹션, 블로그, 커뮤니티의 공간에서 생산되는 게시글 및 댓글 등 584,277건의 소셜텍스트 빅데이터를 분석대상으로 삼았다. 오늘날 소셜미디어에서 생산되는 다양한 소셜텍스트 데이터를 빅데이터로 정의할 수 있는데, 이에 대한 정량적 분석을 시도하여 정책 확산의 양상과 유형에 대해 보다 객관화된 수치를 도출하고자 했다. 정보화 정책 관련 소셜텍스트 확산 양상에 대한 정량적 수치도출을 위해 범위(Scope), 지속성(Duration), 상호작용성(Interactivity), 다양성(Diversity), 주목도(Attention)로 총 다섯 가지의 정책 확산의 촉매제적 구성요소 개념을 제시했다. 이렇게 설정된 구성요소 개념들을 측정하여 정보화 정책과 관련한 소셜텍스트의 확산 양상을 보다 정량적으로 살펴보고 그 구체적인 사례들을 제시하는데 초점을 맞췄다. 연구결과를 통해 정부에 의해 설정된 정보화 정책 키워드들이 어떠한 양상의 소셜텍스트로 확산될 수 있는지 비교 가능한 표준화 지수를 도출해낼 수 있었다. 표준화 지수에서는 위성은 범위와 주목도에서 높은 점수를 보였으며 정보통신 모듈 및 부품은 지속성, RFID는 상호작용성, U-컴퓨팅은 다양성에서 각각 높은 점수를 보이는 것으로 나타났다. 다음으로 연구자는 표준화 지수를 통해 확산의 유형을 구분해보고자 군집분석을 실시하였다. 그 결과 각 정책 키워드는 총 3개의 군집으로 구분되었다. 첫 번째 군집은 범위, 상호작용성, 주목도에서 우위를 보이는 정책 키워드로 구성되었으며 이를 통해 공간확장형 소셜텍스트 확산의 특징이 나타났다. 두 번째 군집은 지속성과 다양성에서 우위를 보여 관심지속형의 확산 유형이 나타났다. 또한, 각 표준화 지수에서 특징적인 수치를 보여주지 않는 세 번째 군집은 인식분산형 소셜텍스트 확산유형을 보이는 것으로 나타났다. 군집분석 결과를 통해 소셜텍스트 확산 유형과 관련된 실제 정책 대응 사례도 살펴볼 수 있었다. 우선 공간확장형 소셜텍스트 확산 유형과 관련해서는 제1차 위성정보 활용 종합계획 발표, RFID 신규사업으로 추진된 특수 RFID 및 RFID 기반 응용서비스, 국가 정보화 시행계획에서 나타난 RFID 기술 예산투입, R&D 사업계획에서 나타난 위성기술 개발 예산발표 등의 사례가 나타났다. 관심지속형 소셜텍스트 유형과 관련된 정책대응 사례로는 차세대 스마트 디바이스 코리아 2020, 네트워크 장비산업 상생발전 실천계획, ICT 장비산업 활성화 정책사례가 나타났다. 마지막으로 인식분산형 소셜텍스트 확산 유형과 관련된 정보화 정책사례로는 제5차 국가정보화 기본계획의 세부사업 중 디지털콘텐츠 유통환경 조성 사업과 지능형 홈 서비스 고도화 사업의 사례가 나타났다. The formation process of Informatization Policy in Korea has been appeared reflecting Top-Down Model. The Top-Down Model is comprised of Two Social Diffusion stages, the 1st and 2nd. In the 1st stage, the government establishes Policy Agendas and Keywords while the Public Agendas form after it in the 2nd stage. This study lays emphasis on the 2nd Social Diffusion Stage by enumerating debates and discussion in the social media. As today`s social media yields a large volume of Social Text Data, this study is to execute the analysis of the data and observe the spreading process of issues risen through the Informatizaion Policy. This study has collected Social Text Data appeared in news sections, blogs, community articles and comments, 584,277 cases in the period of November 2010 ~ October 2013 in order to analyse the data. The study cited or extracted the cases through 12 different Infomatizaion Keywords(Keywords: IPTV, RFID, USN, U-Computing, Broadband Network, Digital Contents, Satellite, Modules and Parts of ICT, ICT Manufacturing, Application-based Devices of ICT, Telematics, Home Network). This study also stipulates five components of issue diffusion mechanisms; Scope, Duration, Interactivity, Diversity, Attention to measure the aspect of diffusion in numerical value and indexes of each components; SDIDA Index. Cases of Informatization Policy would appear in the study by researching the result of this measurement. There have been a few diffusion trends of social texts yielded by the Infomatizaion Policy issues. It shows that those social texts regarding Satellite, Modules and Parts of ICT, RFID, U-Computing have earned high index scores(Satellite-Scope index and Attention index, Modules and parts of ICT-Duration index, RFID-Interactivity index, U-computing-Diversity index). Reflecting the index score, the study found that there are 3 clusters; Type of Space Expansion, Type of Consecutive Interest and Type of Distributed Recognition through SDIDA Index. Finally, the study could find 9 cases of infomatization policy on three types.",
		"KEYWORD": "ICT,ICT 정책,SDIDA Index,국가정보화,빅데이터,소셜미디어,소셜텍스트,이슈 확산,정보화 정책"
	},
	{
		"ID": 117,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "Critical factors affecting the adoption of big data systems for smart grid (BD-SG) in Egypt =이집트의 스마트 그리드(BD-SG)용 빅데이터 시스템의 도입에 영향을 미치는 핵심 요인 연구 ",
		"AUTHOR": "EmadLotfyAshmawy",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 118,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "한국교통대학교 대학원",
		"TITLE": "빅데이터 처리 기술을 이용한 진보된 수요예측시스템에 관한 연구 =A study on the advanced demand forecasting system using big data technique ",
		"AUTHOR": "김효관",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 최영규",
		"STORE_LOCATION": "한국교통대학교 중앙도서관",
		"ABSTRACT": "경제 상황의 급변, 소비 경향의 변화, 대체기술의 부상 등 불확실한 경영환경으로 수요예측의 중요성이 더욱 강조되고 있다. 부적절한 수요예측은 과잉투자나 기회손실 등 금전적인 문제 뿐 만 아니라 리더십의 악화나 새로운 경쟁자의 부상 등 심각한 문제를 초래할 수 있다. 따라서 본 연구에서는 진보된 수요예측시스템을 구현하기 위하여, 수요예측 분석모델 측면에서는 다양한 수요예측 방법론을 조합하여 이를 산업분야에서 바로 적용할 수 있도록 시스템화 하였으며, 데이터 측면에서는 수요예측을 하기 위한 기본 데이터 표준 레이아웃을 정의하였다. 또한 예측을 위한 대량의 데이터를 신속하게 처리 할 수 있는 오픈소스 기반 빅 데이터 분산처리 플랫폼인 스파크를 사용하여 시스템의 처리 성능 및 확장성을 고려하여 시스템화 하였다. 마지막으로 예측 하고자 하는 대상 자료의 분산처리 기준 키 값을 최적화 하여 설계 및 구현 하였다. 시계열 예측기법의 검증을 위해 예측 주차의 예측 값과 과거 시계열 패턴이 일치하게 생성 될 수 있도록 판매량 수요예측을 수행하기 전 과거 1년 이상의 실적 데이터를 활용하여 1년을 53주차로 구분한 후 주차별 제품의 계절성 패턴을 산출 하였다. 판매량 수요예측 시 제품에 속한 모델들의 최근 판매량 지표를 기준으로 미리 산출된 예측주차의 계절성 패턴 비율을 적용함으로써, 예측한 값이 과거의 주차별 제품의 판매패턴을 반영할 수 있도록 시스템화 하였다. 시뮬레이션 완료 후 특정 모델의 예측주차 결과 값과 모델이 속한 제품의 계절성 패턴을 시각화하여 예측한 값이 제품의 과거 주차별 수요 패턴과 일치함을 확인하였다. 수요예측을 위한 제품 단위의 과거 판매실적 자료가 갖추어 졌을 때, 본 논문에서 구현한 시스템을 사용하면 판매량 수요예측을 위한 최근 판매 경향과 제품의 예측 주차의 과거 판매 패턴을 반영한 진보된 수요예측시스템을 제품 종류에 제한 없이 빠르게 구축할 수 있다. 본 연구는 진보된 수요예측시스템을 구현하기 위하여 수요예측 방법론을 시스템화하여 제시하였고, 빅 데이터 분산처리 플랫폼인 스파크에서 수행될 수 있도록 시스템화 하였으며, 이를 산업 분야에서 제품의 수요예측을 위하여 바로 적용할 수 있도록 구현하였다. 앞으로의 연구 과제는 다양한 산업분야에 적용된 후 각 산업 특징에 맞게 데이터 관리자에 의해 지속 관리할 수 있는 방법에 대한 연구가 이루어져야 하겠다.",
		"KEYWORD": null
	},
	{
		"ID": 119,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "순천향대학교 대학원",
		"TITLE": "NoSQL과 R을 이용한 대기정보 빅데이터 분석 연구 =A study on big data analysis of atmospheric information using NoSQL and R ",
		"AUTHOR": "서정연",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 이화민",
		"STORE_LOCATION": "순천향대학교 도서관",
		"ABSTRACT": "IoT시대의 발전, 스마트 디바이스의 발전, SNS의 확산으로 인해, 생성되는 데이터의 양은 점점 늘어나고 있다. 기존에 사용했던 방식인 RDBMS(Relational Database Management System)는 최근 기하급수적으로 늘어나는 데이터를 분석하기에는 많은 하드웨어 비용이 요구된다. 기존의 데이터베이스 시스템이 아닌 새로운 방법이 필요하게 되었고 NoSQL이 대안으로 등장하였다. NoSQL은 작고 값싼 장비 여러 대를 사용하여 대량의 데이터를 분산이 가능하도록 해준다. 본 논문에서는 현재 전세계적으로 이슈가 되고 있는 대기오염 빅데이터를 대상으로 빅데이터를 효율적으로 분석할 수 있는 방법에 대해 연구한다. 빅데이터 환경에서 데이터를 모델링하고, 통계 소프트웨어인 R을 사용해 대기오염 빅데이터를 효율적으로 분석하고 시각화 한다. R을 이용해 데이터들 사이의 상관관계와 패턴을 찾는다. 이러한 상관관계와 패턴 등을 이용하여 대한민국 미세먼지 통계 지도를 구현한다. 가독성이 높은 분석결과를 제공함으로 보다 쉬운 분석이 가능하다. 또한 RDBMS와 NoSQL 방법의 성능비교를 통해 효율적인 빅데이터 분석법을 연구한다. 데이터베이스 시스템은 RDBMS의 MySQL과 NoSQL의 MongoDB를 사용한다. MongoDB의 성능이 MySQL의 성능보다 우수하다는 사실은 익히 알려져 있지만 실제 본 논문과 같은 빅데이터 환경에서 연산 할 때의 우수한 점을 알아낸다. 또한, MongoDB의 Index 성능 평가를 통해 Index의 한계점을 알아낸다. 데이터베이스 시스템의 성능차이를 확인함으로써 상황에 맞게 빅데이터를 설계하고 분석?처리 할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 120,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "빅데이터 분석 기법을?활용한?2015?개정?교육과정?정책에 대한 언론보도 분석 ",
		"AUTHOR": "유예림",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 121,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "소셜 빅데이터 분석을 통한 전기요금 정책관련 국민인식 변화 연구 :전기요금 누진제를 중심으로 ",
		"AUTHOR": "이길량",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "In this study, social big data analysis was conducted focusing on `Progressive Electricity Rates(P.E.R)`, which was hot issue in 2016. By understanding the background of the reorganization of the 6th step (up to 11.7 times difference) that has been maintained for 12 years since 2004 and discovering hidden trigger factor of P.E.R. this study suggests the value and use of social big data analysis for establishment of public policies. The current P.E.R system, which was introduced in 1974 for the first time in the housing market, has been fluctuating its rates several times due to international oil price and power supply and demand conditions. However, there have been no cases in which problem were inspired by public opinion deterioration as in 2016. The system was implemented to avoid wasting energy that people pay higher electricity bills as they used more electricity under the judgement that income and power consumption are propotional. Nonetheless, the system was pointed out as the cause of the ‘ electric charge bomb ’ during the summer and it was considered an outdated system that could not reflect the reality. Faced with such progressive issues, the government finally had to revamp its pricing system to ease the six-stage P.E.R system to three levels, as it had announced earlier. However, the fire for the progressive system did not entirely disappear. If the public`s latent discontent over the progressive fee is re-ignited, it will inevitably lead to another national split and failed policies. Therefore, in this study, social big data were analyzed in 2015 and 2016 to discover the background factors that led to the P.E.R system.(Conducted a buzz analysis, emotional analysis, network analysis, and topic modeling) The study confirmed that the amount of buzz related to Korea Electric Power Corporation jumped more than eight-fold from 2015 to 2016, especially the P.E.R was issued in July and August. In addition, the channel analysis results showed that the issue was caused more by public emotion than the media initiative as the buzz increased based on Twitter and comments rather than official news. Based on these characteristics, this study emphasizes the appropriate utilization of social analysis and analyzed trends in electricity rate policies or changes according to time series to identify negative trends in opinions or trends in the detection of issues. The main achievements of this study were the discovery of a `trigger factor of P.E.R issues in 2016` through social big data analysis. Previous studies mainly addressed ‘international oil prices’, ‘conditions of electricity supply and demand’ and ‘political circumstances’ as crucial factors of the electricity charges(P.E.R system), but they were partly triggered by social issues in 2016. In this study, however, KEPCO operating profit, heat wave, and social groups, which were not handled in the previous studies, were significant determinants of recent P.E.R system by utilizing social bigdata analysis. The major accomplishment of this study is that the social big data analysis revealed `the trigger factor of P.E.R issues in 2016`. In previous researches, the major factors such as `international oil prices`, `electricity supply and demand conditions`, and `political situation` were the main determinants of electricity tariffs. However, this explains the background of P.E.R social progress in 2016. In this study, however, the results of KEPCO operating profits, heat waves, and consumer organizations, which were not significant in the previous studies, Social big data analysis technique. Therefore, it can be said that there is a great deal of suggestion in research and policy making in this field in the future. The number of organizations operating social analytics platforms in the public sector, including the government, has recently increased. However, not many organizations are using it properly. The P.E.R issue in 2016 will not just be limited electricity bills. In republic of Korea, the government has been transforming itself into an advanced country through the stages of development, which are ‘a social issue → public agenda → government agenda’. Therefore, consideration of social change and public sentiment will inevitably increase in future public policy formulation. This study contributes to understand the value of social big data analysis and prompt public interests through establishing sensible policies.",
		"KEYWORD": "big data,buzz analysis,electricity rate system,emotional analysis,national recognition,policy making,progressive electricity rates,progressive electricity rates determinants,social,social analysis,감성 분석,국민인식,누진세,누진요금 결정요인,버즈량 분석,빅데이터,소셜,소셜분석,전기요금,정책수립"
	},
	{
		"ID": 122,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "남서울대학교 복지경영대학원",
		"TITLE": "빅데이터 분석기법을 활용한 국민연금 동향 분석 =Study on national pension trend analysis using big data analysis ",
		"AUTHOR": "서상욱",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 123,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅데이터 환경에서 안전한 가상화 계층을 위한 다중 세션 사용자 인증 기법 =(A)multi session user authentication methods for secure virtualization layer in the big data environments ",
		"AUTHOR": "최도현",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다 지도교수: 전문석 참고문헌: p. 104-106",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 사용자 인증에 관련된 보안기술은 플랫폼의 기술적인 트렌드에 따라 큰 변화를 겪고 있다. 기존 사용자 인증 기술은 보안 취약성에 대한 해결책으로 다양한 인증 기술을 복합적으로 응용하고 있다. 그러나 지속적으로 새로운 보안 취약점이 발견됨에 따라 새로운 보안기술 개발이 요구되고 있다. 본 논문에서는 빅데이터 환경과 같은 최근 플랫폼의 가상화 구조를 고려한 다중 세션 사용자 인증 기법을 제안한다. 가상화 환경에 적합하지 않은 기존 사용자 인증 기술의 취약성을 해결하기 위해 보안 프로토콜의 영역을 내부 가상화 영역까지 확장 하였다. 또한 보안 세션 설립에 인증벡터를 생성하고, 기계학습 알고리즘을 활용하여 패턴을 추출하고 학습, 검증하여 기존 사용자 인증과 다른 사용자 인증 방법을 제공한다. 안전성 및 효율성 분석 결과 기존 사용자 인증 기법과 비교하여 강력한 보안성을 제공하고, 연산 효율성이 동등한 수준임을 증명하였다. 세션이 증가함에 따른 메모리 사용 효율성이 떨어지는 문제는 실시간 처리를 위한 빅데이터 플랫폼 아키텍처와 구축 및 운영 방법의 기술 발전에 따라 해결될 것으로 예상된다. 또한 보안 분야 데이터 분류를 위한 기계학습 알고리즘 최적화 연구가 필요할 것이다. 따라서 본 논문에서 제안하는 다중 세션 사용자 인증 기법은 향후 기계학습 알고리즘을 활용하는 빅데이터 환경에서 추출된 패턴 데이터베이스를 기반으로 안전한 사용자 인증 기술과 이상 징후 탐지 분야에 기여할 것으로 예상된다.",
		"KEYWORD": "가상화,머신러닝,빅데이터,하이퍼바이저"
	},
	{
		"ID": 124,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 법무대학원",
		"TITLE": "공공보건의료 빅데이터의 민간활용 및 개인정보보호 관련 법제에 대한 연구 :일반인 인식조사와 법제 개선방향 모색 ",
		"AUTHOR": "손영주",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 하태훈 부록수록 참고문헌: p. 77-81",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 보건의료산업에 있어 빅데이터 분석을 통한 활용은 치료 패러다임의 변화, 증가하는 의료비에 대한 절감 압박, 의료 서비스 수준에 대한 소비자의 관심 증대 등 당면한 문제를 해결하는 방안이자, 보건의료산업 경쟁력 강화 방안의 일환으로서 큰 주목을 받고 있다. 이미 우리나라는 지난 10여년이 넘는 동안 건강보험정보시스템을 통해 1조 8천억 건이 넘는 방대한 국민건강정보 빅데이터를 구축하고 있다. 정부는 이러한 공공보건의료 빅데이터를 민간부문에 제공함으로써 새로운 비즈니스를 창출하기 위한 정책을 적극적으로 펼치고 있다. 반면, 이와같은 보건의료 분야의 빅데이터 활용에 대한 우려의 시선도 존재한다. 보건의료산업 빅데이터의 원천이 되는 의료정보는 개인정보 중에서도 가장 민감한 정보에 해당하기 때문에, 공공보건의료 빅데이터의 민간활용은 새로운 법률관계의 형성이 필요할 수 있다. 본 연구는 보건의료정보 공공데이터화와 관련된 개인정보보호 측면에서의 법률적 근거를 살펴보고, 공공보건의료 빅데이터화 및 개인 건강정보의 민간부문 활용 등에 대한 일반 국민의 인식을 체계적으로 알아봤다. 이를 기반으로 보건의료 개인 정보공개 및 개인정보 보호에 대한 입법정책 이슈를 도출하고 그 개선방안에 대해서 모색했다. 제2장에서는 보건의료정보 공공데이터화 정책 및 방향에 대해 고찰하며, 개인정보보호의 개념과 보건의료정보의 특수성을 살펴보고 공공보건의료 빅데이터의 개념과 가치, 그리고 관련 정책의 주요 내용과 그 활용 사례를 정리했다. 제3장에서는 이제까지 공공보건의료 빅데이터의 민간활용 및 개인정보의 법적보호에 대한 일반 국민들의 인식조사를 수행하여, 매우 민감한 정보로 분류되는 보건의료정보의 공공데이터화, 민간부문 제공과 활용에 대한 전반적인 인식, 현 법률 체계에 대한 신뢰와 안심 정도 등을 파악하고, 현재의 공공보건의료 빅데이터 정책 방향이 지지되고 법률 체계가 수용되기 위해 어떤 조건들이 필요한 지를 일반 국민의 입장에서 도출했다. 제4장에서는 보건의료정보 공공데이터의 민간 제공과 관련한 법률을 살펴보며 보건의료 빅데이터 활용에 따른 위험요인, 그리고 관련 법안의 충돌 지점에서 발생하는 문제들을 검토하고 법률적 한계점을 짚어봤다. 마지막으로 제5장에서는 이같은 문헌고찰과 일반국민들의 인식 조사결과를 토대로, 보건의료정보 공개 및 개인정보보호에 대한 입법 쟁점을 살펴봤다. 특히 개인정보보호 강화 측면, 빅데이터 산업 진흥 측면에서의 입법 논의 현황과 한계를 고찰해보며 이와 같은 두 가지 가치의 조화로운 양립을 위한 정책적, 입법적 해결방안 제안을 제시함으로써 연구의 결실을 맺고자 한다.",
		"KEYWORD": "개인정보보호,공공데이터화,공공보건의료,보건의료정보,비식별화정보,빅데이터"
	},
	{
		"ID": 125,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "다차원 분석기법을 통한 빅데이터 분야 특허 가치 평가 =Patent value evaluation in big data area based on multi-dimensional analysis ",
		"AUTHOR": "노승윤",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 조완섭",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "2010년대에 들어와 정보통신기술(ICT, Information and Communications Technology) 산업의 빅데이터 비즈니스에 대한 관심이 점차 높아지고 있으며, 세계주요 국가들도 빅데이터를 2012년 이후의 ICT 산업을 선도할 주요 기술로 삼고 있다. 이에 따라, 많은 사람들에게 빅데이터 분야와 관련된 특허에 대한 정보를 제공하는 것은 아주 중요한 의미를 지닌다. 본 연구는 앞서 설명한 빅데이터의 전 세계적인 동향 및 분석을 위해 미국(US), 유럽(EP), 일본(JP), 중국(CN), 특허협력조약(WO), 한국(KR) 빅데이터 분야의 특허 Data를 이용한 다차원기법을 적용한 분석을 시도해 본다. 먼저 검색키워드와 국제특허분류를 조합하여 선별된 빅데이터 분야의 유효특허를 수집하여 ETL과정을 거쳐 스타스키마 형태의 데이터웨어하우스를 구축한다. 다음으로 유용한 정보를 추출하기 위해 빅데이터 분야별 차원 분석, 시간별, 국가별, 국제특허분류, 특허문헌 공개/등록여부, 국가별 특허문헌종류코드를 나타내는 6개의 관점에서 OLAP(Online Analytical Processing) 마이닝 다차원 분석하는 과정을 거친다. 이에 따라서 특허 대용량 데이터를 이용한 OLAP 다차원 분석기법을 통해 상세히 분석하여 그 결과를 신속하게 제공하기 때문에, 데이터와 사전연산 결과를 보다 쉽게 분석할 수 있다. 이러한 다차원기법을 통한 특허정보 분석은 각국의 특허 기술의 기술개발 추이 및 수준을 객관적으로 파악하고, 효율적인 연구개발 및 정책수립을 위한 기초자료를 보다 쉽게 분석할 수 있도록 하였다. 본 논문에서는 다차원 분석 기법을 통한 특허 대용량 데이터베이스 구축 기법과 함께 기존의 ‘검색 키워드’를 이용한 특허 맵을 재발견함으로써, 해당되는 기술들이 특허 맵의 어느 부분에 속하는지 파악할 수 있을 것이며 기술 분야의 흐름을 사용자들이 간편하게 알 수 있다면 특허관련 국가경쟁력에 도움이 될 것이다.",
		"KEYWORD": "OLAP,다차원,빅데이터,특허"
	},
	{
		"ID": 126,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "강원대학교 산업대학원",
		"TITLE": "빅 데이터 활용에 있어서 개인정보보호 문제점 및 개선방안 =Problems of personal information protection in big data utilization and an improvement method using PIMS :PIMS 활용 ",
		"AUTHOR": "김용빈",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김용석 참고문헌 : L.96-98",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "빅데이터를 활용하여 새로운 경제성장을 가져올 것이라는 기대와 달리, 개인정보의 유출 및 오·남용으로 인한 개인정보 침해라는 문제를 낳고 있다. 아직까지 빅데이터가 수집된 정보를 통해 사회현상을 분석하여 경제적 이익을 창출하거나 행정서비스의 결실을 가져올 것이라는 기대를 담고 있어, 수집된 데이터의 조합이 개인의 사생활은 물론 예기치 못한 개인정보의 오·남용을 간과하고 있다. 그러나, 앞으로 집적화된 개인정보를 보호하기 위한 정부차원의 강력한 대책을 필수불가결한 사항이다. 개인정보보호는 이용자의 프라이버시 보호를 위해 필요함은 물론 기업의 리스크 관리를 위해 서도 중요하다. 기업이 개인정보를 제대로 관리하지 못할 경우에는 고객의 신뢰성 저하로 인하여 기업의 이미지가 크게 훼손될 수 있다. 이에 본 연구에서는 2011년 제정된 개인정보보호법을 중심으로 개인정보의 빅데이터에 관한 개선과제를 도출해 하고, ISMS, BS10012의 기능적 특징을 PIMS와 비교 분석하여 각각의 공통점과 각국의 개인정보보호법을 통해 빅데이터 속에서 개인정보를 포함한 각종 정보간의 결합범위, 이용 및 제공에 따른 규제, 안전성 확보조치 등의 세부적인 기준을 검토하여 빅데이터 시대에서 발생하는 다양한 문제점에 대해 개선할 수 있는 방향과 PIMS의 LifeCycle을 개선하여 별도의 모델을 제시하고자 한다, 또한, ISMS와의 상호 인증체계구축에 대한 방안과 PIMS인증 시 개인정보를 다수 보유하고 있는 중소규모 업체에 대한 현실적인 지원정책에 대한 방향을 논의 할 것이며, 본 연구에서는 빅데이터 시대에서의 여러 가지 개인정보침해 라는 문제점과 현재 PIMS가 가지고 있는 다양한 문제의 해결책에 대한 방향을 제시했다.",
		"KEYWORD": "Bigdata,PIMS,개인정보보호법"
	},
	{
		"ID": 127,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "명지대학교 기록정보과학전문대학원",
		"TITLE": "국가기록원 웹사이트의 빅 데이터 분석과 활용 =Analysis and utilization of big data from the website of National Archives of Korea ",
		"AUTHOR": "진주영",
		"REGION": "서울",
		"PROFESSOR": "명지대학교 논문은 저작권에 의해 보호받습니다. 지도교수:이해영",
		"STORE_LOCATION": "명지대학교 도서관(서울)",
		"ABSTRACT": "기록관들은 정보를 찾는 이용자들과 직접적인 커뮤니케이션을 통해 이용자들의 요구를 파악하고 그에 맞는 기록정보서비스를 제공해왔다. 그러나 디지털 시대에 도래하면서 웹 환경이 보편화 되었고 이용자들이 웹을 통해 정보를 이용하고 활용하는 방식으로 달라졌다. 그에 따라 기록원도 웹사이트를 통해 기록원이 소장한 정보들을 제공하고 있으나 웹 환경에서는 이용자들과 직접적인 커뮤니케이션 없어 이용자들의 관심에 맞는 자료를 찾을 수 있도록 도와주는 것은 어렵다. 하지만 웹 환경에서는 이용자들이 웹 사이트를 방문할 때 남겨진 유입경로나 검색어, 클릭 한 게시물 등 이용자 흔적이 담긴 로그 데이터가 있다. 웹사이트에 남겨진 이용자의 흔적인 방대하고 다양한 로그 데이터인 빅 데이터 분석을 통해 이용자들이 요구를 파악할 수 있다. 현재 국가기록원 웹사이트는 2000년도에 만들어져 지금까지 쌓여있는 웹로그의 데이터는 다양하고 방대하다. 본 연구에서 빅 데이터는 데이터의 양과 데이터의 생성속도를 중점으로 최근 데이터들을 갖고 크게 유입경로와 검색어로 나누고 엑셀 피벗테이블을 활용하여 분석하였으며 또 빅 데이터 분석에서 사용되는 워드클라우드 worditout을 활용하여 분석결과를 나타냈다. 이러한 결과를 토대로 포털 사이트 및 SNS, 모바일 등을 활용한 국가기록원 웹사이트의 연계성 강화와 외국어 콘텐츠, 세분화된 주제별 콘텐츠, 최근이슈 콘텐츠를 활용한 콘텐츠 서비스의 고도화 방안 그리고 마지막으로 실시간 검색어, 연관검색어 추천, 다른 이용자가 검색한 검색어 추천, 검색가이드, 통합검색 개선 사항에 관한 검색 서비스 고도화 방안을 제안하였다.",
		"KEYWORD": "국가기록원,기록정보서비스,빅데이터,빅데이터분석,웹로그분석,이용자서비스"
	},
	{
		"ID": 128,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "아주대학교 교통·ITS대학원",
		"TITLE": "정부3.0, 빅데이터 시대 교통데이터 활용 방향에 관한 연구 =Study on traffic data reuse policy in times of big data, government 3.0 ",
		"AUTHOR": "조남민",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 오영태",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "스마트폰을 기반으로 하는 다양한 정보서비스의 욕구도 폭발적으로 증대하고 새로운 정부운영 패러다임인 “정부 3.0”을 키워드로 공공데이터의 적극적 개방 ? 공유를 통해 일자리 창출 및 창조경제 실현이라는 정책을 적극적으로 추진하고 있다. 본 연구에서는 정부정책에 적극적으로 부응하고, 공공데이터의 영역인 교통정보의 가치 창출 및 증진, 대국민 서비스 질적 제고 등을 위하여 교통데이터 개방 및 활용, 교통정보산업 생태계 활성화 방향을 제시하였다. 이를 위해서 국내외 공공데이터 관련정책, 법?제도, 활용사례, 경제적 효과, 기존 연구사례를 우선 고찰하였고, 실질적인 국내 교통데이터현황, 교통데이터 이해관계자 분석, 교통정보산업 생태계에 대하여 조사 분석하여 각종 분석결과를 토대로 문제점을 도출하고 개선방향을 구상하였다. 먼저 교통데이터 개방 및 활용 방향으로 교통데이터 수요자 요구조사 및 충족, 민간과 공공의 적극적 협력관계를 구축, 교통분석 및 빅데이터 분석전문가 양성, 개발자의 교통데이터 교육 및 매뉴얼 작성, 교통데이터의 품질관리 및 제공방식의 표준화 추진, 교통데이터의 민간 활용을 촉진을 위한 다양한 홍보 및 유인방안, 민간 의견수렴, 교통데이터 기반의 우수한 콘텐츠 개발 및 활용 사례의 창업지원제도 추진 등을 제안하였다. 또한, 교통데이터 산업생태계 활성화 방향으로 교통산업진흥법 및 산업진흥기관 설립 등 법/제도적인 기반조성 추진, 타 종류 데이터와 교통데이터를 동시에 제공하는 융합지원을 위한 방안 추진을 제안하였다. 마지막으로 공공과 민간의 각각의 역할을 충실히 수행한다면 교통데이터의 새로운 가치창출 및 창조경제 실현에 조금 더 가까워 질 수 있으리라 판단된다",
		"KEYWORD": "빅데이터,정부3.0"
	},
	{
		"ID": 129,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "텍스트마이닝을 이용한 한, 중 빅 데이터 관련 연구동향 분석과 비교 =Comparing big data research trend in Korea and China by text mining ",
		"AUTHOR": "趙子龍",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 130,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "스마트시티 빅데이터 관점에서의 안전도시 구현에 관한 연구 =Implementation of the safe community in perspective of big data in smart city ",
		"AUTHOR": "장혜정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김도년 참고문헌 : p. 175-182",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "사회가 고도화 될수록 재난은 그 발생 원인이 다양해지고, 예측하지 못한 상태에서 돌발적으로 발생하는 경향을 보인다. 최근 빈번하게 발생하고 점차 다양화·대형화되는 자연재해는 도시 인프라의 붕괴와 인명 및 재산 피해를 유발하고 있다. 이와 함께 각종 안전사고와 사회적 범죄의 증가는 도시민의 신체적·경제적·심리적 안전을 위협하고 있다. 그러나 우리나라는 아직까지 안전에 대한 인식이 미흡할 뿐만 아니라, 안전 관련 인프라 및 시스템 또한 외국 선진도시에 비해 낮은 수준에 머물고 있다. 재난 발생 시 인적·물적 측면의 부족한 대처능력이 드러나고 있으므로 하드웨어적·소프트웨어적 측면에서 안전에 대한 정비가 시급하다. 안전도시 구현을 위해서는 안전·안심을 고려해야 하고 안전문화가 형성되어야 하며, 이는 데이터의 체계적 관리를 기반으로 이루어진다. 그리고 데이터에 기반한 사업 진행은 과제의 시급성 및 중요성에 따른 프로그램의 우선순위를 결정하고, 한정된 자원을 효과적으로 활용하는데 기여한다. 이러한 관점에서 최근 그 중요성이 부각되고 있는 빅데이터의 체계적 활용은 안전도시의 실현성과 효율성을 증진하는 데 기여할 수 있다. 이에 본 연구는 안전도시 구현에 있어서 빅데이터의 활용방안을 제시하는 것을 목적으로 한다. 이를 위한 연구방법으로 첫째, 손상(injury)에 대한 안전에 초점을 두고 다양한 WHO 국제안전도시 사례를 분석하였으며, 각 도시의 공인신청서에 나타난 데이터 항목의 전수조사를 통해 안전도시 데이터 풀(data pool)을 구축하였다. 둘째, 안전도시 데이터 풀을 기반으로 한·일 안전도시 사례를 비교 분석하였다. 구체적으로는 1)데이터 풀을 기반으로 데이터항목 비교분석, 2)고위험군 설정 등 안전과 관련된 문제의 해결과제 도출 및 프로그램 선정까지의 프로세스 비교분석, 3)데이터 및 프로그램의 관리 체계 비교분석을 실시하였다. 셋째, 안전도시에서 손상에 대한 안전 확보를 위해 필요한 해결과제 및 프로그램을 도출하는 과정을 비정형 데이터와 정형 데이터의 활용 측면에서 분석하였다. 그 결과, 빅데이터 관점에서 안전문제 해결을 위한 과정을 총 7단계로 구분하고, 한·일 비교분석 결과를 토대로 빅데이터 관점에서 각 단계별 한국의 한계점과 이에 대한 개선방안을 제시하였다. 신뢰도 높은 데이터의 수집과 활용을 위해서는 손상 현황, 손상의 속성, 손상의 요인을 구체적으로 규정하는 데이터 풀을 확보하고, 사회의 상황과 여건 변화에 따라 지속적으로 발전시켜 나가야 한다. 이러한 관점에서 본 연구에서 구축한 안전도시 데이터 풀은 안전도시 구현에 있어서 손상 분석의 기초자료로서 큰 의미를 갖는다. 한국과 일본의 사례 분석결과, 우리나라는 많은 데이터를 보유하고 있음에도 불구하고 데이터의 활용적 측면에서 한계점이 드러나고 있으므로 이에 대한 개선이 요구된다. 통합적이고 지속가능한 데이터의 수집·활용·관리를 위한 조직 및 체계를 마련함으로써 빅데이터를 효과적으로 활용할 수 있도록 해야 한다. 그리고 우리나라의 뛰어난 ICT 기술력과 손상 통합정보시스템의 결합을 통해 안전도시 프로그램의 실효성을 제고하는 노력 또한 필요하다. 시민에게 지역사회 안전에 관한 오픈 데이터의 제공은 시민이 주체적으로 안전에 대한 현재 상황을 인식하고, 안전에 대한 커뮤니티를 활성화시키는 원동력이 되어 능동형 안심으로 이행하는 효과를 기대할 수 있다.",
		"KEYWORD": "빅데이터,손상,스마트시티,안전·안심,안전도시"
	},
	{
		"ID": 131,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "온라인 빅데이터 분석을 통한 시청률 예측에 대한 연구 :Study of TV rating prediction through analysis of on-line bigdata :드라마 〈별에서 온 그대〉 사례 중심으로 =case of the drama in My Love from the Star ",
		"AUTHOR": "김도연",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 최상현 참고문헌: p.41-44",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "최근 인터넷과 SNS(Social Network Service)의 확산으로 TV를 시청하면서 나누던 대화들이 인터넷과 SNS 공간에서 재현되며, 이른바 소셜 커뮤니케이션이 늘어나고 있다. 다양한 산업분야에서 인터넷에 올라오는 의견을 분석하고 의미를 추출하여 이를 활용하려는 연구들이 활발하게 이루어지고 있다. 한국 미디어 산업에서도 인터넷에서 생성되는 빅데이터 활용이 필요하다. TV 드라마의 흥행성과를 측정할 수 있는 정량적 측정치 중 하나는 시청률(viewer rating data)이다. 드라마의 시청률을 예측할 수 있다면, 광고 및 협찬 등 콘텐츠의 투자여부를 최소한의 시간 내에 판단하여 결정할 수 있을 것이다. 최근 이뤄진 드라마 시장성을 파악하는 연구들은 대부분 소셜 데이터의 영향력에 주목하고 있으며 정량적 분석에 그치거나 시청률과 별개로 구전행위를 분석한 점에서는 다소 아쉬움을 남긴다. 본 연구는 최근 한류드라마 “별에서 온 그대”의 시청률(AMR)과 점유율(SHR)에 유효한 영향을 주는 변수가 무엇인지를 분석하고자 한다. 이를 위해 온라인 버즈워드 데이터를 기반으로 시청률 및 점유율과의 관계에 대해 매체별, 요일별로 나누어 실증적 연구를 수행하였다. 또한 트위터 메시지, 네이버뉴스 기사에서 언급된 드라마 속성들의 버즈량을 살펴봄으로써 정량적 분석과 정성적 분석을 함께 실시하였다.",
		"KEYWORD": "버즈워드,빅데이터,시청률,점유율,텍스트 마이닝,트위터"
	},
	{
		"ID": 132,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울과학종합대학원대학교",
		"TITLE": "금융분야의 빅데이터 활용에 따른 개인정보보호의 문제점과 개선방안에 관한 연구 ",
		"AUTHOR": "김진",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 133,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "한국형 원격의료 도입 및 활성화를 위한 빅데이터 활용 방안에 관한 연구 =Study on big data utilization plan for implementing telemedicine in Korea ",
		"AUTHOR": "조한나",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이희상",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "본 연구에는 한국형 원격의료 도입 및 활성화를 위한 빅데이터 활용 방안이라는 주제를 통해 고령화 사회의 진전과 더불어 급증하는 보건의료 수요에 대하여 보다 정밀한 의료지원에 대하여 정확성 확보와 효율적 운영을 위한 원격의료분야의 의료정보의 활용 방안을 제시하고자 하고자 본 연구를 진행 하였다. 또한, 추진 중에 있는 원격의료분야에서 ICT 기술융합을 통해 폭발적으로 생성되는 의료정보에 대하여 빅데이터 기반의 의료서비스 활용사례 분석을 통해 아직도 그 접근이 부족한 국내의 원격의료 서비스 분야에서 적용 가능한 한국형 원격의료정보의 안정적 정착과 효율적인 체계 구축을 위한 전략적 접근 방법을 제시하였다. 이와 더불어 원격의료와 관련된 개인정보보호 및 데이터 활용을 대한 선진 의료국가와 국내의 법제 및 제도의 차이분석을 통해 국내 원격진료와 데이터 활용에 있어, 법?제도적 문제점들을 고찰하였으며, 더 나아가 원격의료 분야에 다양한 이해관계자간 상이한 목적과 사용 환경 하에 올바른 의료정보의 활용과 효율적 운영을 위해 가장 근간인 원격의료 정보의 효과적인 운용을 선진 의료국가의 사례를 비교 분석함으로서 국내의 빅데이터 원격의료분야의 활용방안에 대해 모색하였다. 세계의 사회(World Medical Association: WMA)는 원격의료를 “원거리로부터 원격통신체계를 통하여 전달된 임상자료, 기록, 기타 정보를 토대로 질병에 대한 중재, 진단, 치료를 결정하고 추천하는 의료행위”라고 정의하고 있다(WMA, 1999). 본 연구에서는 이러한 원격의료를 첫째, 중환자실 환자들의 빅데이터를 활용한 원격진료 사례, 둘째, 만성질환 환자들의 원격진료관련 빅데이터를 활용한 사례, 셋째, 기타 원격 의료서비스 분야에서의 빅데이터 활용 사례 세 부류로 구분하여 원격의료와 빅데이터와의 사례에 대해 제시 하였다. 사례분석 결과 정확한 환자의 상태 파악을 위해서는 환자의 과거 진료기록 및 병력, 가족력 등의 개인 의료정보 관련 빅데이터를 통해 환자의 상태에 대한 정보가 필수적으로 필요하며, 다양한 약에 대한 임상실험 결과 및 부작용과 의료조치에 대한 분석 등의 정보를 기반으로 의료행위를 지원하고, 시공간적 제약을 극복할 수 있는 방안도 함께 마련되어야 한다는 것에 더 노력해야 한다는 것을 알 수 있었다. 다음으로 만성질환자와 원격진료관련 빅데이터를 분석한 결과 한국에서도 원격진료와 환자의 다양한 건강정보 데이터를 활용하여 성과를 본 케이스가 있다는 것을 알게 되었으며, 서울대 간호학과를 중심으로 이뤄졌던 실험에서는 고혈압을 앓고 있는 저소득층 노인들을 대상으로 원격진료를 실시한 사례가 있다는 것을 알 수 있었다. 그 만큼 이제는 원격진료가 어느 단계까지 와 있다는 사실이 입증된 것이기도 하다. 마지막으로 세 번째 최근 원격의료 분야에서 다양한 연구가 이루어지고 있는 인도에서도 빅데이터를 활용을 통한 원격의료가 이루어지고 있다. 주요 내용은 주요 이동수단인 버스와 3G/4G 통신기술을 이용하여 환자 빅데이터의 수집 및 공유하고, 이를 통해 사고 발생 시 치료에 정보를 활용하는 분야로 이루어지고 있다는 것이 도출 되었다. 이러한 여러 가지 본 사례연구 분석결과 빅데이터를 활용한 라이프 케어 서비스는 미래의 건강, 생활을 예측하고 전망하는 ‘예언가’역할 을 할 것이다. 또한 과거의 접근방법보다 훨씬 체계적이고 정확한 방법으로 미래를 예측할 수 있을 것이다. 본 연구 결과 원시적인 의료 접근 방법에서의 가장 최신 진료 방법인 원격진료와 의료계의 변화는 쉽지 않을 것으로 보이나 머지않아 해결 될 것으로 전망된다.",
		"KEYWORD": "개인정보보호,빅데이터,원격의료,의료정보,정보통신"
	},
	{
		"ID": 134,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "강원대학교 대학원",
		"TITLE": "빅데이터 분석을 활용한 한국의 위험문화 분석 =Big data analytics for Korea risk culture and its implications ",
		"AUTHOR": "김철민",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:최충익 참고문헌 : L.103-110",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "오늘날 본 연구는 위험관리 거버넌스를 위하여 위험지각과 인지 특성을 분석하는데 목적이 있다. 오늘날 위험 논의는 대부분 과학적이고 객관적인 영역을 넘어 사회적이고 문화적인 관점에 초점을 맞추고 있다. 문제는 정부의 위험관리가 아직까지 사회문화적 관점을 고려하지 않고 있다는 것이다. 이에 본 연구에서는 위험인지와 문화를 통하여 위험관리 정책에 활용할 수 있는 모델을 제시하였다. 우리는 재난과 관련하여 크롤링 기법을 활용하여 175,823건의 뉴스기사를 찾았다. 이는 자연재난 49,924건과 사회재난 125,899건으로 구성되어 있다. 그리고 기계학습 방법을 이용하여 25가지의 재난으로 분류하였다. 이론적 고찰에서는 위험의 친숙성과 위험문화이론을 기반으로 위험지각과 인지를 살펴보고 거버넌스에 적용 할 수 있는 방안을 고민하였다. 연구모형에서는 위험의 ‘지각-인지-거버넌스’라는 일관된 체계 내에서 단계별로 위험을 해석하고 정책적 의미를 제시하였다. 친숙성은 시계열 요소 분해법을 활용하여 ‘추세’(trend)와 ‘계절성’(seasonality)으로 구분하였다. 이는 ‘낯선 위험’과 ‘익숙한 위험’으로 구분된다. 위험문화는 Group-Grid 모델에서 제시하는 기준에 따라 계층주의, 개인주의, 평등주의 그리고 운명주의로 구분하였다. 또한 위험문화 특성에 따라서 ‘명령과 통제’, ‘신공공관리’, ‘네트워크’ 그리고 ‘교육과 학습’ 같은 위험관리 거버넌스가 어떻게 연결되는지 살펴보았다. 이상의 분석과정을 통하여 도출된 결과를 정리하여 보면 다음과 같다. 첫째, 한국사회는 자연재난보다 사회재난의 위험지각이 상대적으로 큰 것으로 나타났다. 또한 사회재난 비율은 시간에 따라 지속적으로 증가하는 것으로 나타났고, 자연재난 비율은 계속적으로 감소하는 것으로 나타났다. 개별적으로 자연재난에서는 지진, 호우, 태풍이 가장 큰 부분을 차지하였으며 사회재난의 경우 교통사고와 화재에 대한 위험지각이 가장 큰 것으로 나타났다. 둘째, 추세와 계절성을 바탕으로 낯선 위험과 익숙한 위험이라는 관점에서 위험지각의 변화를 살펴보았다. 이를 통하여 낯선 위험(GroupⅠ), 익숙한 위험(GroupⅡ), 일반적 위험(Group Ⅲ) 그리고 불규칙 위험(Group Ⅳ)이라는 위험지각의 네 가지 특성을 도출하였다. 셋째, 문화이론에 따른 위험인지 특성을 살펴본 결과 한국사회의 위험문화는 계층주의가 지배적인 것으로 나타났다. 다만 시간의 흐름에 따라서 계층주의는 점차 감소하고 있으며 개인주의와 평등주의는 꾸준히 증가하는 것으로 나타났다. 또한 위험문화계수(RCQ)를 통하여 개별 재난이 가지는 문화적 특성을 도출하였다. 넷째, 연구모형에 따라 효과적인 위험관리 거버넌스를 도출한 결과 위험지각에 따라 수용태도와 선호하는 해결방안이 다른 것으로 나타났다. 익숙한 위험인 태풍, 호우, 화재는 국가 또는 사회적인 문제로 바라보고 있는 것으로 나타났다. 따라서 자원동원 능력이 뛰어난 명령과 통제 또는 네트워크 거버넌스를 선호하는 것으로 나타났다. 반면 낯선 위험인 황사나 전산망 마비의 경우 위험을 개인적인 문제로 바라보고 있다. 이는 문제해결의 자율성이 높은 신공공관리 접근을 선호하는 것으로 나타났다. 본 연구의 시사점은 크게 정책적 관점과 학술적 관점으로 구분할 수 있다. 전자는 재난위험의 지각 및 인지 특성을 바탕으로 위험관리 방안과 연동하여 국민의 눈높이를 고려한 위험관리 정책을 제시하고자 하였다. 후자는 기존의 현황분석이라는 한계를 넘어서 문화라는 관점을 새롭게 반영함으로써 새로운 접근법을 제시하였다는데 의미가 있다. 후에는 본 연구에서 사용된 분석모델을 확장하여 무형적이고 드러나지 않는 위험까지 다양한 위험을 반영함으로써 포괄적인 관점에서 위험문화를 살펴볼 필요가 있다.",
		"KEYWORD": "기계학습,빅데이터,위위험문화이론,위험관리 거버넌스,위험인지"
	},
	{
		"ID": 135,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "빅데이터 관리를 위한 오피니언 감성사전 모델 설계 =Design of opinion sensitivity dictionary model for big data management ",
		"AUTHOR": "서지훈",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 최진탁",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "본 논문에서는 한국어 텍스트를 기반으로 향상된 오피니언을 도출하기 위한 방법과 이를 빅데이터 환경에서 안정적으로 적용 및 관리하고, 예측할 수 있는 시스템 설계 방법론에 대해서 연구하였다. 한국어 기반의 오피니언 추출을 위한 향상된 감성사전을 구축하기 위해서 반의어와 접속어 기반의 역접관계를 분석하고, 어휘에 연관된 단어의 패턴을 탐색하여, 두 가지 부류의 감성사전을 제시하였으며, 이를 주식 온라인 뉴스 콘텐츠를 테마로 선정하여 빅데이터에서 관리 및 예측 분석이 가능한 한국어 문법 기반의 오피니언 반의어 감성 규칙 기법 모델을 구축하였다. 오피니언의 정확도는 감성사전의 구축을 통하여 크게 차이를 보일 수 있으며, 해외의 다양한 감성분석과 데이터마이닝은 영어 문법 기반의 텍스트마이닝을 위주로 분석을 수행하고 있다. 이에 따라 한국어 문법에서는 영어문법과 비교하여 다양한 접속어 어휘들이 등장하고, 이로 인하여 문장 전체가 긍정적인 구조일지라도 부정 어휘의 출현율에 의해서 상반된 결과를 도출하기도 한다. 본 논문에서는 오피니언마인닝을 빅데이터에 적용할 경우 안정성 있는 환경과 예측 및 분석의 정확도를 높이기 위해서 문장 전체의 연관된 단어의 출현 빈도와 패턴 분석, 반의법을 고려한 형태소 분석, 접속어 중심의 역접관계를 고려한 OASR기법을 제안하여 주식관련 온라인 뉴스를 분석하였으며, 기존의 감성사전에 비해서 오피니언의 도출 및 정확성이 향상된 결과를 얻었다. 본 논문을 통해서 한국어 문법의 향상된 감성분석과 텍스트 처리 및 관리하는 빅데이터의 활용에 있어서 보다 정확한 예측 및 분석이 가능할 것으로 기대된다.",
		"KEYWORD": "감성사전,분류기법,빅데이터,오피니언마이닝,자연어처리,텍스트마이닝"
	},
	{
		"ID": 136,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "빅데이터 분석 방법론의 산업 연구에의 적용 :Essays on big data analytics in industrial research :친환경 에너지 정책과 특허전쟁을 중심으로 =green energy policy and patent litigation ",
		"AUTHOR": "이동현",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 137,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "포항공과대학교 대학원",
		"TITLE": "빅데이터 기반의 비즈니스 인텔리전스 발전 전략 :Development strategy for business intelligence based on big data :미래 BI를 위한 핵심요소 =priority of key elements for next BI ",
		"AUTHOR": "장준기",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수:정우성",
		"STORE_LOCATION": "포항공과대학교 도서관",
		"ABSTRACT": "Generally we have facilitated Business Intelligence(BI) action through more than a decade, but it still seems that it has stayed in a strange area. The reason why the term is unfamiliar to us would be that BI is working around us in different name like SCM, CRM, ERP etc. But they became to offer only a limited definition and role of BI in these days due to the emerging of Big Data, which is a fundamental challenge for enterprises and governments. Through case studies of IBM, Oracle and Teradata, this research figures out 3 critical competences that BI vendors must consider to get initiative in future BI infra market based on Big Date environment. These companies are suggesting new key capabilities like Big Data analysis, real time transaction and BI standardization. However, this research has limitation that the environment of research is based on an assumption that every companies may need BI solution for unstructured data. Unfortunately, most of enterprises has B2B business model which requires only a capability for structured data, in other word, non-Big Data thing.",
		"KEYWORD": "Big data,business intelligence,DM,DW,OLAP"
	},
	{
		"ID": 138,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "염색가공산업의 에너지 고효율화를 위한 빅데이터 기반 재염 원인 및 영향에 관한 연구 ",
		"AUTHOR": "박희진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 노상도 참고문헌 : p. 37-38",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "4차 산업혁명을 맞이하여 에너지 분야 대응방안으로 빅데이터를 활용한 가상물리시스템(Cyber-Physical System), 인공지능 에너지 수요관리 등 ICT와 융합한 에너지관리 기술이 새롭게 주목받고 있다. 특히 고부가가치 산업인 염색가공산업에서의 공정 관리를 최적화 하여 에너지 낭비를 줄여 효율화를 도모하고 이를 통해 부가가치의 증대에 기여할 수 있는 기술개발이 중요시되고 있다. 그러나 기존 염색가공산업에서의 에너지 효율화와 관련된 연구들은 공정기 개발에만 집중되어 정작 공정관리 개선 방안에 대한 연구가 부족하다. 본 논문에서는 염색가공산업 현장 실제 데이터를 기반으로 재염 및 에너지 사용량의 원인에 대하여 분석하고 에너지 효율화에 최적화된 모델을 도출함으로써 염색가공산업에서의 빅데이터 활용방안과 에너지 고효율화를 제고하려고 한다. 본 논문에서는 빅데이터 수집이 구현된 환경에서 분산분석을 통하여 데이터를 분석하고 회귀모델 방법론을 이용한 에너지 효율화 모델을 구현한다. 또한 현장 실제 데이터와 에너지 고효율화 모델에서 나온 예측 데이터를 비교하여 효과를 검증한다.",
		"KEYWORD": "빅데이터(Big data),에너지 고효율(Energy Efficiency),염색가공산업(Dyeing and Finishing Industry),재염(Re-dye),회귀모델(Regression Analysis Model)"
	},
	{
		"ID": 139,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "빅데이터 분석 기법을 활용한 도서관발전종합계획 동향 분석 =Analysis on trends of library development plan by using big data analysis ",
		"AUTHOR": "김동석",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 노영희",
		"STORE_LOCATION": "건국대학교 GLOCAL(글로컬)캠퍼스 중원도서관",
		"ABSTRACT": "빅데이터 분석 기법을 활용한 도서관발전종합계획 동향 분석 본 연구는 도서관발전종합계획에 대한 언론보도를 빅데이터 분석 기법을 활용하여 분석 한 후 도서관발전종합계획의 시기별 동향과 시사점을 제공하고자 하였다. 이를 위해 2009년부터 2017년까지 포털사이트에서 제공되는 언론보도 기사를 시기별로 수집한 후 텍스트 마이닝 과정을 통해 데이터를 정규화 하였다. 이를 바탕으로 각 주제어의 빈도 분석, TF-IDF, 중심성 및 의미연결망, 구조적 등위성 분석 기법을 활용하여 연구를 수행하였다. 제1·2차 도서관발전종합계획이 시행되는 시기에 따라 데이터를 수집 하여 총 2,296건의 데이터에서 기사 제목과 부제, 텍스트 전문을 수집하였다. 분석은 텍스톰(Textom)과 Ucinet6를 활용하였다. 분석을 통해 결과로 확인할 수 있는 시기별 특징은 다음과 같다. 첫째, 공통적으로 사용되는 주제어는 시기에 따라 약간의 편차가 보였으나 높은 출현 빈도와 중요도 지수를 가지고 있는 것으로 나타났으며 50개의 상위 빈도 주제어 중 약 절반의 주제어가 공통적으로 사용되고 있어 제1·2차 도서관발전종합계획에 대한 의식이나 시각, 접근방식이 유사하다는 점이 드러났다. 둘째, 연결 중심성, 근접 중심성, 매개 중심성, 위세 중심성을 통해 시기별로 활발한 의미 활동을 수행하는 주제어를 도출하였다. ‘지역’과 ‘공동도서관’이 각각 제1·2차 도서관발전종합계획에서 활발한 역할 수행을 하는 것으로 나타났다. 의미 연결망 구성에 있어 제1차 도서관발전종합계획은 ‘추진’, ‘운영’, ‘지원’, ‘도서’ 등의 주제를 중심으로 연결 관계를 맺는 경향이 나타났으며, 제2차 도서관발전종합계획에서는 대부분의 주제어가 고른 연결 관계를 보였다. 셋째, 구조적 등위성을 통해 주제어를 군집화 한 결과 두 시기 모두 군집에 속한 주제어가 강한 연결 관계를 가지고 있는 것이 확인되었고 군집 간 개별성도 뚜렷이 나타나고 있었다. 제1차 도서관발전종합계획은 도서관 시설과 환경 등 외연적인 분야의 주제어로 구성된 군집이 중심을 이루고 있는 반면, 제2차 도서관발전종합계획에서는 도서관과 관련된 다양한 분야가 군집으로 형성되었다. 도서관발전종합계획 언론보도 기사를 대상으로 주제어를 분석한 내용을 통해 유추할 수 있는 시사점은 다음과 같다. 첫째, 제1·2차 도서관발전종합계획은 도서관의 양적인 성장에 상당히 많은 비중을 두고 있음을 확인할 수 있다. 제1차 도서관발전종합계획이 도서관의 외연적 성장에 치우쳐 있다면 제2차 도서관발전종합계획은도서관 외연적 성장과 더불어 내적 성장도 고려하고 있음을 확인할 수 있다. 둘째, 시기별 언론보도 경향이 다른 이유로 도서관 및 사회·문화적 환경 변화를 들 수 있다. 제1차 도서관발전종합계획이 수립될 당시 도서관의 환경은 디지털도서관 서비스의 확대가 필요했다면, 제2차 도서관발전종합계획을 수립할 시기의 도서관은 초 고령 사회 진입에 대비한 생애주기별 평생학습의 역할이 강조되고 있었다. 이러한 환경적 차이는 도서관발전종합계획의 정책을 수립하는데 있어 큰 영향을 미쳤을 것으로 판단된다. 셋째, 국내 언론보도는 도서관 확충과 관련된 정책에 많은 부분 초점을 맞추고 있음을 확인할 수 있었다. 이는 도서관발전종합계획 정책에 대한 취지나 의도가 일반 대중에게 정확하게 전달되지 못하고 있으며, 정책의 홍보가 가시적인 성과가 확인되는 특정 정책에 국한되어 있음을 시사한다. 따라서 충실한 정책 수행과 국민적 공감대를 높이기 위해서는 정책을 수립한 정부 또는 소관부처의 홍보 활동 강화가 필요하다. 넷째, 지방자치단체가 도서관 정책을 수행하는 새로운 주체로 주목받고 있음을 확인할 수 있었다. 제2차 도서관발전종합계획에서는 이원화된 공공도서관의 행정체계를 지방자치단체를 중심으로 일원화하는 정책을 제시하고 있으며, 그 밖에 지역대표도서관을 중심으로 다수의 정책이 제시되어 있음을 확인할 수 있었다. 다섯째, 앞으로 수립될 제3차 도서관발전종합계획에서는 미래지향적 정책의 수립이 필요하다. 도서관 서비스의 내실화를 위해 차대세 도서관서비스에 대한 연구 및 개발이 필요하며, 이를 위해 전문적이고 고도화된 역할을 수행할 수 있는 정책이 제시될 수 있어야 할 것이다. 본 연구는 도서관발전종합계획 언론보도에 대한 빅데이터 분석 기법을 활용하여 사회적으로 도서관발전종합계획이 어떻게 이슈를 형성하는지 확인하고자 하였다. 이를 위해 의미연결망 분석을 통해 시기별 동향을 파악하고 어떤 의미를 가지고 있는지 도출하여 도서관발전종합계획의 현주소와 의미를 규명하였다. 이러한 연구방법은 앞으로 도서관 정책에 대한 연구와 관련하여 사람들의 인식과 사회적으로 형성된 이슈를 파악하고 앞으로의 전망을 예측하는 연구에 유용한 방법이 될 것으로 생각된다. 향후, 연구 결과에 대한 질적 연구가 보완하고 정책과 관련된 이해당사자의 의견 및 선호도를 분석하는 연구가 수행된다면 도서발전종합계획의 비전을 제시하는 연구로서 의의를 가질 수 있을 것이다.",
		"KEYWORD": "구조적 등위성,도서관 정책,도서관발전종합계획,빅데이터,사회연결망분석,텍스트 마이닝"
	},
	{
		"ID": 140,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "동아대학교 대학원",
		"TITLE": "빅데이터 분석에 의한 선박 엔진 고장 예측 알고리즘 ",
		"AUTHOR": "박준현",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 조장우 참고문헌: p. 26-27",
		"STORE_LOCATION": "동아대학교 도서관",
		"ABSTRACT": "선박의 대형화, 고속화, 자동화로 해상물동량과 선박보유량이 지속적으로 증가하고 있으며 이로 인한 선박 관리 산업의 역할이 중요하게 되었다. 선박 운항 중 갑작스러운 주요설비 고장은 선박관리업계에 큰 경제적 손실을 야기시킬 수 있으므로 사전에 고장을 예측하고 예방할 수있는 알고리즘이 요구되고 있다. 이런 요구에 대응한 기존의 알고리즘들은 일반적으로 센서들의 임계치를 설정하거나 센서 간의 상관관계를 고려하여 고장을 예측하는 단순한 방법들을 사용하기 때문에 고장 사전 예측에 한계가 있다. 본 논문에서는 실시간으로 들어오는 빅데이터의 센서 값들을 상관분석을 이용하여 차원을 축소시켜 계산의 효율성을 높이고, 회귀분석적 방법을 적용하여 고장데이터를 검출할 수 있는 효과적인 알고리즘을 제시한다. H해운사의 실제 운항 중인 선박에서 생성된 데이터와 고장 보고서에 근거하여 시뮬레이션 해 본 결과 제시한 알고리즘이 효과적으로 고장을 사전에 예측할 수 있음을 실험적으로 입증하였다.",
		"KEYWORD": "선박,회귀분석"
	},
	{
		"ID": 141,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양사이버대학교 경영대학원",
		"TITLE": "빅데이터 기반 원격 군관리시스템을 적용한 건물에너지관리 효과 분석 :(An)analysis on the effect of building energy management according to the remote group management system based on big data :KT를 대상으로 =KT ",
		"AUTHOR": "김동준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최선",
		"STORE_LOCATION": "한양사이버대학교",
		"ABSTRACT": "탄소 배출량 증가에 따른 에너지 절감은 전 세계 각 국가 및 국제기구에서 가장 중요한 안건 중 하나가 되었다. 특히 전체 에너지 소비량 중 건물 부분의 소비 비중이 크게 차지하면서, 건물에너지를 줄이기 위한 연구와 개발이 활발히 이루어지고 있다. 최근 정보통신 기술의 발달로 건물에너지관리시스템 도입을 통해 에너지사용량을 보다 효율적으로 관리할 수 있는 기반이 마련되였으나, 초기에는 모니터링 수준에 불가하여 건물주에게 개선 효과가 미비하고 실효성 없는 시스템으로 인식되면서 실제 현장 적용에 어려움이 많아 활성화 되지 못하였다. 그러나 공공기관 보유 정보와 공공데이터 개방을 가속화 하면서 빅데이터 분석과 활용이 신성장동력 창출의 기회로 증가하였고, 건물에너지 빅데이터를 수집?분석?개선하여 소비되는 에너지를 줄이기 위한 연구개발이 활발히 이루어지면서 빅데이터의 활용은 건물 운영의 패러다임을 바꾸어 새로운 부가가치를 창출하는 신사업으로 주목받게 되었다. 최근에는 클라우드 기반의 원격 군관리 서비스를 시행함에 따라 건물주는 초기 구축 비용이 줄고, 다수의 건물을 보유하고 있는 기업들도 건물에너지와 시설운영을 보다 효율적으로 관리할 수 있다. 본 논문은 빅데이터 기반 원격 군관리시스템 적용을 통해 실질적인 건물에너지 절감량을 조사하고 분석하여 에너지절감 방안 및 비즈니스 활성화 방향을 제시하고자 한다. 빅데이터 기반 원격 군관리시스템 적용으로 에너지관리, 점검, 조치, 사후관리를 통한 에너지절감 방안을 마련하기 위해 32개 kt 지사에 대한 조사를 하였고, 정량적인 에너지 절감량과 환경효과를 분석하였다. 또한 비즈니스 장애 요인을 조사하고, 발전 방향을 제언하였다.",
		"KEYWORD": "Big-Data,Building Energy,Building Management,Energy Saving,Remote Group Management,건물관리,건물에너지,빅데이터,에너지 절감,원격 군관리"
	},
	{
		"ID": 142,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "빅데이터 기반의 아파트 수요 트렌드 분석에 관한 연구 =Trend analysis of apartment demand based on big data ",
		"AUTHOR": "김태경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김한수",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "2015년 현재, 우리나라 전체 주택 중 아파트는 59.9%의 비중을 차지하며 매년 증가하는 추세이다. 또한 아파트에 대한 수요는 고객이 생각하는 가치에 따라 다양하게 변화하고 있기 때문에 아파트의 수요 트렌드를 이해하고 분석하고 대응하는 것은 매우 중요한 의의를 지닌다. 그러나 현재 아파트 트렌드에 대한 분석은 주로 지엽적인 주제를 다루거나 정형 데이터를 기반으로 하는 경향이 있기 때문에 아파트 수요 트렌드라는 정성적인 개념을 분석하기에는 한계가 있었다. 따라서 본 연구에서는 빅데이터 분석기법 중 텍스트 마이닝을 활용하여 아파트 관련 뉴스기사를 분석하고, 아파트 수요 트렌드와 그에 따른 특징을 도출하고자 하였다. 분석 결과 아파트 수요에 대하여 개발, 거래, 분양, 입지, 정책, 주거환경, 투자?수익 등 7개의 테마별로 17개의 주요 트렌드가 도출되었으며, 7개의 테마 중 입지와 주거환경에 대한 관심이 가장 큰 것으로 나타났다. 본 연구의 결과인 아파트 수요 트렌드와 특징, 그에 따른 시사점은 건설기업에게는 새로운 상품을 준비하기 위한 참고자료로써, 정부 입장에서는 공공 복지를 위해 주택정책 개선에 대한 의사결정의 참고자료로써 유용하게 활용될 수 있다.",
		"KEYWORD": "빅데이터,수요,아파트,텍스트 마이닝,트렌드"
	},
	{
		"ID": 143,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "순천향대학교 대학원",
		"TITLE": "안전한 개인정보 보호조치를 통한 빅데이터 산업 활성화 방안 :The activation plan of big data industry through secure protection of personally identifiable information : focusing on the policy and de-identification ",
		"AUTHOR": "김동환",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 염흥열",
		"STORE_LOCATION": "순천향대학교 도서관",
		"ABSTRACT": "빅데이터는 ICBM(IoT, Cloud, BigData, Mobile)으로 대표되는 정보통신분야의 하나로 잠재력이 크다는 점에서 육성할 필요성이 인정된다. 그러나, 우리나라 현행 개인정보보호 관련 법규의 보호대상이 되는 ‘개인정보’의 경우 개인 식별정보(Personally Identifiable Information, PII) 외에 해당 정보만으로는 특정 개인을 알아볼 수 없더라도 다른 정보와 쉽게 결합하여 알아볼 수 있는 비식별 정보(Non-PII) 또한 포함시키고 있는 상황이다. 빅데이터 산업의 발전은 필연적으로 개인정보보호 이슈를 동반하게 되고 개인정보 유출과 지나친 보호 모두 문제가 발생되는 규제적 딜레마를 발생 시키게 된다. 빅데이터 활성화를 위해서는 개인정보가 적절히 보호되면서 자유롭게 활용될 수 있는 기술적, 법적 환경을 구축해야 할 것이다. 이를 위해서 본 논문은 현 시점에서 우리나라의 문제점을 파악하고 해외 정책과 법 제도를 비교 분석하여 해결방안을 제시하고자 한다.",
		"KEYWORD": "개인정보보호,비식별화,빅데이터,산업 활성화,재식별화,정보 프라이버시"
	},
	{
		"ID": 144,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 글로벌창업대학원",
		"TITLE": "기술사업화 초기 단계에서 빅데이터 활용이 경영성과에 미치는 영향 연구 :A study on the effect of big data utilization on business performance at the early stage of technology commercialization subtitle : focusing on the mediating effect of development performance ",
		"AUTHOR": "노석현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김경환 참고문헌 : p. 57-60",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "경제 환경의 불확실성이 높아지고 과학 기술의 발달로 노동 생산성이 높아지면서 기존 기업에서는 고용을 늘리기 어려운 상황으로 청년 실업 문제가 심화되고 있는 가운데 창업의 중요성이 강조되고 있다. 문제는 창업 기업의 성공률이 높지 않다는 데 있다. 따라서 창업 초기 실패율을 낮추는 것이 창업 활성화에서 중요한 부분이라고 할 수 있다. 한국 창업기업의 가장 주된 실패 요인은 ‘사업준비 부족형’으로 신제품의 역할 확보, 시장과 기술 등 트렌드 조사, 전략적 마케팅 등 사업 타당성 분석이 미흡한 상태에서 창업하여 시장에서 실패하게 되는 경우라고 한다. 이러한 실패요인을 빅데이터 활용을 통해 스타트업의 Death Valley 극복의 돌파구로서 적용될 수 있지 않을까 고민하게 되었다. 본 연구의 목적은 최근 기술창업기업들이 기술사업화 초기 단계에서 빅데이터를 제품(서비스) 개선 및 마케팅에 적용하고 있는지 확인하고, 나아가 기술창업기업들의 개발성과와 경영성과에 유의미한 영향을 미치는지에 대해 실증 검증하고자 하였다. 그 결과, 빅데이터를 활용한 제품 및 서비스 개선 활동 등 개발성과를 높이는 것이 경영성과에 매우 긍정적인 영향을 미치고 있음을 확인 할 수 있었다.",
		"KEYWORD": "기술사업화,빅데이터,생존율,스타트업,졸리 기술사업화 모형"
	},
	{
		"ID": 145,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "지방정부에서 빅데이터 활용의 영향요인에 관한 실증적 연구 =(An)empirical study on the factors of bigdata utilization in local government ",
		"AUTHOR": "강정묵",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현성",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Korea applied and used Bigdata to variety of fields by selecting it as Government 3.0 Major Project. However, Bigdata were not utilized properly for indefinite regulation and lack of understanding, analyzing technique, and professionalism. The advanced study on Bigdata was mostly for private sectors than public sectors and study approached empirically was insufficient. Therefore, the purpose of this study was to find elements of effect on Bigdata utilization. The influence factors of Bigdata utilization were deduced by reviewing theoretical background and discussion on Bigdata in order to achieve the research purpose. The deduced factors were empirically analyzed through surveys and interviews, and hypothesis was verified and political implication was proposed for influence factors of Bigdata utilization. The survey of this study was performed to public officials of Seoul city and total of 510 surveys were used. In addition, interviews were performed to Bigdata experts. The results of surveys and interviews are as in the following. According to average value(individual/department) of major variables, the total average of Bigdata utilization as dependent variable was 3.07/3.06, Bigdata utilization degree as detail index was 2.83/2.83, and Bigdata utilization volition was 3.31/3.26. According to interview results, there was an opinion that the utilization of Bigdata was low for unopened useful data where public data were actively opened. The total average of legal and institutional factor as independent variable was 2.90/2.97, legal understanding as detail index was 2.74/2.84, legal clarity was 2.81/2.86, information protection was 3.09/3.17, and security system was 2.99/3.02. According to interview results, conflict opinion with survey result was shown that security system was constructed and well managed with regard to control procedure. The total average of technology factor was 3.06/2.78, technology development as detail index was 3.46/2.71, standardization was 2.86/2.79, and network was 2.89/2.86. According to interview results, the difference with average value of network was shown that Korea is IT powerful nation and maintaining stable network with no big issue. The total average of data factor was 3.27/3.29, accuracy as detail index was 3.17/3.24, objectivity was 3.36/3.36, reliability was 3.37/3.33, and data management was 3.20/3.26. According to interview results, there was an opinion that there was difficulty in managing data systematically for no updated data in real time. The total average of behavioral factor as parameter was 2.90/2.89, Bigdata awareness as detail index was 2.90/2.89, open attitude was 2.95/3.02, cooperation was 2.84/2.89, and professionalism was 2.64/2.74. According to interview results, there was an opinion that useful data of public sector should be opened and shared, and construct cooperation with private sector. Technology factor, data factor, and behavioral factor were affecting Bigdata utilization but not affecting legal and institutional factor as influencing relationship of major variables for Bigdata utilization were analyzed. In addition, all independent variables were affecting behavioral factors which were parameters. The behavioral factors such as Bigdata understanding, open attitude, cooperation, and professionalism improved Bigdata utilization as parameter role when independent variables as Bigdata fundamental environment were constructed. The following political proposals were made based on above analysis results. First, legal regulations on utilization and provision of personal information should be well-acquainted in order to improve Bigdata utilization. In addition, Bigdata related specific regulation should be reviewed and concrete guidelines should be made in order to use personal information properly. Second, variety of technologies to collect, save, and analyze large scaled data in order to utilize Bigdata for a long-term. In addition, financial support should be made to maintain and manage stable network and security system. Third, various types of data produced in real time across the board should be secured. In addition, classification work to increase accuracy, objectivity, and reliability of data are needed, and management system to improve data quality should be constructed. Fourth, educational program to increase understanding on Bigdata and train professionals needs to be established. In addition, the relation of cooperation between public sector and private sector should be developed by creating culture of opening or sharing public and possessed data. This study has meaning of research that it empirically researched to reveal influencing factors on Bigdata utilization and proposed Bigdata application plan by apprehending awareness and influencing relationship on major variables. Key word: Bigdata utilization, behavioral factor, legal and institutional factor, technology factor, data factor",
		"KEYWORD": "기술 요인,데이터 요인,빅데이터 활용,행태 요인. 법제도 요인"
	},
	{
		"ID": 146,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "하둡을 이용한 빅데이터 번호판 인식 =Automatic number plate recognition for big data using Hadoop ",
		"AUTHOR": "박진우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박호현 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "현재 이미지가 고화질 고화소 추세이며, 정보통신기술의 발달로 인해 이미지 데이터의 사이즈와 양이 기하급수적으로 증가하고 있다. 따라서 기존의 단일컴퓨터로 처리하던 번호판 인식처리기는 늘어나는 데이터를 처리하기에는 한계가 있다. 본 논문은 분산 처리 프레임워크인 Hadoop을 이용하여 번호판 인식 시스템을 제안한다. SequenceFile을 이용하여 매퍼당 여러 개의 이미지 데이터를 가지고 있는 데이터 블록을 인풋으로 받아 번호판 인식을 수행한다. 실험결과 하둡의 데이터 노드 1개와 비교하여 데이터 노드 16개에서 최대 14.7배의 속도향상을 보였으며, 데이터 셋의 크기를 10배 증가하여도 데이터 노드가 점진적으로 늘어남에 따라 번호판 인식 속도의 강인함을 확인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 147,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "빅데이터 이용에 대한 경쟁법 적용 연구 :빅데이터의 온라인상 수집 및 활용의 관점에서 ",
		"AUTHOR": "유현근",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 李煌 참고문헌: p. 81-84",
		"STORE_LOCATION": "고려대학교 도서관",
		"ABSTRACT": "빅데이터는 21세기에 혁신을 가져올 중요한 원천으로서 빅데이터를 활용한 비즈니스 모델이 하나의 선택이 아니라 필수로 자리매김하고 있다. 그러나 경쟁법적으로 보았을 때, 신규사업자가 과연 직관과 사업능력만으로 빅데이터를 보유한 사업자를 극복할 수 있는지에 대한 문제가 제기되고 있다. 그러나 국내에서는 아직까지 빅데이터를 개인정보보호의 관점에서만 다루고 있는 실정이다. 본 논문에서는 빅데이터가 수집상 야기되는 문제점과 그것이 빅데이터 활용에 어떠한 부정적 영향을 미치는지 살펴본 후, 빅데이터 수집과 그에 이은 활용의 전 과정에 걸쳐 발생하는 시장실패 현상을 경쟁법적으로 어떻게 규제할 수 있는지를 논의하고자 한다. 특히 빅데이터 수집상의 문제에 왜 경쟁법적 규제가 필요한지에 대하여 살펴보았다. 구체적으로 빅데이터 수집과 관련하여 국내 공정거래법상 거래거절, 필수설비이론, 가격남용의 법리가 문제될 수 있음을 논증하였고. 그 전제로 관련시장 획정 시에는 SSNIP 테스트 보다는 SSNDQ 테스트가 적절할 수 있음을 설시하였다. 마지막으로 빅데이터 수집단계에서 경쟁법이 개입하는 것은 단순한 ‘규제’의 의미가 아니라 빅데이터가 활발히 활용되어 다양한 서비스가 생겨날 수 있는 환경을 ‘조성’하는 의미임을 강조하였다.",
		"KEYWORD": "Big data,Data portability,Network effect,SSNDQ,가격남용,거래거절,네트워크 효과,데이터 이동성,빅데이터,시장지배력 전이,필수설비이론"
	},
	{
		"ID": 148,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "빅데이터 분석기법을 활용한 국가주요시설물의 안전등급 예측모델에 관한 연구 :다중이용건축물을 중심으로 ",
		"AUTHOR": "김일환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 尹之源 참고문헌 수록",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "본 연구는 시설물의 감리ㆍ시공ㆍ설계 및 유지관리 등 시설물 생애주기(Life-Cycle)에서 발생하는 모든 정보를 통합 관리ㆍ공유하는 시스템인 시설물정보관리종합시스템(Facility Management System)에 축적된 데이터를 빅데이터 분석 기술을 활용하여 시설물 상태에 영향을 주는 요인을 분석하고 생애주기관리 상태를 예측하였다. 이를 위하여 시설물 관리 현황, 안전점검 및 정밀안전진단 제도 현황, 시설물 안전성 평가 방법, 보수보강 실적 등을 조사ㆍ분석하였으며, 빅데이터에 대한 정의, 기술 동향, 활용 사례를 파악하고 데이터 속성 분석을 위한 탐색적 자료 분석, 의사결정나무 모형을 활용한 분류 분석, 비정형데이터 분석을 위한 텍스트 분석 등 빅데이터 분석 기술을 활용하여 다중이용건축물에 대한 점검·진단, 보수·보강 등 관리 상태 분석, 안전등급과 보수·보강간의 관계 분석, 점검·진단 결과 분석, 안전등급에 영향을 주는 요인들을 분석하였다. 분석결과 다중이용건축물의 기본정보 및 점검진단 정보를 통하여 향후 시설물의 위험성을 예측할 수 있는 안전등급 예측모델을 도출하였다.",
		"KEYWORD": "국가주요시설물,빅데이터 분석,시설물유지관리,안전등급 예측모델"
	},
	{
		"ID": 149,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "국방대학교 국방관리대학원",
		"TITLE": "빅데이터 분석을 활용한 지상군 훈련 전투원의 생존시간에 관한 연구 =(A)study on survival time of ground training combatant using big data analysis ",
		"AUTHOR": "백창일",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 150,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "빅 데이터를 이용한 고객 행태 분석에 대한 연구 :A study on the customer behavioral analysis using big data of distribution industry ",
		"AUTHOR": "서현지",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 고승곤",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "다양한 산업 발전과 데이터의 저장 기술의 발전은 대규모 데이터에 대한 생성과 수집을 가능하게 하였고 이를 이용한 통계적 분석은 중요 현상에 대한 실시간 의사 결정을 가능하게 하였다. 이러한 추세는 다변화된 현상들을 올바로 설명하고 예측하기 위하여 정치, 사회, 경제, 문화 분야로 확대 적용되고 있다. 현재 유통업에서는 다양한 채널에서 수집되는 고객 정보를 이용하여 개별 고객에 대한 선호를 파악하여 고객이 원하는 제품/서비스를 제공하기 위하여 노력하고 있다. 이러한 노력 중의 하나로 개별 고객의 멤버십 그리고/또는 거래 데이터를 이용하여 의미 있는 고객 정보를 도출하여 기업 경영에 적용하고자 시도 하고 있다. 본 논문은 기업의 지속성에 기초가 되는 고객 데이터의 올바른 수집과 분석을 위하여 기존의 고객 관계 경영(Customer Relationship Management)을 기초로 새롭게 등장한 Big Data의 유용성을 고찰해 보고자 하였다. 이를 위하여 유통업의 고객/거래 관련 데이터의 수집 구조를 파악하고 개인 고객 관점의 고객 지표의 생성 그리고 이를 이용한 고객 세분화 방법과 체계적인 통계 분석을 위한 사전 준비 작업을 제안해 보고자 한다. 제안된 방법은 2016년 특정 기간 동안에 수집된 유통업 A사의 다채널 수집 데이터 30TB에 적용하여 그 사례를 함께 제시하였다.",
		"KEYWORD": "CRM,고객 세분화,고객 지표,단일 고객 관점,빅 데이터,유통업,통계적 방법"
	},
	{
		"ID": 151,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "목포대학교 대학원",
		"TITLE": "빅 데이터를 활용한 공유숙박의 선택속성이 만족도·행동의도에 미치는 영향 :The effect of selection attribute of shared accommodation using big data on satisfaction and behavior intention : focusing on the cultural adaptation regulatory effects ",
		"AUTHOR": "김주일",
		"REGION": "전라남도",
		"PROFESSOR": "지도교수: 박흥식",
		"STORE_LOCATION": "목포대학교 도서관",
		"ABSTRACT": "여행객의 여행 패턴의 변화와 새로운 형태의 경제개념의 발전에 따라 관광산업에서도 기존의 숙박유형과 차이를 가지는 숙박유형이 나타나게 되었다. 공유경제의 발전은 관광산업과 함께 새로운 숙박유형인 공유숙박 서비스가 등장하였다. 여행객의 여행패턴과 맞물려 관광산업 내에서 중요한 부분이 되었다. 그러나 공유숙박 서비스의 중요성이 부각되고 있지만, 공유경제 모델에서 중요한 역할을 하는 대여자, 이용자, 공유경제 플랫폼에 대한 연구는 부족한 실정이다. 이에 본 연구에서는 공유숙박 서비스를 이용하는 수요자 중심의 선택속성을 도출해 내고, 도출되어진 수요자 중심의 선택속성이 만족도와 행동의도에 어떠한 영향을 미치는가를 파악하였다. 또한, 공유숙박 서비스 선택속성이 이용자의 문화적응도의 조절효과 정도에 따라 전반적인 만족에 어떠한 영향을 미치는지 구조적관계를 실증분석을 통해 파악하고자 하였다. 본 연구의 목적달성을 위하여 가장 중요한 공유숙박 서비스의 수요자 중심 선택속성을 도출하기 위하여 빅 데이터를 활용하여 공유숙박 서비스의 선택속성을 도출하였다. 빅 데이터 분석기법 중 텍스트 마이닝을 이용하여 추출된 단어를 중심으로 정제과정을 거쳐 52개의 공유숙박 서비스 선택속성을 도출하였다. 도출된 52개의 공유숙박 서비스 선택속성이 만족도와 행동의도에 미치는 영향을 파악하기 위하여, 공유숙박 서비스를 이용한 경험을 가진 이용객을 대상으로 2016년 10월 1일부터 10월 7일까지 온라인 설문을 통하여 348개의 표본을 수집하였다. 본 연구에 사용된 분석방법은 SPSS 22.0을 활용하여 기술통계와 탐색적 요인분석, 표준 단순회귀분석, 표준 다중회귀분석, 위계적 회귀분석을 실시하였다. 본 연구의 가설의 검증을 실시한 결과를 요약하면 다음과 같다. 첫째, “공유숙박 서비스의 선택속성은 만족도에 유의한 영향을 미칠 것이다”에서는 숙박시설 선택속성(가격정책, 편의시설, 내부시설, 접근성, 예약정책, 부대시설), 호스트 선택속성(서비스, 정보제공 및 평판, 이미지), 사이트 선택속성(플랫폼) 모두 만족도에 유의한 결과를 미치는 것으로 나타나 가설이 모두 채택되었다. 둘째, “공유숙박 서비스의 선택속성은 행동의도에 유의한 영향을 미칠 것 이다”에서는 숙박시설 선택속성(가격정책, 편의시설, 내부시설, 접근성, 예약정책, 부대시설), 호스트 선택속성(서비스, 정보제공 및 평판, 이미지), 사이트 선택속성(플랫폼) 모두 만족도에 유의한 결과를 미치는 것으로 나타나 가설이 모두 채택되었다. 셋째, “공유숙박 서비스 만족도가 행동의도에 유의한 영향을 미칠 것 이다.”에서는 만족도가 행동의도에 영향을 미치는 것으로 나타나 가설이 채택되었다. 마지막으로 공유숙박 서비스 선택속성이 만족도에 미치는 영향에 있어 문화적응도의 조절효과를 분석한 결과, 숙박시설 선택속성(가격정책, 편의시설, 내부시설, 접근성, 예약정책, 부대시설), 호스트 선택속성(서비스, 정보제공 및 평판, 이미지), 사이트 선택속성(플랫폼)이 유의한 영향을 미치는 것으로 나타났다. 이러한 연구결과를 바탕으로 방문지역의 문화에 대한 적응과 이해는 공유숙박 서비스 이용에 있어 만족도를 높일 수 있을 것으로 사료된다. 따라서, 본 연구 결과를 통하여 공유숙박 서비스의 이용에 있어서, 기존의 숙박시설들과의 다른 선택속성이 존재하는 것을 알 수 있으며, 공유숙박 서비스의 이용자 중심의 선택속성 대한 부분을 활용하여 이용자의 요구를 고려한다면 공유숙박 서비스에 대한 만족을 높일 수 있으며, 재구매 및 긍정적 구전효과를 이끌어 낼 수 있을 것이다. 또한, 이용자 역시, 방문지역의 문화를 이해하고 공유숙박 서비스를 이용한다면 높은 만족을 얻을 수 있을 것이다. 향후 연구에서는 공유숙박 서비스의 선택속성들을 더욱 구체적으로 세분화하여 객관적인 연구가 필요할 것으로 보이며, 공유숙박 서비스를 통한 관광산업이 성장할 수 있도록 다양한 방향에서 이용자 측면에서 깊이 있는 연구가 계속 되어야 할 것으로 사료된다.",
		"KEYWORD": "공유숙박 서비스,만족도,문화적응도,빅 데이터,선택속성,조절효과,행동의도"
	},
	{
		"ID": 152,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "데이터 품질 기반의 빅데이터 성숙도 모델에 관한 연구 =(A)study based on the data quality of bigdata maturity model ",
		"AUTHOR": "최광렬",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김창재",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "빅데이터 분석 성과를 더욱 효율적으로 향상시키기 위해서는 효과적인 빅데이터 운영 체계를 구축해야 한다. 이를 위해서는 빅데이터 운영 체계의 수준을 평가하고 개선할 수 있어야 한다. 그러나 대부분의 조직에서 이러한 요구를 충분히 만족시킬만한 모델은 제시되지 못했다. 따라서 본 연구에서는 기존의 빅데이터 관련 연구들에 대한 분석을 통해 조직의 빅데이터 운영 체계의 수준을 체계적으로 평가할 수 있는 빅데이터 성숙도 모델을 제시한다. 제시한 빅데이터 성숙도 모델은 빅데이터의 속성 저장성, 충분성, 신뢰성, 확장성, 보안성, 분석성, 활용성 7가지의 평가 영역들에 대해 CMMI을 기반으로 5단계의 빅데이터 성숙도 개념을 Staged 방식으로 적용시켰다. 본 논문에서 제시된 성숙도 모델은 빅데이터를 활용하는 조직의 빅데이터 분석 프로세스 운영 체계에 대해 자체적으로 빅데이터 성숙수준을 진단하고 체계적인 빅데이터 성숙도 전략을 수립하여 개선 방향을 설정하는 데 도움이 될 것으로 기대되며, 궁극적으로는 빅데이터의 성과 향상과 효과적인 의사결정에 기여할 수 있을 것으로 기대된다.",
		"KEYWORD": "BigData,BigData Features,BigData Maturity Model,BigData Properties,CMMI,Data Quality Management"
	},
	{
		"ID": 153,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "게임 중독 문제를 해결하기 위한 인지적 빅데이터 접근법 =A cognitive and big data approach to solve game addiction problems ",
		"AUTHOR": "정규수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진화 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 154,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "홍익대학교 경영대학원",
		"TITLE": "빅데이터 환경에서 소셜 커뮤니케이션을 위한 문화예술기관의 정보화 추진 방안에 관한 연구 =A study on informatization for social communication of arts and cultural institution in big data environment ",
		"AUTHOR": "황현경",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 조명계 참고문헌: 장 64-69",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "대다수의 문화예술기관들은 추진하고 있는 각종 공연, 전시, 교육 등 프로그램의 홍보부터 기관과의 지속적인 관계 형성 및 유지, 심지어 예술 창작과 제작분야까지 소셜 미디어를 적극 활용하고 있다. 문화예술의 생산과 향유방식을 둘러싼 커뮤니케이션 환경이 전통적인 형식에서 새로운 방식으로 대대적인 변화를 겪고 있는 것이다. 이에 본 연구는 문화예술기관의 소셜 미디어 활용 특성과 정보화 여건을 분석하여 최근 빅데이터 환경에서 기관의 소셜 커뮤니케이션을 위한 정보화 추진방안을 제시해 보고자 하였다. 최근 문화예술기관의 소셜 미디어 활용 현황과 정보화 추진 현황으로 볼 때, 기관 커뮤니케이션에서 소셜 미디어의 비중이 점차 커지고 있고 다양한 영역에서 효용성을 발휘하고 있다는 것을 확인할 수 있었다. 그러나, 활용 범위가 확대되고 전략이 다양해지는 것에 비해 아직까지 이를 뒷받침하는 정보화 환경은 매우 열악하여 대다수의 문화예술기관은 기본적인 정보시스템조차 구축하지 못한 상황이다. 문화예술기관 운영에서 지역사회 및 구성원들과의 커뮤니케이션의 성공여부가 운영의 성패를 가늠하는 주요한 지표가 된다. 현재 전 분야에 걸쳐 커뮤니케이션은 물론 많은 서비스들이 온라인화 되고 있으며, 최근 등장하는 혁신적인 기술들로 인해 그 기능이나 운영방식은 급속도로 변화하고 발전할 것으로 전망되고 있다. 이제 성공적인 커뮤니케이션을 위한 정보화 추진과 인프라 조성이 반드시 필요한 시점이다. 이에 본 연구의 결과로서 다음과 같이 정보화 추진방안을 제시하였다. 첫째, 기관 상황에 최적화된 소셜 커뮤니케이션 시스템 설계, 둘째, 빅데이터 환경으로 확장가능한 데이터베이스 설계 및 구축, 셋째, 고객관계관리, 분석시스템 등 기존 연계 시스템과의 통합, 넷째, 장기적으로 안정된 예산 계획 및 확보, 다섯째, 시스템 구축을 위한 전문 인력 및 독립적인 전담부서 조직, 여섯째, 소셜 커뮤니케이션 및 시스템 관련 전체 직원 교육이다. 다만, 대다수 문화예술기관의 소셜 미디어 활용이 소셜 네트워크 서비스가 중심이 되고 있어 현황 분석의 범위가 다양한 미디어로 진행될 수 없었으며, 현재 문화예술기관의 정보화 수준으로는 실제 빅데이터와 같은 최신 기술환경을 고려하기 어려웠던 것은 본 연구의 한계점으로 남았다. 가까운 미래에 더욱 다양한 소셜 미디어가 활용되고 이에 따른 혁신적인 정보시스템이 필요로 하게 되는 것은 예상 할 수 있는 바이다. 이에 향후 과제로서 빅데이터와 같은 최근의 다양한 기술 환경에서 소셜 미디어 활용을 위한 정보시스템이 어떻게 구축되어야 하는지와 같은 본 연구 주제에서 발전된 보다 세분화된 연구와 조직, 예산, 사업 등 기관의 운영 규모별 최적화된 정보화 모델에 관한 연구를 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 155,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "울산대학교 대학원",
		"TITLE": "빅데이터 분석을 통한 한국 여성의 진행성 폐암 환자의 EGFR-TKI 성적 =The real world experience of first generation epidermal growth factor receptor-tyrosine kinase inhibitor (EGFR-TKI) in patients with advanced lung cancer : explorative analysis of big data from Korean cohort ",
		"AUTHOR": "권병수",
		"REGION": "울산",
		"PROFESSOR": "지도교수: 최창민",
		"STORE_LOCATION": "울산대학교 도서관",
		"ABSTRACT": "연구배경 EGFR 변이 양성인 환자에서 EGFR-TKI 의 efficacy 는 여러 연구들을 통하여 알려져 있지만, 아직 실제 임상 현장에서의 결과는 없다. 이에 빅 데이터 분석을 통하여 1세대 EGFR-TKI의 10년간의 성적을 알아보고자 한다. 연구방법 본 연구는 한국의 진행성 폐암으로 진단된 여성 환자들에서 EGFR-TKI 의 임상에서의 실제적 효용성을 알아보고자 계획된 후향적 연구이다. 연구의 참가 대상은 20세 이상, 동반 암이 없는 여성 폐암 환자로서 초 치료로 고식적 항암치료를 받은 자들로 선정하였다. 이들 중 1세대 EGFR-TKI 인 gefitinib 또는 erlotinib 을 투약 받은 환자와 EGFR-TKI 를 한번도 투약 받지 않은 환자들로 구분하였고, 항암제는 gemcitabine, pemetrexed을 단독 투약 받거나 cisplatin 또는 carboplatin과 병합한 경우, 또는 docetaxel 을 단독으로 투약 받은 환자군으로 분류하였다. EGFR-TKI을 투약 받은 군과 투약 받지 않은 군으로 나누어 무진행생존률 및 전체생존률을 측정하였고, EGFR-TKI 를 1차- 2차 치료제로 투약된 경우에 따른 생존률에 차이가 있는지 비교 분석 하였다. 결과 2004년부터 2013년까지 11,045명의 환자가 본 연구에 포함되었다. 6,170(55.8%)명이 EGFR-TKI 를 복용한 환자였고, 4,875(44.1%)명이 EGFR-TKI를 한번도 투약 받지 않은 환자였다. EGFR-TKI 군의 6,170명 중 2.572(41.7%) 명이 6개월 이상 EGFR-TKI 를 복용하였다. EGFR-TKI 투약군과 비투약군의 전체생존률은 각각 574일 (95% CI 555-590 일), 284일 (95% CI 272-295 일)로 통계적으로 유의한 차이가 있었다(p<0.001). EGFR-TKI 복용 기간을 6개월로 나누어서 전체생존률을 비교하면 6개월 이상 복용 군, 6개월 미만 복용 군, 비투약군 각각 910일 (95% CI 886-936 일), 369일(95% CI 356-380 일), 284일(95% CI 272-295 일)로 EGFR-TKI를 6개월 이상 복용한 환자군에서 전체생존률이 유의하게 길었다 (p<0.001). 무진행생존률은 EGFR-TKI 를 6개월 이상 투약한 경우 475일 (95%CI 452-489 일)로 6개월 미만 군의 112일 (95% CI 105-115 일) 보다 통계적으로 유의하게 연장되었다 (p<0.001). 또한, EGFR-TKI 가 1차 치료제로 투약되었을 때 무진행생존률이 2차 치료제로 투약된 경우보다 더 길었고(p<0.001), 연령 및 투약된 항암제 횟수로 보정하였을 때 무진행생존률도 통계적으로 유의하게 길었다 (P<0.001). 결론 EGFR 변이율이 높고, 흡연률이 낮은 한국, 여성 폐암 환자를 대상으로 빅 데이터 분석을 실시한 본 연구는 EGFR-TKI을 투약받은 환자에서 전체생존률 및 무진행생존률의 향상이 있었음을 실제 임상에서 입증한 연구라는 점에서 의의가 크다. EGFR-TKI 의 적응증이 되는 환자에서 적극적인 EGFR-TKI 의 투약이 진행성 폐암 환자의 생존률 향상에 기여할 수 있을 것이다.",
		"KEYWORD": "EGFR-TKI,빅데이터,여성,진행성 폐암"
	},
	{
		"ID": 156,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 공학대학원",
		"TITLE": "빅데이터 분석을 통한 기술과 사회 트렌드의 상관관계 분석 =A correlation analysis with technology and social trend using big data analysis ",
		"AUTHOR": "김현동",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박상성 참고문헌: 장 21-22",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "본 연구에서는 복잡화된 환경 속에서 기업의 불확실한 의사결정에 대한 위험성을 낮추고 기술개발의 효율성을 높이기 위한 방안으로서 기술과 사회의 관계를 정량적으로 분석하기 위한 방법을 제안한다. 분석 자료는 대표적인 기술데이터로 평가받는 특허데이터와 사회 트렌드를 대변할 수 있는 구글트렌드의 웹, 유튜브, 뉴스 데이터를 이용하였다. 우리는 이들 데이터를 통하여 기술과 사회의 각각의 구성요소가 서로 갖는 관계를 파악하고자 상관관계분석과 통계적 유의성 검정을 실시하였다.",
		"KEYWORD": "기술과사회트랜드"
	},
	{
		"ID": 157,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "서강대학교 경영전문대학원",
		"TITLE": "빅데이터 마케팅을 이용한 스포츠스타의 광고 적합성 연구 ",
		"AUTHOR": "우미나",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진화 참고문헌 수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "모바일 인터넷 보편화에 따른 SNS의 발전은 현재 기업들의 적극적인 마케팅 홍보 공간으로 활용되는 결과를 낳았다. 방대한 양의 소비자 의견 데이터를 분석하는 빅데이터 분석 방법은 소비자들의 제품에 관한 의견과 반응을 알 수 있고, 더하여 더욱 과학적이고 효과적인 마케팅 의사결정을 하도록 지원하고 있다. 온라인 리뷰는 다른 소비자들에 의해 쓰여지기 때문에, 소비자들의 실제적인 소비 경험을 나타네는 리뷰 데이터의 신뢰성과 유용성은 많이 강조되어 왔다. 이에, 본 연구의 목적은 조화가설 이론에 근거하여, 빅데이터를 이용한 스포츠 스타와 광고 제품들간의 적합성을 측정하는 분석방식을 제시하는 것이다. 특히 트위터나 다른 블로그에서 수집한 데이터는 텍스트 형식이기 때문에, 이 연구에서는 텍스트 마이닝 방식 중에 하나인 키워드 추출 방식을 사용하였다. 스포츠 스타들로는 김연아, 손연재, 류현진, 추성훈 그리고 기성용이 포함 되었으며, 제품으로는 냉장고, 마사지기, 세탁기, 식품, 에어컨, 통신사, 핸드폰, 화장품 등이 고려되었다. 이들을 대상으로 제품과 스포츠 스타 각각의 이미지 적합성을 계산하여 선정된 스포츠스타 별 광고 시장에서의 활용을 논하였다. 분석 결과에 따르면 김연아는 식품, 통신사, 핸드폰과 높은 이미지 적합성을 보였으며, 손연재는 냉장고, 마사지기, 세탁기, 식품, 류현진은 에어컨, 추성훈은 에어컨, 통신사, 핸드폰, 화장품과 이미지 적합성이 높은 것이 발견되었다. 본 연구는 연구방법론 측면에서 방대한 비정형 데이타형식의 빅데이터 분석방법을 스포츠 스타와 제품간의 적합성을 평가하는데 활용할 수 있다는 점을 증명해 보였다. 백분율로 계산해주는 수식을 통해 브랜드와 최적의 이미지 적합성을 갖는 마케팅 전략을 세울 수 있기 때문이다. 즉 기존의 정형화된 설문방식의 단점을 보안한 빅데이터 분석 방법을 활용해 스포츠스타의 광고에 국한되지 않고, 향후 기업의 브랜드 마케팅 전략의 수립과 방향을 제시하는데 응용하여 적용할 수 있다는 의의를 갖는다.",
		"KEYWORD": null
	},
	{
		"ID": 158,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "빅데이터 기반의 건설기술 개발 트렌드 분석에 관한 연구 :Analysis of the trends of construction technology development based on big data : focused on construction patents in relation to the 4th industrial revolution ICT technologies ",
		"AUTHOR": "한재훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김한수",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "최근 4차 산업혁명 관련 기술에 대한 관심이 증가로 전 세계적으로 이에 대응하기 위한 노력하고 있으며, 특히 건설산업에서는 ICT 기술의 활용이 높아지고 있었다. 건설산업의 능동적, 선제적 대응을 위해 본 연구는 빅데이터 기법을 활용하여 지난 10년간의 ICT 건설기술 개발 트렌드를 분석하고 주요 특징을 도출하는 목적으로 수행되었다. 트렌드 분석은 거시적 관점에서 미시적 관점이라는 흐름을 가지고 단계적으로 수행되었다. 트렌드 분석 결과 전(全) 산업특허, 건설특허, ICT 건설특허는 모두 증가하였으며, 특히 건설특허 내 ICT 건설특허는 그 비중이 눈에 띄게 증가하는 추세를 보였다. 주로 건설시공 및 재료기술, 건설환경 및 설비 기술개발 등 하드웨어 기술이 ICT 건설기술과 접목되어 개발되었으며, 소프트웨어 ICT 건설기술 개발에도 노력을 경주해야 한다. 친환경, 안전, 환경기술과 관련된 ICT 건설기술의 경우 최근 증가하고 있는 추세이며, 현재 증가하고 있는 환경 및 안전에 대한 관심과 인식을 고려하였을 때 지속적으로 증가할 전망으로 보인다.",
		"KEYWORD": "4차 산업혁명,ICT 기술,건설특허,빅데이터,트렌드 분석"
	},
	{
		"ID": 159,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "강원대학교 산업대학원",
		"TITLE": "빅데이터 기반 도서추천시스템의 설계에 관한 연구 =A study on design of book recommendation systems based on big data ",
		"AUTHOR": "정경숙",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:권호열 참고문헌 : p.59-61",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "최근 한국의 교육은 디지털 사회로 전환되는 패러다임 아래 스마트교육을 중심으로 변화하고 있으며, 그 대상도 유아 및 초중등학생부터 평생교육 학습자까지 확대되고 있다. 특히 독서의 중요성은 스마트 교육에서도 여전히 강조되고 있지만 스마트 기기에 익숙해지는 사용자들이 흥미를 느낄 수 있는 독서지원 서비스는 그 수요를 따라가지 못하고 있는 상황이다. 현재 독서지원서비스와 관련한 많은 웹 또는 앱 서비스를 하고 있지만 공공도서관을 대상으로 독서지원서비스를 통합하여 지원하는 서비스는 부족한 현실이다. 또한, 복합적인 빅데이터를 기반으로 도서추천서비스를 지원하고, 부분적인 기능으로 산재되어 있는 독서지원서비스를 통합하여 하나의 시스템으로 설계하고자 하였다. 본 논문에서는 공공도서관에 대한 독서지원서비스 요구사항을 분석하고 복합적인 빅데이터를 기반으로 한 도서추천시스템을 설계하였다. 이를 위해 공공도서관의 기능과 빅데이터 등 관련 기술에 대해 알아보고 도서관 정보 나루, 네티즌 도서 리뷰 점수, 감성어 분석 등을 활용하여 다양한 빅데이터 기반의 도서추천시스템에 대한 설계를 하였다. 또한, 독서지원서비스 시스템의 기능적 요구사항과 비기능적 요구사항에 대해 분석 하였으며, Usecase와 Class-diagram, sequence-diagram을 정의하였다. 본 논문을 통해 공공도서관의 사용하는 이용자들의 독서에 대한 흥미를 유발하고 스마트 기기를 활용한 독서지원서비스에 대한 수요를 만족시킬 수 있을 것으로 기대된다.",
		"KEYWORD": "도서검색서비스,도서추천서비스,독서지원서비스,빅데이터,온라인서평서비스"
	},
	{
		"ID": 160,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "크라우드 소싱 빅데이터 분석 기반 마케팅 분석 및 자동 홍보영상 제작·맞춤형 배포 시스템 =A marketing analysis and automatic promotional video creation·targeting distribution using crowd sourcing bigdata ",
		"AUTHOR": "정종진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이한구",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "In this study, a variety of structured and unstructured crowd sourcing big data was collected to analyze commercial district information efficiently and marketing strategies stereoscopically for small businesses. On this basis, a system that would help small business owners easily create and distribute digital advertisements on their own to promote their businesses in a tailored manner was proposed. This system was designed to include a core analysis technology, an algorithm, and subsystems that realized them, technology connecting the subsystems, and service-providing technologies that could support small business startups and improve their current business activities. It also incorporated software that could allow small businesses with only ideas to create their own customized promotional video images. With the system, small business owners would be able to create unique and competitive digital promotional material fit for their business activities and also effectively deliver it to their potential customers. Accordingly, diverse structured and unstructured data were collected for analysis, and on the basis of these data, a diagnosis of the reality, an analysis of the prediction, and an analysis of the direction were carried out through a multidimensional knowledge base established by business types and strategies. Furthermore, the promotion strategy was developed on the basis of the analyzed marketing strategies. Therefore, the promotional material took the form of an organic digital advertisement and could eventually entail an enhanced promotion effect when it was created in the form of applications for smartphones, digital signage, smart TVs, etc. The study consisted of four subsystems: a subsystem that collects and refines crowd sourcing geo-user data in various fields, a subsystem that builds a knowledge base and generates a stereoscopic marketing strategy from the collected and refined data, a subsystem that automatically creates a digital advertisement with the induced marketing strategy for the small business owners, and a subsystem that distributes the created digital promotional material to their customers in a tailored manner such that it will have the greatest promotional effect. The system proposed in this study aims to help start up new businesses and improve their competency by providing a professional marketing service for low-income small business owners and supporting them in the creation of competitive promotional material. It will cause them turn their eyes to other promotion platforms such as animation and video footage from the existing leaflets and ultimately contribute to protecting and fostering small businesses and making more profits with low-cost marketing and promotional support. It is also expected that anyone can start their own business confidently by receiving key information on startups anytime and anywhere and engage in economic activities through promotion and marketing.",
		"KEYWORD": "다차원 홍보물 매쉬업,맞춤형 홍보물 배포,입체적 마케팅 전략,크라우드 소싱 빅데이터,홍보물 자동 제작"
	},
	{
		"ID": 161,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "빅 데이터를 활용한 토픽감정 성향에 대한 연구 ",
		"AUTHOR": "ShenHongmei",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 162,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 컴퓨터정보통신대학원",
		"TITLE": "로그 데이터 적재 성능 개선을 위한 빅데이터 처리 시스템 성능 평가 =Performance evaluation of big data processing system to improve log data loading performance ",
		"AUTHOR": "이재한",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 유헌창 참고문헌: 장 26-27",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 수 년 동안 효과적인 의사결정을 위해 빅데이터 분석 시스템을 구축하여 활용하는 기업이 증가하고 있다. 하둡의 등장으로 기존의 데이터 웨어하우스 시스템에 비해 저렴한 비용으로 데이터를 처리할 수 있게 되었다. 또한 하둡에서 구조적인 데이터를 저장하고 SQL을 사용하기 위한 SQL-on-Hadoop 을 비롯한 하둡 에코 시스템이 개발되었다. 하둡은 대용량 데이터의 배치 처리에 우수한 성능을 보였지만 입출력이 반복되는 작업에서 비효율적인 디스크 I/O가 발생하게 된다. 이러한 단점을 개선한 아파치 스파크가 개발되어 데이터 처리 시스템 구축에 사용되고 있다. 본 논문의 연구 목표는 수집된 데이터를 처리하여 RDBMS에 저장하는 과정을 효율적으로 처리하기 위한 방안을 탐구하는 것이다. 기존에 하둡이나 스파크에서 처리 성능을 비교 분석하는 연구는 많았지만 데이터를 적재하고 처리된 데이터를 RDBMS에 적재하는 과정에 대한 성능을 분석하는 논문이 부족하였다. 본 연구를 통해 빅데이터 처리 시스템 구축 시 효율적으로 데이터를 적재할 수 있는 방안을 제시하는 것을 목적으로 한다. 기존의 자바 프로그램으로 작성된 데이터 처리 프로그램을 개선하기 위해 하둡 에코시스템을 사용하여 시스템을 구축하였다. 정형화된 데이터를 효과적으로 처리하기 위해 하이브와 연동하여 테이블 형태로 저장하고 HiveQL을 사용하여 SQL 연산을 실행하였다. 저장된 로그데이터 파일을 하이브 테이블에 저장하고 처리가 완료된 데이터를 RDBMS로 이동하기 위해 위해 스쿱을 사용하였다. 하둡 에코시스템을 이용하여 구축된 시스템과 기존의 자바 프로그램과 비교하여 뛰어난 성능이 나타나는 것을 확인하였다. 하지만 시스템 구축 과정에서 처리되는 작업의 유형별로 필요한 하둡 에코시스템을 선정하고 설정하는 복잡한 과정이 필요했다. 스파크를 이용한 로그데이터 처리 시스템 구축에서는 복잡한 에코시스템 구축 없이 내장된 함수를 이용하여 데이터를 처리할 수 있었다. 추가로 스파크 데이터처리 시스템에서 파일 유형에 따라 데이터 처리 성능에 어떠한 영향을 미치는지 분석하였다. 각 시스템 별로 구축된 로그데이터 처리 시스템의 성능을 비교하여 효율적인 데이터 처리 시스템 구축 방안을 제안한다.",
		"KEYWORD": "빅데이터"
	},
	{
		"ID": 163,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "지방세 납세 유형 분석을 위한 빅데이터 구축 방법 및 분석 결과 =Construction method and results for payment pattern analysis of local tax with big data ",
		"AUTHOR": "김중엽",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조인휘",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "사회가 발전 할수록 정부의 정책 또한 다양해 지고, 이런 수요를 충족시키기 위한 국가의 재정 수요 또한 증가하게 된다. 따라서 세수 확대를 위하여 체납된 세금을 받아 낼 수 있다면 증세 없이 세수를 확보할 수 있다. 본 논문에서는 지방세에 대한 자료를 모아서 유형별로 분석하여 미수납율이 높은 패턴을 찾아내 중점적으로 관리할 수 있는 방법을 제시한다. 분석을 위해서는 우선 분석을 할 수 있는 자료를 구축해야 한다. 본 논문에서는 현재 지방세와 관련 있는 데이터를 바탕으로 분석에 유용한 자료들을 1차적으로 분석하여 선별한다. 그 후 실제 자료들을 데이터 구축용 자료로 변환을 하여 취합을 하고, 서버로 이관을 한다. 마지막으로 SQL LOADER를 이용하여 자료를 구축하는 방법으로 빅데이터를 구축하였다. 구축된 자료를 토대로 하여 기본적으로 의사결정나무 분석을 중심으로 자료를 분석하였다. 그리고 부족한 부분은 비슷한 수준의 2개 이상의 변수를 두고 변수들을 교차시켜 중복된 분포를 보이는 자료에 대하여 분석하는 교차 분석을 통하여 원하는 분석 결과를 얻어낼 수 있었다. ?",
		"KEYWORD": "SQL LOADER,빅데이터,의사결정나무 분석"
	},
	{
		"ID": 164,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 정보통신대학원",
		"TITLE": "빅데이터 기반의 로그데이터 분석을 통한 시스템 장애 감지기법 연구 =Big data based on system fault detection through log analysis techniques study ",
		"AUTHOR": "김진흥",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김지인",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "최근 인터넷 서비스의 증가와 다양화로 인해 서비스 로그들은 기하급수적으로 증가하고 있다. 서비스 운영자는 안정적인 운영을 위해 많은 양의 서비스 로그들을 분석하고 이상징후를 판단해야 하는 상황에 놓여 있으며, 최근 다양화되고 있는 서비스에 따라 대용량의 다양한 로그데이터가 생성되어 이벤트가 발생하였을 때 사람이 분석을 하는 등의 전통적인 방법에 의한 모니터링은 불가능한 상황에 놓여있고, 이를 해결하기 위해 분석을 위한 백업 데이터베이스와 같은 별도의 시스템을 구축하는 것에는 비용과 시간이 많이 소모되어 구현이 어려운 것이 현실이다. 이러한 환경에서 대용량 서비스 로그를 분석하고 의미 있는 데이터를 생성해 내는 과정을 자동화하여 서비스 운영자의 편의성을 높여주는 전통적인 방법 대비 고성능, 고효율의 분석기법을 고려 해 볼 수 있으며, 이를 위해 대용량, 비정형 데이터 처리에 효과적인 빅데이터를 기반으로 소프트웨어적인 구현을 하고자 한다. Java기반의 빅데이터 데이터베이스를 사용하여 비정형데이터인 로그데이터를 Java 프로세스와 CQL을 활용하여 대용량 데이터를 백업장비 도움 없이 필요한 부분만 선택하여 미리 정의 되어진 키워드 검색을 통해 데이터 분석을 자동화하는 방법을 빅데이터 기반의 소프트웨어적인 프로세스 구현을 통해 보다 적은 비용으로 기존의 시스템에 적용하여 활용 할 수 있는 기법을 구현하고자 한다.",
		"KEYWORD": "Big Data,CQL,Java,Log"
	},
	{
		"ID": 165,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구 =Big data-based fuel consumption estimation model using actual on-road DTG data and spatial data ",
		"AUTHOR": "조원희",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 최은미 참고문헌: p. 108-120",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "As part of the movement to reduce traffic accidents in Korea, it has become mandatory that all commercial vehicles are equipped with Digital Tachograph (DTG) devices, and large amounts of driving record data, including GPS trajectories, have been generated. So far, such DTG data has been used mainly for the purpose of inducing safe traffic driving. However, the utilization of DTG data is to expand in a variety of fields, such as eco-driving field to reduce fuel consumption. This study aims to establish a model that can enable fuel consumption estimation using a large amount of actual on-road DTG data and spatial big data analysis. Existing fuel consumption estimation models are mainly verified in a laboratory environment or in limited areas, and there are many variables that are difficult to collect in the actual environments of commercial vehicles. Additionally, if a variety of nationwide Korean driving record data is applied, the problem of lower accuracy arises. In this study, we proposed the SBiFEM(Spatial Big Data Fuel Estimation Model), which is the fuel consumption estimation model using DTG data and spatial big data analysis to improve this problem. SBiFEM is an analysis method that utilizes a variety of road information as additional input variables by using driving patterns and a spatial big data map-matching technique to reflect the wide range of environmental information of the road. In this study, a spatial big data analysis process using MapReduce is established and the entire process is verified, leading to preprocessing, spatial big data analysis, and driving pattern generation. First, the preprocess technology was advanced. For sensing data characteristics, there are large amounts of outlier data, so the results are not reliable if this data is not filtered. We studied the filtering technology using statistical techniques and driving pattern analysis. Second, a spatial big data analysis framework using large amounts of GPS trajectories was created. The map-matching technology is essential for analyzing vehicle travel data. Map-matching is the process of mapping GPS coordinates to road networks to identify appropriate map links. Most map-matching technology is not suitable for big data analysis that requires a fast analysis speed, because it has mainly been used for real-time navigation purposes. In this paper, we studied the map-matching technology using the spatial big data process of mapping GPS coordinates to road networks. Third, a model for estimating the fuel consumption was established. In contrast with the existing model, we have added variables to reflect the actual driving environment. One kind is driving patterns to reflect the vehicle driving characteristic, and the other kind is the addition of nationwide road environment information as variables. They were used for the spatial big data map-matching process to reflect the road environment information. To validate the performance of the SBiFEM analysis system, we used five distributed servers to establish a Hadoop/HBase echo system and to run the MapReduce program. To verify the fuel consumption estimation quality of SBiFEM, we compared the results of applying DTG data to the SBiFEM model and exemplary fuel consumption models, which are SIDRA, VSP, and VT-Micro. In the results of the analysis, the correlation comparing the actual value and the estimated value was 0.9169 and the mean absolute percentage error (MAPE) was 0.1846 in SBiFEM; these are superior values compared with other models. These results are expected to verify the excellence of the SBiFEM model.",
		"KEYWORD": null
	},
	{
		"ID": 166,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "빅데이터 분석을 통한 개인형 맞춤 의료 대책 방안 연구 =(A)study of a plan for personal tailored medicine through big data analysis :감염병 중심으로 ",
		"AUTHOR": "허준구",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 송관호 참고문헌: p. 47",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "빅데이터를 통한 감염병의 분석 및 예측은 해외에서는 매우 활발하게 이루어지고 있다. 하지만 국내에서는 감염병 유행에 대한 기존 체계는 사후 대처만 가능하며 이에 따라 사회경제적 비용이 발생할 수 밖에 없다. 최근에 들어서 소셜 미디어 정보를 융합한 질병 예측 모델에 관한 연구가 진행되었고 서비스를 시작하였으나 제한된 전염병에 한해서 제공하고 있다. 본 논문에서는 과거 2001년부터 2014년도까지의 개방된 감염병 데이터를 활용하여 법정 감염병에 대한 예방 및 예측 중심의 분석을 제공하고자 시도한다. 질병관리본부에서 제공하는 빅데이터를 통해 연도별 발병률 추이와 발병 패턴, 발병률을 도식화하고 상관관계를 확인하여 현재 시점에서 유행할 수 있는 감염병에 대한 위험도 및 사전 예방에 도움이 될 수 있는 분석을 제공하고자 한다.",
		"KEYWORD": "분석,빅데이터"
	},
	{
		"ID": 167,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "빅데이터를 활용한 패션디자인 감성분석 연구 :텍스트마이닝과 의미연결망 분석을 중심으로 ",
		"AUTHOR": "안효선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박민정 참고문헌: p. 148-163",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "The usage of smart phones and expansion of mobile services in the information era have established a new communications environment between the members of society and are implementing a market environment focused on the users. Social media especially has composed an online environment where sellers and users communicate freely rather than in a single linear relationship which presents an approach method to the methodology of converging user opinions in a completely new perspective. Due to this change in paradigm that focuses on the users, the necessity of a new sentiment analysis on fashion design is on the rise. In the field of fashion design, most sentiment analyses on design are studies that statistically evaluate surveys conducted on a certain respondent group and there are limitations of exploratory analyses being impossible to carry out that deviates from a certain boundary of terminology composed in the planning process of a study. Hence, this study intends to grasp the users’ perception and sentimental reactions on fashion design by analyzing data from social media which has become a method of public communication. As a new approach on traditional sentiment analysis methods, this study looks to proposing a method for a sentiment analysis through approaching big data which analyzes the texts in the posts of online users. Also as a method of sentiment analysis on fashion design, this study intends to derive sentimental terms on the design attributes of men’s stripe shirts as well as the characteristics of new sentiment analysis methods through a comparison with sentimental terms from preceding studies. Document research and an empirical study were conducted to fulfill the research purposes. Theories on sentiment analysis and analysis methods from preceding studies were reviewed, and a research procedure for the big data sentiment analysis was designed for analyzing atypical data made up of actual language of the users using text mining and semantic network analysis. This study collected texts related to men’s stripe shirts mainly from blogs from Naver and Daum. Texts from a total of 13,648 posts from November 1st, 2015 to October 31st, 2016 were analyzed and then compared with that of preceding studies to derive and organize the characteristics. A summary of the results of the study are as the following. First, without a traditional evaluation process through a survey where the users assess the sentimental factors followed by the researcher analyzing the results, this study collected the opinion texts from posts posted by the users and presented a procedure for big data sentiment analysis that can grasp the topics and contents of the evaluation through text mining and semantic network analysis. Secondly, as a result of analyzing the related terms that make up the superordinate topics through a topic modeling analysis of the text mining process, the wearing status per season and subjects of men’s stripe shirts were derived. Across the entire period, key contents of men’s stripe shirts were coordinating a daily look related to styling, popular fits of the season, utilizing seasonal items, and methods for coordinating colors. In terms of seasons, spring time which was from April 1st to April 30th, 2016 mainly showed the sharing of information on coordinating daily looks or boyfriend-looks, and during the winter season from November 1st to November 30th, 2015 the information shared were mainly about shirts suitable for special occasions such as job interviews, images formed by patterns of the shirts, patterns of ties that go well with certain shirts, and stripe shirts that match suits. Thirdly, a quantitative as well as an exploratory analysis was proven to be possible by visualizing the entire network based on a co-appearance correlation of design attributes and sentimental terms within the sentences through a semantic network analysis. As a result of the one-mode network analysis, this study found out that the contents related to the design of men’s stripe shirts can be categorized into four categories including patterns and color expressions, characteristics of everyday clothes, characteristics of shapes, and functional characteristics, based on the structural equivalence of the terminology index. As a result of the two-mode network analysis, patterns, colors, material, coordination, styles, and fits were derived as representative design attributes of men’s stripe shirts, and the sentimental terms connected to each of the design attributes were shown to be categorized into a cooperative sentimental terminology index that has a connection for three of less design attributes and a comprehensive sentimental terminology index that has a connection for four or more various design attributes. Also, this study confirmed which pattern, color, material, style, etc. which are main design attributes of men’s stripe shirts, are closely related to which fashion image or user sentimental reaction, through a visualization of the sentimental terms connected to each of the design attributes and fashion images. This study was conducted to present a method for deriving user perception and sentiment information on fashion design by data-fying the languages used in social media and examine the characteristics of the results. In the field of fashion, big data analysis is usually attempted in commercial terms such as distribution and marketing, and this study has significant academic meaning given that text analysis studies using big data in academic design analysis is at an initial stage and that it utilized data from social media which is a user-oriented communication environment as well as the fact that a systematical research was conducted on fashion design through big data analysis methods such as topic modeling and semantic network analysis. This study also has practical meaning, having derived terms based on actual language currently used and emphasized by ordinary users, and having presented a design guideline focused on the users based on the relations between sentimental terms and design attributes that reflect periodical and social situations. Furthermore, this study is expected to provide an opportunity of being used as information that presents a clear methodical guideline in the design development process, and to become a foundation for the development of superior research methods and various data utilization strategies through the sentiment analysis and sentiment terminology developed in terms of a research methodology in fashion design.",
		"KEYWORD": null
	},
	{
		"ID": 168,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "공주대학교 대학원",
		"TITLE": "빅데이터 기반의 보안관제 방안에 대한 실증적 연구 =(An)empirical study of security monitor system using big data analysis ",
		"AUTHOR": "최지우",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수:서창호 참고문헌 : 88-92장",
		"STORE_LOCATION": "공주대학교 도서관",
		"ABSTRACT": "기존의 보안관제는 시그니처 기반의 탐지를 통해 사이버공격에 대한 부분에 해왔다면, 빅데이터 시대가 되면서 여러 기관들에서 수집해야 할 데이터들이 커지고, 분석해야할 데이터들이 증가 및 해커들이 사이버공격이 진화로 탐지하기도 힘들어지고 있다. 알 수 없는 공격들을 탐지하기 위해서는 본 논문에서 제안한 방법을 통해 모든 데이터의 연관성 분석 및 탐지하여 기관들의 안전한 사이버환경을 구축하기 위해 신속하게 사이버위협에 대해서 통보함으로 기관에서 대응이 용이하도록 하여한다. 위의 3가지의 시나리오를 기반으로 기존 보안관제 방법과의 비교를 통해 빅데이터 보안관제의방법을 제안함으로 보안관제의 수집 및 탐지 방법이 변화 할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 169,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "빅데이터를 활용한 자동 문서 감사 시스템 =Automatic document audit system utilizing big data ",
		"AUTHOR": "김근원",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진화 참고문헌 수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "인터넷이 발달함에 따라서 처리하는 데이터의 양이 방대해지고 있다. 2012년 오바마 전 대통령이 빅데이터 분석을 이용하여 재선에 성공하면서 빅데이터에 대한 관심은 더욱 높아지게 되었다. 최근 이러한 빅데이터 분석 기법들은 기업에서뿐만이 아니라 선거활동 등 다양한 분야에서 활용되고 있다. 현재 국내 기업에서는 끊임없는 분식회계 등의 부조리가 발생하고 있다. 해외 기업의 경우 이미 자동화된 문서의 부조리 감시 시스템을 자체적으로 사용하고 있다. 그러나 국내에서는 자동화된 문서 감사를 위한 소프트웨어를 개발하고 있지만, 빅데이터 분석 기법을 통한 문서 감사에 대한 연구는 아직 미흡한 수준이다. 그래서 소프트웨어를 통한 문서 감사 시스템이 아닌 빅데이터 분석 기법을 통한 자동 문서 감사 시스템에 대한 연구를 진행하였다. 본 연구에서는 다양한 빅데이터 분석 기법들을 이용하여 자동 문서 감사 시스템에 대한 연구를 진행하였다. 빅데이터 분석 기법 중 텍스트 마이닝 분석을 통해 비용 청구서의 주요 키워드를 추출하고, 인공 신경망 분석과 회귀 분석 그리고 서포트 벡터 머신 분석을 진행하여 어떠한 분석의 예측 모델이 더 좋은 성능을 나타내는지 탐색하고자 하였다. 이를 위해서 본 연구에서는 총 100개의 비용 청구서 문서를 활용하여 텍스트 마이닝 분석을 통하여 문서 내에서 빈도가 높은 단어들을 추출하였다. 100개의 데이터를 하나로 통합하여 텍스트 마이닝 분석을 하여 전체 문서 내에서의 빈도가 높은 단어를 추출하였다. 그리고 유사한 단어들은 하나의 단어로 통합시키는 과정을 통하여 주요 키워드 20개를 선정하여 예측 모델에 사용하였다. 그다음으로 100개의 문서를 개별 텍스트 마이닝 분석을 진행하여 각 문서 내에서 주요 키워드 20개에 대한 빈도를 도출하였다. 그리고 주요 키워드 20개에 대한 각 문서별 단어 빈도 테이블을 생성하여 분석을 진행하였다. 청구금액을 정규화 전처리 작업을 진행하여 분석에 사용할 새로운 데이터를 생성하였고, 인공 신경망 분석과 회귀 분석 그리고 서포트 벡터 머신 분석 예측 모델을 구성하여 청구 금액에 대한 예측 값을 분석하였다. 예측 모델의 예측 값을 실제 값과 비교하여 오차율을 계산하였고, 오차 범위 ±5%와 ±10% 그리고 ±15%에서의 예측률을 분석하였다. 그리고 더 정확한 예측률을 분석하기 10-fold Cross Validation을 진행하여 예측률을 분석하였고, 비교 분석을 통하여 각 오차 범위에서 어떠한 분석의 예측 모델이 더 좋은 예측률을 나타내는지 분석하였다. 비교 분석 결과 오차 범위 ±5%와 ±10% 그리고 ±15% 모두에서 서포트 벡터 머신 분석이 더 좋은 예측률을 나타냈다. 본 연구는 자동 문서 감사 시스템을 위한 빅데이터 분석 기법을 활용하여 연구를 진행함으로써 비용 청구서와 같은 문서를 분석할 때 어떤 예측 모델을 구성하는 것이 더 좋은지 확인하는 것에 의의를 두고 진행하였다. 앞으로 빅데이터 기법을 활용한 문서 감사 시스템을 개발할 경우 어떠한 분석 예측 모델을 이용하는 것이 더 좋은 예측 결과를 나타내는지 확인할 수 있었고, 서포트 벡터 머신 분석을 이용할 경우 인공 신경망 분석이나 회귀 분석보다 더 좋은 예측 결과를 얻을 수 있을 것이라고 판단된다.",
		"KEYWORD": null
	},
	{
		"ID": 170,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "빅데이터 사회에서 개인신용정보의 보호와 이용에 관한 연구 =A study on the protection and use of personal credit information in big data society ",
		"AUTHOR": "백승엽",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김일환 참고문헌: p. 295-342",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "오늘날 현대사회는 빅데이터, IoT(Internet of things, 사물인터넷) 등 새로운 IT 기술과 융합산업의 출현에 따라 개인정보의 활용도가 점증하고 있는 반면, 효과적인 개인정보 처리 및 무분별한 수집·활용으로 인한 헌법상 기본권인 개인정보자기결정권이 침해되지 않도록 엄격히 보호되고 규제되어야 할 필요성 또한 매우 높아지고 있다. 이러한 현상은 2014년 초 국내 대형 신용카드사의 개인정보 유출사건을 계기로 더욱 두드러지고 있다. 개인정보는 공공부문에서 국가의 존재가치를 발현하는데 있어서 필수적인 요소이므로 복지국가의 이념과 전자정부의 구현을 위해서는 효과적인 개인정보의 처리가 불가피할 수 밖에 없다. 또한 민간부문에서도 효과적인 상품 개발과 서비스 제공을 위해 필수적이며, 특히 빅데이터 환경에서는 한층 더 정밀한 개인 맞춤형 서비스를 제공하는데 필수적으로 활용되어지고 있다. 따라서 개인정보의 활용과 관련하여서는 개인정보의 보호와 신사업 발전이라는 두 측면을 동시에 조화롭게 모색해야 하는 과제가 제기되고 있다. 한편 국내 개인정보보호법제는 ?신용정보법?과 ?개인정보보호법?으로 양분되어 있는데, 각 법률간의 연혁적, 일부 조문의 기술방식과 해석상의 문제로 인하여 개인정보의 범주에 속하는 신용정보에 대한 규제시 두 법률이 중복적으로 적용되는 상황이 발생하고 있다. 이러한 국내 개인정보보호법제간 중복규제는 단순히 법 적용의 우선순위의 차이만을 초래하는 것이 아니라 적용에 따른 규제수준에도 차이가 발생하는 바, 이를 해소함으로써 개인신용정보의 효과적인 보호와 규제를 보다 철저히 시행할 필요성이 매우 높다고 할 수 있다. 이러한 문제를 해결하기 위하여 정부는 신용정보의 법적 규율에 대해서는 ?신용정보법?으로 규제를 일원화한다는 취지에 따라 여러 차례의 입법적 정비를 시도 하였으나, 여전히 해석상 모순적인 법적용을 초래하고 있어서 각 법률간의 우선순위 문제가 해결되지 못하고 있는 실정이다. 이와 같은 규정 체계의 상호모순을 해소하기 위한 ?신용정보법?의 입법적 정비 필요성이 크다고 할 수 있다. 오늘날 빅데이터 환경에서는 개인정보의 취합과 2차적 사용 등으로 인하여 정보주체가 원하지 않음에도 개인신용정보가 노출되기도 하고, 개인의 사회적 정체성이 파악될 뿐만 아니라 개인의 행동을 예측하고 규정화함으로써 특정 개인에 대한 처벌이나 사회적 차별을 가하고, 복지 수혜 기회를 박탈하거나 불이익을 줄 수도 있다. 위와 같은 문제들은 개인이 개인정보의 흐름에 대하여 직접 참여함으로써 자신의 사회적 인격상을 형성하고 자신이 원하는 바에 따라 이를 드러내며 사회 속에서 부당하게 취급당하지 않을 수 있는 헌법상의 권리인 개인정보자기결정권과의 맥락에서 살펴보아야 한다. 빅데이터 환경에서 개인신용정보를 보호하는 것은 단순히 개인의 재산적 징표를 보호하는 것 이상으로서 개인정보자기결정권이라는 헌법상 기본권의 보호로 이어진다고 할 수 있다. 따라서 개인신용정보는 기본권 보호라는 차원에서 최대한 보호되어야 하므로, 개인신용정보의 이용은 개인의 기본권 보호를 기반으로 할 때에만 정당화될 수 있다고 할 것이다. ",
		"KEYWORD": "개인신용정보 보호와 이용,개인정보보호법제,개인정보자기결정권,비식별 조치,빅데이터 사회"
	},
	{
		"ID": 171,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "빅데이터에 기반한 미디어 의제의 집중도와 생존기간에 관한 연구 =Study on the concentration and survival period of media agenda based on big data ",
		"AUTHOR": "오동건",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 손승혜",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "본 연구는 언론의 현장에서 사용되는 의제의 개념을 빅데이터를 통해 측량화하여 현재 한국 미디어 의제의 문제점을 지적하는데 목적이 있다. 선행 연구를 살펴보면 의제의 개념이 모호한 측면이 많아, 미디어 의제 자체의 속성을 통해 언론 현실 문제를 지적한 논문은 없었다. 현재 한국의 미디어는 뉴스가 의제가 되는 확대 과정에서 뉴스 편집자의 의도가 반영되는 문제가 곳곳에서 드러나고 있다. 이를 추적하기 위해 DBSCAN 군집 분석의 빅데이터 자료 추출 방법을 이용해 4개 매체의 10여 년 간의 의제 200개를 각각 추출하여 의제 집중도와 생존기간을 수량화하였고, 이를 비교 분석하였다. 연구결과 뉴스 의제의 지나친 과잉 정치화가 발견되었다. 지상파 방송, 신문, 종합편성 채널, 보도 채널에서 모두 정치와 북한 의제의 빈도수가 매우 높았지만, 집중도와 생존기간은 크게 높거나 길지 않았다. 뉴스가 확산되어 의제가 될 때 언론사들이 지나치게 정치 문제에 몰입하고 있음이 나타났다. 이 같은 문제의 원인을 살펴보기 위해 종합편성 채널 개국일을 중심으로 시기를 나눈 두 집단의 변화를 측정했다. 그 결과 지상파 방송과 신문에서 종편 개국 이후 정치 의제의 빈도수가 크게 증가했음이 발견되었고, 정치 의제의 집중도 또한 높아졌음을 확인했다. 종합편성 채널은 매체 비교 분석에서도 정치 의제의 비중이 가장 높아 과정치화 현상이 가장 두드러졌고, 대통령 관련 의제의 키워드에서 정치인 개인의 이름이 가장 많이 나타나 타 매체와 정치 의제의 보도 내용에서도 차이가 컸다. 이는 종합편성 채널의 정치 의제 몰입과 특이성이 한국 미디어 의제 전체에 부정적인 영향을 주고 있음을 시사하는 것으로 판단된다. 의제의 과정치화 원인은 짚어보기 위해서는 더욱 다층적 연구가 필요함도 밝힌다. 특히 언론사 편집자가 종합편성 채널로부터 어떤 영향을 받았는지 그것이 어떻게 의제화에 영향을 끼쳤는지 살펴봐야 한다. 또한 시계열적 요소를 추가하여 의제 변화의 추이를 면밀히 추적해 한국 미디어 의제의 문제점을 더욱 심도 있게 살펴볼 필요가 있다.",
		"KEYWORD": "DBSCAN,과정치화,미디어 의제,빅데이터,의제 생존기간,의제 집중도"
	},
	{
		"ID": 172,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "빅데이터 감성정보 추출을 통한 도심부 활성화 요인 분석 연구 =A study on factors affecting the revitalization of central urban area extracted from the big data of emotional information of customers :서울의 도심부 전통시장을 중심으로 ",
		"AUTHOR": "박상훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이희정",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Central urban areas in most cities have been the centers of regional economies with respective urban infrastructures developed for a long time in convenient sites whereon, the historical and traditional heritages are remaining. On entering the 1990s, the downtown areas with its functions, attracted people thereto so far, began declining gradually, reducing population thereby, and even resulting in consequences of the cavitation thereof. Further, together with the encounter of the trend of development of large scaled stores in new town areas with the declining competitiveness of individual stores located in central urban areas, the commercial activities therein became stagnated gradually. The declining of central urban areas accompanying shrunk commercial spheres typically lead to the declining of regional distribution and services, to be followed by the reduced values and attraction of corresponding areas. Therefore, the importance, to take proper actions against the declining of central urban areas with methods of systematic maintenance, to provide them with spaces of respective identities enabling each space to be equipped with attractive functionalities, emerges. In the 5-year Plan of the Governmental Administration recently established, the new moves, to regulate large scaled business of distribution to revitalize regional commercial spheres, are included. Traditional commercial spheres have been played an important role of blood vessels for respective cities and regional economies wherein people communicate to each other and live their own lives. Thus the revitalization of traditional commercial spheres placed in downtowns of cities will result in the revitalization of downtowns leading to the eventual revitalization of regional economies. In this context, this study intended to take new approaches to issues related to the revitalization of traditional commercial spheres, contrary to the approaches taken in prior studies, by focusing on the aspects the social, cultural, and economic roles of traditional commercial spheres. Therefore, apart from the fragmental or subjective data typically collected from questionnaires distributed to participants in respective studies, which are frequently delved into topics involving the revitalization of existing spaces, this study was focusing on systematic establishment of atypical information created by many people. For the practical application of the information, the Big Data of non-physical information, combined with physical spaces, were analyzed. Besides, the factors affecting the revitalization of traditional commercial spheres and the extent of spatial changes in cities were quantified to develop an objective database enabled to present customers’ requirements and recognition, which are the basis of the establishment of policies of revitalization of traditional commercial spheres. The results obtained from the objective database would not be different from those presented by previous studies delved into topics related to topics of the revitalization of traditional commercial spheres. But rather, the results are expected to compensate the results presented by previous studies, by complementing methodologies of conventional approaches failed to derive the parts essential for the revitalization of traditional commercial spheres. Based on the aforementioned approach, this study will comprise following 4 parts. First, the characteristics, growth, and decline of central urban area in cities will be examined to review the significance and necessity of the revival of central urban areas. Further, the characteristics, functions, and necessities for the revitalization of traditional commercial spheres will be explored to present topics and basis of the orientation of this study. In addition, prior studies, delved into the effects of the changes in urban spaces and factors affecting the revitalization of traditional markets, will be examined, together with the limitations in studies explored the revitalization of urban spaces by exploiting the analyses of Big Data, to distinguish the approaches taken in this study from previous ones. Second, the theoretical relationship between the information (of customers’ recognition and emotion on traditional markets) and the revitalization of traditional markets, together with the Big Data thereof, will be clarified, to validate the contents and approaches of this study. The roles and necessities of the analyses of Big Data will be presented together with the details thereof included in each stage of the approaches. The sites corresponded to the criteria, prepared to choose the subject sites of this study, were selected for this study. And the effects of customers’ recognition, varied according to changes in external spaces, were derived, with establishment of the system, capable of extracting and analyzing the information of customers’ emotional responses to factors of revitalization. Third, the “Dongdaemun Market” will be selected for the analysis employing text mining to be conducted to identify the effects of the customers’ recognition of traditional markets varied according to changes in urban spaces. The commercial package “Textom” was used to collect necessary data, and the “NetDraw” was used for the analyses of keywords’ network, centralities (degree centrality, closeness centrality, betweenness centrality, and eigenvector centrality), and Convergence of Iteration Correlation (CONCOR). Fourth, the factors affecting the revitalization of traditional markets will be derived, and the ‘Opinion Mining’ will be carried out in the “Gwangjang Market (= the plaza market)” to extract and analyze the emotional information of customers by which, the factors affecting the revitalization of traditional markets, which were absent from results of prior studies, will be analyzed. Based on results obtained from the analyses of “Dongdaemun Market” and “Gwangjang Market”, the factors affecting the revitalization of subject sites, emotional information behind the extracted factors, and the relationship of influences in between the factors and emotions of customers, will be examined. The results obtained from this study are as summarized in the following: First, the Big Data, reflecting the recognition of customers of “Dongdaemun Market” changed with the opening of Dongdaemun Design Plaza (DDP) in 2014 after the removal of “Dongdaemun Stadium”, were analyzed. By which, many keywords related to “tourism” were found, and the customers’ recognitions of previous “Dongdaemun Market” were found changed accordingly, from the previous space of the transaction of commodities to the space of tourists’ experiences, connected with other tourists’ destinations. In particular, the places such as “Dongdaemun History and Culture Park”, “Cheonggyecheon”, “Dongdaemun Fashion Town” etc. were found, from the analyses of keywords centralities, as tourists’ destinations affecting tourists’ visit to “Dongdaemun Market” indirectly; this necessitates the regional revival to be involving with such tourists’ places. This also suggests new possibilities, exploiting external effects, for the revitalization of (traditional) market, to conventional policies focused solely on spontaneous transformation of traditional market. Second, the emotional aspects of customers’ views on factors of current commercial vitalization of “Gwangjang Market”, which has been exposed to public through broadcasts or mass media since 2010, were analyzed, from which, the most positive emotional factor, among diverse factors attracting customers to “Gwangjang Market”, was found involved with the “Specialized Articles of Clothing” of “Gwangjang Market”. The rank of “Specialized Articles of Clothing”, which are known as unique products of “Gwangjang Market”, was found above conventionally high ranked factors, such as, various “Tasty Foods” or “Restaurants or Spots of Tasty Foods” from the keywords network analysis; this suggests the significance thereof. On the contrary, the emotional factor related to the “Reminiscence” was found as negative one. Thus the strategies, established by projects supported by policies or based on suggestions resulted from academic researches for the revitalization of commercial spheres, which had frequently employed the invocation of the “reminiscence” of customers therefor, seem to be influenced thereby. Suggestions of the results obtained from the analyses are as follows: First, the function of traditional market, identified as an urban space attracting tourists, needs to be taken into account, beyond conventional recognition as a space for distribution of commodities. Thus the establishment, of policies or projects to support the revitalization of “Dongdaemun Market” or other neighboring markets, needs to employ strategies, exploiting peripheral spaces around target market places as tourist attractions, beyond current approaches focused on rearrangement of existing facilities used for sales of commodities. The strategies are thus expected to play key roles developing better commercial spaces to be resulting in the revitalization of central urban areas. Second, as shown in results obtained from the social network analyses on “Gwangjang Market” through the keywords found from internet including social network services, the robust correspondence between frequent reference to keywords and positive emotions of customers was not found. This needs to be taken into account for policies to be established for the revitalization of other traditional markets as well as “Gwangjang Market”. Recently, to attract customers, the majority of traditional markets employ strategies among the contents oriented to providing unique foods or spots of tasty foods etc., preferred to rather than the unique contents of long sold commodities of respective markets. However, the unique contents of each market, which were found responsive to or attracting positive emotions of customers, need to be taken into account to establish strategies for the revitalization of traditional markets. The research process presented and employed in this study is expected to be applicable to the establishment of plans focused on the revitalization of diverse urban spaces in that, it can accommodate diverse factors characterized by regions and purposes of each space as well as the spaces of traditional markets. The presentation of visions, for the revitalization of urban spaces which are recognizable by people, through the networked information residing in the on-line internet beyond those of policies or of economy, seems quite significant for the prediction of the formation of future urban spaces.",
		"KEYWORD": "감성 분석,도심부 재생,빅데이터 분석,소셜 네트워크 분석,오피니언 마이닝,전통시장 활성화,텍스트 마이닝"
	},
	{
		"ID": 173,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "음식관광 빅데이터를 이용한 관광목적지 브랜드 개성에 관한 연구 :Study on destination brand personality using food tourism big data : focusing on Chinese tourists in Korea ",
		"AUTHOR": "NianChen",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 174,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "빅데이터를 활용한 공유숙박의 지각된 위험 인식에 관한 연구 =A study on perceived risk perception of shared house using big data ",
		"AUTHOR": "이혜미",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 한진수 참고문헌: p. 160-182",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "사회적 측면에서 에어비앤비는 사용되지 않는 자원을 타인과 공유함으로써 불필요한 자원에 대한 소비를 줄이고, 사회 공동의 이익증가를 위한 대안적 사회·경제활동이다(송순영, 2015). 이러한 경제활동은 지역 내 유휴 인적·물적 자원을 상품화하고 새로운 인터넷 플랫폼을 매개로 수요를 도출함으로써 경제적 이득의 실현을 가능하게 하였다. 또한 유휴자원의 활용측면에서 사회적 공헌을 이끌어 내고, 새로운 고용의 창출과 넓게는 지역경제 활성화에 영향을 미치고 있다. 결국 에어비앤비는 관광산업의 신성장동력으로 합리적인 소비에 대한 관심과 자유여행, SNS의 발달 등 다양한 측면에서 신규 사업을 창출 시킬 수 있는 사업으로 여겨지고 있다. 그러나 긍정적인 현상만큼 부정적인 현상도 함께 나타나고 있는데, 서비스 안전성이 가장 큰 문제요소로 지적되고 있으며, 이에 따른 신뢰 또한 논란이 되고 있다. 결국 향후 공유경제의 도입과 사회 적용이 필수불변의 요소로 작용됨에 따라 공유경제 서비스가 성공적으로 적용되고 발생되는 문제점을 최소화하기 위해서는 공유경제의 대표적인 기업인 에어비앤비가 직면한 문제점들을 살펴보아야 한다. 따라서 본 연구는 첫째, 공유가치에 따른 협력적 소비에 대한 개념적 정의를 시도하고 대표적인 공유경제 기업인 에어비앤비의 현황에 대한 조사를 실시한다. 둘째, 문헌조사를 통해 공유경제의 사례현황과 법·제도 현황, 소비자의 불만과 피해현황을 파악하고자 한다. 셋째, 에어비앤비의 운영에 따라 새롭게 정립되는 공유민박업에 대한 고찰을 실시하고 발생되는 다양한 사회문제와 관련된 주제들을 언어네트워크 분석을 통해 주요 쟁점 과제를 논의하고자 한다. 넷째, 언어네트워크 분석을 통해 도출 된 단어들은 전문가의 의견수렴을 통해 실증분석을 위한 설문문항으로 도출하고 도출된 구성 개념들 간의 인과관계를 검증하고자 한다. 결국 공유민박업의 도입에 따라 발생 가능한 문제점을 최소화함으로써 효율적인 운영방안 마련을 위한 제언을 도출할 수 있을 것으로 판단된다. 연구의 목적을 달성하기 위해 본 연구는 방대한 양의 데이터를 분석할 수 있는 데이터마이닝 분석과 설문조사를 통한 실증분석을 순차적으로 진행하였다. 에어비앤비로 인해 발생되는 다양한 사회적 현상을 파악하고자 언론을 통해 보도되는 자료를 모두 수집하고 이를 바탕으로 정성적 판단에 근거하여 정량적으로 측정이 가능한 문항을 도출하였다. 수집된 데이터의 텍스트 분석은 Textom을 통해 실시하고 그 결과를 바탕으로 단어들 간의 근접도를 파악하기 위해 Ucinet분석을 실시하였다. 이때 문항의 도출과정에서 발생될 수 있는 지각의 오류를 제거하고자 일정부분에 대해서는 전문가의 의견을 수렴하였다. 또한 도출된 단어들을 바탕으로 설문 문항을 구성한 뒤 전문가 인터뷰와 잠재 소비자를 대상으로 사전조사를 실시하여 좀 더 다양한 의견을 수렴하였다. 사전조사 결과 총 30개의 설문지가 수집되었으며, 문항 도출을 위해 실시한 탐색적 요인분석 결과 아이겐 값이 1이상인 8개의 요인이 도출되었고 총 52개의 문항 중 기준값에 미치지 못하거나 중복 적재된 항목 11개의 문항을 제거한 41개의 문항을 최종분석에 사용하였다. 전체 변량의 설명력에 있어서는 67.578%를 설명하고 있는 것으로 나타났으며, 추출된 요인은 각각의 특성에 따라 ‘사회적 위험’, ‘시설적 위험’, ‘심리적 위험’, ‘재무적 위험’, ‘절차적 위험’, ‘안전 위험’, ‘정책적 위험’, ‘법적 위험’이라 명명하였다. 사전조사를 바탕으로 총 376명의 표본을 대상으로 본 조사를 실시하였으며, 확인적 요인 분석을 통해 10개의 문항 정제과정을 거쳐 최종 49개의 문항을 통한 모형 적합도 평가를 실시하였다. 분석결과 적합 지수가 기준값 이상을 상회하고 있으며, 집중 타당성과 개념 신뢰성 또한 확보되었다. 가설 검증을 위해서는 구조방정식 모형검증을 통해 가설을 검증하였으며, 검증결과 사회적 위험, 재무적 위험, 절차적 위험, 안전 위험, 정책적 위험은 인지적 신뢰에 유의한 영향을 미치는 것으로 나타났으며, 정서적 신뢰에는 사회적 위험, 시설적 위험, 심리적 위험, 절차적 위험, 안전 위험, 정책적 위험, 법적 위험이 유의한 영향을 미치는 것으로 증명되었다. 마지막으로 인지적 신뢰와 정서적 신뢰는 구매의도에 유의한 영향을 미치는 것으로 나타났다. 모형적합도는 X²=1610.868 (p<0.000), 자유도(d.f.)= 1077, X²/df= 1.496, P=.000, GFI= 0.882, AGFI= 0.838, RMR= 0.053, IFI= 0.985, NFI= 0.919, TLI= 0.963, CFI= 0.983으로 나타나, 권고 수준을 상회하여 양호한 것으로 증명되었다.",
		"KEYWORD": "Big Data,Perceived Risk,Purchase Intention,Semantic Network Analysis,Shared Economy Services,Trust"
	},
	{
		"ID": 175,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "빅데이터를 활용한 통일의식 분석 연구 ",
		"AUTHOR": "임대규",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "통일의 주체는 국민이기에 통일을 실현하는데 있어 국민의 통일의식을 정확하게 파악하는 것은 무엇보다 중요한 의미를 지닌다. 현재 국민의 통일의식을 파악하기 위해 주로 여론조사 방식의 통일의식조사가 실시되고 있으나, 조사의 결과가 여론조사 방식에 포함될 수 있는 수많은 오류와 편향이 무시된 체 비판 없이 받아들이는 경향을 확인할 수 있었다. 연구자는 지금과 같은 상황은 국민들의 통일의식에 대한 잘못된 이해를 만들고, 나아가 통일에 대한 남남갈등을 유발할 수 있다는 문제의식을 갖게 되었다. 이에 본 연구의 목적은 여론조사 방식의 통일의식조사가 국민들의 통일의식을 제대로 반영하고 있는지 그 타당성과 신뢰성을 확인하고, 여론조사방식의 한계를 보완할 수 있는 빅데이터를 활용한 통일의식 분석 방안을 모색하는 것이다. 이를 위해 먼저 서울대 통일평화연구원 「통일의식조사」와 KBS 남북교류협력단 「국민통일의식조사」의 조사결과를 분석 자료로 상호간의 비교 분석을 시도하였다. 비교 분석을 통해 확인된 통일의식조사의 의의는 오랜 기간 축적된 데이터를 통해 통일의식 변화 추세를 확인할 수 있고, 조사 과정을 통해 국민들에게 통일에 대한 다양한 정보를 제공해 주며, 조사 결과 활용을 통해 통일에 대한 사회적 논의를 유발하는데 기여하고 있다는 것이다. 이와 함께 다음과 같은 통일의식조사의 한계를 발견할 수 있었다. 첫째, 통일의식조사는 설문지 구성을 통해 설정된 조건 안에서만 통일의식 변화의 대략적 추세를 확인할 수 있는 제한적 조사방법으로 평가할 수 있었다. 조사기관이 ‘어떻게 묻느냐’에 따라 국민의 통일의식이 서로 다르게 평가되는 사례를 발견하였다. 둘째, 통일의식조사는 국민의 통일의식을 과도하게 단순화시킬 수 있는 위험성을 지니고 있었다. ‘제한된 선택지’에 다양한 통일의식을 반영하려는 시도 자체가 무리한 것으로 평가될 수 있으며, 특정기간에 실시한 여론조사 결과를 1년간의 통일의식으로 해석하는 것 또한 확대 해석의 오류를 피할 수 없었다. 셋째, 통일의식조사는 조사 방법상의 한계를 인정하지 않고 조사 결과를 절대적 수치인 것처럼 해석하는 문제점을 지니고 있었다. 오차범위 내의 미미한 수치변화에도 큰 의미를 부여하고, 그 원인을 추측하는 비과학적인 분석태도를 확인할 수 있었다. 이러한 통일의식조사의 한계를 보완할 수 있는 방법으로써 다음 세 가지 빅데이터 분석기법을 활용하여 통일의식을 분석하였다. 첫째, 소셜 마이닝 분석기법이다. ㈜코난테크놀로지의 소셜미디어 분석 솔루션 펄스K(http://www.pulsek.com/pulsek/)를 분석환경으로, 소셜미디어를 대표하는 페이스북, 트위터, 블로그에서 2014년에 발생한 통일 관련 버즈 전체를 수집하고 이를 분석에 활용하였다. 둘째, 웹 로그 분석기법을 시도하였다. 통일 관련 5개 공공기관 홈페이지의 최근 3년간 로그 데이터를 정보공개청구제도를 통해 수집하였고, 각 홈페이지의 기간별, 성별, 연령대별 접속 추이 분석과 웹페이지별 조회 로그 분석을 시도하였다. 셋째, 웹 검색 트래픽 분석기법 사용하였다. ‘통일’ 검색 트래픽의 특징과 ‘통일’관련 연관검색어 트래픽을 검토하여 ‘통일’에 대한 관심 수준 변화와 검색어 활용의 의도를 분석하였다. 다음은 빅데이터를 활용한 통일의식 분석결과이다. 첫째, 소셜미디어 언급량 분석 결과, 2014년 통일 관련 키워드가 중복 글 포함 총 1,216,965건(통일 : 25,850건, 대북관련 사안 : 147,532건, 북한 : 950,270건, 북한정권 : 93,913건)이 발생되었음을 확인하였다. 또한 ‘통일’ 검색 트래픽은 대체적으로 ‘인권’, ‘환경’ 검색량과 유사한 수준을 보였으며, ‘통일’ 검색량이 집중되는 시기에는 ‘맛집’, ‘영어’ 검색 트래픽을 상위했다. 둘째, 소셜미디어에서 발생한 통일 관련 키워드 간의 언급량을 상호 비교한 결과, 통일 관련 논의는 ‘통일’을 직접 언급하기보다 주로 ‘북한’, ‘대북 관련 사안’, ‘북한정권’에 집중되어 있음을 확인할 수 있었다. 대북관련 사안 중에서는 주로 ‘북한인권’과 ‘이산가족’에 관심이 집중되었다. 또한 북한정보포털 웹페이지 조회 로그 분석을 통해 북한에 대한 관심이 주로 북한 정권의 주요 인물에 집중되어 있음을 확인했다. 셋째, 2014년에 발생한 소셜미디어 ‘통일’에 대한 언급 중 긍정적 정서가 37%, 부정적인 정서가 55%로 나타냈다. 특히 10월부터 12월 사이의 부정 여론 증가를 확인하였고, 연관어 분석을 통해 10월 10일 대북전단 발원지 무력 충돌 사건에서 그 원인을 찾을 수 있다. ‘북한’ 키워드의 감성 분석 결과 긍정 정서가 31%, 부정 정서가 60%를 차지했다. 2014년 4월과 10월에 ‘북한’에 대한 부정 여론이 높게 나타났으며, 연관어 분석을 통해 4월 무인항공기 이슈에서 그 원인을 찾을 수 있었다. ‘북한정권’ 키워드의 감성 분석 결과 긍정 정서가 23%, 부정 정서가 69%를 보였다. 10월과 12월에 ‘북한정권’에 대한 부정 여론이 높게 나타났으며, 연관어 분석을 통해 12월 김정은 암살을 다룬 ‘더 인터뷰(The interview)’ 영화상영 이슈로 부정 여론이 증가한 것을 확인할 수 있었다. 본 연구의 앞선 분석 결과들을 종합해 볼 때 빅데이터를 활용한 통일의식 분석의 의의는 다음과 같이 설명할 수 있다. 첫째, 빅데이터 분석은 통일 관련 소셜미디어나 홈페이지, 검색포털서비스 이용 행태와 같은 능동적 행위 데이터를 분석함으로써 여론조사에 비해 조사기관의 의도 개입 가능성이 적은 객관적인 조사 방법으로서 의의를 지니고 있다. 둘째, 빅데이터 분석은 통일에 대한 국민의 관심 변화 등에 대해 세부적으로 분석할 수 있다는 장점을 지니고 있다. 소셜 분석을 통해 통일에 대한 관심변화 추세를 일자별로 확인할 수 있었고, 검색 트래픽 분석을 통해 통일에 대한 관심이 특정 시기에 집중되는 특성을 발견하였다. 셋째, 빅데이터 분석은 데이터를 기반으로 과학적 분석이 가능하다는 점에서 그 의의를 찾을 수 있다. 소셜미디어 언급량 분석을 통해 국민의 관심이 북한정권의 인물에 집중되어 있으며, 통일 정서의 변화는 북한관련 안보 이슈에 주로 영향을 받는다는 것을 확인하였다. 또한 웹 검색 트래픽 분석을 통해 통일교육 관련 정보 수집 수요가 웹상에서 통일에 대한 급격한 관심증가를 유발하고 있음을 발견할 수 있었다. 본 연구 결과는 통일의식조사의 한계를 명확히 밝혀 조사 결과를 주체적으로 활용해야하는 이유를 규명하였으며, 빅데이터를 활용한 통일의식 분석을 통해 통일의식에 대한 객관적이고 종합적인 이해에 기여하였다는 점에서 그 의의를 찾을 수 있다.",
		"KEYWORD": "빅데이터,여론조사,통일교육,통일의식,통일의식조사"
	},
	{
		"ID": 176,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "동국대학교 국제정보대학원",
		"TITLE": "기업의 빅데이터 활성화에 따른 개인정보 문제점에 관한 연구 =(A)study on the personal information problem according to the company big data activation ",
		"AUTHOR": "홍상진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이재우",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "",
		"KEYWORD": "개인정보,빅데이터"
	},
	{
		"ID": 177,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "빅데이터 시스템의 수용의도에 영향을 미치는 수용조직의 환경요인에 관한 연구 ",
		"AUTHOR": "김은영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이정훈",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "bigdata system,organization information system infra maturity,organization innovation,organization slank,perceived benefits of bigdata system,technology acceptance model,기술수용모델,빅데이터 시스템,빅데이터 시스템의 인지된 해택,조직의 여유자원,조직의 정보시스템 인프라적 성숙도,조직의 혁신성"
	},
	{
		"ID": 178,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "전력산업분야에서 빅데이터의 활용방안에 관한 연구 ",
		"AUTHOR": "윤종현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이정우",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "This research proposes description and understanding on big data analysis using existing researches in South Korea. Based on the result and interview with specialists, researcher also derived the application of big data analysis in electricity industry. Big data refers to a dataset that is hard to be analyzed by existing analytic techniques and has three features; Volume, Variety, and Velocity. In electricity industry in Korea, there has been medium- and long-term plans on the application of big data analysis using facility, customer, and electric use data. Especially, with the increased interest on smart grid, electric cars, electric power IoT, diverse researches on big data analysis in electric have been conducted, but the research on the application of the analysis has not provided measurable results. Thus, this research suggests a new direction for research on the application of big data analysis based on classification of existing researches and interviews with electricity specialists.",
		"KEYWORD": "applying plan,big data applying,electric power,in depth interview,systematic literature review,빅데이터,빅데이터 활용,빅데이터 활용 분야,빅데이터 활용 사례,전력,전문가 심층 인터뷰,체계적 문헌 연구"
	},
	{
		"ID": 179,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 경영전문대학원",
		"TITLE": "빅데이터 분석기법을 이용한 이슈기술분석 =Issue technologies analysis through big data analysis methods ",
		"AUTHOR": "유지연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김명석 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 180,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 환경에서 HMD 사용자를 위한 스마트 교육용 콘텐츠 뷰어의 설계 및 구현 =Design and implementation of a smart educational content viewer for HMD users in bigdata environment ",
		"AUTHOR": "주성연",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:류관희 참고문헌:p. 46-48",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Smart education that has been implemented since 2007 on a trial basis is drawing public attention. Smart education, which is an experience based creative learning orientation using a variety of activities and content learning anytime and anywhere, has been generating a great deal of interests in digital textbooks and educational contents. Therefore, an educational content viewer has been developed to meet the system goal of smart education that needs to provide educational content. Also, a bigdata analysis that has the characteristics of volume, multiplicity and velocity was used to develop abundant educational contents. High quality educational contents can be provided using the multiplicity characteristic of these bigdata. In addition, educational contents were output using HMD that is a next-generation display device to increase the concentration of learners on them. HMD(Head Mounted Display) has an advantage that learners can focus on the educational contents without being disturbed by indirect vision. Furthermore, the use of a HMD device allows learners to study educational contents for a long time since it relieves eye strain. Thus, in this paper, the educational contents have been developed by utilizing the bigdata that had the characteristics of multiplicity in order to develop abundant educational contents meeting the intent of smart education. Also, an educational content viewer that output the educational contents was designed and implemented using HMD to increase learning effect. The system proposed in this paper was implemented to be compatible in various devices by creating it as a XML-based document, and underwent a parsing process for creating a document page by page in order to output a XML document in smart devices and a XSLT transformation process for outputting a parsed document. These processes were carried out by dividing them into basic and interactive controls. In this paper, 73% of respondents answered that their interest in educational contents increased by using HMD, which was very high, and 60% of learners answered that there was learning effect in the case of learning educational contents using HMD, which was also high. By using a smart educational content viewer utilizing the bigdata analysis proposed by these experimental results, it is expected that abundant educational contents can be provided, and the concentration on the contents will increase, leading to the higher learning efficiency of learners and the improvement in the learning effect.",
		"KEYWORD": null
	},
	{
		"ID": 181,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한국교원대학교 교육대학원",
		"TITLE": "빅데이터 분석 기법을 활용한 수능 절대평가 여론 텍스트데이터 분석 ",
		"AUTHOR": "권순보",
		"REGION": "충청북도",
		"PROFESSOR": "한국교원대학교 논문은 저작권에 의해 보호받습니다. 지도교수 : 유진은 참고문헌 : p.124-133",
		"STORE_LOCATION": "한국교원대학교 도서관",
		"ABSTRACT": "본 연구는 빅데이터 분석 기술을 활용하여 수능 절대평가에 대해 나타나는 주요 키워드와 쟁점을 인터넷 뉴스 기사와 뉴스 기사의 댓글을 중심으로 하여 분석하고자 하였다. 연구문제는 다음과 같다. 첫째, 수능 절대평가에 대한 언론 매체의 관심도와 사람들의 관심도는 연구 기간 속에서 어떻게 변화하는가? 둘째, 수능 절대평가에 대한 뉴스 기사와 뉴스 기사의 댓글에서 나타나는 주요 키워드는 무엇이며 어떤 공통점과 차이점이 나타나는가? 셋째, 수능 절대평가에 대한 언론 보도에서는 어떤 쟁점이 등장하는가? 연구문제를 해결하기 위해 2017년 4월 7일부터 2017년 9월 10일까지 수능 절대평가에 대한 총 2577건의 인터넷 뉴스를 웹 크롤링 기법으로 수집하였다. 또한, 수능 절대평가 관련 인터넷 기사 중 댓글이 100개 이상인 경우 기사별로 댓글을 수집하여 총 56건의 뉴스를 수집하였다. 수집된 자료는 R프로그래밍을 이용하여 키워드 분석과 LDA 기반의 토픽 분석을 하였다. 그 결과 다음과 같은 결과가 도출되었다. 첫째, 수능 절대평가에 대해 언론 매체는 교육부의 동향과 관련하여 민감하게 반응을 하였으나, 사람들의 관심도는 자신들에게 직접적으로 영향력을 주는 사건에 민감하게 반응을 하였다. 둘째, 수능 절대평가 관련 뉴스 기사와 뉴스 기사의 댓글에서 등장한 키워드 분석 결과 수능 절대평가에 대해 언론 매체와 사람들의 생각에 있어 차이가 나타남을 확인할 수 있었다. 셋째, 수능 절대평가의 쟁점은 전체 기간을 기준으로 31개가 나타났고 연구 기간 동안에 설정한 단계에 따라 1단계에서는 7개, 2단계에서는 14개, 3단계에서는 12개의 쟁점이 나타났다. 이 연구는 수능 절대평가에 대한 여론 텍스트데이터를 빅데이터 분석 기법으로 분석하여 주요 쟁점을 구체화하였다. 또한, 언론매체와 사람들의 생각에 있어 유사점과 차이점을 비교 분석함으로써 향후 수능 개편안을 마련함에 있어 시사점을 제공했다는 점에서 의의를 찾을 수 있다.",
		"KEYWORD": "댓글,수능,신문기사,언론,여론,잠재디리클레할당,절대평가,텍스트마이,토픽모델링"
	},
	{
		"ID": 182,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "In-Memory Data Grid 기술을 적용한 교통 빅데이터 실시간 처리 성능향상 방법 =(A)method to enhance the real-time processing performance of traffic big data by applying in-memory data grid technology ",
		"AUTHOR": "박민규",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 나종화 참고문헌: p.53-55",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "본 논문은 최근 각광받고 있는 여러 NoSQL(Not Only SQL)기술들 중, 인메모리 데이터 그리드(In-Memory Data Grid, IMDG) 기술을 교통 빅데이터 처리 분야에 적용시켜 보다 효율적이고 경쟁력 있는 시스템 구조를 구현하는데 목표가 있다. 특히, 콜택시(혹은 앱택시) 업계에서는 애플리케이션의 사용자 수가 증가함에 따라 실시간 트랜잭션 처리에 대한 시스템 성능이 중대한 이슈로 부각되고 있어, 이 분야에 가장 적합한 구조를 제안하기 위해 서로 다른 데이터 저장 기술인 MariaDB, Redis, Hazelcast를 사용해 각각의 성능을 측정하고 비교해본다. 또한, 객관적이고 합리적인 성능평가를 위해 두 가지 방법의 실험(YCSB실험, 모의실험)을 토대로 검증했고, 그 결과는 다음과 같다. In-Memory 기반의 Key-Value 저장소(Redis와 Hazelcast)는 MariaDB에 비해 약 500배 더 많은 양의 데이터를 동시에 처리할 수 있으며, Scale-out 방식의 확장을 통해 시스템 성능을 선형적으로 향상시킬 수 있다. 추가로, Hazelcast의 SQL-like한 함수의 사용은 Redis에 비해 데이터 검색속도를 약 10배 높일 수 있다.",
		"KEYWORD": "In-Memory Data Grid(IMDG),NoSQL,모의평가,성능평가,트랜잭션 처리 시스템"
	},
	{
		"ID": 183,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "노후경유차 운행제한에 따른 미세먼지 저감효과와 빅데이터를 활용한 노출인구 평가 =The effect of PM reduction due to the restriction of old diesel vehicles and population exposure assessment using big data ",
		"AUTHOR": "김형석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 선우영",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "우리나라의 주요 대도시, 특히 서울시에서는 한양도성 내부를 ‘녹색교통 진흥지역’으로 선정하여 노후경유차 운행제한 대책에 대한 특별 관리하고 있다. 이에 본 연구에서는 녹색교통진흥지역의 노후경유차 운행제한에 따른 대기오염물질 배출량을 산정하였으며 농도에 대한 저감효과로 분석하기 위해 BFM(Brute Force Method)과 WRF-SMOKE-CMAQ (Weather Research and Forecasting model - Sparse Matrix Operator Kernel Emissions - Community Multi-scale Air Quality Model)로 구성된 대기질 모델링 시스템을 활용하였다. 이와 더불어 수용체 중심의 미세먼지 저감효과로 인한 평가를 하고자, WHO(World Health Organization)의 대기오염에 대한 기여 사망자수 산정식을 사용하였으며 인구 유동을 고려할 수 있는 모바일폰 기반 인구 빅데이터를 활용한 노출인구 평가를 진행하였다. 녹색교통진흥지역에서 노후경유차 운행제한 대책 시행으로 인해 삭감된 배출량은 PM10 4,832∼5,322kg/yr, NOx 114,211∼129,039kg/yr이었으며 이동오염원 배출량 대비 PM10 32.5∼34.0%, NOx 18.0∼21.0%의 감축률로 나타났다. 종로구의 일평균 PM10, NO2 개선효과는 각각 0.24∼1.41㎍/㎥, 0.32∼1.86ppb이었으며 중구는 PM10 0.28∼1.35㎍/㎥, NO2 0.38∼1.91ppb 이었다. 빅데이터를 통해 산정된 일평균 인구는 종로구 163,153∼272,263명, 중구 360,278∼661,383명으로 종로구에 비해 중구에서 인구가 많이 산정 되었다. 산출된 결과인 PM10 개선효과 및 인구 빅데이터를 활용하여 노출인구 평가한 결과, 종로구에서 개선효과와 인구 변화에 따른 감소사망자수는 일별 0.11∼0.70명/년이었으며 중구에서는 0.30∼1.62명/년이었다. 종로구와 중구의 감소사망자수 차이는 인구 빅데이터의 정량적 차이이며 인구 산정이 많은 날일수록 감소사망자수도 많아지는 것을 확인할 수 있었다. 노후경유차 운행제한으로 인해 감소된 사망자수의 변화는 종로구와 중구 모두에서 인구 빅데이터보다 PM10 개선효과에 의한 상관계수 값이 컸다. 대상지역에서는 개선효과가 일별 노출인구 평가에 더 큰 영향을 주는 것으로 판명되었으며 지역별 감소사망자수 차이는 노출인구수에 따라 차이가 났다. 본 연구에서는 WRF-SMOKE-CMAQ 모델링을 통해 노후경유차 운행 제한 정책에 따른 대기오염물질별 개선효과 정도를 평가할 수 있었고 대기질 모델링에 대한 단순 대기질 농도분포도 작성에서 그치는 것이 아닌 모델링을 활용한 노출인구 평가 방법의 형태를 제시하였다. 또한 일반적인 노출인구 평가에서 인구 유동을 고려하지 못하는 통계청 인구의 한계를 극복하고자 모바일폰 기반 인구 빅데이터를 도입하였으며 인구 유동의 편차가 큰 지역일수록 현실이 반영된 대기오염 노출인구 예측과 평가방법이 필요함을 제시하였다.",
		"KEYWORD": "노출인구 평가,노후경유차 운행제한,녹색교통진흥지역,미세먼지,빅데이터"
	},
	{
		"ID": 184,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 행정대학원",
		"TITLE": "빅데이터를 활용한 쓰레기 발생 패턴 분석 :Big data analysis of waste generation pattern : focusing on food waste in Cheongju City ",
		"AUTHOR": "고덕영",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:이민규 참고문헌 : p.76-80",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "본 연구에서는 청주시 동 지역에서 발생하는 음식물 쓰레기의 양을 6개 수집·운반 구역과 계절별로 나누어 분석하였다. 분석을 위해 2015년 1월 1일부터 2016년 12월 31일까지 청주시 음식물류 폐기물 자원화시설에 반입된 음식물 쓰레기양을 자료로 사용하였다. 모든 구역에서 설 연휴, 여름철, 추석 연휴, 김장철 등의 시기에 음식물 쓰레기 발생이 가장 많았다. 구역별로는 설 연휴, 여름철, 추석 연휴, 김장철 등의 시기에 음식물 쓰레기 발생량이 많다는 점은 공통되었다. 그러나 계절에 따라 발생하는 쓰레기양의 변동 정도는 구역에 따라 차이가 있었다. 특히, 2구역에서 설 연휴 및 추석 연휴를 전후하여 증가하는 쓰레기 발생량은 다른 지역에 비해 상대적으로 컸다 (2015년 7주·33주, 2016년 5주·37주). 음식물 쓰레기 발생이 집중되는 정도를 분석하기 위해 주간 발생량이 연중 가장 많은 13주에 대하여 분석한 결과, 구역에 따라 음식물 쓰레기 발생량이 집중되는 시기에는 차이가 있는 것으로 나타났다. 이러한 차이가 존재한다는 것은 청주시라는 기초 자치단체 내에서 구역별로 음식물 쓰레기 발생 패턴에 차이가 있음을 의미하고, 나아가서 장래에 맞춤형 음식물 쓰레기 발생 억제 정책이 실현 가능하다는 점을 시사한다.",
		"KEYWORD": "빅데이터,음식물류폐기물,청소행정"
	},
	{
		"ID": 185,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울대학교 융합과학기술대학원",
		"TITLE": "빅데이터로서 수사기록 보존·폐기에 관한 연구 =(A)study on the management and disposing of investigative records as big data ",
		"AUTHOR": "홍승아",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 186,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "울산대학교 산업대학원",
		"TITLE": "빅데이터 오픈 소스 분석 툴을 활용한 대규모 웹 서비스 실시간 모니터링 시스템 =(A)real-time monitoring system for large-scale web service using big data open source analytics tools ",
		"AUTHOR": "황덕래",
		"REGION": "울산",
		"PROFESSOR": "울산대학교 논문은 저작권에 의해 보호받습니다. 참고문헌(p. 31) 수록",
		"STORE_LOCATION": "울산대학교 도서관",
		"ABSTRACT": "빅데이터가 이슈로 떠오르면서 과거 데이터와 지금도 발생되고 있는 실시간 로그에 대한 관심이 증폭되고 있다. 저장 후 버려지는 실시간 데이터를 활용하여 새로운 패턴을 추출하고 신규 비즈니스나 기존 업무에 활용하는 과정에 있다. 현재 대기업들은 기존 성능 어플리케이션 관리 툴(APM)이나 서버 자원 관리 툴을 활용하여 웹 서버들의 성능과 장애에 대한 모니터링을 수행하고 있으나, 중소기업들은 비용 부담 때문에 서버와 서비스 장애에 대해 모니터링을 하지 못하고 있다. 이에 중소기업에서도 오픈 소스를 활용하여 웹 서비스 모니터링 시스템을 구축하고 활용할 수 있는 방안이 필요한 실정이다. 본 연구에서는 상용 빅데이터 솔루션을 지양하고 오픈 소스 툴을 활용하여 웹 서비스 실시간 모니터링 시스템을 개발한다. 중소기업은 오픈 소스 툴을 활용하여 비용 부담 없이 최신 기술의 모니터링 환경을 구축할 수 있다. 개발된 시스템은 웹 서비스 로그와 서버 자원 로그를 대상으로 분석 데이터를 수집하며 기능과 사용자 인터페이스는 빅데이터 오픈 소스 툴인 Elasticsearch, Logstash, Kibana를 활용한다. 나아가 각 오픈 소스 툴들의 기능과 특징을 확인하고, 전체 서비스 실시간 모니터링, 장애 사전감지 대시보드 등 다양한 대시보드들의 역할을 확인한다. 또한 오픈 소스로 개발된 실시간 모니터링 시스템과 상용 빅데이터 솔루션을 비교/분석하여 오픈 소스의 유용성과 활용 가치를 검증한다.",
		"KEYWORD": "Big Data,BigData,빅데이터"
	},
	{
		"ID": 187,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "기업의 빅데이터 분석 역량 기반 전략적 성과 연구 :A study on firm`s strategic performance leveraged by big data analytics(BDA) : focused on organizational structural dimensions ",
		"AUTHOR": "이가희",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "다양한 스마트 디바이스의 등장과 이로 인한 네트워크 확산으로, 데이터 생산량이 기하급수적으로 늘고 있다. 4차 산업혁명의 신성장 동력이자 핵심 자원으로 이러한 데이터의 운용 역량이 경쟁력으로 직결되는 사회가 도래하였다. 이러한 흐름을 주도하고 있는 기업들에서는 데이터 수집과 분석을 위한 인프라를 구축 및 많은 투자가 이루어지고 있지만, 여전히 많은 곳에서 투자 대비 성과를 거두지 못하고 있는 실정이다. 대다수의 연구 또한 빅데이터 시스템 및 기술 구현을 위한 연구에 편중되어 있어, 기업들에 효과적인 도입에 대한 가이드라인을 제시하지 못하고 있다. 본 연구는 지식기반이론과 동적역량이론을 토대로 기업들의 빅데이터 애널리틱스 기반 비즈니스 가치 사슬에 대해 다루고 있다. 지식 자산의 활용이 조직적 민첩성, 업무 처리 효율성과 기업의 경쟁우위에 미치는 영향의 관계를 구조방정식을 통하여 살펴보았다. 추가적으로, 데이터 주도적 경영 환경으로의 전환에 따라, 기업의 구조적 특성이 데이터 기반 지식경영행태의 미치는 영향의 차이를 분석하고, 이에 대한 경영적 함의 점을 도출하고자 하였다. 연구 결과 적극적인 애널리틱스 툴을 통한 지식 자산의 활용이 조직의 민첩성, 업무 처리 효율성과 경쟁우위에 직접적인 영향을 미치는 것을 확인하였다. 하지만, 형식성과 집권성의 구조적 차이를 보이는 그룹 간 비교 분석을 통해서, 데이터 주도적 지식경영이 경쟁 우위에 영향을 미치는 경로는 다르게 나타나는 것을 확인하였다. 본 연구의 결과는 빅데이터 애널리틱스를 기 도입한 기업들 뿐 아니라 도입을 계획중인 기업 및 조직들의 향후 장기 인력 운용 및 경영 전략 수립에 토대로 활용될 수 있을 것이다.",
		"KEYWORD": "빅데이터 애널리틱스(BDA),조직 구조,조직적 민첩성,지식 자산"
	},
	{
		"ID": 188,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "시공간 RDF 빅데이터의 효율적인 분산 병렬 처리 기술 =Efficient distributed parallel processing methods for spatio-temporal big data ",
		"AUTHOR": "신인수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 민덕기",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "Today, in the fast developing web, the semantic web service gets more popular to provide spatio-temporal information such as location, distance and times by linking between web data and GIS. Furthermore, as an era of Big Data is coming the number of spatio-temporal RDF big data that is generated by XML, GML, RDF is increased. Regarding to that the interest of research for distributed processing of these data is growing high. In order to store and manage spatio-temporal RDF big data, the following information should be efficiently stored: general data, data types, operations, and index. Researches for efficient search of spatio-temporal RDF big data is also needed in distributed semantic web environments. However, in the existing spatial information area, semantic web-based systems are inadequate to deal with storing and processing of spatio-temporal RDF big data. Moreover, HBase, MongoDB and Cassandra which are distributed database systems to process big data are difficult to search for spatio-temporal. This issue caused by absence of spatio-temporal operators and indexation. The number of MapReduce Jobs are increases by increase of join processing queries. The process of various triple pattern conditions in SPARQL for search query also makes it complicated. Finally these issues cause the degradation of query processing performance. This thesis proposes the spatio-temporal RDF big data processing architecture to solve these problems and process spatio-temporal RDF big data efficiently in distributed semantic web environment. The spatio-temporal RDF big data processing architecture is comprised of the spatio-temporal operation method, the spatio-temporal indexing method, and the spatio-temporal query execution plan methods. First, the spatio-temporal operation method, called TS-Operation, supports spatial data types and operators that comply with the OGC standard. Temporal data types and operators that comply with the ISO standard and spatio-temporal data types and operators that unify spatial and temporal data. This thesis compare spatio-temporal types, operations, and search performance with other existing spatio-temporal operation researches and prove the superiority. Second, the spatio-temporal indexing method, called TS-Index, constructs a spatio-temporal index and cluster to search spatio-temporal RDF big data efficiently. This thesis compare search performance with other existing spatio-temporal index researches and proves the excellence. Finally, the spatio-temporal query execution plan method, called TS-ExecPlan, makes join execution plans of SPARQL query with the catalog information table, join priority rule, and multi-join algorithm that performs efficient query processing. This thesis compare search performance with other existing SPARQL query processing researches and prove its advantage.",
		"KEYWORD": "병렬 처리,분산 시맨틱 웹,빅데이터,시공간 데이터베이스,질의 최적화"
	},
	{
		"ID": 189,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Process of big data analysis adoption :빅데이터 분석 도입의 프로세스에 관한 연구 :defining big data as a new IS innovation and examining factors affecting the process =IS 혁신으로서의 빅데이터 정의와 프로세스에 영향을 미치는 요인들 ",
		"AUTHOR": "Kang,Dongwoo",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 190,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "Ontology-based path query processing for relationship finding over semantic big data =온톨로지 기반 경로 질의처리를 이용한 시맨틱 빅데이터 상의 관계탐색 ",
		"AUTHOR": "JungSungJae",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 191,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "뉴스 빅데이터 분석을 통한 종목별 주가예측 =Prediction of individual stock price through news bigdata keyword analysis ",
		"AUTHOR": "이예지",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:최상현 참고문헌 : p. 39-40",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "The purpose of the concerned study was to forecast stock price volatility depending on news keywords while it measures frequencies of positive/negative opinion-based news keywords related to particular stocks, conducting positive/negative analyses on news at the same time. In order to determine stocks to be investigated in the study, a basic analysis on the total KOSPI index and the individual stock index was first carried out. Afterwards, a total of 192 positively related stocks and other 34 negatively related stocks were categorized into groups of businesses and based on the distributions of those stocks in the study and information on the average correlation coefficient, the study developed its investigation. News data was collected as the study reviewed articles in a portal site, which had included assigned keywords. NAVER was determined as a research portal site in the study while articles on the economy, written by one of the press agencies of NAVER, and other articles by an economy newspaper were examined as research subjects of the same study. The data was collected for two months from June 1, 2013 to July 31, 2013 and the search keyword was LG Electronics Inc. Only titles of the selected articles were used as the articles were first gone through a preconditioning process and the titles were, then, categorized by word class via a morphological analysis so that they could be processed in a general sensitivity analysis. Words, considered to determine opinions, were extracted from separate sentences grouped by morpheme and were tagged to be positive, neutral, negative and others before they were arranged again for the frequency depending on opinions. As for the frequency here in the study, a relative frequency was used. The study looked into changes in stock fluctuation caused by different frequencies of negative words and the findings reported that the higher the negative word frequency, the greater the stock decline. Next, the accuracy was measured via a multiple regression analysis and the study increased the accuracy by adding weight to the negative word frequency.",
		"KEYWORD": null
	},
	{
		"ID": 192,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "오픈소스 ELK Stack 활용 정보보호 빅데이터 분석을 통한 보안관제 구현 ",
		"AUTHOR": "현정훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 41-42",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "사이버 테러와 같은 전자적 침해로 공공기관 및 일반기업에 위해를 가하거나 중요한 정보를 탈취하는 사이버 해킹 범죄가 나날이 증가 추세에 있으며, 이러한 해킹 범죄는 IT발전에 힘입어 고도화되고 정교화되고 있다. 금융이나 민간부분에 정보공유분석센터로 금융보안원(FSI)과 한국인터넷진흥원(KISA)에서 보안관제, 침해대응 및 사고분석 등 다양한 지원을 하고 있으나, 보호해야 할 중요 자산을 보유하고 있는 기업은 자체적으로 침해대응 및 보안관제 체계를 구축하고 있어야 한다. 본 연구에서 정보보호 침해대응 관제 빅데이터 분석은 정보보호 시스템에서 발생하는 이벤트 로그뿐만 아니라 간과하고 지나칠 수 있는 정상 로그를 포함한 전체 로그와 단말 및 서버에서 발생하는 로그 데이터를 활용했다. 오픈소스 기술을 이용하여 수집, 저장, 분석하고 시각화를 통해 이상행위와 같은 특이점을 도출하고자 했다. 현재의 TCP/IP 환경에서는 사이버 침해 흔적은 반드시 남기 마련이다. 로그 데이터만으로는 정상과 침해행위를 구별할 수 없을 뿐이다. 패킷이 전달되는 경로에 구축된 정보보호시스템에서 발생되는 로그 전수 데이터와 패킷이 도달하는 목적지 시스템의 로그 데이터를 시계열 연관 분석을 통한 시각화로 평상시와는 다른 특이점을 찾고자 했다. 시계열 연관성 분석으로 이상행위에 대한 최초 발생시점과 어떤 행위가 있었는지를 알 수 있다. 이것이 빅데이터 분석의 근본 목적인 다양한 침해행위를 사전 탐지하고 대응하는 것이다. 침해대응 관제에 오픈소스를 활용한 것에는 의미가 크다. 기업에서 발생하는 데이터를 바탕으로 자체 정보보호 인력과 기술력으로 정보보호 관제를 직접 구현함으로써 관련 기술노하우를 축적할 수 있다. 이것이 가능한 것은 오프소스 기술 특성상 기술 공유 커뮤니티 활용에 있고, 고가의 상용 관제시스템에서 제약이 되는 이기종 시스템과의 연동에 대한 라이선스 문제도 비용투자 없이 연동이 가능하다는 것이다. 또한, 기술 커뮤니티를 통한 유사 기술 공유를 통해 한층 더 업그레이드 된 보안관제의 구현이 가능하다.",
		"KEYWORD": "ELK Stack,보안관제,오픈소스,정보보호 빅데이터"
	},
	{
		"ID": 193,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "소셜 미디어 빅데이터 분석을 통한 직무만족도에 영향을 미치는 내부평판 요인에 관한 연구 ",
		"AUTHOR": "서운채",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金炯中 참고문헌: 장 53-58",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "본 연구는 전·현직 구성원이 자사에 대한 내부 평가를 입력하고 공유하는 기업정보 제공 소셜미디어에 나타난 빅데이터 분석을 통해 구성원의 직무만족도에 영향을 미치는 내부평판 요인과 각 평판 요인별로 대기업과 중소기업간의 차이가 있는지를 분석하였다. 연구 결과 전체적으로는 ‘복지 및 급여’가 가장 큰 영향을 미치는 요인으로 확인되었으며, 대기업에서는 ‘경영진’ 항목이, 중소기업에서는 ‘복지 및 급여’ 항목이 가장 큰 영향을 미치는 요인으로 분석되었다. 대기업과 중소기업간 차이를 분석한 결과 ‘직무만족도’, ‘복지 및 급여’, ‘업무와 삶의 균형’ 항목이 두 집단간에 통계적으로 유의미한 차이가 있는 수준에서 대기업 평균이 높은 것으로 확인되었으나, 정성적인 평가 내용이 포함된 비정형데이터 분석 결과 ‘직무만족도’와 ‘업무와 삶의 균형’ 항목에 대한 만족도 비율은 중소기업이 높은 것으로 나타났다. 본 연구는 기존 평판 연구에서 진행된 설문이나 실험연구 방식이 아닌 소셜 미디어에 나타난 빅데이터를 활용하여 구성원의 직무만족도와 그 요인을 분석하였다는 점과 소셜 미디어 빅데이터 분석을 통한 인식조사의 한계와 가능성을 제시하였다는 점에서 의의를 갖는다.",
		"KEYWORD": "기업평판,내부평판,소셜 네트워크 분석,소셜 미디어,소셜 빅데이터,직무만족,텍스트 분석"
	},
	{
		"ID": 194,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "클라우드 컴퓨팅을 이용한 유시티 비디오 빅데이터 분석 =(An)analysis of big video data with cloud computing in ubiquitous city ",
		"AUTHOR": "이학건",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이용우",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "현대의 도시에서는 수많은 카메라가 다양한 목적으로 설치되고 다양한 비디오 시스템이 사용된다. 미래의 도시인 유비쿼터스 시티(유시티)에서도 다양한 유시티 서비스를 지원하기 위하여, 도시의 다양한 장소에 다양한 목적으로 수많은 카메라가 설치된다. 유시티에서는 이러한 수많은 비디오 카메라에서 발생하는 영상들을 관리 및 분석해야한다. 하지만 도시규모의 비디오 카메라에서 발생하는 양은 일반적인 시스템으로서는 감당하기 힘들 정도의 양이다. 본 연구에서는 이러한 대규모 비디오 데이터를 처리하기 위하여 이를 위한 유시티 비디오 시스템 아키텍쳐를 설계하였다. 이 시스템은 클라우드 컴퓨팅의 확장성있는 스토리지를 이용하여 대용량의 비디오를 저장하고 관리할 수 있도록 설계되었다. 또한, 대용량의 비디오 데이터를 처리하기 위해 근래 주목받고 있는 데이터 병렬처리 프레임워크인 하둡 맵리듀스(Hadoop MapReduce)를 이용하였다. 이를 통하여 노드를 추가함에 따라 처리시간을 줄임으로써 성능 문제를 해결하도록 하였다. 성능평가로 14대의 PC를 이용한 결과를 소개한다.",
		"KEYWORD": "Cloud Computing,Hadoop,MapReduce,System Architectures,U-City,Ubiquitous City,맵리듀스,시스템 아키텍처,유비쿼터스 시티,유시티,클라우드 컴퓨팅,하둡"
	},
	{
		"ID": 195,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울과학기술대학교 대학원",
		"TITLE": "토픽모델링을 이용한 빅데이터 동향의 다각적 분석 =Bigdata trend diversified analysis using topic modeling ",
		"AUTHOR": "민혜종",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 금영정",
		"STORE_LOCATION": "서울과학기술대학교 도서관",
		"ABSTRACT": "최근 빅데이터에 대한 관심이 기업 및 학계에서 두드러지고 있다. 빅데이터는 다양한 분야 및 영역에서 광범위하게 사용되고 있는 용어로서 이에 대한 동향을 파악하기 위해서는 빅데이터가 연구 및 활용되고 있는 다양한 관점에서 다각도로 분석해볼 필요성이 있다. 본 연구에서는 빅데이터의 동향을 다각도에서 분석하기 위하여 다양한 데이터 원천을 통해 빅데이터의 동향을 분석하고자 한다. 이를 위해 논문, 특허, 웹 뉴스를 데이터 원천으로 빅데이터 관련 문서들을 수집하고 학문적, 기술적, 사회적 관점에서 빅데이터의 동향을 분석하고자 한다. 본 연구는 다음과 같은 단계로 구성된다. 첫번째로 빅데이터의 동향을 다각도에서 잘 파악할 수 있는 다양한 데이터 원천을 탐색하고 해당 데이터 원천의 문서 데이터 수집을 실시한다. 두 번째 단계로 LDA를 이용하여 전체 문서 및 논문, 특허, 웹 뉴스 문서 각각에 대한 토픽모델링을 수행하여 학문적, 기술적, 사회적 관점에서의 핵심 토픽을 파악하고, 각 토픽들을 일정 기준에 따라 네 가지 유형으로 분류하여 분석한다. 세 번째로는 도출된 토픽에 대하여 토픽 간 연계구조 파악하기 위하여 네트워크 분석을 실시한 후, 각 관점별 빅데이터 관련 토픽의 양상을 분석한다. 마지막으로 전체 문서 토픽모델링의 결과를 통해 각 토픽들의 학문적, 기술적, 사회적 관점에서의 영향력과 우위 관계를 분석한다. 본 연구는 빅데이터 연구 및 활용 동향의 분석을 다양한 관점에서 분석함으로써 학문적, 기술적, 사회적 관점에서의 빅데이터 활용 현황 및 주요 특성을 파악할 수 있으며, 기업 및 학계에서 주요 연구주제의 발굴 및 향후 빅데이터 연구 및 활용에 있어서 발전방향에 대한 단서를 제공할 수 있을 것으로 기대된다.",
		"KEYWORD": null
	},
	{
		"ID": 196,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "주성분 분석 기법을 활용한 제조 빅데이터 공정 이상 원인진단 ",
		"AUTHOR": "홍성진",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.38-40",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Manufacturing technology is getting upgraded rapidly because of IoT(Internet of Things) and big data technologies which are related to Industry 4.0 and Smart Manufacturing. In manufacturing progress, developed countries are doing various research for collecting, storing, and appling of manufacturing big data using IoT and existing ICT(Information and Communication Technologies). However, most research on manufacturing big data has focused on the infra and system rather than analysis and the applications. Recently, development of analysis method and process for effective usages of manufacturing big data becomes an imponent issue in the manufacturing area. This research shows how to effectively use manufacturing big data by using Principal Component Analysis(PCA). PCA has been used for quality and process fault diagnosis. In addition, we use PCA loading factor for finding the causes of fault and abnormality in manufacturing area. We also look into the operation execution speed of PCA for manufacturing big data circumstance. A guideline of using an in-memory system for increasing big data performance has been proposed.",
		"KEYWORD": "Anomaly Detection,Apache Spark,Big Data Analysis,Manufacturing Big Data,Principle Component Analysis,R analysis"
	},
	{
		"ID": 197,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "헬스케어 빅데이터 포털에서 MongoDB 기반 질의 생성 및 처리 알고리즘 설계 및 구현 =Design and implementation of MongoDB query process algorithm for healthcare big data portal ",
		"AUTHOR": "신윤철",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.27-28",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "The emergence of big data is coming to an era in which new insights can be derived from rapidly growing data. Recently, medical big data environment in Korea has been studied for application and utilization of medical big data for creating new value through the period of infrastructure construction, and there is a growing demand for linked data sets for research progress. Healthcare Big Data Portal is a service that provides medical linkage data sets from scattered health data. The database for the portal is developed by adopting MongoDB which is faster than conventional RDBMS especially in selection query. In order to provide the linkage data set desired by the portal user, it is necessary to freely generate the MongoDB query statement from the portal GUI. However, existing server - client data exchange models have a static structure and limit the user to generate the desired query. In this paper, we propose a new model that can express the recursive structure of MongoDB query format that can not be handled by the existing JSON format limitation in Healthcare Big Data Portal. The model has been designed and implemented so that it can be freely generated.",
		"KEYWORD": null
	},
	{
		"ID": 198,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 정책대학원",
		"TITLE": "빅데이터 분석을 위한 실시간 로지스틱 회귀모형에 관한 연구 :베이지안 접근법을 중심으로 ",
		"AUTHOR": "김동완",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최태련 참고문헌: 22-23",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "본 논문은 배치 방식에 대비되는 온라인 모형 적합 방법을 샘플 수가 수천만건에 이르고 다수의 범주형 변수, 그리고 범주의 개수가 유동적인 대규모 데이터에 적용하기 위한 모형 적합 방법과 해싱을 이용한 가변수 코딩(Feature Hashing)에 대해 고려해 보고 각 방법의 특성에 대해서 고찰하였다. 적합 방법으로는 최적화 알고리즘의 하나인 확률적 경사하강법(Stochastic Gradient Descent)과 변분 베이즈(Variational Bayes) 방법의 하나인 추정된 밀도 필터링(Assumed Density Filtering)을 소규모 데이터에 적용하여 그 성능이 배치 방식의 로지스틱 회귀 모형에 비견할만 하다는 것을 확인 했고, 이러한 방법이 대규모 데이터 분석에도 유용함을 확인하기 위해 천만건 이상의 이항 반응 변수 데이터에 적용해 보았다.",
		"KEYWORD": "Assumed Density Filtering,Python,R,Stochastic Gradient Descent,로지스틱 회귀,베이지안,빅데이터"
	},
	{
		"ID": 199,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "국방대학교 국방관리대학원",
		"TITLE": "빅데이터 분석 기법의 국방적용 방안 연구 :(A)study on the application of BigData analytics to military :국방 전화통화 데이터 중심으로 =based on military telephonic communication data ",
		"AUTHOR": "김정래",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 200,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 분석을 통한 전자계 인식도 조사 및 분석 =(A)survey on perception level of electromagnetic field through big data analysis ",
		"AUTHOR": "김좌근",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 나종화 참고문헌: p.41-42",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Campaigns against transmission tower construction have been brought into relief as issues of social conflict to be resolved on a government level since they were reported in the press. Therefore, for effective policy establishment, investigations on the level of perception about electromagnetic waves from transmission towers, in other words, the electromagnetic field, should be performed together. Existing investigations in the form of surveys on interested parties have limitation in their investigation scope not sufficiently considering the population. In order to complement such problem, indirect investigation on ordinary people`s level of perception about electromagnetic waves needs to be performed. Accordingly, this study collected social information (news, tweets, and comments related to the electromagnetic field), and based on the information conducted analysis of the level of perception and issues about the electromagnetic field, analysis of social networks, and positive and negative analysis. For issue analysis, nouns were extracted using KoNLP, R`s Korean text mining package. The nouns which appeared most are issues in which ordinary people had most interest. In addition, social network analysis using an apriori algorithm of association analysis was performed to identify the most central words and related words and visualize them. and positive and negative analysis was carried out based on a sensitivity classification dictionary. This paper selected keywords related to the electromagnetic field in order to investigate people`s level of perception about the electromagnetic field. In addition, unstructured data such as news, tweets, and comments related to the keywords were collected and processed, and issue analysis, social network analysis, and positive and negative analysis of them were performed. The most frequent issues related to the electromagnetic field were transmission towers and residents and according to the social network analysis result, many terms related to transmission towers were those with negative meanings about the towers such as sit-in, opposition, and resistance. In the positive and negative analysis, the rate of negative thoughts (87%) was higher than that of positive thoughts (13%), although the rate of the former was slightly lower than the result of existing surveys.",
		"KEYWORD": "빅데이터,전자계"
	},
	{
		"ID": 201,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "개인 정보 보호를 강화하는 보건의료 빅데이터 연계 프로세스 =Healthcare big data linkage process with enhanced privacy protection ",
		"AUTHOR": "김현준",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.39-41",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "With big data technology, diversity of data can be used to discover and reveal hidden information. Data linkage is the most essential and effective method to gain benefit from such diversity of data. However, most of the existing data is fragmented. And linking that kind of data may have limitations due to privacy issues and legal reasons. Here we proposed a personal information protection method for linking healthcare big data. We used exact matching methods and a total of five organizations participated in the data linkage process. The five organizations are linked requesting organization, deliberation and encryption authority, data retention and provisioning organizations, link numbering organization, linkage and storage organization. The personal identifier used in the linkage are encrypted with the SHA-256 one-way hash algorithm to avoid the risk of personal information leakage. It also minimizes the movement of the encrypted personal identifier by giving a separate connection number. In this process, we expect that data that have been linked can be used for various researches and decision making area with enhanced privacy and security issues. Furthermore, the linkage process seems to alleviate Big Brother by the sharing of duties among the organizations.",
		"KEYWORD": "데이터연계,빅데이터"
	},
	{
		"ID": 202,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "금오공과대학교 대학원",
		"TITLE": "빅데이터 처리를 위한 개방형 플랫폼 기반 IoT 센서 미들웨어의 설계 ",
		"AUTHOR": "신승혁",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 이이섭",
		"STORE_LOCATION": "금오공과대학교 도서관",
		"ABSTRACT": "IoT 환경은 다양한 산업 분야에서 활용되고 있다. 특히 제품을 생산하는 제조기반의 사업장에서는 인터넷을 기반으로 생산 설비를 운영하기 위하여 IoT 환경으로 전환하고 있는 실정이다. IoT 환경으로의 전환은 생산 효율성 및 유사 설비의 운용 효율성 등 경쟁 우위를 선점하기 위한 방안이기도 하다. 본 논문에서는 기존의 설비를 그대로 운용하고 신규 설비에 대하여 표준화된 인터페이스를 제공할 수 있는 센서 미들웨어와 IoT 환경을 구성하고 있는 시스템에서의 효율적인 데이터 수집 방안을 제안한다. 이를 위하여 오픈 소스 하드웨어인 아두이노와 라즈베리파이를 이용하여 물리적인 시스템을 구성하며, 산업용 표준 통신 프로토콜인 모드버스 프로토콜을 이용한다. 그리고 수학적 알고리즘을 이용하여 고속으로 발생하는 빅데이터에 대한 수집방안을 제안한다. 또한 대량의 데이터를 수집하기 위한 이중버퍼 알고리즘도 함께 제안한다.",
		"KEYWORD": "IoT 센서 미들웨어,개방형 플랫폼,빅데이터 수집"
	},
	{
		"ID": 203,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울과학종합대학원대학교",
		"TITLE": "머신러닝을 이용한 빅데이터 품질진단 자동화에 관한 연구 :L사의 데이터 품질 진단 사례 중심으로 ",
		"AUTHOR": "이진형",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 204,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 기반의 안심귀가 서비스 시스템 설계 및 구현 =Design and implementation of a safe return service system based on big data ",
		"AUTHOR": "이재원",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 류관희",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "In the living environment in the smart era, the generation of data is carried out between people and equipment, with the equipment and the equipment. Thus, the amount of data generated has increased exponentially. In other words, big data has been created in multiple environments. Various services using big data produced in this manner have been developed. Safe return service is one of the services of these applications. There is a tendency that recent crimes from day to day surge, crimes that target young people and the elderly and women who return home late in particular is increasing rapidly. In addition, a lot of people are using smart phones in the spread of smart phones. Through analysis of information of big data generated from this and crime data, it is possible to grasp crime what type occur where crimes frequently occurring. If this service is developed, smart phone users can return home late safety. Further, it will be possible to prevent significantly crimes occurring in returning home by using these services.",
		"KEYWORD": "빅데이터,안심귀가"
	},
	{
		"ID": 205,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "정보 사회에 있어 재귀적 지식의 생산에 관한 연구 :`빅 데이터` 프레임과 한국 IT 정책지식 재구성 사례를 중심으로 ",
		"AUTHOR": "손준우",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "The thesis sheds light on the process through which Information Technology (IT) policy is accompanied by reflexive knowledge making on sociotechnical world. Given that the gap between an actor`s cognitive capacity and the complex, thus unobservable world give birth to a number of institutions producing reflexive knowledge, IT policy makers experiences the same gap; the social interaction among providers, consumers, and mediators of IT is showing greatly increased volume, complexity, and velocity. Although the earlier studies have pointed out that one can find competition among policy makers to give names, definitions, identifications or symbolic meanings to newly emerging, thus obscure, technologies, they did not pay enough attention to the possibility that those names, definition, or symbols could be parts of knowledge designed to explain sociotechnical changes. Based on the assumption that reflexive knowledge is not only simple description of interaction between an actor and the world, but the performative speech act constructing the actual relationship as the knowledge describe it, the thesis focuses on influence of a certain way of explanation, in the context of making IT policy knowledge. `Big Data` policy in South Korea, originally proposed in October 2011, was the latest form of IT policy designed to reform the whole government agencies by applying new technology and R&D. Granted that such policies have a reflexive feature, the policies had been backed up by knowledge produced by public policy research institutions, in order to know in advance what kind of reflexive results are expected. On the one hand, the term `Big Data` means data with great volume, variety, and velocity, whereas it also selectively means new analytic tools and system infrastructure for those data, media for sharing and circulation, or community of practice responsible to all of them, on the other hand. This coverage and complexity makes it hard to grasp the whole image of `Big Data`; such difficulties made government demand more participation in reflexive knowledge making from the public policy research institutions that had already worked for IT policy for decades. Nevertheless, it is not the continuity with the past, but the discontinuity that needs careful scrutiny. In other words, `Big Data` policy knowledge making in Korea depended on the global IT consultancy. Global IT consultancy constructed an explanatory system in which the phrase `Big Data` summarized the on going changes in the sociotechnical world. By providing analytic map for complicated and rapid interactions in the field of IT, the consultancy secures its influential intermediary status between providers and consumers. When it comes to `Big Data,` its explanation of what parts of the sociotechnical world should be known mobilized conceptual apparatus including the definition of `Big Data` and the model for classifying and sorting various data, technology, and actors, and survey results and visualized graphs indicating enormous growth of valuable data inside and outside of all kinds of organizations. This explanation shaped the frame, in which an organization as an actor was depicted as an individualized market actor purchasing required data and analytic toolkit from outsiders, and surrounding world as an inventory for valuable resources. When policy knowledge making in South Korea made use of explanatory equipments originally designed by a group of global IT consultants, the way to understand IT policy gradually resembled their frame. Research for `Big Data` policy design and implementation showed compatibility with earlier studies on the use of government`s public data to set a new relationship among governmental organizations, and, among government, citizens, and private corporations. Nevertheless, the concept of market transactions gradually substituted in the policy knowledge the past concept of cooperative relationships for contriving creative data usage in which citizens take the lead. Simultaneously, the world depicted by the knowledge excluded the `citizen` as an actor, while `consumers` and `private corporations` are left. In an identical case serving as `the best practice` in two discrete kind of policy knowledge, the knowledge concerning `Big Data` drastically reshaped the prior interpretation, and the policy rested on completely different understandings of the reflexive relationship between government as an actor and sociotechnical environment. This does not mean that `Big Data` explanatory frame constructed by IT consultancy has always been stabilized during policy knowledge production in South Korea. It has been questioned and even partly replaced by other ways of explanation. Most of all, critics mostly questioned the behavioral model in which an individualized actor including government as an organization can purchase data and analytic toolkit required, and the point of view in which world is depicted as an usable inventory. Consequently, emphasis on collective, not individualized, relationships and the world as place of social interactions was partly recovered in the policy knowledge. However it was still different from the precedent ones; `the collective` means competitive, not cooperative relationships in mobilizing potential data resources. `Citizens` also came back into the policy knowledge, not as a participatory subjects but as potential sources of valuable data. It still understands data as capital, not as a medium for civil cooperation, and takes resource accumulation as the virtue of all actors within the sociotechnical world. This suggest that even conceding the explanations constructed by global IT consultancy are not always fully accepted, it possibly leaves a trace on policy knowledge even after it is questioned. In this regard, the result of this study might not be limited to a single case. Along with policy knowledge making, reflexive knowledge has been constructed and circulated through various channels such as insurance companies, futurology, and technology assessment this mirrors the reality that decision-makings on technological issues extends their influence. Although there might be various reasons that one might choose a sort of reflexive knowledge as integrated part of such efforts, and such knowledge might be contested easily then one originally thought, the thesis suggests that it is quite difficult to eliminate all of its influence after the knowledge has been used.",
		"KEYWORD": "빅 데이터,재귀적 지식,정보기술 정책,정책지식,지식의 수행성"
	},
	{
		"ID": 206,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "4차 산업혁명에서의 공공빅데이터를 활용한 보건의료 정책 연구 :A study on healthcare policy using public big data in the fourth industrial revolution : focusing on the development of dementia predictive model for the senior population ",
		"AUTHOR": "김희철",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 문영호",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "한국의 보건의료 정책 문제 중 하나인 고령화는 점점 심화되고 있으며, 빠른 고령화는 여러 가지 사회적 문제를 만든다. 고령화에 의한 증상 중의 하나인 치매로부터 발생하는 보건의료 정책 문제를 해결하고자 국민건강보험공단 노인코호트 데이터베이스의 빅데이터를 활용하여, 치매 예측 연구를 하였다. 치매노인과 정상노인 간에는 증상의 유무에 따라 의료기록 상의 차이가 발생할 것이다. 의료 기록 중에서도 진료내역의 시계열적 변화를 치매 증상이 시작되기 전에 찾아내어 측정하게 된다면 치매를 예측 할 수 있을 것이다. 예측 모델 개발을 위해 국민건강보험공단 노인코호트 데이터베이스 중에서 자격DB, 진료DB, 건강검진 DB에서 변수들을 추출하였다. 기계학습 기법 중 의사결정나무 (Decision tree: DT), 랜덤 포레스트 (Random Forest: RF), 지지벡터기계 (Support Vector Machine: SVM), 딥 러닝 (Deep Learning: DL) 을 사용하여 모델을 만들었으며, 10-fold validation을 수행하였다. 그 결과 0.8268 F-Measure로 치매를 예측하는 모델을 만들었다. 한국 전체 인구를 대표하는 표본을 대상으로 수행된 연구로 시계열 관련 변수들의 영향력이 상대적으로 큰 것을 확인하였다. 빅데이터를 활용한 질병의 예측 연구들을 통해 보건의료 정책 문제의 완화가 될 수 있을 것이라 기대된다.",
		"KEYWORD": "4차 산업혁명,고령화,기계학습,빅데이터,치매"
	},
	{
		"ID": 207,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "조직에서의 빅데이터 시스템 도입을 위한 결정요인에 대한 연구 =Research on determinants for big data system adoption in organizations ",
		"AUTHOR": "이선우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이희상 부록수록 참고문헌 : p. 111-122",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "정보 통신 기술(Information Communication Technology: ICT)의 발전으로 인해서 데이터는 급격히 증가했고 이로 인하여 빅데이터 기술은 최신 정보기술 중 크게 조명되는 혁신 기술 중 하나가 되었다. 조직들은 다양한 형태의 데이터를 분석하고 이를 활용하여 새로운 비즈니스를 창출하기 위하여 빅데이터 시스템 도입에 관심을 갖고 있다. 조직에서의 신기술 도입을 통한 경쟁력 강화는 조직의 생존에 중요한 사항이다. 본 연구의 목적은 빅데이터의 사용 행동과 행위 의도에 영향을 미치는 요인의 분석을 통해서 빅데이터 시스템 도입을 위한 통합된 기술수용모형을 구축하기 위함이다. 또한 연구는 주로 조직 차원에서의 신기술 도입에 사용되어 온 기술?조직?환경 프레임워크(Technology-Organization-Environment: TOE)에 조직에서 기술도입에 있어서 개인의 입장에 따라 도입요인에 영향을 주는 변수를 감안하여 수행하였다. 본 연구는 개인차원의 기술 도입 연구에 사용되어왔던 통합기술수용모형(Unified Theory of Acceptance and Use of Technology: UTAUT)과 통합하여 확장된 기술수용모형을 제시하였다. 또한 혁신 기술의 도입에 적용하는 혁신확산이론(Diffusion of Innovation: DOI)을 연구모형에 추가하였다. 확장된 연구 모형을 기반으로 빅데이터 시스템을 구축하는 ICT 서비스 산업과 사용자 산업의 도입요인을 비교하였다. 본 연구는 ICT 서비스, 금융, 공공, 통신과 제조 산업에 근무하는 직원들을 대상으로 하였고 총 474개의 유효 조사데이터를 확보하여 본 연구 모형을 검증하였다. 연구의 결과는 각 모형(TOE, UTAUT)의 여러 변수가 기술을 도입함을 의미하는 행위 의도와 도입된 기술의 확대 사용을 의미하는 사용 행동에 영향을 미쳤다는 것을 확인하였다. TOE의 기술요인, 조직요인과 환경요인이 모두 행위 의도와 사용 행동에 영향을 미쳤고, UTAUT의 촉진조건이 행위 의도에 영향을 미쳤다. 따라서 빅데이터 시스템 기술 도입을 위해서 제안된 통합 모형은 적합했음을 검증하였다. 또한 제시된 모형을 ICT 서비스 산업과 사용자 산업에 적용하였고 두 산업을 비교 분석하였다. 그 결과 두 집단 모두가 적합하다고 확인되었으며 사용자 산업에서 ICT 산업보다 더 많은 가설이 채택되었다. 두 집단 간의 차이점으로는 사용자 산업에서는 직원 개인의 촉진요인이 빅데이터 기술도입에 영향을 미친 반면에 ICT 서비스 산업에서는 개인의 촉진요인이 빅데이터 기술도입에 영향을 미치지 않았다. 본 연구에서 제시하는 시사점으로는 다음과 같다. 첫째, 빅데이터 시스템이 기존 시스템과 비교해서 기술적으로 사용하기 편리하고 업무가 질적으로 좋아지면 사용자는 빅데이터 시스템 도입에 긍정적이게 될 것이다. 둘째, 비용이 적게 사용되고 보안의 위험이 작다면 도입에 긍정적이게 될 것이다. 셋째, 빅데이터 시스템 도입이 많은 비용이 필요하고 업무 프로세스 변화까지 있을 수 있기 때문에 최고 경영층의 적극적인 지원이 필요하다. 넷째, 동종 업계에서 빅데이터 시스템을 도입했거나 빅데이터 시스템 도입을 위한 관련 규정이 잘 되어있다면 빅데이터 시스템 도입은 더 적극적이 될 것이다. 다섯째, 조직원 개인의 기술 습득에 대한 지원이 충분하다면 조직은 빅데이터 시스템을 도입에 대해 적극적일 것이다. 마지막으로, ICT 산업과 사용자 산업의 빅데이터 시스템 도입에 대해 비교했을 때에 일부 도입 요인에 차이가 있었다. 이와 같이 본 연구는 빅데이터 시스템 도입을 위한 이론적, 실용적 시사점을 제공하였다.",
		"KEYWORD": "TOE,UTAUT,도입,빅데이타,산업간 비교"
	},
	{
		"ID": 208,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "Hive 기반의 소셜빅데이터 분석 시스템 설계 및 구현 =Design and implementation of social bigdata analyzing system based on hive ",
		"AUTHOR": "서승현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이한구",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "최근 스마트폰의 보급과 인터넷 기술의 발전으로 사용자에 의해 데이터 양이 폭발적으로 증가하고 있다. 때와 장소에 구애받지 않고 인터넷에 접속할 수 있기 때문이다. 특히 많은 사람들이 소셜 네트워크 서비스(Social Network Services, 이하 SNS)를 통하여 소셜빅데이터를 생산 및 공유한다. 이에 따라 다양한 분야에서 고객의 니즈와 트렌드를 분석하기 위해 소셜빅데이터를 활용하여 이윤을 창출하기 위한 시스템을 필요로 하고 있다. 기존 소셜빅데이터 분석 시스템은 RDBMS 기반으로 소셜빅데이터를 가공 및 분석하기에 저장 용량의 한계와 분석 속도의 한계가 있다. 이러한 단점을 보완하고, 소셜빅데이터 분석 시스템의 저장 및 분석 효율성을 위하여 본 논문에서는 Hive, HBase, Hadoop 을 사용한 Hive 기반의 소셜빅데이터 분석 시스템을 설계 및 구현 하였다. 본 시스템은 Hadoop의 Mapreduce 작업 구조를 적용하여, 필요한 데이터를 HiveQL 쿼리를 통해 빠르게 정제 및 가공하고, 사용자의 의도를 쉽게 파악하기 위해 웹인터페이스로 설계 및 구현 하였다. 구현 계층은 수집, 저장, 분석, 표현 계층으로 나뉜다. 수집 계층은 트위터 데이터를 수집하기 위한 Streaming API와 Search API, 그리고 Gnip과 연계하여 Historical 데이터를 수집하였다. 저장 계층은 대용량 소셜빅데이터를 저장하기 위한 HBase, 실시간 그래프 데이터를 저장하기 위한 MySQL을 사용하였다. 분석 계층은 HiveQL을 이용하여 필요한 데이터를 추출 하였다. 마지막으로 표현 계층은 JSP와 Servlet, 구글차트 API를 사용하여 웹페이지로 구현 하였다. 구현된 Hive 기반의 소셜빅데이터 분석 시스템을 통해 사용자의 의도를 분석하고 트렌드를 예측한다. 또한 결과 분석을 통하여 향후 연구방안을 제시한다.",
		"KEYWORD": "BigData,Hadoop,HBase,Hive,Mapreduce,MySQL,SNS"
	},
	{
		"ID": 209,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "홈쇼핑 산업에서의 고객경험분석 플랫폼 구축사례 연구 ",
		"AUTHOR": "유철민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김희웅",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "Domestic home shopping industry is continuously growing and customer contact channel is expanding from a single channel that is centered on call center to Omni Channel. As a result of these changes, the number of customers who are using mobile devices is increasing, and the service usage patterns are becoming more diverse. Therefore, there is a need to analyze customer contact channels. Many companies try to analyze customer experiences to provide differentiated services and strengthen competitiveness of the companies based on understanding and analyzing positive and negative experiences of customers in the contact channel. However, in the process various technical and organizational difficulties are expected. Current study investigated the cases of building a customer experience analysis platform for the home shopping and introduces the procedures and technical steps to consider when building the platform through the examinations of both the scholarly and business perspectives. The following are the suggestions after the study. First, there is a standard for defining the customer journey stage in the home shopping industry and provides indicators for measuring the performance of the non-face-to-face channel that can be switched from the conceptual stage to the actual stage. Second, there are the technical elements to be prepared for integrating and analyzing diverse and vast customer experience data, and provide practical assistant by presenting technical issues and solutions to be reviewed in advance. Third, when planning and reviewing the analysis platform, it is difficult to predict its use and performance. In order to alleviate the situation, the analysis platform utilization plan and the achievement performance are provided in detail. Through this study, it is possible to present the direction of each stage of the similar project to analyze and utilize the customer experience on the Omni Channel, and this study provides practical help in domestic areas where it is difficult to find similar cases.",
		"KEYWORD": "big data,call center,customer experience,customer experience analytics,customerexperience management,home shopping,mobile,non-face-to-face channel,omni channel,고객경험,고객경험관리,고객경험분석,모바일,비대면채널,빅데이터,옴니채널,콜센터,홈쇼핑"
	},
	{
		"ID": 210,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서울과학종합대학원대학교",
		"TITLE": "금융 지주회사의 클라우드 컴퓨팅 도입을 위한 법제 연구 :빅데이터 활용 방안을 중심으로 ",
		"AUTHOR": "이주영",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 211,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "토픽모델링과 시계열 분석을 이용한 부동산 투자이민제에 관한 연구 ",
		"AUTHOR": "권혜련",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "The real estate investment immigration system has gained economic benefits, such as economic activation and population increase through foreign capital inflows as visible economic results appear since its implementation in February 2010; however, on the hidden side of economic benefits, side effects, such as investment bias and investment overheating as well as the phenomena that Chinese people are being concentrated on Jeju Island are appearing. As a result, research on the real estate investment immigration system has been actively carried out, but research on the change of social recognition using a topic modeling technique has not been carried out yet. Therefore, this study examined the formation and change of the public recognition by using the topic modeling technique and topic map focusing on online news articles about the real estate investment immigration system. The topic modeling technique was used to extract the topic formed in the whole news about the real estate investment immigration system, and the change of the topic weight according to the time flow was confirmed through the time series analysis on the extracted topic. As a result, we confirmed the formation and change of the public recognition by drawing up the before and after topic map starting from Jun 2013, which is the time the weighs of topics change rapidly. We also identified that the weight of the social public recognition about the real estate investment immigration system is high on the concentration of Chinese people in Jeju Island.",
		"KEYWORD": "big data,online news,real estate investment immigration system,text mining,topic map,topic modeling,부동산 투자이민제,빅데이터,온라인 뉴스,텍스트 마이닝,토픽맵,토픽모델링"
	},
	{
		"ID": 212,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Business analytics adoption process and capabilities under big data environment =빅데이터 환경에서의 비즈니스 애널리틱스 도입 프로세스 및 역량에 관한 연구 ",
		"AUTHOR": "Nam,Dalwoo",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 213,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충남대학교 산업대학원",
		"TITLE": "대기질 모니터링 시스템과 빅데이터 플랫폼의 연동을 위한 DMS 설계 및 구현 ",
		"AUTHOR": "황신범",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 權榮美 참고문헌 : p. 60",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "The data collected from existing automatic air pollution monitoring networks is spatially limited to only the currently installed area and the cost of installing such a network is expensive. Using Passive Diffusive Samplers to complement the shortcomings of this existing system is necessary to implement an effective air pollution monitoring system. Also, using a big data platform to process the large amount of data will increase the value of the data. The PDS is easy to install and collect and its costs are also quite affordable. Because people will be operating directly in a mobile environment, an Android-based client to assist with the work is required. Additionally, data collected from the client must be sent to a server that manages and monitors the data. Finally, after the data management server finishes collecting the data, the data is stored on a big data platform. The data management server can also send requests to the big data platform at any time to retrieve the data stored there. The Android Client Application (ACA) uses the bar code information from the PDS, combines it with GPS coordinate and uploads this data to the Data Management Server (DMS). The ACA can also send analyzed data. The DMS administrator can input data directly. This collected air quality data is saved on the Xively big data platform and can be retrieved and checked at any time through the DMS using Xively’s Open API. This paper details the implementation of the air quality monitoring system, describes how the spatial limitations of the conventional automatic air pollution monitoring network were overcome, and shows how using a big data platform lowers costs while significantly increasing the usage of the data.",
		"KEYWORD": null
	},
	{
		"ID": 214,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 정보통신대학원",
		"TITLE": "유비쿼터스시설물 안전관리 통합화 방안에 관한 연구 :(A)study on integrated safety management of ubiquitous infrastructure :빅데이터 기술 중심으로 =focusing on big data technology ",
		"AUTHOR": "이만효",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형복",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "1960년대 이후 현재까지 산업혁명이 급속히 발전하면서 수많은 사회기반시설이 구축되었다. 대형토목 공사는 물론이고, 공장, 아파트, 빌딩, 대형 상가, 선박, 항공기, 자동차등 급변하는 사회 물결 속에 팽창하는 인구증가와 함께 그를 수용하고 이동할 수 있는 교통수단이 만들어 졌으며, 대형 구조물들도 함께 설계 및 건설. 건축 되었다. 하지만 이렇듯 빠르게 성장한 대한민국의 이면에는 안전이라는 최우선 과제가 등한시 되었던 것 같다. 수많은 사건 사고가 발생하고 있다는 것이 이를 증명하는 것이라 생각한다. 그 예로 성수대교 붕괴사고, 상품백화점 붕괴사고, 항공기추락사고, 대구지하철 화재 사고, 특히 최근에 수많은 인명피해를 가져온 여객선 세월호 침몰 사고에 이르기까지 국가 재난관리시스템에 큰 구멍이 발생되었다는 것이 사실로 드러나고 있다. 이는 어느 한 분야에만 국한된 것이 아닌 이를 관리감독 해야 할 국가적 행정시스템에 이르기 까지 많은 곳에서 큰 문제점들이 있다는 사실이 속속 들어나 국민들의 울분을 사고 있다 할 수 있겠다. 이렇듯 사회 전 분야에 걸쳐 안전사고가 끊이질 않고 있는 것이다. 자연재해 또한 빈번하게 발생되고 있다. 해년마다 반복되는 겨울철 폭설에 의한 피해, 강한 바람으로 모든 것을 앗아버리는 태풍피해, 한번 내리면 그칠지 모르는 많은 양의 비로 인한 홍수피해, 지진발생으로 인한 해일피해. 시설물 붕괴로 인한 인명피해, 가뭄으로 인한 농작물의 피해 등 지구 온난화로 빚어지는 대형 재난 사건 사고 또한 빈번하게 일어나고 있는 것이다. 이는 수십, 수천년에 걸쳐 이룩한 모든 것들을 한순간에 잃어버리는 가혹한 재해인 것이다. 또한 조류인플레인자등 바이러스에 의한 피해 또한 가혹하기는 마찬가지이다. 안전사고 발생 직후 초기 대응 또한 문제점으로 지적되기도 한다. 이러한 문제는 전문 구조인력 부족과 사고발생 직후 체계화된 구조 시스템이 잘 갖추어지지 않아서 발생을 한다. 그러나 무엇보다도 중요한 것은 사고를 미연에 방지하는 것이 최선일 것이다. 이를 위해서는 국가적인 차원에서 체계화된 재난관리 시스템과 모든 구조물에 대하여 안전관리를 강화하는 방법 그리고 장기적으로는 안전관리에 대한 조기교육을 실현하여 국민들의 안전의식의 체질을 근본적으로 바꾸어 나가는 노력을 해야 할 것이다. 세계 각국에서는 우리나라를 일컬어 IT 강국이라 칭한다. 1990년대 이 후 거의 모든 국민이 스마트폰을 비롯한 무선인터넷기기 사용을 생활화 하고 있다. 24시간 스마트폰을 손에서 놓지 않고 생활하는 사람도 꽤 많으리라 생각 한다. 이는 그에 따른 무선통신기술이 잘 발달된 나라라는 것을 반증하는 것이기도 하다. 그렇다면 이렇게 잘 갖추어진 무선네트워크시스템을 안전관리의 조기 대응 시스템으로 활용할 수 만 있다면 지금보다 좀 더 안전한 생활을 할 수 있으리라 생각한다. 무선네트워킹 통신 기술이 발전함에 따라 그에 관련된 무수히 많은 산업들이 발전하고 있다. 언제 어디서, 누구든 쉽게 무선 네트 워크에 접근할 수 있는 환경이 된 것이다. 바로 유비쿼터스(Ubiquitous) 네트워크가 바로 그것이다. 사람과 사람, 사람과 사물, 사물과 사물 간에 까지 확대되어 폭넓게 발전하고 있는 것이다. 즉 사물인터넷시대(IOT)가 온 것이다.이처럼 잘 갖추어진 IT인프라에 RFID와 사물인터넷(IOT) 그리고 빅데이타기술(Big Data Technology)을 융. 복합하여 국가에서 전국의 모든 시설물을 통합 관리하는 “시설물안전관리통합IT방재센타”를 구축하여 재난피해 발생 대상자 스마트폰으로 재난발생 예정 및 사실을 실시간 통보하여 신속한 대피를 유도하는 조기대응 안전관리시스템 만들어 활용한다면 진정한 U-City가 되지 않을까 생각하여 그에 관한 연구 논문을 작성하고자 한다.",
		"KEYWORD": "빅데이터,사물인터넷,시설물안전관리,유비쿼터스"
	},
	{
		"ID": 215,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "(A) study on safety-critical cyber physical system architecture and its time series big data analysis =안전필수 사이버물리시스템 구조 및 시계열 빅데이터 분석 연구 ",
		"AUTHOR": "YoojinLim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 216,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "Spark based distributed deep learning framework for big data applications =빅데이터 애플리케이션을 위한 아파치 스파크 기반 분산 딥러닝 프레임워크 ",
		"AUTHOR": "AkhmedovKhumoyunMarufjonovich",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 217,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한성대학교 지식서비스&컨설팅대학원",
		"TITLE": "e-CRM이 고객 만족에 미치는 영향에 관한 연구 :(A)study in the influencing e-CRM on customer satifaction :빅데이터 활용을 중심으로 =focusing on big data ",
		"AUTHOR": "이원일",
		"REGION": "서울",
		"PROFESSOR": "부록: 설문지 참고문헌: p. 75-84 서지적 각주 수록",
		"STORE_LOCATION": "한성대학교 도서관",
		"ABSTRACT": "최근 스마트시대에 IT 분야의 화두는 클라우드 컴퓨팅, IoT, 빅데이터 등을 들 수 있다. 인터넷기반의 컴퓨터, 스마트폰 등 정보기기의 확산으로 수많은 양의 정보가 생성, 유통, 소멸되고 있다. 특히 SNS의 발달로 다양한 정보채널들이 생겨나고 이를 통하여 생성되는 데이터는 기하급수적으로 증가하고 있고 IoT의 발달로 과거에는 추출하지 못한 새로운 데이터가 증가하고 있다. 따라서 이렇게 생성된 빅데이터를 관리하고 활용하여 또 다른 가치창출에 활용할 수 있는 기술에 많은 관심을 가지게 되었고 본 연구는 빅데이터를 활용하여 효과적인 e-CRM 구축을 위하여 빅데이터 분석과 고객 만족, e-CRM 요인과 고객 만족간의 관계를 실증 분석을 통해 연구하는 것에 목적을 둔다. 연구 목적을 달성하기 위해 설문조사를 통해 회수된 설문을 연구에 사용하였다. 실증연구에 앞서 e-CRM 개념, 고객 만족의 개념, 빅데이터 개념에 대한 이론 및 선행연구와 e-CRM과 빅데이터에 대한 사례 등을 고찰하였다. 실증적인 분석을 위한 방법으로 설문조사대상의 인구 통계적 특성을 분석하기 위해 빈도분석을 이용하였고, 조사를 위해 설정한 문항들의 타당성 검증을 위해 요인분석 방법을 이용하였다. 더불어 변수들 간의 신뢰성 측정을 위하여 Cronbach’s α 계수를 활용하였다. 그리고 연구모형의 판별 타당성을 검증하기 위해 상관분석을 실시하였고, 빅데이터 분석이 고객 만족에 미치는 영향과 e-CRM 구성요인이 고객 만족에 미치는 영향을 분석하기 위하여 단순회귀분석과 다중회귀분석 방법을 사용하였다. 모든 실증분석은 SPSS 22 통계 프로그램을 사용하였다. 실증적인 분석 결과 도출된 연구결과는 다음과 같다. 첫째, 빅데이터 분석과 고객 만족의 관계를 분석한 결과, 빅데이터 분석이 고객 만족에 유의적인 영향을 미치는 것으로 나타났다. 둘째, e-CRM 구성요인과 고객 만족의 관계를 분석한 결과, e-Marketing, e-Sales, e-Service, e-Communication 4가지 하위변인 모두가 고객 만족에 유의적인 영향을 미친다는 점을 알 수 있었고, e-Sales, e-Marketing, e-Communication, e-Service 순으로 고객만족도에 유의한 영향을 미치는 것으로 나타났다.",
		"KEYWORD": "e-CRM,e-마케팅,e-서비스,e-세일,고객 만족,빅데이터"
	},
	{
		"ID": 218,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "빅데이터 기반의 연비 추정을 통한 전기자동차 주행가능거리 예측 =Big-data approach based on fuel efficiency estimation for range prediction of electric vehicle ",
		"AUTHOR": "전종찬",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박장현 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 37-38",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "본 연구는 전기자동차의 주행정보를 수집하여 Big-Data를 구축하고 이를 기반으로 각 도로 Link의 연비를 추정하여 전기자동차 주행가능거리를 예측하는 것을 목적으로 수행되었다. 기존의 전기자동차 주행가능거리 예측 기술은 차량의 과거 수회 주행패턴 기록에 의존하기 때문에 평소의 주행환경과 상이한 환경에서는 예측 정확도가 낮아지는 한계점을 지니고 있다. 따라서 본 연구에서는 전기자동차의 주행기록을 Big-Data로 구성하고 이를 기반으로 연비를 추정하여 주행가능거리를 예측하는 기술을 제시하였다. 유사한 방식의 선행연구도 이루어지고 있지만 Big-Data를 활용한 대부분의 기존 연구방식은 주행 데이터를 수집하여 차량 시뮬레이션을 돌리는데 정보를 활용하는 것에 그치고 있다. 본 연구에서는 수집된 실 주행 데이터를 통계처리과정을 거쳐 도로별 소모부하 예측모델 개발에 사용하였고 이를 통해 전체 주행가능거리 예측을 수행하였다. 예측된 소모부하로부터 전체 소모 에너지를 연산하고 도로별 연비를 추정하여 주행가능거리를 예측하게 된다. Big-Data 확보를 위해 연구용 시험차량의 실 주행 모니터링 데이터를 이용하였고 특정경로에 대한 분석과 범용경로에 대한 분석을 병행하며 두 가지의 접근방법으로 연구를 수행하였다. 연구를 진행하면서 예측 정확도를 향상시킬 수 있는 방법을 같이 제시하였고 실제로 실험과정에서도 제시한 방법을 적용하며 예측을 수행하였다. 또한 실 개발 시 발생할 수 있는 문제점들에 대한 해결방안도 제시하여 양산을 위한 개발 시 적용 할 수 있도록 하였다. 부하 분석은 구동부하, 전장부하, 공조부하 별로 구분하여 통계처리를 하는 방식으로 수행하였으며 부하와 영향인자간의 상관관계를 분석하여 각 조건에 맞는 예측 모델을 제시하였다.",
		"KEYWORD": "자동차공학"
	},
	{
		"ID": 219,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "공동주택 하자 빅데이터 구축 및 평면속성별 하자발생 특성 연구 ",
		"AUTHOR": "안용신",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이강",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "2016년 기준 인구주택총조사 전수집계 결과에 따르면 전체 주택유형에서 공동주택이 60.1%를 차지하기 때문에, 공동주택의 하자는 우리나라 주거환경에서 가장 중요한 문제 중 하나이다. 공동주택 하자와 관련한 연구가 국제학술지보다 국내학술지에 집중되어 있는 점도 이를 증명한다. 그동안 공동주택의 하자 연구는 하자유형 및 요인 분석을 중심으로 진행되었다. 하자유형 연구는 하자를 공종별 또는 증상별로 분류하였다. 하자요인 연구는 주로 전용면적, 평면유형, 외기 노출면수, 층수, 주동형태, 구조공법 등과 하자의 관련성을 분석하였다. 하지만 기존 연구는 단기간의 데이터를 분석하였고 기술통계에만 그치는 등 체계적인 통계 분석이 부족하였으며, 하자 데이터에 대한 하자유형 분류체계도 달라 정보 처리에 통일성이 부족하다는 한계점이 있다. 본 연구의 목적은 하자 빅데이터를 구축하고 기존 하자발생 연구 재검증을 통하여 하자 발생과 관련된 평면특성 및 공종 도출을 하고 추후 정보의 활용을 가능하도록 하는 것이다. 본 연구는 2002년부터 2010년까지 공사를 진행한 국내 8개의 공동주택에서 입주후 발생한 3만건의 하자 접수 및 처리 자료를 연구의 대상으로 하였다. 그리고 기존 연구에서는 통일되지 않았던 하자 분류체계를 정리하여 하자 빅데이터를 구축하였다. 이렇게 구축된 하자 데이터로 기존의 연구 결과를 재검증하여 각 평면특성별 주요 하자발생 요인 및 관련 공종을 도출하였다. 본 연구에서는 다음 가설을 통하여 평면특성의 하자발생 영향에 관한 기존 연구의 가설을 재검증하였다. 기존 연구 결과의 재검증이 필요한 이유는 다음과 같다. 1) 기존 가설들은 설계, 시공관리, 아파트 유지관리 등에 있어서 중요하다고 파악된 가설이다. 2) 그러나 기술통계에 의존하였던 기존 데이터 분석의 한계로 교차분석, 다수의 변수를 이용한 분석이 부족하여 재검증을 통한 통계적 신뢰성 확보가 필요하다. 3) 기존 연구 결과를 토대로 하자 관리시 유의해야할 평면특성 및 공종을 도출할 필요성이 있다. 4) 시대에 따라 공동주택과 관련된 기술이 변천하여 이전 연구 결과가 유효한지 재검증이 필요하다. H1: 전용면적이 넓을수록 하자발생빈도수가 증가할 것이다. H2: 평면형태가 복잡할수록 하자발생빈도수가 증가할 것이다. H3: 복잡한 평면(매스중첩형)은 시간의 흐름에 따라서 하자 발생이 줄어들 것이다. H4: 외기 노출면수가 많을수록 습기 관련 하자의 수가 증가할 것이다. H5: 시간이 지날수록 외기 노출면수와 습기 관련 하자의 상관관계는 낮아질 것이다. H6: 층 구간(저층, 중층, 고층)별로 하자 발생률이 다를 것이다. H7: 주동형태가 복잡할수록 하자 발생률이 증가할 것이다. H8: 탑상형은 시간의 흐름에 따라서 하자 발생이 줄어들 것이다. H9: 탑상형은 다른 주동형태에 비해서 습기 관련 하자 발생이 많을 것이다. H10: SRC 공법과 RC 공법을 적용한 세대는 하자 발생률이 다를 것이다. H11: RC 공동주택은 시간의 흐름에 따라서 하자 발생이 줄어들 것이다. 하자 빅데이터 가설 검증 결과, 전용면적(‘하자 발생수/세대수/방개수’기준: r=0.690, n=29, p=0.000), 평면유형(‘하자 발생수/세대수/방개수’기준: r=0.609, n=17, p=0.010, ‘하자 발생수/세대수/전용면적’기준: r=0.635, n=17, p=0.006), 주동형태(하자 발생수/세대수/방개수’기준: r=0.427, n=1805, p=0.000, ‘하자 발생수/세대수/전용면적’기준: r=0.361, n=1805, p=0.000) 등은 하자발생빈도와 상관관계를 가지며, SRC 공법이 RC 공법이 적용된 세대보다 약 2배 하자발생확률이 높았다. 반면 외기 노출면수, 층수는 하자발생빈도와 상관관계가 없었다. 다양한 분석 결과 H1, H2, H7, H9, H10에 대한 가설은 통계적으로 유의한 것으로 나타났으며, H3, H4, H5, H6, H8 가설은 기각되었다. 본 연구는 평면특성에 따른 하자발생 연구 결과를 재검증하여 각 평면특성에서 나타나는 하자의 공종 중심으로 하자관리를 할 것을 제안한다. 또한 통계 신뢰성 문제를 해결하고 지속적으로 발생하는 하자에 대한 빅데이터를 구축하였다는 점에 의의를 둔다. 본 연구의 기여점은 3만건의 공동주택 빅데이터를 구축하고, 분석을 통하여 하자발생에 큰 영향을 미치는 평면 특성은 평면유형, 주동형태이며, 설계단계에서부터 이와 관련된 특성에 주의해야 한다는 점을 규명한 것이다. 또한 시간별 분석을 통하여 하자 발생은 기술의 발전 보다는 설계단계부터의 예방이나 지속적 관리가 더 중요하다는 것을 밝혔다.",
		"KEYWORD": "apartment defect big data,apartment defect factors,apartment defects,use of defect information,공동주택 하자,공동주택 하자 빅데이터,공동주택 하자 요인,하자 정보 활용"
	},
	{
		"ID": 220,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "교통정보 빅데이터 기반의 시공간 혼잡지표 개발 =Development of spatiotemporal congestion recognition index based on big traffic data ",
		"AUTHOR": "한여희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김영찬",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "4차 산업혁명과 더불어 고품질의 교통정보 빅데이터의 시대에 접어들었다. 개별차량 위치정보 기반의 링크별 통행시간 자료를 이용하여 교통관리 목적의 혼잡 지표를 개발하였다. 신호운영의 효율성 등 교통 운영에 대한 효과를 평가할 수 있도록 과포화 상태를 모니터링하는 혼잡 지표를 개발하였다. 기존의 혼잡 지표와는 다르게 혼잡 강도와 혼잡 시간을 동시에 표출하는 지표로 모형을 개발하였다. 교통정보 빅데이터 중 실제 교통관리 목적으로 활용가능한 자료를 검토하였다. 도심 네트워크를 대상으로 광범위한 지역에서 상시 수집이 가능한 교통정보로 링크 평균통행속도를 선택하였다. 택시의 위치정보를 기반으로 가공된 서울시 교통정보센터(TOPIS)의 통행속도의 생성을 위한 가공단계에 따라 자료명을 정의하고, 속성을 검토하였다. 차량궤적이 생성되는 교통정보 빅데이터 시대에 있지만, 실제의 데이터 활용은 링크의 평균통행속도를 사용할 수 밖에 없는 현실을 진단했다. 서울시 TOPIS의 링크 평균통행속도를 기본으로 시간적-공간적 표현이 가능한 혼잡지표 모형(SCRIN)을 개발하였다. 링크 통행속도와 자유속도 개념의 기준속도를 이용하여 링크 추가여행시간을 산출한다. 이를 효과척도로 사용하여 링크의 과포화 상태를 판단하였다. 과포화 상태를 혼잡수준 F, FF, FFF로 정의한 후 혼잡수준을 혼잡 강도 계수로 표현하였다. 하루 중 얼마동안 과포화 상태를 경험하는지의 혼잡 시간 계수를 추가하여 SCRIN 지수 모형을 구축하였다. SCRIN 지수는 혼잡 평균 강도와 혼잡 지속 시간의 특성 계수로 구성하여 혼잡의 특성을 유추할 수 있도록 하였다. 지수 중 혼잡 평균 강도의 물리적인 의미는 1에 가까울수록 과포화 상태가 가장 극심한 상황인 혼잡도 FFF 상태이고 0에 가까울수록 과포화 상태에서 혼잡도가 가장 낮은 F 상태를 뜻한다. 혼잡 지속 시간의 물리적 의미는 하루 24시간을 기준으로 과포화 상태를 몇 시간 동안 겪는지를 뜻한다. 15분 단위의 링크 추가여행시간으로 개별 링크의 SCRIN 지수를 산출하는 과정을 설명하였다. 거시적인 혼잡 모니터링을 위하여 두 개 이상의 링크로 구성되는 교차로 단위, 축 단위, 네트워크 단위에서의 SCRIN 지수 산출 방법을 정립하였다. SCRIN 지수는 다양한 공간적 범위에 적용이 가능하고, 혼잡 강도와 혼잡 시간의 혼잡 특징 속성을 나타내도록 개발하였다. 이를 검증하기 위하여 2016년 서울시 링크 평균통행속도 이력자료를 기준으로 시간적-공간적 범위의 다양한 시나리오에 대한 혼잡 분석을 실시하였다. 혼잡 평균 강도와 혼잡 지속 시간과의 관계로 이루어진 SCRIN 지수 분포를 이용하여 구간별, 기간별 과포화 상태를 모니터링 하였다. SCRIN 지수의 활용성을 위하여 기술통계량 분석을 이용한 혼잡 상세 모니터링 방법과 혼잡 강도 분산을 추가하여 모형을 발전시켰다. SCRIN의 혼잡 지표는 도심 네트워크의 과포화 상태를 교통 운영 관점에서 거시적으로 모니터링 할 수 있다. 실제 교통정보 빅데이터 기반의 SCRIN으로 극심한 혼잡을 겪는 구간과 시간대 등을 예측할 수 있다. 향후에는 SCRIN을 이용하여 교통관리분야에서의 평가지표(Performance Index)로 활용할 수 있을 것으로 기대한다.",
		"KEYWORD": "과포화 상태,교통정보 빅데이터,추가여행시간,혼잡 강도,혼잡 시간,혼잡 지표"
	},
	{
		"ID": 221,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "공공 빅데이터 재식별성 위험도 평가 ",
		"AUTHOR": "김민준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김우주",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "20세기 말 미국의 미래학자인 엘빈토플러가 예견한 제3의 물결이 이제 현실 세계가 되었다. 제 3의 물결이 의미하는 정보화 사회는 더욱 고도화 되어 정보의 범람을 낳았고, 정보의 홍수를 통제하고자 하는 인간의 욕망은 빅데이터 환경 구축이라는 새로운 패러다임을 추구 하고 있다. “제 2의 원유”라고도 불리는 빅데이터 산업은 민간에서 이미 그 활용 가치를 인식하고 우리 생활 깊숙이 침투하였다. 구글, 아마존, 페이스북 같은 글로벌 인터넷 기업에서는 매일 수십억 건의 데이터를 분석하여 기업의 성장 전략에 활용할 뿐만 아니라, 월마트, 이마트, GM, 벤츠, 리츠 칼튼 등 일반 기업에서도 기업의 주요 의사결정과, 고객 Insight 기반의 판매전략 수립을 위해 빅데이터를 적극 활용하고 있다. 이러한 물결을 타고 미국을 선두로 공공분야에서도 빅데이터 환경 구축을 통해 정부의 주요 정책에 대한 의사 결정이나, 국민 맞춤형 국가 시스템 구축을 꾀하기 위해 관련 산업 육성에 힘쓰고 있다. 우리나라도 이에 뒤지지 않기 위해 2012년부터 안전행정부를 중심으로 빅데이터 기반 마련을 위한 법과 제도를 정비하고 많은 예산을 수립해 공공정보의 개방과 공유를 통한 맞춤형 서비스 구현에 힘쓰고 있다. 그러나 우리는 빅데이터의 활성 방안에만 치중한 나머지 빅데이터가 가져오는 개인정보 유출에 대한 심각성에 대해서는 아직 깊이 인지하지 못하고 있다. 특히 빅데이터 환경에서는 아무리 보안을 철저히 하더라도, 빅데이터 환경의 특성상 수 많은 데이터가 모임으로써 발생하는 데이터 테이블 상호간의 유사성을 기반으로 한 재식별성의 위험을 피할 수는 없다. 이번 논문에서는 빅데이터 환경에서 필연적으로 따라올 수 밖에 없는 재식별성에 대한 문제를 제기하고 재식별성의 위험도를 측정할 수 있는 모형을 개발하는 것을 목적으로 한다. 그리고 모형의 이론적 근거를 마련하기 위해 데이터셋 간의 유사성을 측정하는 방법론을 제시한 Rostin, A.가 2009년에 발표한 “A Machine Learning Approach to Foreign Key Discover” 이라는 논문을 참조하고 일부 검증해 보고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 222,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "동의대학교 대학원",
		"TITLE": "석유화학공정을 위한 빅데이터 처리 모델링에 관한 연구 ",
		"AUTHOR": "박주황",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다 참고문헌: p. 160-164",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "석유화학업종을 포함한 제조업은 기업의 효율적인 경영을 위하여 ERP(Enterprise Resource Planning), LIMS(Laboratory Information Management System), MES(Manufacturing Execution System), PIS(Plant Information System)와 같은 단위 시스템으로부터 발생되는 많은 종류의 데이터를 보유하고 있다. 석유화학공정의 품질관리를 위해서 다양한 전산시스템이 구축되는데, 품질 정보를 빠르게 판단하여 즉각적인 의사를 반영할 수 있는 시스템은 특히 중요하다고 할 수 있다. 이러한 시스템은 다양한 품질 분석 방법을 사용하여 공정의 이상 유무를 파악할 수 있고, 제품의 불량원인을 쉽게 추적할 수 있도록 지원하여야 하며, 원재료를 가공하기 위한 공정 분석이 최적화되어 인과관계를 도출하여 개선방향을 도출할 수 있어야 하고, 개선의 방향을 추적할 수 있어야 한다. 특히 MES와 같은 시스템의 경우에는 석유화학 공정을 모니터링하기 위해서 다양한 센서들이 실시간으로 데이터를 수집하여 빅데이터를 저장하고 있는 경우가 많다. 기업에서 보유하고 있는 분산된 개별 전산시스템이 보유하고 있는 빅데이터를 마이닝하면 공정개선을 기대할 수 있어서 기업의 경영 개선에 많은 도움을 줄 수 있다. 석유화학 주요 공정은 해당 설비의 운전을 실시간으로 모니터링하기 위해 다양한 센서들을 사용하며, 이 센서들로부터 수집된 데이터는 가공방법에 따라 제품의 품질과 수율을 향상시킬 수 있으며, 이러한 목적을 달성하기 위해서는 공정과 관련된 실시간 데이터 분석과 그에 따른 피드백이 중요하다. 국내 석유화학기업에서는 시추 등의 여러 분야 중에서 Production과 Operation 분야의 빅데이터가 주요 관심사이며, 과거 결과(Historical Result)를 활용하여 미래의 성능(Performance)을 예측하거나 보다 생산적인 공정으로 자산을 이동하여 사용할 수 있어서 원유 회수율(Oil recovery rates) 역시 개선될 수 있다. 또한 압력, 온도, 양, 진동 등의 변수가 라인 정지를 일으키는 요소를 찾아내어 정비 기간(maintenance intervals)을 효과적으로 운영하기 위한 라인 정지 시간 예측과 장비의 오류를 예측하고 정비를 효과적으로 하기 위한 시점을 파악하기 위한 효과적인 예방 정비 시간 운용(Optimizing field scheduling)과 같은 효과적인 예측기반의 정비 계획 수립도 가능해 진다. 실시간으로 운전 정보와 상태를 모니터링하기 위해서 공정의 센서들로부터 수집된 빅데이터는 정제하고 처리하는 방법에 따라 제품의 품질과 수율을 향상시킬 수 있는데, 이러한 목적을 달성하기 위해서는 정제되지 않고 보유하고 있는 빅데이터에 대한 분석이 필요하다. 본 논문에서는 원유의 가공 공정 중에 발생되는 빅데이터를 정제, 분석하여 해당 공정을 제어하기 위한 빅데이터 처리 시스템을 설계하고 구현하였다. 시스템의 구현에 있어서 석유화학공정을 제어하기 위하여 구축된 시스템을 사용하여 제품 생산 공정에서 취득되는 빅데이터를 분석하여 공정을 제어하기 위한 기존의 통계공정제어 방법을 개선한 다변량 통계공정제어 기법을 제안하고, 그 적용 기법을 보인다. 또한 조업 편차를 분석하기 위한 화면 구성을 위해 K-Means 군집 알고리즘을 사용하였고, K-Mean알고리즘의 군집화 과정에서 오류를 최소화 하기 위하여 클러스터링 반복 회수를 적절히 사용하게 하여 일반적인 K-Means알고리즘 보다 석유화학공정과 같은 대량 생산 시나리오에서 적합한 K-Means Clustering 환경을 적용하였다. 또한 회귀식을 도출하기 위해 Logistic 회귀분석 모델을 구현하고 최적화하였으며, 성능평가를 위하여 다른 솔루션과 비교 분석하였다. 본 논문에서 제안된 기법을 이용하면 통계를 이용한 석유화학업종의 공정분석에서 기존의 수동 검사 방식을 대체하여 검사 시간 및 비용을 단축할 수 있고, 문제가 발생한 공정에 대해 신속하게 대응할 수 있는 기반을 마련할 수 있다. 그리고 결함패턴 검사에 대한 표준화가 가능하여 검사자의 주관적인 지식과 경험에 의존하지 않고 시스템을 통하여 수리와 통계에 기초한 객관적인 검사기준을 수립할 수 있다. 또한 꾸준한 오류 검출과 정확도를 향상시켜서 석유화학공정을 실시간으로 제어하기 위한 빅데이터 처리 시스템을 구현할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 223,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "빅데이터 활용과 분석기술 고찰 ",
		"AUTHOR": "김지숙",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 陳瑞勳 참고문헌: 장 48-49",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "소셜미디어와 스마트폰의 등장으로 촉발된 빅데이터 이슈가 산업 전반에 확산되면서 빅데이터 분석기술은 기업의 경쟁력을 높이는 중요한 요소가 되고 있다. 빠른 속도로 데이터가 급증함에 따라 빅데이터의 분석은 기존의 분석 방법과 달리 정교한 분석기술과 통계적 의미 부여가 필요하게 되었다. 이는 기업들이 축적한 빅데이터를 어떻게 분석하고 활용할 것인가에 따라 향후 기업의 성패를 좌우하기 때문이다. 하지만 축적된 빅데이터 중에서 가치 있는 데이터는 소수에 불과하다. 따라서 모든 기업이 보유한 빅데이터를 누가 먼저 그 가치를 추출해 내느냐에 따라 기업의 성패를 가늠할 상황에 직면해 있는 지금 대용량 데이터를 분석하여 의미 있는 데이터로 발전하는 기술이 필요하다. 빅데이터는 미래의 새로운 자원이다. 인터넷의 폭발적인 성장과 클라우드 컴퓨팅의 도입으로 유발된 빅데이터는 다가올 스마트시대에 핵심 자원이기 때문이다. 또한 향상된 데이터 저장 ? 처리기술과 분석기술을 이용하여 이제까지 다루지 못했던 방대한 규모의 데이터를 활용한다면 빅데이터는 새로운 비즈니스 기회를 창출할 수 있을 것이다. 본 논문에서는 빅데이터의 속성 및 활용요소에 대해 알아보고 빅데이터 활용을 지원하는 빅데이터 분석기술과 활용사례를 소개하였다. 또한 오피니언 마이닝을 통해 소비자들이 소셜미디어에 표출한 반응을 기업이미지의 선행지표가 될 수 있음을 살펴보았다.",
		"KEYWORD": "데이터 마이닝,빅데이터,오피니언 마이닝"
	},
	{
		"ID": 224,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "빅데이터 환경을 고려한 수요예측 향상 기법 연구 ",
		"AUTHOR": "손다래",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 남호기",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 225,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "공간 빅데이터 마이닝을 통한 환경민원 패턴분석 =Pattern analysis of environment complaint using the spatial big data mining ",
		"AUTHOR": "박훈진",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 최병길",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "본 논문의 목적은 공간 빅데이터 마이닝 기법을 활용한 환경민원의 패턴분석 방법에 대하여 연구하는데 있다. 도시의 발전과 더불어 환경에 대한 시민들의 의식수준 향상과 관심 증가로 인해 민원이 급속도로 증가하고 있으나 환경문제의 원인은 매우 복합적인 특성을 내포하고 있어, 합리적인 발생원인 규명 및 해소방안에 대한 연구가 이루어지지 못하고 있다. 최근 다양한 분야에서 다량의 비정형 자료인 빅데이터가 자료간의 연관성을 규명하고 미래전략을 수립하는데 활용되고 있으며, 빅데이터에 공간적인 위치정보가 포함되어진 공간 빅데이터를 활용한 사회적 문제해결을 위한 노력들이 이루어지고 있다. 따라서 공간 빅데이터를 이용한 합리적이고 체계적인 환경민원의 발생원인 및 해소방안의 분석방법에 대한 연구가 필요하다. 본 논문에서는 환경민원의 합리적이고 체계적인 발생원인 및 해소방안을 제시하기 위해 다량의 정형 및 비정형의 환경민원 자료의 체계적인 수집방법과 공간 빅데이터 데이터베이스 구축 방법을 연구하였다. 또한 데이터 마이닝, 복잡계 네트워크분석, 공간 데이터 마이닝, 공간 데이터 클러스터링, 공간 의사결정 지원 시스템, 소셜 네트워크분석, 공간 R 등의 공간 빅데이터의 분석 방법을 정립하고, 공간 빅데이터의 복잡계 네트워크분석, 공간 상관성분석, 핫스팟분석 등의 합리적인 환경민원의 패턴분석 방법에 대하여 연구하였다. 그 결과 환경민원 자료의 경우 민원발생지역, 민원처리대상 등의 공간정보가 포함되어 있음을 알 수 있었으며, 보다 정확한 공간패턴분석을 위해서는 공간 빅데이터의 데이터베이스 구축 시 공간정보와의 연계가 필요함을 알 수 있었다. 또한 공간 빅데이터 마이닝 방법을 이용하여 환경민원 자료를 분석한 결과 환경 민원의 발생원인 도출을 위한 분야별 연관 단어를 도출할 수 있었다. 환경민원에 대한 복잡계 네트워크 분석결과 대상지역과 환경민원 분야의 상호 연관성을 분석할 수 있었으며, 핫스팟 분석을 통하여 환경민원 발생 밀집지역 및 민원발생원인과의 상관성을 도출할 수 있음을 알 수 있었다.",
		"KEYWORD": "공간 빅데이터,공간 패턴분석,네트워크분석,상관관계,환경민원"
	},
	{
		"ID": 226,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "빅데이터 분석 시스템을 이용한 TV의 시간대별 시청률과 광고효율성 분석 =(A)study on the difference between program ratings and advertising ratings using big data analysis system ",
		"AUTHOR": "이민섭",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "There have been various analyses of TV ratings as the number of TV channels and research panels for TV ratings increase. However, the research is time consuming because the viewer rating analysis based on the previous RDBMS has many limits due to the increased size of data. To solve these problems, we raised the efficiency of the research by using MapReduce, which is a programming model for disposal of massive data based on clusters, and InfiniData, which is a distributed database management system of TmaxData. The purpose of this paper is to analyze the characteristics of RDBMS, MapReduce, and InfiniData by data quality and query types. While the previous researches have shown that advertisement ratings were proportional to the viewer ratings of the program, this research verified that the advertisement and program viewer ratings are not always proportional, and that it depends on time slots. The viewer ratings of the advertisement dropped at 8 to 9 pm everyday except for Sundays, and the efficiency of the advertisement (ADRATIO) was the lowest at 8-9pm weekdays. The three systems used in research had higher performance in order of InfiniData, Hadoop, and RDBMS. However, we verified that those three systems had quite different performances based on queries.",
		"KEYWORD": "ADRATIO,Big Data,InfiniData,MapReduce,TV Ratings,광고효율성,맵리듀스,빅데이터,시청률,인피니데이터"
	},
	{
		"ID": 227,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "광운대학교 대학원",
		"TITLE": "하둡과 HBase에서의 교통카드 빅데이터 분석 =Analysis of traffic card big data with hadoop and HBase ",
		"AUTHOR": "화가엽",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김우생 참고문헌 수록",
		"STORE_LOCATION": "광운대학교 중앙도서관",
		"ABSTRACT": "A fundamental requirement of transportation-planning is having accurate data for travelling behaviors. Therefore, a lot of endeavors have been laid on the trip data generation by various models. However, we can get enormously valuable real information for passenger travelling behaviors in the Metropolitan area since the public transportation reforms the traffic information. More than 10,000,000 card records have been produced per day by the whole actual travelling passengers using Smart-Card. They provide real data for actual passenger travelling behaviors of the Metropolitan area, and can be transformed as the real traffic demand for each point of transportation networks by utilizing proper Big Data handling procedures such as Hadoop technique. Data mining has been explored various capabilities in recent due to the increasing use of information technologies. In particular, mining traversal patterns is desirable in applying to the Smart-Card data. Mining traversal patterns of passengers in Metro Traffic System can be considered of one type of mining sequential patterns in the KDD (Knowledge Discovery in Databases) society. The purpose of this study is to analyze the travel behaviors of transit users in the Metropolitan area. Regarding to this purpose we analyze the traversal patterns of transit users by utilizing smart-card user data by Hadoop related techniques. We develop a sequential data mining algorithm to analyze the traversal patterns of transit users. We determine the travelling sequences of passengers, and then explore the volumes of support on each point of transportation networks in the Metropolitan area.",
		"KEYWORD": null
	},
	{
		"ID": 228,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "수원대학교 대학원",
		"TITLE": "대상체의 신장 추정 및 효율적인 빅데이터 처리를 위한 센서 클라우드 게이트웨이 ",
		"AUTHOR": "심재석",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 임유진",
		"STORE_LOCATION": "수원대학교 도서관",
		"ABSTRACT": "The sensor cloud has become a core of the smart surveillance system. This paper proposes the sensor cloud gateway for big data processing and height-based prediction to extract the meaningful data, and examines feasibility of our height-based prediction through various test. Finally, we design and implement smart surveillance system based on Apache Hadoop Framework.",
		"KEYWORD": null
	},
	{
		"ID": 229,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "빅데이터 분석을 통한 모바일 광고 플랫폼의 광고효과 연구 :(The)effect of mobile advertising platform through big data analytics :광고특성, 매체특성, 상품특성을 중심으로 =focusing on advertising, media, and product characteristics ",
		"AUTHOR": "배성덕",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 박도형 참고문헌 수록",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "최근 스마트폰의 확산에 힘입어 유용한 광고 매체로서 모바일 미디어에 대한 관심이 증가되고 있다. 모바일 미디어는 소비자들에게 언제, 어디서나 원하는 정보를 제공할 수 있을 뿐만 아니라 실시간으로 상호작용이 가능하다는 점에서 기존 광고매체들과는 차별화된 장점을 가진 것으로 평가 받고 있다. 그 동안 모바일 광고 연구들은 모바일 광고에 대한 만족도, 수용도 등을 서베이를 토대로 분석한 연구와 모바일 광고 메시지 수신에 영향을 미치는 요인을 중점적으로 탐구한 연구, 실험연구를 통해서 모바일 광고가 브랜드 회상, 광고태도, 브랜드 태도 등에 미치는 영향을 검증하는 연구들이 많이 진행되었다. 그러나 실증데이터를 통한 연구는 거의 진행되지 않았다. 본 연구에서는 상용서비스 중인 모바일 광고플랫폼을 기반으로 광고효과를 알아보기 위하여 광고주, 광고플랫폼, 퍼블리셔 관점에서 상품특성, 광고특성, 매체특성을 정의하고 각 특성이 광고효과에 미치는 영향을 분석하였다. 각 특성에 대한 회귀분석 결과 모바일 광고의 광고특성인 광고규격과 쾌락적, 실용적으로 구별한 매체특성이 광고효과에 유의미한 결과를 나타냈으며, 서로간의 상호작용 효과도 확인하였다. 그리고 상품특성인 고관여/저관여와 광고소재에 연예인 포함여부에 따른 광고효과, 매체특성과 광고소재에 애니메이션 포함여부에 따른 광고효과의 변화와 상호작용을 일변량 분석을 통하여 확인하였다. 연구결과를 통하여 모바일 광고 업무 시 광고상품에 맞는 광고소재 제작 및 매체계획 등 광고효과에 최적화된 광고전략 수립에 기여할 것으로 보인다.",
		"KEYWORD": null
	},
	{
		"ID": 230,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "소셜 빅데이터 기반 VOC, TV시청률, 스포츠 경기력의 상호 연관성에 관한 연구 =Inter-relationship among the voice of customers, television ratings, and sports performance based on social big data ",
		"AUTHOR": "박성건",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 이수원 참고문헌: p. 102-108",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "스포츠빅이벤트에 대한 대중적 관심은 해당 이벤트의 특성, 사회·문화·정치적 환경, 이벤트 성과, 종목 특성, 경기력 수준에 따라 차이가 나타날 수 있다. 본 연구의 목적은 스포츠빅이벤트에 대한 VOC, TV시청률, 스포츠 경기력 간의 상호 연관성에 대해 알아보는 것이다. 본 연구의 분석 대상은 2016 리우올림픽 한국축구 경기와 관련 VOC이며, 본 연구를 수행하기 위해 수집된 데이터는 네이버 웹 뉴스 및 댓글, 축구 경기분석 데이터, 그리고 TV시청률이다. 경기별 분석 대상별 주요 이슈 및 대중들의 관심사를 알아보기 위해 연관단어 분석을 실시하고, NodeXL을 이용하여 시각화하였다. 스포츠 경기력이 스포츠빅이벤트 VOC에 어떤 영향을 주는지 알아보기 위해 스포츠빅이벤트 VOC를 종속변수, 스포츠 경기력을 독립변수로 설정하여 다중회귀분석을 실시하였다. 그리고 스포츠 경기력이 TV시청률에 미치는 영향과 VOC와 TV시청률의 상관관계를 분석하였으며, 통계적인 유의수준은 p<0.05로 설정하였다. 연구 결과, 1) 대중들에게 높은 관심을 받은 경기는 피지의 경기(VOC: 45,249건), 한국축구대표팀 관련 인물은 손흥민(인물 VOC: 1,854건), 해설위원은 이영표(인물 VOC: 265건), 캐스터는 조우종(인물 VOC: 240건)으로 나타났다. 2) 스포츠 경기력(한국축구대표팀의 득점 여부, 상대팀의 패스 횟수)은 스포츠빅이벤트 VOC에 통계적으로 유의미한 영향을 미치는 것으로 나타났다. 3) KBS2채널을 제외하고 스포츠 경기력(한국축구대표팀의 볼 점유율, 상대팀의 패스 횟수, 볼 점유율, 슈팅수)은 TV시청률(MBC, SBS)에 통계적으로 유의미한 영향을 미치는 것으로 나타났다. 4) 스포츠빅이벤트 VOC와 모든 지상파 방송사의 TV시청률은 통계적으로 유의미한 상관관계가 있는 것으로 나타났다. 5) KBS2채널을 제외하고 해설자 VOC와 MBC, SBS의 TV시청률은 통계적으로 유의미한 상관관계가 있는 것으로 나타났다. 6) 한국축구대표팀 VOC와 모든 지상파 방송사의 TV시청률은 통계적으로 유의미한 상관관계가 있는 것으로 나타났다. 본 연구에서는 웹 뉴스 및 댓글을 연구 대상으로 설정하고, 연관단어 중 긍/부정의 의미를 연구자의 주관적 해석한 것은 연구의 한계점이다. 하지만, 본 연구는 VOC, TV시청률, 스포츠 경기력의 상호 연관성의 통계적 검증을 위해 사회과학과 미디어, 스포츠과학, 컴퓨터과학이 결합된 융합 연구를 수행했다는 점에서 연구의 차별성 및 독창성을 갖는다. 본 연구에서 수행한 연구 방법은 농구, 야구, 배구와 같은 다른 스포츠 종목 및 스포츠빅이벤트 등에 활용 가능할 뿐만 아니라 TV시청률 유입효과 분석, 스포츠 인게이지먼트 연구, 스포츠 감성분석 등에 응용 가능하기 때문에, 본 연구 결과가 갖는 학술적인 가치는 매우 높다.",
		"KEYWORD": null
	},
	{
		"ID": 231,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "한국체육대학교 대학원",
		"TITLE": "소셜 빅데이터 기반 한국프로야구 실시간 선수평가모형 개발 :A real-time players evaluation model development base on social big data in Korea professional baseball : sentiment analysis using machine learning ",
		"AUTHOR": "윤효준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박재현",
		"STORE_LOCATION": "한국체육대학교 도서관",
		"ABSTRACT": "이 연구의 목적은 소셜 빅데이터 기반 한국프로야구 실시간 선수평가 모형을 개발하는 것이다. 연구의 목적을 달성하기 위해 세 가지 연구내용을 구성하였다. 첫 번째 연구내용은 ‘소셜 빅데이터 기반 한국프로야구 선수평가모형 개발’이다. 이를 위해 2016 정규시즌 문자중계 댓글을 연구대상으로 선정하였으며, 텍스트 전처리와 BOW방법을 적용하여 정형화하였다. 머신러닝기반의 감성분석은 벌점회귀모형인 능형회귀와 LASSO를 적용하였으며 교차타당화를 통해 최적 벌점모수와 최종모형을 선정하였다. 선수평가지표는 2016 정규시즌 댓글 자료를 머신러닝기반 감성분석과 교차타당화 과정을 거쳐 최종적으로 선정한 모형에 적용하여 표준화된 변환점수로 개발하였다. 두 번째 연구내용은 ‘경기기록에 준거로 한 소셜 빅데이터 기반 선수평가모형의 타당도’이다. 이를 위해 경기결과 특성을 고려하여 임의적으로 2016 정규시즌 다섯 경기를 연구대상으로 선정하였다. 선정된 다섯 경기의 댓글자료를 최종선수평가모형에 적용하여 선수평가지표를 산출하였으며 실제경기기록과 비교하였다. 세 번째 연구내용은 ‘경기내용에 준거로 한 소셜 빅데이터 기반 선수평가모형의 타당도’이다. 이를 위해 자료수집부터 결과산출까지 자동화 프로그램을 개발하여 실시간 선수평가를 실시하였다. 선수평가지표는 선수별 그리고 이닝별로 산출하여 경기 중 이벤트가 발생하였을 때 평가지표가 어떻게 변화하는지 확인하였다. 이 연구의 결론은 다음과 같다. 첫째, 전체선수를 대상으로 개발한 모형의 경우 투수에게는 부적합하다. 따라서 선수평가모형을 적용할 때 타자와 투수를 구분하여 평가모형에 적용하는 것이 적합하다. 둘째, 타자의 경우 결승타, 홈런 등을 기록한 선수의 평가지표가 높게 나타났으며, 투수의 경우 승리투수 혹은 홀드, 세이브를 기록한 선수의 평가지표가 높게 나타났다. 따라서 이 연구에서 개발한 선수평가모형은 경기기록에 준거하여 타당하다. 셋째, 타점이나 홈런과 같은 이벤트가 발생하였을 때 선수평가지표는 상승하였으며, 득점기회상황에서 아웃과 병살타 등의 이벤트가 발생했을 때 선수평가지표는 하락하였다. 안타의 경우 2사 주자가 없는 상황보다는 선두타자 혹은 주자가 있는 상황에서 이벤트가 발생하였을 때 평가지표가 상승하였다. 따라서 이 연구에서 개발한 선수평가모형은 경기내용에 준거하여 타당하다. 넷째, 실점으로 이어지는 기록된 실책과 기록되지 않은 실책성 수비를 수행하였을 때 선수평가지표는 하락하였으며, 중요한 상황에서 호수비를 수행하였을 때 선수평가지표는 상승하는 것으로 나타났다. 따라서 이 연구에서 개발한 선수평가모형은 수비능력을 고려함과 동시에 경기내용에 준거하여 타당하다. 결론적으로 이 연구는 소셜 빅데이터를 활용하여 경기기록과 경기내용을 반영하여 타당한 선수평가모형을 개발하였다. 나아가 이 연구는 한국프로야구 경기의 실시간 선수평가 정보를 제공할 수 있는 프로세스를 설계함으로서 프로야구 경기를 관람하는 대중들이 흥미를 높이기 위한 기초자료로 활용될 수 있을 것이다.",
		"KEYWORD": "감성분석,머신러닝,선수평가,소셜 빅데이터,한국프로야구"
	},
	{
		"ID": 232,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "프로파일링 시각화를 위한 빅데이터 포렌식 분석 모델 ",
		"AUTHOR": "이찬진",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 정목동 교수",
		"STORE_LOCATION": "부경대학교 도서관",
		"ABSTRACT": "Recently, the competition among global IT companies for the market occupancy of the Big-Data is fierce. Big-Data is all the things and people around the world connected to the Internet, and it is becoming more and more intelligent. In addition, for the purpose of providing users with a customized services to variety of context-awareness, Big-Data platform and related research have been active area. For example, today as digital devices are widespread, a variety of user`s private information is created and managed in digital form. In this thesis, we analyze third party instant messengers of Windows 8 Style UI and propose a digital forensic methodology. And, we are well aware of the Android-based map and navigation applications. What we want to show is GPS information analysis by using the R. And we propose a unstructured data analysis applying the KoNLP model using public data in the digital forensics modules. In addition, we propose a structured data analysis applying the hierarchical clustering model using and k-means algorithm GPS data in the digital forensics modules. The proposed model is expected to help support the Big-Data services and efficient criminal investigation process.",
		"KEYWORD": "디지털 포렌식"
	},
	{
		"ID": 233,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "홈 라이프로그 빅데이터 마이닝 프레임워크 설계 및 스마트 서모스타트 솔루션 구현 =Design of home life-log big data mining framework and implementation of smart thermostat solution ",
		"AUTHOR": "김찬빈",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 정선태 참고문헌: p. 43-44",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "스마트홈은 홈 네트워크 및 사물인터넷(IoT)으로 가정 내의 센서 및 기기에서 수집되는 모든 홈라이프로그 데이터 분석의 기반으로 스마트 홈서비스를 공급하는 인간 중심의 스마트 라이프 환경을 제공하는 주거 환경을 말한다. 현재, 수많은 가구에서 수집되는 다양하고 많은 홈라이프로그 데이터를 각 가정에서 원하는 스마트홈 서비스 제공을 위해 신속하게 효과적으로 분석하고 마이닝하고 추론하기 위해서는 홈라이프로그 빅데이터 프레임워크 개발이 필요하다. 본 논문에서는 각 가정에서 수집된 홈라이프로그 데이터를 처리하고, 데이터 마이닝하여 추출된 메타데이터를 기반으로 상황 인지를 위한 규칙 기반 추론 시스템을 이용하여 스마트홈의 에너지 절감 서비스인 스마트 서모스타트의 설계 및 구현을 제시하고, 이를 기반으로 홈라이프로그의 빅데이터 마이닝 프레임워크의 설계를 제시한다. 구현하여 제시된 스마트 서모스타트의 효과적인 동작은 시뮬레이션을 통해서 확인하였다.",
		"KEYWORD": "데이터마이닝,빅데이터,스마트홈"
	},
	{
		"ID": 234,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "동의대학교 대학원",
		"TITLE": "Google Analytics API를 이용한 빅데이터 구축 및 시각화 ",
		"AUTHOR": "안장근",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 장시웅 참고문헌: p. 31-33",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "최근 IoT 기술발달로 인한 스마트폰 및 대용량 미디어기기 사용증가로 인터넷 네트워크 사용량이 폭발적으로 증가되고 있고, 이러한 데이터 사용량 급증으로 대량의 데이터를 지칭하는 빅데이터 수집 및 분석에 많은 기업과 정부가 주목하고 있다. 빅데이터는 기존에 없던 새로운 데이터의 구축이 아니며, 그동안 축적된 다방면의 방대한 데이터의 집합이라 할 수 있다. 빅데 이터의 이용 및 분석에 대한 기업·정부·학계의 수요는 증가하고 있지만, 고난도의 빅데이터 분석을 위해서는 비정형 및 정형 빅테이터의 수집을 위한 IoT 센서 디바이스, 수집된 데이터를 저장할수 있는 서버장비, 빅데이터 수집분석을 위한 어플리케이션 소프트웨어 등 인프라 구축이 선결과제이어서, 이러한 인프라구축 비용 때문에 빅데이터 분석이 일선 산업분야에 바로 적용하는데 많은 장애요인이 되어 산업 및 학계에서 빅데이터 수집 및 분석진행에 애로사항으로 존재한다 이러한 어려움을 해소하기 위한 방안으로 새로운 인프라 구축 없이 Google Analytics API를 연동한 R 프로그래밍의 데이터 시각화를 활용한 데이터 분석 방안을 제시하고자 한다. 본 연구에서는 구글 애널리틱스 API를 연동하여 사용자 웹사이트의 사용자접속, 사이트운영, 이벤트 발생 등의 데이터를 R 프로그램을 활용하여 사이트 현황을 데이터 시각화로 분석하고 운영 중인 웹사이트에 적용 가능한 콘텐츠 개발 방안에 대해 연구한다.",
		"KEYWORD": null
	},
	{
		"ID": 235,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한밭대학교 정보통신전문대학원",
		"TITLE": "시맨틱 빅데이터 분석을 위한 온톨로지 지식베이스 자동 변환 프레임워크 =A framework of automatically transforming ontology knowledge base for semantic big data analysis ",
		"AUTHOR": "백귀현",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 안기홍",
		"STORE_LOCATION": "한밭대학교 도서관",
		"ABSTRACT": "본 논문은 관계형 데이터 모델 (RDM; Relational Data Model)을 기반으로 많은 반정형 데이터 집합 (스프레드시트, JSON, XML, CSV, TSV 등)들을 온톨로지 스키마 모델 기반의 최적화된 온톨로지 지식베이스로 동적으로 변환하기 위한 방법을 제안한다. 빅데이터 분석 능력의 고도화를 위해서 맥락이나 의미에 기반한 분류 및 분석 방법이 제공되어야 하며, 최근 IoT 환경에서도 고수준의 서비스를 위해서는 개체간의 의미적 상호작용의 방법이 요구되고 있다. 기존의 관계형 데이터베이스 (RDB; Relational Database)는 RDM의 특성상 도메인에 한정된 메타데이터와 스키마로 구성되어 운용되기 때문에 다양한 데이터들의 공유나 상호작용이 어렵고 이는 맥락적인 빅데이터 분석이나 IoT의 개체간 상호작용을 저해하는 요인이다. 따라서 기존 RDB를 맥락적이고 의미적인 표현이 가능한 온톨로지 지식베이스로 변환하려는 연구들이 진행되었고 그 대표적인 방법 중 하나가 W3C RDB2RDF Working Group에서 발행한 R2RML이다. 하지만 대부분 현장에 운용중인 RDB들은 서비스 도메인에 한정되어 설계?구축되거나 정규화가 구성되지 않아 데이터 또는 메타데이터의 중복성과 이질성 등이 발생되고, 데이터집합이 반정형 데이터들로 주어진 경우 그것을 온톨로지 지식베이스로 변환할 때 부가적인 작업을 요구한다. 그러므로, 앞에 기술한 고수준의 빅데이터 분석과 IoT 서비스를 위해서 편리하고 정확하게 RDB와 반정형 데이터들을 온톨로지 지식베이스로 변환하는 방법이 필요하다. 본 논문은 유동적으로 값을 가져올 수 있도록 셀값 삽입기 (CVI; Cell-Value Importer)와 가상변환테이블 생성자 (VTTG; Virtual Transformation Table Generator)를 제안하며, 직관적이면서 간결한 문장으로 속성 매핑 정보를 표현할 수 있도록 속성 표현자 (Property Expresser)을 정의하였다. 또한, 아파치 재단에서 운영하고 있는 프로젝트 중 제나 (Jena) 추론 엔진과 제나 TDB를 조사?분석하여 R-Box 기반의 경량형 추론 시스템을 제안하였고 최적화된 온톨로지 지식베이스 (OKB; Ontology Knowledge Base)를 동적으로 구성할 수 있는 방법을 연구하였다. 마지막으로 이에 대한 이론을 기반으로 프로토타입을 구현한 후, 실험을 통하여 변환된 RDF 트리플들이 정상적으로 온톨로지 지식베이스로 구성되는 것을 보였다.",
		"KEYWORD": "반정형 데이터,시맨틱 웹,온톨로지,온톨로지 변환 프레임워크,지식베이스,추론엔진"
	},
	{
		"ID": 236,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "제주대학교 산업대학원",
		"TITLE": "유소년 승마프로그램의 질적향상을 위한 빅데이터 적용 연구 ",
		"AUTHOR": "허석",
		"REGION": "제주도",
		"PROFESSOR": "지도교수:류연철 참고문헌 : p.",
		"STORE_LOCATION": "제주대학교 중앙도서관",
		"ABSTRACT": "우리나라의 승마산업은 지금으로부터 불과 6년 전이던 2011년 말산업육성법 제정과 함께 본격적인 대중화의 길로 접어들기 시작한다. 하지만 다른 스포츠와는 달리 단순 체험만을 목적으로 유입되는 일회성 인구비율이 매우 높은 비중을 차지하기 때문에 정확한 가입인구 파악이나 트렌드 분석 등에도 많은 어려움이 따른다. 귀족 스포츠로서의 이미지가 매우 강했던 승마가 일반 서민들도 쉽게 접할 수 있는 계기가 마련되면서 직장인 등 승마인구가 증가하였다. 모든 스포츠 분야에서 유소년이 가지는 의미는 곧 향후 세대교체라는 매우 중요한 의미가 내포되어 있으며 세대교체의 성공여부는 해당 스포츠와 관련된 모든 분야의 성장과 성패를 좌우한다. 우리나라 승마관련 분야의 성장 둔화 혹은 감소 추세는 아이러니하게도 급성장 시기인 2014년 전후부터 나타나고 있다. 최근 유소년 승마를 희망하는 잠재 고객의 수요가 증가하고 있는 시점에서 이러한 성장 둔화의 원인을 명확하게 파악하는 연구는 매우 중요하다. 본 논문은 승마분야의 다양한 트렌드를 객관적이면서도 과학적으로 분석하기 위하여 빅데이터 개념을 도입하고, 이러한 빅데이터의 융합분석을 통하여 먼저 우리나라 전체 및 제주도의 승마산업과 관련된 다양한 트렌드 변화를 지난 10년에 대하여 분석하였다. 현재까지의 승마는 그 행정과 예산이 대부분 경마에 치중된 경향이 강하고 현장에서도 당연히 구분될 필요가 있는 엘리트 승마와 레저승마가 혼재되어 사실상 지향하는 목표와 방향성이 매우 이질적인 2가지 승마문화가 혼동되어 운영되고 있는 실정이다. 제주도는 몽골과 유사하게 야외에서 일정 거리 이상 지속적으로 홀스 라이딩이 가능한 지형적 특성을 갖추고 있음에도 불구하고 현재의 우리나라 승마는 레저승마인구라는 고객의 니즈를 사실상 전혀 반영하지 못하고 있다. 이러한 문제점들을 파악하고 유소년의 특성을 고려한 프로그램 개발과 제주도 특유 환경을 활용한 레저승마 프로그램을 개발하여 현재까지 귀족스포츠로 인식 되었던 승마를 누구나 즐길수 있는 레저스포츠로서 새롭게 바뀔수 있도록 프로그램의 질적인 부분을 개선 해야 한다",
		"KEYWORD": null
	},
	{
		"ID": 237,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경상대학교 대학원",
		"TITLE": "빅데이터 서비스에서 IP Spoofing 공격에 대한 대응 모델 설계 =Correspondence model design for big data service to IP spoofing attack ",
		"AUTHOR": "유양",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 김상복",
		"STORE_LOCATION": "경상대학교 도서관",
		"ABSTRACT": "Environments of collecting data and receiving services are generally based on a cloud computing technology. These environments are easily exposed to illegal accesses, which use IP Spoofing compared to that of a single system. In this study traceback information is used to identify normal users in order to response to illegal accesses in a cloud computing environment. Then, services are provided after the identification process for the normal access frequency of users by comparing it with access failure information within a specific time. If there exists mismatches in traceback information or the access failure information exceeds a critical value, the access will be identified as an illegal access. Then, the access is immediately interrupted and is recorded as illegal access information. In addition, as an access that is attempted at an unexpected location, which is not registered in the existing user traceback information due to movements of normal users, is presented, the data will be provided after encrypting it for responding illegal accesses due to leaks of OTP. The model presented in this study is safe for authorized users against illegal accesses, which use IP Spoofing in a cloud computing based big data collecting environment, and improves service availabilities.",
		"KEYWORD": "IP Spoofing 공격,빅데이터,클라우드 컴퓨팅,트레이스 백"
	},
	{
		"ID": 238,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "영남대학교 대학원",
		"TITLE": "빅데이터 분석 방법을 활용한 건설현장 안전사고 요인분석 ",
		"AUTHOR": "김준수",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 박영목",
		"STORE_LOCATION": "영남대학교 도서관",
		"ABSTRACT": "본 논문은 건설현장에 발생하는 안전사고를 통계분석 프로그램 R을 활용하여 웹상의 원하는 정보를 수집 및 저장하는 웹 크롤링을 설계하였다. SBS뉴스에서 건설현장 안전사고와 관련된 기사 7,384건을 수집하여 전체 안전사고중 건설현장화재와 건설현장붕괴사고가 27%라는 결과를 얻었다. 또한, 계절별 안전사고 인터넷 기사를 주성분 분석한 결과, 동일한 사고유형일 경우라도 겨울과 여름에는 이상고온과 집중호우의 날씨요인이 크게 작용함을 알 수 있었다. 봄과 가을에는 안전수칙 위반 및 무리한 시공 진행이 안전사고에 큰 영향을 미치는 것을 확인하였다. 또한, 공통요인으로 중장비 충돌과 구조물 결함, 부실시공 등의 요인이 건설현장 안전사고에 크게 관련됨을 알았다.",
		"KEYWORD": "건설현장,빅데이터,안전사고"
	},
	{
		"ID": 239,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "홍익대학교 공연예술대학원",
		"TITLE": "공연관객의 선호 및 홍보 요인에 관한 빅데이터 분석 =Big data analysis on audience preference and public relation factors in performing arts ",
		"AUTHOR": "김정민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 고희경",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "Traditional marketing, so called, have been aimed for sales and product. In present, target marketing focused on individual customer satisfaction is important due to the rapid growth of the Internet industry. Recently, big data analysis has been used to meet the individual needs of customers. This research studies the necessity of big data utilized in performing arts through the survey. Also it exemplifies big data of the ‘Naver blog’ and ‘Twitter’ about the eight performances and observes their keywords of Interest and promotional factors of audiences. First, the survey was used to understand the importance of the audiences’ preferences in a certain production by collecting keywords and word-of-mouth facilitating big date analysis. Next, big data analysis paves the way for extracting keywords about the performances and investigating promotional factors which the volume of ‘Twitter’ and ‘Naver buzz’ have been affected. A successful marketing strategy begins with a understanding and predicting of the audience. Even now audiences are writing reviews sharing enormous information with each other on social media. Therefore, with the help of big data the performing arts will attract not only existing audience but also potential customers to the theater.",
		"KEYWORD": null
	},
	{
		"ID": 240,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "빅데이터 분석기반 전력관리 시스템 구현 =Implementation of big data analysis based power management system ",
		"AUTHOR": "은순기",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 최성곤 참고문헌 : p.78-80",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "In this paper, we propose a way to store and analyse the power data by using the BigData system. we use these system that alerts and control for a large number of users. In the recent, a power grid has developed for intelligent through a smart grid which is electricity and information and communication technology convergence to provide high quality service and maximize energy efficiency in the power industry. It is difficult to store/analysis the data because it is increased with collected data and smart grid supply. the efficient management based on BigData, it is increasing interest to create new value added from a large amount of data. The new service needs to drive a predicted value of existing data from the history data. Accordingly, this paper proposed system makes use of methods of data collecting, storing and processing, which also includes some BigData processing from some periods. We can confirm that the proposed system and algorithms have increased the power efficiency by about 14%.",
		"KEYWORD": "전력관리,클러스터링 분석"
	},
	{
		"ID": 241,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 국제관광대학원",
		"TITLE": "빅데이터 분석을 통한 중국 관광시장의 한국 관광 인식 분석 =A study on awareness of Korea tourism in Chinese tourism market through big data analysis ",
		"AUTHOR": "한혜림",
		"REGION": "서울",
		"PROFESSOR": "권두 국문요지, 권말 Abstract 수록 지도교수: 최승담 참고문헌: p. 70-73",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "중국 아웃바운드 시장의 성장에 따라 방한 중국 관광객의 수가 증가하고 있다. 이에 중국 관광객의 효과적인 유치를 위한 다양한 연구가 진행되고 있으며, 과거의 마케팅 사례, 중국의 관광정책, 여행상품 등의 자료를 기반으로 현황을 분석하여 마케팅 전략을 제시하는 선행 연구가 행해져왔다. 그러나 중국 관광객 대상의 빅데이터 분석을 기반으로 한 연구는 거의 발견되지 않고 있다. 본 연구의 목적은 온라인 빅데이터를 활용하여 중국인의 한국 관광에 대한 전반적인 인식 및 트렌드와 그 변화를 분석하는 데에 있다. 빅데이터 분석을 위해서 데이터 분석 프로그램인 텍스톰(Textom)을 사용하였으며, 중국 최대 포털 사이트 바이두(BAIDU)를 분석 대상으로 하였고 한국 관광에 대한 기본적인 인식을 분석하고자 키워드를 ‘한국 관광지’, ‘한국 여행’으로 선정하였다. 또한 ‘한국 여행’ 연관 검색어 상위 빈도와 <2015 외래관광객 실태조사>에서 제시된 ‘중국 관광객의 한국 방문 선택시 고려 요인’을 종합 반영하여 ‘한국 맛집’, ‘한국 명소’를 키워드로 선정하였다. ‘한국 관광지’ 키워드 분석 결과, 빈도가 높은 목적지는 한국, 서울, 제주도, 부산, 경상 순으로 나타났는데, 이는 <2015 외래관광객 실태조사>의 ‘중국 관광객의 한국 여행 방문 권역’자료와 차이를 보이고 있다. 사드 배치 이전의 ‘한국 여행’, ‘한국 맛집’, ‘한국 명소’ 키워드의 연관 검색어 분석 결과, 2015년 이후 ‘자유여행’, ‘게스트하우스’ 빈도가 증가하여 개별 관광과 맞춤 여행에 대한 선호가 증가하고 있음을 보여주고 있다. 한편, 사드 배치 이후의 ‘한국 여행’, ‘한국 맛집’, ‘한국 명소’ 키워드 분석 결과, 사드 이슈가 집중적으로 언론에 보도된 7, 10, 3월의 경우 새로운 연관 검색어로 ‘보도’, ‘사건’, ‘신문’, ‘소식’, ‘매체’ 등이 나타났다. 타 달의 경우는 사드가 이슈화된 이전의 결과와 연관 검색어가 유사하게 나타났다. 이는 사드 문제가 중국 시장에서 한국 관광에 대한 인식의 근원적 변화를 일으키고 있지 않음을 시사하고 있다. 본 연구는 빅데이터 분석을 활용해 연구영역을 확대하여 중국 관광객의 한국 관광 인식과 그 트렌드의 변화를 분석하였다는데 의의가 있다. 이러한 빅데이터를 활용한 중국 관광객의 관광인식 진단은 중국 관광객 유치 전략 수립에 기초자료가 될 수 있을 것으로 기대한다. 또한, 분석 결과를 토대로 중국 관광객 대상 관광 상품 및 컨텐츠 개발에 적용 가능한 실무적 시사점을 제공하고 있다.",
		"KEYWORD": "관광"
	},
	{
		"ID": 242,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "클라우드 기반의 실시간 비디오 빅데이터 처리에 대한 연구 =(A)study on real-time processing of cloud-based video big data ",
		"AUTHOR": "윤철상",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이용우",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "오늘날의 현대화된 도시에는 공공목적과 사적인 목적으로 많은 CCTV가 설치되어 있으며, 그 유용성이 증명됨에 따라, 그 수가 더욱 증가 되고 있다. 스마트시티는, 일반적으로, 다양한 서비스를 제공하기 위하여, 많은 CCTV를 설치하여 사용하고 있다. 이러한 많은 수의 CCTV에서 매순간 발생하는 비디오 빅데이터를 처리하기 위해서는, 막대한 컴퓨팅 파워가 필요하다. 더욱이, 긴급 상황에 효율적으로 대처하기 위하여는, 실시간 처리가 필요한 상황인데, 실시간 처리를 위해서는 더욱 더 막대한 컴퓨팅 파워가 필요하게 된다. 본 연구에서는 스마트시티를 위해서, 이와 같은, CCTV에서 생성되는 비디오 빅데이터를, 실시간으로 처리할 수 있게 하는, 실시간 빅 비디오 데이터 처리 시스템을 개발하였다. 이 시스템은 클라우드 컴퓨팅이 제공하는 확장성 있는 저장장치를 이용하여 비디오 빅데이터를 실시간으로 저장하면서, 실시간으로 요구 되는 처리도 할 수 있도록 개발되었다. 비디오 빅데이터의 실시간 처리를 위하여, 최신 개방형 소프트웨어인 Storm을 사용하고 있게 하였으며, Storm을 사용할 때에, 처리 노드를 스케일러불하게 추가할 수 있도록 개발하였다. 개발된 시스템을 PC 클러스터를 이용한 클라우드 컴퓨팅으로 성능평가를 하였으며, 본 논문에서 그 결과를 소개한다.",
		"KEYWORD": "맵리듀스(MapReduce),스마트 시티(Smart City),스톰(Storm),실시간처리(Real-time Processing),클라우드 컴퓨팅(Cloud Computing),하둡(Hadoop)"
	},
	{
		"ID": 243,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "홍익대학교 국제디자인전문대학원",
		"TITLE": "피트니스 센터 회원관리와 빅데이터 처방 서비스를 위한 애플리케이션 =Application for fitness center`s member management and big data prescribe service ",
		"AUTHOR": "하주형",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 김승인 참고문헌: 장 47-49",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "본 연구는 피트니스 센터에서 빅데이터를 사용해 각 회원들에게 맞는 운동 방법과 알맞은 식단을 처방해주는 헬스케어 애플리케이션을 개발하는데 목적이 있다. 현대인들은 고령화가 시대가 되어가면서 건강에 대한 관심도가 높아졌고, 그에 따라 헬스 케어와 건강식품에 대한 소비가 늘어났으며 자신의 몸을 관리하고 좋은 몸을 만들기 위해 시간과 자본을 투자해 퍼스널 트레이너에게 관리와 서비스를 받기 원한다. 이 애플리케이션은 퍼스널 트레이너가 회원들의 운동 처방을 올바르게 할 수 있도록 해주는 빅데이터 활용이 중요한데, 빅데이터는 정보화 시대가 오면서 인터넷 상에 존재하는 정보가 많아지고 매 순간 쏟아져 나오는 데이터의 양이 방대해졌기 때문에 등장했다. 이는 소셜 네트워크 서비스와 무료 영상 서비스 같은 언제나 어디서나 사용할 수 있는 서비스가 확산되었기 때문에 하루에 발생하는 콘텐츠 양이 기하급수 적으로 증가하였고 그 데이터를 처리해야 하는 상황이 발생했다. 빅데이터는 그 데이터를 처리하는 것이 요점이 아니라 그 데이터를 분석하는 것이 중요한 포인트이다. 빅데이터의 기초가 되는 원천 데이터(Raw Data) 분석을 통해서 제품, 서비스 등에 대한 새로운 정보를 발견, 사실 여부를 판단하는 것이 주 목적이다. 이를 통해 기업들은 실시간으로 기업에 대한 의견을 듣고 상황을 파악하고 판단할 수 있게 되었고, 앞으로 기업이 나아갈 방향에 대해서 결정하며, 생산성과 효율성을 높이는 효과적인 방법으로 사용된다. 이러한 기능을 잘 사용하기 위해 기존에 있는 모바일 헬스케어 관련 애플리케이션의 현황을 조사 분석하고 서비스 디자인 방법론을 통해 기존의 애플리케이션의 장점을 흡수하고 단점을 보완하며 애플리케이션의 주 기능인 ‘빅데이터 운동 처방’을 함께 추가시켰다. 퍼소나와 사용자 여정 지도를 통해 사용자가 피트니스 센터에서 겪게 되는 상황과 그에 따른 니즈를 도출하였고, 이를 통해 디자인 방향과 컨셉을 도출하고 적용하였으며 기능 구조도를 작성하였다. 마지막으로 빅데이터 운동 처방 애플리케이션, ‘Tri Balancy’의 GUI 디자인하여 최종 프로토타입으로 제안하였다. 본 연구에서 제안하는 ‘Tri Balancy’의 개발 방향은 다음과 같다. 첫째, 사용자들의 경험 개선을 위해서 운동 스케쥴 관리와 커뮤니케이션 기능, 운동 정보에 관한 서비스를 제공하였다. 둘째, 편리한 GUI 개발과 시각적인 부분을 통해 사용하는 회원과 트레이너 모두 사용하기 편리하도록 하였고 블루투스 기능을 통해 사용자의 신체 데이터를 인바디에서 간편하게 끌어 올 수 있도록 정보 누적을 위한 시스템 또한 편리하게 구성하였다. 마지막으로 회원들이 투자하는 만큼 또는 그 이상의 서비스 제공을 위해 트레이너가 밀접하게 회원들의 스케쥴, 식단, 운동 구성을 짤 수 있도록 하였으며 빅데이터 비교 분석을 통해 회원들의 의욕을 증진시켜 지속적으로 운동을 할 수 있도록 하였다. 본 연구를 통해 피트니스 업계 서비스(퍼스널 트레이닝)의 품질이 증진?개선되고 향후 5년, 10년 후에 데이터의 축적량이 늘어났을 때 사용자들로 하여금 더 정확하고 신뢰성 높은 처방을 내릴 수 있을 것으로 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 244,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "빅데이터 분석을 위한 슈퍼컴퓨터 환경에서 R의 병렬처리 =Parallel computing environment for R with on supercomputer systems ",
		"AUTHOR": "이상열",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 白埈杰 참고문헌: 장 36-40",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "We study parallel processing techniques for the R programming language of high performance computing technology. In this study, we used massively parallel computing system which has 25,408 cpu cores. We conducted a performance evaluation of a distributed memory system using MPI and of a the shared memory system using OpenMP. Our findings are summarized as follows. First, For some particular algorithms, parallel processing is about 150 times faster than serial processing in R. Second, the distributed memory system gets faster as the number of nodes increases while shared memory system is limited in the improvement of performance, due to the limit of the number of cpus in a single system.",
		"KEYWORD": "Hadoop,MPI,OpenMP,Parallel Programming,R,Supercomputer"
	},
	{
		"ID": 245,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 언론홍보대학원",
		"TITLE": "TV프로그램 제작에 정성적 빅데이터 활용 사례연구 :(A)case study on the practical usage of big data on producing TV programs :SBS `정글의 법칙`을 중심으로 =in the case of SBS program `The Law in the Jungle` ",
		"AUTHOR": "박수언",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 황용석",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "어떻게 하면 시청자 만족형 프로그램을 제작할 수 있을 것인가 하는 문제는 TV 프로그램 제작자들에게는 큰 고민이었다. 시청률 데이터 같은 패널 자료와 시청자 게시판 분석 같은 참여형 데이터 분석을 시도했지만 여전히 시청자 의견을 정확히 반영하기에는 어려움이 많았다. 최근들어 소셜 TV의 등장으로 이제는 시청자 의견을 프로그램 제작에 반영할 수 있을 것이라는 기대감이 생겨났다. 소셜미디어에 나타난 수많은 다중 참여형 자료들은 빅데이터화 하고 있으며 이런 데이터를 통해 시청자 의견을 파악할 수 있게 된 것이다. 그렇다고 하여도 빅데이터 분석이 바로 프로그램 제작에 연결되기는 쉽지 않다. 본 연구에서는 SBS <정글의 법칙>에 대한 시청자 의견을 분석하고 이를 프로그램 제작에 반영해 결과를 확인해 보려는 시도를 하였다. 연구 결과 시즌별, 회차별 버즈량과 여기에서 추출한 버즈량의 특성을 분석해 시청자들이 회차별로 프로그램에 대해 느끼는 감정의 주요한 흐름을 찾아낼 수 있었다. <시즌6>에서 불거진 조작논란 이후 프로그램의 진정성에 대한 의심으로 전체적으로 버즈량이 감소했으며, 프로그램 초반에 느꼈던 신선함이 점차 시청자들의 반응에서 사라지고 있는 것으로 분석됐다. 또 시즌별 키워드 네트워크의 구조와 주요 키워드에 대한 시계열적 분석, 그리고 원문 분석을 통해 프로그램 포맷상의 단순 반복이 주는 지루함을 찾아냈고, 김병만에 도전할 수 있는 강력한 남성 출연자의 필요성과 단순히 보조적인 역할이 아닌 정글 환경 속에서 제 몫을 다하는 도전적인 여성 출연자의 필요성을 알게 되었다. SBS는 이런 분석 결과를 토대로 새로운 프로그램을 구성해 실제 프로그램 제작에 활용하였다. 이런 협업이 가능하게 된 것은 SBS 조직상의 변화에 기인한 것으로 분석됐다. 이렇게 제작된 새로운 프로그램은 만족할 만한 성과가 있었던 것으로 나타났다. 이에따라 앞으로 빅데이터 분석이 TV프로그램 제작에 어느 정도 활용될 수 있다는 가능성을 확인하였다.",
		"KEYWORD": "SBS,TV프로그램,빅데이터,소셜TV,소셜미디어,정글의법칙"
	},
	{
		"ID": 246,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "창원대학교 대학원",
		"TITLE": "야구 경기에서 빅데이터 분석과 마르코프 연쇄를 이용한 득점 예측 모형 =Prediction of runs using big data analysis and Markov chain in baseball game ",
		"AUTHOR": "문형우",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 우용태",
		"STORE_LOCATION": "창원대학교 도서관",
		"ABSTRACT": "This paper presents a new model for predicting the number of runs scored in a baseball game on the basis of a big data analysis and a Markov chain. To this end, a database model was designed to implement a systematic management of the large amount of baseball game data. The MapReduce technique in the Hadoop framework, a method widely used in big data analyses, was used for effective storage and systematic management of the large amount of game score data consisting of unstructured text data. For efficient configuration of the proposed Markov chain-based score prediction model, the probabilities of advancing and hitting were redefined to accurately simulate the real-world baseball game situations. Using the probabilities of advancing and hitting, we obtained the score distributions and the number of batters for each inning, and constructed the Markov chain model to predict the scoring runs in each game. A -test was used for verifying the difference in the probabilities of advancing and hitting between right- and left-handed pitchers, and a score prediction model reflecting the characteristics of right- and left-handed pitchers was constructed. Real game data from korean professional baseball were used for experimentally proving the efficiency of the proposed prediction model. The experiment also included a score prediction model that takes into account the characteristics of left- or right-handed pitchers by reflecting their respective probabilities of advancing and hitting. The proposed model is expected to be useful in establishing strategies for deciding the batting order or enhancing game performance through efficient predictions of the scoring runs and the winning odds.",
		"KEYWORD": null
	},
	{
		"ID": 247,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "동국대학교 대학원",
		"TITLE": "빅데이터 속성이 재난대응 의사결정에 미치는 영향에 관한 연구 =Research on the impact of big data attributes to decision-making in disaster response ",
		"AUTHOR": "민금영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정덕훈",
		"STORE_LOCATION": "동국대학교 경주도서관,동국대학교 중앙도서관",
		"ABSTRACT": "The era of Big data, in which the data becomes social and economic asset, has come because of emerge of social media, spread of machine to machine (M2M). By acknowledging potential risk in advance, big data supports real-time response system and fast decision making. Situation awareness means a status of awareness before decision making. In risk management, manager’s recognition of situation is the most important. In addition, through analysis of big data, it becomes possible to recognize situation, solve problems, and predict future. Thus, with these advantages, big data works as a major engine to create value in the environment of uncertainty. Like this, characteristics of big data are expected to have a significant influence on decision making in prompt disaster response with quick situation awareness. Therefore, in this research, we (1) formed hypotheses about decision making between situation awareness and disaster response by defining major characteristics of big data (Volume, Variety, Velocity, Complexity) from bibliographies, (2) proved whether there is an moderating effect in cause-and-effect relationship by visualizing big data. To test the hypotheses, it was conducted a questionnaire survey of civil servants in charge of disaster-related government employees, and collected 320 data(without 12 undependable responses). The research findings are suggested the attributes of accumulation, expandability, flexibility, real-time, analytical, combination of Big Data have a strong effect on disaster manager’s situation awareness.",
		"KEYWORD": null
	},
	{
		"ID": 248,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "명지대학교 대학원",
		"TITLE": "내부자 위협 탐지를 위한 빅데이터 로그 분석 연구 =Study on big data log analysis for insider threat detection ",
		"AUTHOR": "강기태",
		"REGION": "서울",
		"PROFESSOR": "명지대학교 논문은 저작권에 의해 보호받습니다. Study on Big Data Log Analysis for Insider Threat Detection 지도교수:류연승 참고문헌 : p.35",
		"STORE_LOCATION": "명지대학교 도서관(서울),명지대학교 도서관(용인)",
		"ABSTRACT": "우리나라 기업 및 연구소가 연구 개발하는 과학기술은 세계적 수준에 이르고 있으며 기술 유출 및 침해 시 기업의 경쟁력 저하뿐만 아니라 국가 경제에도 심각한 영향을 주게 된다. 기술 침해 유형은 크게 사이버 해킹과 내부자 위협에 의한 침해로 볼 수 있다. 내부자 위협은 기업의 내부 자산에 합법적 접근 권한을 가진 임직원에 의한 기술 유출이기 때문에 기존의 보안솔루션으로는 대응하기가 어렵다. 또한 내부자 위협의 특성상 사고가 발생한 것을 알아차린 순간 이미 정보는 유출된 상태이기 때문에 사전 대응을 해야 한다. 그래서 본 논문에서는 기계학습을 이용하여 내부자가 평소와는 다르게 악의적으로 정보를 훔치려한다고 생각되는 행위를 탐지 할 수 있는 시스템을 개발하여 내부자 위협에 사전 대응할 수 있도록 그에 관한 연구를 진행하였다. 내부자 위협에 사전 대응하기 위해서는 기업의 임직원이 사용하는 업무용 정보 단말기에서 발생하는 이벤트 로그들을 실시간으로 수집 분석함으로서 보호 자산에 대한 비정상 접근 행위의 사전 탐지가 필요하다. 이를 위해 이벤트 로그를 기계학습 기법으로 분석하여 정상행위를 학습하고 이상행위를 실시간으로 탐지하는 기술이 필요하다. 본 논문에서는 내부자 위협 탐지 시스템에서 필요한 로그 중 윈도우 기반의 PC에서 발생하는 이벤트 로그 수집에 관한 연구와 수집한 로그를 기반으로 CERT데이터를 활용하여 평소와는 다른 행동을 하는 직원을 탐지하는 실험을 수행하였다. 이를 통해 윈도우 환경에서의 내부자 위협 탐지 연구에 기여할 수 있을 것으로 예상된다.",
		"KEYWORD": "CERT데이터,기계학습,내부자 위협,이벤트 로그 수집,이상행위 탐지"
	},
	{
		"ID": 249,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "동시출현단어분석을 통한 국내외 빅데이터 분야 연구동향 비교에 관한 연구 ",
		"AUTHOR": "김수연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정은경 참고문헌: p. 86-93",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "본 연구에서는 빅데이터를 주제로 한 국내외 문헌을 수집하여, 동시출현단어 분석을 실시하여 빅데이터의 지적구조를 파악하고 국내외 연구동향을 비교하였다. 분석 대상 데이터베이스로 국내는 한국학술지인용색인(KCI), 국외는 Web of Science core collection를 선정하였다. 관련 문헌을 검색하기 위해 KCI에서는 논문제목과 키워드, 초록 필드에서‘빅데이터’란 질의어로 검색하였으며, WoS에서는 Topic 검색에서‘big data’라는 키워드를 사용하여 검색을 진행하였다. 검색 대상 기간은 2009년 1월 1일부터 2015년 12월 31일까지로 설정하였다. 수집된 문헌에서 중복 문헌을 제외한 최종 분석대상 문헌은 국내 778건, 국외 2,135건이다. 분석 대상 키워드로 KCI에서는 저자 키워드, Web of Science에서는 저자 키워드와 키워드 플러스에 부여되어 있는 키워드를 선정하였으며, 저자키워드가 부여되어 있지 않은 경우 제목과 초록에서 키워드를 추출하였다. 추출된 키워드들의 정규화 작업 후 국내는 문헌 빈도수 4회 이상의 키워드 83개, 국외는 문헌빈도 15회 이상의 키워드 86개를 최종 분석 키워드로 선정하였다. 선정된 키워드들의 동시출현단어 행렬과 코사인 계수 행렬, 피어슨 상관계수 행렬을 산출하였다. 이후 피어슨 상관계수 행렬을 대상으로 네트워크 분석과 군집분석, 다차원척도분석을 실시하였다. 네트워크 분석에서 패스파인더 네트워크와 병렬 최근접 이웃 클러스터링 알고리즘을 통해 형성된 군집은 국내 22군집, 국외 20군집이다. 중심성 분석을 통해 전역중심성, 지역중심성, 매개중심성이 높은 키워드를 확인하였으며, 이를 통해 국내외 빅데이터 분야의 핵심 주제어, 군집 내에서 영향력이 높은 주제어, 군집의 매개가 되는 주제어를 확인하였다. 군집분석을 통해 국내는 5군집, 국외는 6군집으로 주제 영역을 분류하였으며, 다차원분석을 적용하여 MDS 지도에 키워드 사이의 관계를 시각화하였다. 국내외 빅데이터의 연구 동향을 비교한 결과는 다음과 같다. 첫째, WoS 주제 분야 분류를 통해 빅데이터와 관련된 연구는 공학, 컴퓨터학, 과학 및 기술, 경영 및 경제, 수학, 정보통신 분야에서 활발하게 이루어지는 것을 확인하였다. 둘째, 국내외 빅데이터 분야에서 공통으로 나타난 핵심 주제어는 빅데이터분석, 데이터마이닝, 소셜네트워크, 맵리듀스인 것으로 나타났다. 국내 빅데이터 분야에서 핵심 주제어로 나타난 키워드는 정보보호, 사생활, 개인정보보호법이었으며, 국외에서 나타난 핵심 주제어는 Prediction, Cloud Computing, Internet이었다. 셋째, 군집분석을 통해 공통적으로 나타난 하위 주제 영역은‘빅데이터 저장 및 처리 기술’과‘데이터마이닝’으로 나타났다. 넷째, 군집분석을 통해 국내와 국외에서 특정 주제 분야가 출현하는 현상을 확인할 수 있었다. 국내는 정보보호 군집, 국외는 의료와 생물정보학 군집이 출현하는 것을 확인하였다. 본 연구의 결과는 국내외 빅데이터 분야의 최근 연구 동향을 파악할 수 있도록 해주며, 향후 연구 방향성을 모색하고자 하는 연구자들에게 유용한 정보를 제공해 줄 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 250,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "동국대학교 대학원",
		"TITLE": "연관성 규칙 기법을 이용한 빅데이터 분석 ",
		"AUTHOR": "강인경",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권법에 의해 보호받습니다. 지도교수:이영섭",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "Nowadays, according to increase rapidly in quantity of various information, it becomes more important to find hidden information in the large database. Under these circumstances, the type of data has been developed in the form of Bigdata. Hence the Big data and the techniques of handling the Bigdata are on the rise. Typically treatment for Bigdata is applied to the improvement of statistics, computer science, among others machine learning and data mining fields to meet the massive data processing. Data mining is getting high interest as a way to search meaningful knowledge. Data mining is the means to find hidden data patterns. Association rule mining is the interesting fields that have been numerous studied. In this thesis, we apply the association rules method to real large database. Meaningful interpretation of the association rules may be utilized for further intensified studies such as recommendation system.",
		"KEYWORD": "빅데이터,연관성 규칙"
	},
	{
		"ID": 251,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "빅데이터 분산처리시스템의 품질평가모델 =(A)quality evaluation model for distributed processing systems of big data ",
		"AUTHOR": "최승준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최재현",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "IT기술이 발전함에 따라, 우리가 접하는 데이터의 양은 기하급수적으로 늘어나고 있다. 이처럼 방대한 데이터들을 분석하고 관리하기 위한 기술로 등장한 것이 빅데이터 분산처리시스템이다. 기존의 분산처리시스템에 대한 품질평가는 정형 데이터 중심의 환경을 바탕으로 이루어져 왔기 때문에 이를 비정형 데이터 분석이 핵심인 빅데이터 분산처리시스템에 그대로 적용시킬 경우, 정확한 품질평가가 이루어질 수 없다. 따라서 빅데이터 분석 환경을 고려한 분산처리시스템의 품질평가모델에 대한 연구가 필요하다. 본 논문에서는 소프트웨어 품질에 관한 국제 표준인 ISO/IEC9126에 근거하여 빅데이터 분산처리시스템의 품질평가에서 요구되는 평가요소를 도출하는 동시에, 관련연구를 토대로 새로이 요구되는 평가요소를 종합적으로 고려함으로써 보다 신뢰성 있는 품질평가모델을 제안한다. 또한, 각 품질요소의 측정을 위한 메트릭을 정의하고 실제 품질평가모델 적용 방안에 대한 예시를 제시한다. 본 논문에서 제안하는 모델을 적용한 결과, 기존에는 불가능하였던 빅데이터 환경의 분산처리시스템에 대한 품질요소를 평가할 수 있었다. 이러한 평가결과는 빅데이터 분산처리시스템의 구축 시 또는, 운용 중인 빅데이터 분산처리시스템에 대한 품질개선 시도 시에 활용될 수 있을 것이다. 향후에는 실제 기업 또는 기관에서의 모델 적용을 통한 품질요소와 메트릭에 대한 공식화가 필요할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 252,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울과학기술대학교 대학원",
		"TITLE": "빅데이터 처리를 위한 하드웨어 기반 고속압축가속기 연구 =Hardware based compression accelerator for big data management ",
		"AUTHOR": "김상돈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이승은",
		"STORE_LOCATION": "서울과학기술대학교 도서관",
		"ABSTRACT": "아파치 하둡 (Apache Hadoop)은 빅데이터를 처리할 수 있는 자바 소프트웨어 프레임워크이다. 하둡은 대량의 데이터를 분산처리하기 위해 여러개의 서버를 하나의 시스템으로 구성한다. 따라서 빅데이터를 처리할 때 분산처리를 수행함으로써 높은 처리성능을 구현할 수 있으며 하둡의 최적화된 구성으로 빅데이터 처리시스템의 안정성을 극대화 시킬 수 있다. 하둡 시스템에서 처리된 빅데이터를 효과적으로 저장/분석/활용하기 위하여 고성능의 스토리지 시스템이 요구되며, 이는 물리적인 대역폭의 한계를 가지는 스토리지를 효율적으로 구성함으로써 구현될 수 있다. 하둡 분산파일 시스템(Haddop Distributed File System)은 빅데이터를 분석 및 관리하는 Name Node와 실제 데이터의 저장을 수행하는 Data Node로 구성된다. 빅데이터로 인한 네트워크 트래픽을 감소시키기 위하여 빅데이터는 압축되어 네트워크로 전송되며 Data Node의 스토리지에 저장된다. 그러나 데이터를 분석하기 위한 MapReduce 동작을 수행할 때 압축된 데이터는 압축해제된 후 분석되고, 다시 압축하는 과정을 수행하게 된다. 데이터 입출력 기능을 수행하기 위한 처리장치로써 저전력 Atom 프로세서는 충분한 성능을 가지고 있으나 데이터 압축 및 압축해제 과정을 수행할 때 CPU 사용량이 급증한다. 이는 별도의 압축가속기를 구성함으로써 CPU 사용량을 완화할 수 있으며 동작속도를 빠르게 하는데 도움이 된다. 따라서 하둡 시스템을 구성할 때 저전력 기반의 Atom 서버를 Data Node에 적용하여 하둡 시스템의 구축비용 및 소비전력을 감소하는 효과를 얻을 수 있다. 또한 압축된 데이터를 사용함으로써 하드디스크의 추가적인 저장공간을 확보하고 Disk I/O의 Bandwidth 제한에서 발생하는 데이터 입출력의 지연시간을 완화할 수 있다. 데이터 무손실 압축은 Gzip, Bzip2, LZ4 등 다양한 알고리즘이 사용되고 있으며 각기 다른 압축효율과 성능을 가진다. 빅데이터를 처리하는 작업은 단위시간동안 최대한 많은 작업을 수행하기 위해 압축속도에 중점을 둘 수 있으며 압축알고리즘은 데이터의 크기와 처리성능에 따라 선택적으로 사용하여야 한다. Gzip과 Bzip2는 리눅스 시스템에서 널리 쓰이는 압축방식으로써 데이터 압축효율이 좋은 반면 알고리즘이 복잡하여 데이터 압축 시 많은 처리시간과 CPU 리소스를 필요로 한다. LZ4 압축알고리즘은 Dictionary 압축을 기본으로 하여 무손실 압축을 수행한다. 이는 비교적 압축효율이 낮은 반면 빠른 데이터 처리속도를 특징으로 하며 빅데이터를 고속으로 처리하는데 사용될 수 있다. 따라서 하둡 분산파일 시스템에서 고속으로 데이터를 압축하기 위한 알고리즘으로 사용될 수 있으며 데이터 처리의 실시간성을 최대한 보장한다. 하둡 시스템에서 압축 동작을 수행할 때 많은 데이터를 처리하기 위하여 고속의 통신채널이 필요하다. PCI Express 인터페이스는 고속 직렬인터페이스로써 1 Lane당 5Gbps의 데이터를 송수신할 수 있으며 최대 32Lane까지 확장함으로써 160Gbps의 대역폭을 지원한다. 따라서 빅데이터를 압축요청하고 결과를 수신하는데 요구되는 충분한 대역폭을 지원한다. 본 논문에서는 고속 통신채널인 PCI Express 인터페이스를 이용한 데이터 고속압축 가속기의 구현에 대하여 기술한다. 먼저 하둡 분산파일시스템의 구조를 분석하고 하드웨어의 구조를 설명한다. 그리고 하드웨어 기반 고속압축가속기에서 사용되어야 하는 데이터 압축알고리즘을 벤치마크를 통하여 분석하며 고속압축 가속기의 구조에 대하여 설명한다. PCI Express 통신채널은 데이터를 빠르게 전송하기 위한 인터페이스로 사용되었으며 PCI Express Endpoint를 구현하는 과정에 대하여 설명한다. CPU로부터 압축요청을 받은 데이터는 압축처리장치인 Compression Engine까지 전달되기 위하여 내부 메모리 버퍼를 사용한다. 메모리 버퍼는 FPGA의 내부 메모리를 이용하여 구현되며 메모리의 구조에 따라 동작속도 및 메모리 사용률이 상이하므로 FPGA의 구조를 고려한 적절한 형태의 메모리 구조가 설계되어야 한다. 마지막으로 구현된 고속압축가속기를 검증하기 위한 실험환경을 구축하고 성능측정을 수행함으로써 구현된 고속압축가속기의 동작 및 성능을 측정한다. 본 연구를 통해 빅데이터를 처리하는 하둡 분산파일 시스템에서 CPU의 압축 및 압축해제 동작을 보조할 수 있는 고속압축 가속기를 설계할 수 있다. 따라서 기존의 고성능 CPU를 사용하는 서버시스템을 저전력 CPU와 압축가속기로 대체함으로써 시스템의 구현비용 및 소비전력을 낮추는 효과를 가져올 수 있다. 향후 지속적인 연구를 통하여 데이터 압축알고리즘의 병렬처리를 수행할 것이며 범용 CPU에서 데이터 압축을 수행하는 과정보다 빠른 데이터 처리속도를 구현함으로써 고성능 CPU를 대체할 수 있는 저전력 서버 시스템을 구현할 수 있다.",
		"KEYWORD": "Compression Accelerator,FPGA,Hadoop,LZ4"
	},
	{
		"ID": 253,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "동국대학교 대학원",
		"TITLE": "빅데이터 처리 및 분석을 위한 R의 활용 ",
		"AUTHOR": "고영준",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김진석",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "Hadoop system was developed based on GFS and mapreduce technologies of Goolgle Inc., which was considered as the standard platform for processing the big data recently. A lot of modern systems with big data was designed to be based on Hadoop, which also have been adopted the R software as the analytic tool, because the R is flexible to other softwares and has many libraries for complex analysis. In this thesis, we first introduced the R package, RHIPE for analysing the big data under the Hadoop system. We implemented the mapreduce program using R for multiple regression especially. In addition, we compared the computing speeds of our program with the other packages (ff and bigmemory) for processing the large data. The simulation results showed that our program was more fast than ff and bigmemory as the size of data are increased.",
		"KEYWORD": "빅데이터"
	},
	{
		"ID": 254,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "고려대학교 컴퓨터정보통신대학원",
		"TITLE": "빅데이터 기술과 활용 방안 ",
		"AUTHOR": "이윤호",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 255,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한남대학교 대학원",
		"TITLE": "빅데이터 처리를 위한 R 병렬 패키지에 관한 연구 =A study on R parallel package for big data processing ",
		"AUTHOR": "박준형",
		"REGION": "대전",
		"PROFESSOR": "한남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 이상구 참고문헌: p. 26-29",
		"STORE_LOCATION": "한남대학교 도서관",
		"ABSTRACT": "본 논문에서는 빅데이터의 개념과 현황, 처리 및 분석기법, 시각화 툴과 그 툴의 패키지 등을 소개하며, 다차원의 대용량 데이터를 R 프로그래밍으로 분석하려 할 때 생기는 문제점과 문제점의 해결방법 및 과정을 제시 하였다. 자료 수집 과정에서 다차원 데이터를 R 프로그래밍에서 수집 및 분석이 가능하도록 구조를 변경하며, 패키지들의 도움을 받고, 그 문제에 대하여 다양한 해결방안을 제시한다. 빅데이터 시대인 요즘 데이터를 분석하고 수집하려 할 때 상당히 빈번하게 접하는 문제들이며, 이러한 문제들에 자주 노출되는 분석가 및 처리가 들에게 도움이 될 수 있을 것이다. 향후 처리 속도의 향상을 위해 다양한 병렬화 처리 기법들에 대해 지속적인 연구가 필요하다.",
		"KEYWORD": null
	},
	{
		"ID": 256,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "RFID와 바코드를 이용한 Closed-loop medication administration 시스템의 빅데이터 분석을 통한 투약 오류에 영향을 미치는 요인 분석 ",
		"AUTHOR": "황연수",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 박래웅",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "본 연구에서는 투약과정에서 발생할 수 있는 medication administration error (MAE) alert의 발생률과 오류 발생의 원인이 될 수 있는 위험요인을 분석하였다. MAE의 발생률과 발생요인을 분석한 여러 연구들이 있었지만, 대부분의 이전 연구들은 연구자가 투약과정을 직접 관찰하여 기록하는 직접적 관찰 방법에 의해 수행되었다. 이런 연구들은 적은 수의 표본에 따른 객관성 부족과 직접적 관찰 방법에서 발생할 수 있는 관찰자 효과로 인한 결과의 편향과 같은 한계를 가지고 있었다. 본 연구에서는 국내 단일 상급종합병원에서 발생한 1년 동안의 투약 데이터를 closed-loop medication administration 시스템을 통해 수집하였다. Closed-loop medication administration 시스템은 투약의 전 과정을 모니터링 하여 발생 가능한 오류를 사전에 확인할 수 있는 시스템으로, 이를 통해 어떤 인위적인 조작이나 편향 없이 자동으로 투약 데이터를 수집하여 이전 연구들이 갖는 한계를 극복하고자 하였다. 2012년의 연구기간 1년 동안 30,232명 환자의 38,468건 입원, 882.6 patient-years로부터 2,874,539건의 투약 데이터를 가지고 단변량분석과 로지스틱 회귀분석을 수행하였다. 전체 투약 데이터에 대한 빅데이터 분석 결과, 투약시간(administration time), 처방종류(order type), 투여경로(medication route), 간호사의 대상병원 근무기간(employment duration), 간호사 근무스케줄(working schedule), 단위시간당 투약건수(the number of medication doses administered)가 MAE alert를 유발하는 위험요인이 될 수 있다는 것을 확인하였다. 전체 투약건수에 대한 MAE alert의 발생률은 1.22%였으며, 연구기간 1년 동안 대상병원에서는 closed-loop medication administration 시스템을 통해 35,082건의 MAE 발생과 이에 유발되는 adverse drug event (ADE)를 예방할 수 있었다. 투약의 정확성을 향상시키고 MAE 또는 MAE alert 발생을 방지하기 위해서는 투약에 대한 프로세스를 표준화, 정형화하여 가능한 한 계획된 상황에서 투약을 수행해야 하며, 무엇보다 간호사에게 투약에 집중할 수 있는 임상환경과 충분한 시간을 제공하여야 한다.",
		"KEYWORD": "Closed-loop medication administration,Medication Error,Patient Safety,Point-of-Care system,Radio-Frequency Identification (RFID)"
	},
	{
		"ID": 257,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "광운대학교 정보콘텐츠대학원",
		"TITLE": "빅데이터 처리를 위한 맵리듀스 기반 DBaaS 클라우드 시스템 설계 =(A)design of DBaaS Cloud system based on MapReduce for bigdata processing ",
		"AUTHOR": "정연우",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 정계동 참고문헌 수록",
		"STORE_LOCATION": "광운대학교 중앙도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 258,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 기술경영전문대학원",
		"TITLE": "빅데이터 분석을 통한 기업 마케팅 활동 효과에 대한 연구 =(A)study of effectiveness for company marketing activity using bigdata analysis ",
		"AUTHOR": "김광희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김영준 참고문헌: 장 50-51",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "정보통신 발달에 따른 시대적 배경에 따라 본 논문에서는 빅데이터 출현 배경과 더불어 정의, 구성요소, 특징 요구 사항등을 정리하고 빅데이터를 활용하기 위한 3대 요소에 대해 설명한다. 그리고 효율적인 빅데이터 처리 및 분석의 성공적은 사례를 분석하여 효과에 대한 검증할 예정이며 나아가 실제 SNS 상의 빅데이터 분석을 통해 분석결과와 기업 마케팅 활동에 대한 효과를 비교 검증할 것이다.",
		"KEYWORD": "SNS 분석,마케팅 효과 분석,빅데이터 분석,텍스트 마이닝"
	},
	{
		"ID": 259,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "빅데이터 기반의 6시그마 적용 방안에 관한 연구 :A study on the methodology for application of 6sigma based on big data : on the case of process optimization for solar cell ",
		"AUTHOR": "고동기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 배석주",
		"STORE_LOCATION": "한양대학교 중앙도서관",
		"ABSTRACT": "오늘날 대부분의 장치산업은 많은 복잡한 공정 파라미터와 데이터들로 구성되어 있으며, 이로 인해 원인을 파악하는 데 많은 시간, 비용 및 자원을 요구한다. 이러한 환경을 극복하고 경쟁에서 앞서나가려면 생산 경쟁력이 요구되는데 이제까지는 경쟁력 향상 방안의 하나로써 일부 기업들을 중심으로 6시그마 방법론을 주로 사용하였다. 그러나 위와 같이 Volume, Variety, Velocity특성을 내포하는 빅데이터를 사용해야 하는 과제에서는 분석에 있어 한계에 직면하게 된다. 근래 디스플레이, 반도체 등 장치산업에서는 빅데이터 분석을 활용하여 공정최적화에 상당한 효과를 거두고 있지만, 빅데이터 활용을 통한 이점 뿐 아니라 다른 부작용, 예를 들면 상관관계를 인과관계로 해석하거나 편향된 결과로 오판할 수도 있으며, 전체적 관점의 문제 해결이 아닌 국부적 요소 최적화로 재현성 확보가 어려울 뿐 만 아니라 예측 적확도가 오히려 떨어질 수도 있다. 이를 위해 6시그마 방법론의 전체 관점 문제 해결 프로세스, 빅데이터 분석의 데이터 형태와 관계없이 전수데이터를 중심으로 한 분석 및 최적화, 즉 6시그마 방법론과 빅데이터 분석 방법론의 장점을 접목한 새로운 적용 방안을 연구하고자 하며, 솔라셀 공정을 사례로 하여 효과를 검증하였다. 빅데이터 분석과6시그마의 대표적인 프로세스인 Define ? Measure ? Analyze ? Improve ? Control (DMAIC)를 접목한 새로운 문제해결 방법론 적용으로 보다 체계적이고 논리적인 변수선택 방법론을 제시하였고, 솔라셀 공정의 결과 수 천개의 공정 파라미터를 수 십개로 축소한 가운데 예측 적확도는 90%를 달성하였고 중요 특성인 효율 또한 Max 0.23%까지 개선 하였다.",
		"KEYWORD": null
	},
	{
		"ID": 260,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "빅데이터 생명주기를 고려한 개인정보보호 수준 평가항목 개발 =Development of personal information protection level evaluation items considering big data life cycle ",
		"AUTHOR": "김민선",
		"REGION": "서울",
		"PROFESSOR": "중앙대학교 논문은 저작권에 의해 보호받습니다 지도교수: 신동천 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "인터넷, 소셜 미디어와 같은 서비스 확산과 개인 스마트 기기의 발전에 따라 데이터양이 기하급수적으로 증가하고 있다. 기존의 데이터 분석 및 지원 기술로는 감당하기 어려울 정도 이며, 빅데이터의 활용은 가까운 미래를 예측하거나 조직의 가치를 현실화함으로써 미래의 경쟁력으로 인식하게 되었다. 하지만, 빅데이터 환경에서 프라이버시 침해가 제기됨에 따라 이에 대응하기 위한 방안이 요구되며, 현존하는 개인정보 보호 평가항목과 달리 빅데이터의 환경에서 적용할 수 있는 평가항목이 요구된다. 왜냐하면 1) 빅데이터 환경에서는 대용량 데이터 확보를 위하여 고도화된 정보 수집 기술로 주체자의 동의 없이 정보를 가공하여 무분별하게 활용, 2) 접속채널의 다양화로 인하여 무분별한 접근 및 열람, 3) 산발적으로 관리되는 분산시스템의 특성에 따라 개인정보의 완전한 폐기가 어렵다는 문제점이 있기 때문이다. 따라서 본 논문은 다음과 같은 단계로 구성하여 빅데이터 생명주기를 기반으로 한 개인정보 보호 수준 평가항목을 제안하였다. 세부적인 절차는 1) 빅데이터 처리 프로세스 별 관련 기술을 파악, 2) 빅데이터 관련 개인정보 침해 사례를 통하여 빅데이터 환경에서 개인정보보호의 필요성 제기, 3) 현존하는 개인정보 보호 체계에서 향후 필요한 개인정보 보호 기술에 대한 방향성 제시하였다. 이를 통하여 빅데이터 생명주기를 기반으로 한 평가항목의 타당성을 검토하였다. 비록, 평가항목을 실무에 적용하지 않아 본 논문에서 제안한 평가항목의 실제 효과를 규명하지 못하였지만, 기존의 개인정보보호 평가항목과 다른 빅데이터 환경에서 요구하는 기술에 대하여 이론적인 고찰을 수행하였음에 의의가 있다. 실제로 ‘빅데이터 활용’과 ‘개인정보 보호’의 영역의 균형을 맞추기란 어려운 일이다. 하지만, 조직은 빅데이터 생명주기별 개인정보의 침해 위협 자체를 간과하여서는 안 되며, 빅데이터 환경과 개인정보 침해 위협의 연계성을 고려하여야 한다. 이에 따라 본 논문의 평가항목을 활용하여 조직이 보다 더 안전한 빅데이터를 활용하는데 기여하는 바이다.",
		"KEYWORD": null
	},
	{
		"ID": 261,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "전북대학교 대학원",
		"TITLE": "빅데이터 산업의 활성화에 따른 개인정보 보호에 관한 연구 =A study on the protection of personal information in accordance with the activation of big data industry ",
		"AUTHOR": "차상휘",
		"REGION": "전라북도",
		"PROFESSOR": "지도교수: 송양호",
		"STORE_LOCATION": "전북대학교 중앙도서관",
		"ABSTRACT": "Due to the progress of ICT and Internet, the supply of devices like a smartphone and a digital camera, the increase of transaction by using a credit card and online and the spread of social networking like Facebook, Twitter, the amount of data is increasing rapidly. As Big Data industry becomes more active, individual sensitive information such as personal hobbies, personal preferences, health status or purchasing history is collected through various channels. The possibilities that the violation of personal information would be broken out are getting higher and higher. For the sake of the activation of Big Data industry, data subject has to trust the process of collecting information and believe in safety that there is no leakage of personal information. Therefore, the protection of personal information is a necessary condition for the activation of Big Data industry in Big Data era. This thesis suggests some ideas about improvements for Korean Personal Information Protection Act(PIPA). First, I suggest some ideas about plans to improve the utilization of Big Data. PIPA needs to be revised the purpose of legislation that pursues the protection of personal information and the activation of Big Data at the same time. It is necessary to re-organize the concept of personal information more definitely for the increasing of predictability and introduce the concept of “De-identification information” for the activation of Big Data industry. Second, we need to reinforce the right of data subject. This thesis suggests PIPA should be revised that a request for correction and erasure of personal information could be effective without pre-reading. A ‘Right to portability’ means a right to receive the personal information concerning him or her, which he or she has provided to a controller and a right to transmit those data from one controller to another without hindrance from the controller to which information has been provided. A ‘Right to portability’ makes data subject control whose information more effectively and market environment more competitively. The data subject should have the right to object his or her profiling because profiling can analyze or evaluate certain personal aspects relating to subject’s performance at work, economic situation, health, personal preferences, interests, and so on. Third, we need to reinforce the responsibility of personal information controller. This means that we need to convert the responsibility for processing information from data subject to a controller because the strict pre-consent of data subject has possibility that a responsibility for processing information could be transmitted from a controller to data subject. Lastly, this thesis suggests that we need to revise remedies for the breach of personal information. When the collective dispute for leakage of personal information like that is occurred, we try to enhance the effectiveness of collective dispute mediation. I suggest that court has to dismiss a lawsuit when it comes to plead collective dispute mediation. And I also suggests the introduction of the insurance system for the infringement of personal information to guarantee a liability for compensation of a controller.",
		"KEYWORD": "개인정보,개인정보보호,개인정보보호법,빅데이터,정보주체"
	},
	{
		"ID": 262,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 언론대학원",
		"TITLE": "빅데이터 분석을 통한 공기업 이미지 및 주요정책 평가 연구 :한국토지주택공사(LH) 사례를 중심으로 ",
		"AUTHOR": "석지연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김성태 참고문헌: 장 51-53",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 빅데이터는 기업의 활동에 관한 다양한 가치를 평가하고 발굴할 수 있도록 도와주며 이를 통해 다양한 부가가치를 창출할 수 있어 활용 범위가 넓어지고 있다. 이러한 빅데이터 활용 가치에의 각광과 동시에 최근 소셜미디어에 대한 사람들의 높아진 관심과 더불어 기업들의 대고객 관리에 소셜미디어를 적극 활용하고 있어 소셜미디어상의 다양한 자료에 대한 빅데이터 분석이 더욱 더 중요해지고 있는 상황이다. 정부의 정책 또한 국민들의 생활에 직간접적으로 영향을 미치고 이를 실행하는 공기업의 이미지에 직접적인 연관성을 지니므로 정부의 정책을 정확히 전달하는 커뮤니케이션에 대한 확인과 반응을 분석해 정책에 반영하는 정책 순환 구조를 분석하고자 한국토지주택공사 소셜 데이터 빅데이터를 분석하였다. 구체적으로 최근 5년간 한국토지주택공사에 대한 언론보도와 추진해왔던 주요 정책에 대한 사람들의 목소리인 소셜 빅데이터에 대한 연관어와 이미지에 대한 시계열적 추이분석을 하였다. 이를 통해 공사의 주력사업인 주거복지 정책에 대한 뉴스보도와 사람들의 평가에 대한 큰 그림을 그리고, 정책에 대한 이미지와 감성적 평가가 어떠했는지 통시적으로 살펴보았다. 본 연구에서 공사의 주거복지 정책에 관해 공급자 위주의 키워드가 압도적으로 많았으며 언론보도에서 통신사에 의해 팩트 위주의 간결한 기사들이 많고, 주로 경제지에 의해 보도되었음이 확인되었다. 또한 공사가 추진한 주요 정책들에 대한 소셜미디어상의 다양한 이슈가 도출되었으며 정책 수혜자들이 느끼는 고충을 극복하기 위한 정책적 제안들도 많이 포함되어 있어 정책평가나 보완시스템으로서 본 연구는 매우 탐색적이지만 고무적인 시도였다고 판단된다. 마지막으로 주요 정책들에 대한 감성적 평가에서 거의 모든 정책에 대해 긍정적인 내용보다는 부정적인 내용이 상대적으로 많았음을 알 수 있었다. 이는 부정적 평가를 하는 사람들이 더 적극적으로 포스팅하는 경향이 있음을 감안할 때 정책 평가와 선순환적 구조를 형성할 수 있다는 점에서 의의를 찾을 수 있다. 이러한 연구 결과의 시사점과 함께 분석시스템에 대한 자세한 기술이나 사전적 형태소 목록, 언급된 감성어를 지면의 한계 등으로 다 나열하지 못한 점으로 연구가 가진 한계를 밝혀두었다.",
		"KEYWORD": "PR,공기업,빅데이터,소셜미디어"
	},
	{
		"ID": 263,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경상대학교 경영대학원",
		"TITLE": "기업에서의 빅데이터 구축방안과 적용사례 연구 =(An)establishment of big data at a corporation and a study on the application ",
		"AUTHOR": "문대홍",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 정찬용",
		"STORE_LOCATION": "경상대학교 도서관",
		"ABSTRACT": "2015년에는 ICT 분야는 물론 전 산업에 걸쳐 빅데이터에 대한 관심이 증대되면서 시장의 긍정적 징후와 함께 다양한 활용사례가 속속 등장하였다. 세계시장에서 빅데이터는 단순한 열풍에서 가치가 입증 된 기술로 변모되고 있으며, 빅데이터와 예측분석 솔루션을 이용하여 데이터의 가치를 최적화 하려는 움직임이 활발하였다. 빅데이터는 미래사회에서의 다양한 기회요인을 기대하게 한다. 미래사회의 불확실성, 리스크, 스마트, 융합 등의 키워드에 대해 통찰력, 대응력, 경쟁력, 창조력을 제공하는 토대가 될 것이며, 특히 불확실성에 대해서는 현실세계에서 수집 된 데이터를 기반으로 패턴분석과 다양한 가능성에 대한 시나리오의 개발 및 검증을 통해 미래의 상황변화에 유연하게 대처 할 수 있는 통찰력을 제공할 것이다. 이와 함께 리스크에 대해서는 소셜 등 모니터링 정보의 패턴분석을 통해 위험 징후와 이상 신호의 포착, 주요이슈를 사전에 인지하고 분석하여 빠른 의사결정의 지원, 기업과 국가 경영의 낭비요소 절감 등의 대응력을 키워줄 것이다. 급속한 정보기기의 발달로 인하여 현대사회는 방대한 데이터를 생성시키고 또 이를 실시간으로 처리 하고 있다. 이러한 데이터를 활용하여 정보를 만들고 그것을 기반하여 사업 분야에 적용할 뿐만 아니라, 생활의 편의성 향상에도 많은 기여를 하고 있다. 따라서 정보의 활용은 경쟁력의 발로이며 이를 잘 활용할 수 있다면 타 기업보다 선도적으로 전략을 수립 하고 시장을 점유해 나갈 수 있을 것이다. 빅데이터 기술은 갑자기 탄생된 기술은 아니며, 예전부터 각 기업에서는 고객만족과 가치창출을 위해서 기존에 관리하고 있는 데이터를 분석하여 영업이나 사업전략에 이용 하였다. 그러나 과거에는 하드웨어, 소프트웨어 등 관련 인프라 기술 및 데이터 분석기술의 부족으로 한계가 있었으나, 현대사회는 이러한 부족한 점을 모두 충족할 수 있는 환경이 구축이 되고 있다. 이러한 시대적 변화에 따라 빅데이터 기술이 수년 전부터 각 기업과 연구소 및 관련 공급자 등에서 관심과 각광을 받고 있으나, 그 효과성에 대해서는 다양한 의견이 나오고 있는 실정이다. 2015년말에 빅데이터 관련 비즈니스 기업들이 2016년에 실제 뉴스로 보도되었으면 하는 데이터 주요이슈를 조사했는데, 이는 즉, 가상뉴스로서 향후 빅데이터가 시장에서 가장 희망 하고 주목할 만한 내용은 무엇인지를 알아보는 조사였다. 올해의 희망 뉴스에 가장 많은 선택을 받은 의견은 바로 빅데이터 산업에 대한 정부의 투자 확대였는데 이는 정부의 빅데이터 활성화 정책에 따라 전체산업의 활성화 수준을 높여보자는 의도가 반영된 결과로 판단된다, 그리고 2위에 위치한 의견은 빅데이터 업종별 대표사례를 확대해야 한다는 것으로 빅데이터 사례확보에 대한 필요성과 중요성을 확인하였다는 점에서 의미가 있겠다. 본 논문에서는 이러한 빅데이터에 대해 이론적 배경과 트렌드 현황, 그리고 사례를 통하여 기업에서의 빅데이터 구축을 방해하는 요소들을 어떻게 하면 잘 제거하여 성공적인 구축을 이루게 하고 이를 통해 경영의사 결정의 핵심 툴로 위치하게 되는지를 국내외 각 기업의 실제 사례를 중심으로 알아보고 그 효과성에 대해 연구하고자 하였다.",
		"KEYWORD": "기업에서의 빅데이터 구축방안"
	},
	{
		"ID": 264,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "기상 및 교통량 빅데이터 융합을 통한 고속도로 상태 분석 시스템의 설계 및 구현 =Design and implementation of an expressway condition analysis system using the convergence of wealther and traffic big data ",
		"AUTHOR": "董成",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 265,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "보건의료 빅데이터 연구시스템 설계 고려요소에 대한 연구 =A study on the considering factors for the design of big data research system in healthcare ",
		"AUTHOR": "문선태",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 정윤원 참고문헌: p. 28",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "보건의료 빅데이터 분석을 위한 연구는 보건의료 데이터의 민감성, 분석 tool license의 고비용 등으로 인해 연구자들이 쉽게 접근하기 어려운 한계가 있다. 이러한 문제점을 해결하기 위해 연구자들이 초기 투자비용 없이 더 많은 데이터를 쉽고, 편리하게 연구할 수 있는 클라우드 서비스 기반의 보건의료 빅데이터 연구시스템이 요구된다. 본 논문에서는 해외사례 및 보건의료 연구자들을 대상으로 한 설문 조사 등을 통해 현재 보건의료 빅데이터 연구환경을 조사하고, 이를 바탕으로 클라우드 기반의 보건의료 빅데이터 연구분석 시스템 설계 시 고려해야 하는 요소를 도출하였다.",
		"KEYWORD": "보건의료,빅데이터,클라우드"
	},
	{
		"ID": 266,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국항공대학교 대학원",
		"TITLE": "SSD를 사용한 빅데이터 플랫폼 성능향상 연구 =The research for improving bigdata platform using SSD ",
		"AUTHOR": "최준",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이재환",
		"STORE_LOCATION": "한국항공대학교 도서관",
		"ABSTRACT": "본 논문에서는 인메모리컴퓨팅 기반의 스파크 시스템의 성능향상을 위한 방안들을 제시하고, 실험을 통해 분석 하였다. 스파크 시스템은 메모리 기반의 시스템이기 때문에 메모리의 물리적 제한이 있을 때 급격한 성능저하를 보인다. 이를 해결하기 위해 SSD를 메모리의 부족한 대역을 보완하기 위해 사용하였다. 스파크의 메모리 사용 환경설정과 스파크에서 사용되는 데이터셋인 RDD(Resilient Distributed Datasets) 캐싱 정책을 이용해서 평균 20%의 성능향상을 보였다. 또한, 메모리 기반의 분산 저장 시스템인 타키온 파일 시스템[2]을 이용해서 스파크와 타키온을 함께 구성 해 부족한 메모리의 효율적 사용을 제시한다.",
		"KEYWORD": null
	},
	{
		"ID": 267,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "철도 선로전환기의 빅데이터 분석 프레임워크 설계 및 구현 =Big data analysis of railway point machine framework design and implementation ",
		"AUTHOR": "최희수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 朴大熙 참고문헌: 장 57-58",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "선로전환기는 분기기에서 열차의 진로를 설정하는 핵심 궤도장치 중 하나로서, 해당 부품의 고장은 열차 사고에 직접적인 영향을 미친다. 현재 철도 현장에서는 관리자가 모니터링 시스템을 통해 선로전환기의 장애 및 이상상황을 감시하고 철도공사 지침서에 따라 선로전환기 관리를 수행한다. 하지만 현재 모니터링 시스템을 통해 수집된 데이터는 이상상황이나 장애가 발생했을 시 단발성 유지보수를 위한 사후처리 용도로 사용되며, 데이터를 이용한 심층적이고 근본적인 장애의 원인 분석은 이루어지지 않고 있다. 또한, 장애 및 이상상황에 대한 사고원인 확인 시 관리자가 직접 이전 이상상황 로그를 확인해야 하는 불편함이 있다. 본 논문에서는 실제 현장에서 발생하는 대규모 선로전환기 이상상황 데이터를 대상으로 빅 데이터 해석학적 입장에서 새로운 철도 선로전환기 유지보수 분석 시스템의 프로토타입을 제안하고, 선로전환기 빅 데이터 분석 프레임워크를 설계하였다. 제안하는 시스템은 현재의 단편적이고 단발적인 유지보수에서 벗어나, 심도 있고 고도화된 철도 선로전환기 이상상황 분석 및 처리를 위해 두 가지 기능을 제공한다. 첫 번째, 실제 현장에서 발생한 선로전환기 이상상황 데이터를 이용해 빅 데이터 분석 기법에서 사용하는 데이터 큐브(Data Cube)와 OLAP(On-Line Analytical Processing)을 적용하여 철도 유지보수 큐브를 생성하고, 오라클에서 제공하는 AWM을 활용해 빅 데이터 해석학적 입장에서 이상상황 데이터에 대한 다차원적이고 심층적인 분석을 수행한다. 본 논문에서는 해당 기능의 전반적인 이해를 돕기 위해 몇 가지 시나리오를 제시한다. 두 번째, 철도 선로전환기의 전류 그래프와 주변 장치들로부터 도출된 장애 및 이상상황들의 규칙을 CEP(Complex Event Processing)엔진에 등록하여, 선로전환기의 이상신호 발생 시 실시간으로 수집되는 장치들의 동시다발적인 이벤트를 저장된 규칙에 따라 처리한다. 만일 실시간으로 감지된 이벤트가 선로전환기 이상상황의 유효 이벤트일 경우, 경고 알람과 함께 원인이 되는 동작 계통 및 해결방안을 관리자들에게 메시지로 제공한다.",
		"KEYWORD": "CEP,OLAP,Railway Point Machine,Switch point machine,모니터링 시스템,빅데이터,빅데이터 프레임워크,철도 선로전환기"
	},
	{
		"ID": 268,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "원광대학교 대학원",
		"TITLE": "사물인터넷 기반의 스마트 주얼리 시스템을 활용한 빅데이터 처리 방법론 =Big data process methodology using smart jewelry system based on IoT ",
		"AUTHOR": "尹麗",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 269,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "빅데이터 시대의 재무행정법상 개인정보 보호에 관한 연구 ",
		"AUTHOR": "지유석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 朴鍾秀 참고문헌: 장 84-86",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "개인정보보호의 법적문제는 크게 정보의 수집단계에서의 문제, 관리단계에서의 법적문제, 특히 정보공개의 문제 등으로 나누어 볼 수 있다. 오늘날의 행정에서는 행정작용 그 자체의 적법성과 실효성을 담보하는 것과 함께 행정작용을 위한 정보를 어떻게 수집하여 관리하며, 수집된 정보를 어떤 요건 하에서 대외적으로 공개할 것인가를 결정하는 것 또한 매우 중요한 부분을 차지하고 있다. 조세법률주의의 한 측면인 조세행정의 법률적합성의 원칙은 이러한 정보와 관련한 일련의 행정작용들도 법령에 따라 행해질 것을 요구하고 있다. 현재 행정기관들은 각자의 사무영역에서에서의 필요에 따라 엄청난 양의 개인정보를 수집·관리하고 있다. 특히 국세청 또한 예외가 아니어서 방대한 양의 과세자료를 수집?관리하고 있으며, 과세자료의 분석을 통해 공평과세와 조세정의를 실현하고 있다. 그러나 과세정보 또는 과세자료의 수집과 관리 및 그 공개와 관련한 제 단계에서 얼마만큼 법치주의정신이 실현되고 있는지가 의문시 되고 있다. 현행 조세행정법제하에서는 과세정보의 수집·관리 및 공개와 관련하여 헌법상 개인정보자기결정권의 제약이 수반될 것이다. 본 연구에서는 현행 법령을 근거하여 과세정보의 수집, 관리 및 공개 등의 각각의 단계에서 제기될 수 있는 법적 문제를 검토하고 또한 앞으로의 입법·정책적인 방향을 제시해 보았다.",
		"KEYWORD": "개인정보,과세자료,과세정보,빅데이터"
	},
	{
		"ID": 270,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "연세대학교 행정대학원",
		"TITLE": "납세서비스 환경변화에 따른 빅데이터 기반의 BI 구축에 관한 연구 :국세청 사례를 중심으로 ",
		"AUTHOR": "나향미",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이은국",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "analytics,BI,big data,business intelligence,data mining,data scientist,datawarehouse,DW,OLAP,데이터마이닝,데이터웨어하우즈,비즈니스 인텔리전스,빅데이터,정보분석"
	},
	{
		"ID": 271,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "온톨로지 기반 빅데이터 분석에 따른 식품안전 위험도 예측 ",
		"AUTHOR": "배지영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조미숙 참고문헌: p. 187-204",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "산업화 시대 이후 급증한 식품안전 사고는 국민 식품 소비를 위축시키고 막연한 공포감 조성으로 올바른 식품섭취를 유지할 수 없도록 한다. 실제 한국 소비자의 식품에 대한 불안감은 매우 높은 것으로 나타나고 있으며 이에 대한 대응책을 마련하고자 정부와 식품업계, 학계 등은 고심하고 있다. 본 연구는 식품안전에 대한 소비자의 인식과 위해요인에 대한 버즈를 인터넷 상에서 빅데이터로 추출하고, 그 관계성과 위험 요인이 무엇인지 알아보는 것이 목적이다. 하지만 기존의 연구처럼 설문지기법이나 질적 연구가 아닌 빅데이터를 활용함으로써 신뢰도와 활용도를 높이고자 하였다. 트렌드를 반영한 위해요인을 도출하며 나아가 위험요인를 예측할 수 있는 모형을 만드는데 최종 목적을 두고 있기 때문이다. 이에 본 연구는 빅데이터 추출을 위한 식품안전 온톨로지를 개발한 뒤 빅데이터 추출과 분석을 거쳐 최종적으로 위험도 예측 모형을 제시하였다. 연구1에서는 Noy&mcguinness(2001)가 제시한‘Ontology Development101’의 방식을 따라 식품안전에 대한 온톨로지 개발을 목표로 하였다. 본 연구에서는 식품안전 관련 온톨로지의 범위를 개인이 접할 수 있는 식품의 모든 유형을 포함하지만, 식품과 관련해 기존에 일어났던 사건이나 사고, 또는 사고가 일어날 가능성이 높다는 연구가 나온 범위 내에서 온톨로지를 개발하였다. 결과, 예방요인·생성요인·결과요인·사회관계요인의 대분류와 그에 따른 중분류, 소분류로 온톨로지를 개발할 수 있었다. 식품안전에 대한 온톨로지는 처음 개발됐다는 데에 의의가 있다. 연구2에서는 빅데이터 분석을 통해 식품안전 인식에 대한 위험요인을 예측하고자 하였다. 연구는 온라인 뉴스와 소셜미디어(SNS) 등 인터넷 웹을 통해 수집된 소셜 빅데이터를 대상으로 하였다. 분석에서는 온라인 뉴스 사이트 160개와 게시판 14곳, 트위터(SNS), 블로그 4개, 카페 2개 등 모두 181개의 온라인상의 채널이 포함됐다. 소셜빅데이터는 이곳 채널들을 통해 수집할 수 있는 텍스트를 기반으로 한 웹문서(버즈)로 정의하였다. 식품안전 관련 토픽(topic)은 2011년부터 2014년까지 4개년간 매년 3/4분기(7,8,9월달)를 총 12개월 동안의 것을 수집했으며 총 470,131건 (2011년: 100,475건, 2012년: 107,919건, 2013년: 140,706건, 2014년: 121,031건)의 텍스트(Text) 문서를 최종적으로 본 연구의 분석에 포함시켰다. 식품안전 토픽은 모든 관련 문서를 수집하기 위해 ‘식품안전’이라는 토픽을 사용하였으며, 토픽과 같은 의미로 사용되는 토픽 유사어와 수집의 정확도를 떨어트리는 불용어도 지정했다. 소셜 빅데이터를 수집하는 방법은 크롤러(Crawler) 프로그램을 이용하는 방법을 사용하였고, 이후 주제분석을 거쳐 수집된 명사형 어휘들을 유목화(categorization)하여 분석의 틀로 사용하였다. 결과는 크게 다섯 가지를 분석했다. 첫 번째로 용어의 단순 빈도를 살펴봤다. 두 번째는 시계열 추이다. 세 번째는 연관성예측이다. 네 번째는 영향 요인 분석이다. 마지막으로 위험도 예측을 했다. 빈도분석에서 식품안전에 대한 불안 감정은 23.2%로 기존 연구와 비슷한 수준이었다. 생애주기별 대상자 중에서는 ‘영아’와 ‘노인’이, 폐해 중에서는 ‘건강위협’이, 질병 중에서는 ‘암’,‘치매’에 대한 우려가 높았다. 예방 요인으로는 ‘인증제’와 ‘법 규정’에 가장 관심을 두고 있었고 나라별로는 ‘일본’을 가장 우려하고 있었다. 또한 시계열별 추이에서는 식품안전 관련 버즈는 오전 6시경부터 증가하여 오전 11시경 급감하고 다시 13시 이후 급감하다 다시 13시 이후 증가해 17시 이후 감소하며 20시 이후 증가해 23시 이후 급감하는 패턴을 보였다. 식품안전과 관련된 식품명의 대한 불안감정은 월별로 약간의 차이를 보였지만 농산물이 1위, 수산물이 2위라는 점에서는 변함이 없었다. 다만 7월이‘음료’에 대한 불안감정이 약간 높았다. 식품안전에 대한 감정간의 연관성 예측을 알아본 결과로는 긍정의 감정은 {도움, 효과, 보호, 신선}=> {풍부}에 가장 강하게 연결돼 있었다. 즉,‘도움, 효과, 보호, 신선’이라는 단어가 언급됐을 때 인터넷 사용자들이 안전하게 느끼는 감정을 나타낼 확률(‘풍부’라는 긍정적 단어가 언급될 확률)이 이들 키워드가 언급되지 않았을 때보다 6.84배 더 높게 나타났다. 부정적 감정과의 연관성 비교로는 ‘문제, 수치, 불구, 의심’이 언급되었을 때 그렇지 않았을 때보다 불안한 감정을 나타내는(‘피해’가 언급될) 확률이 10.25배 더 높았다. 한편 위해요소와 감정과의 연관성 예측에서는 ‘중금속, 식품첨가물, 화학조미료, 자연독소’가 포함되었을 때‘불안’이라는 부정적 감정이 그렇지 않았을 때보다 2.3배 더 강했다. 식품안전에 영향을 미치는 요소에 대한 회귀분석으로는 미디어, 대상, 질병, 폐해, 인증제, 안전예방, 위생활동, 판매처, 식품, 위해요소, 채널 총 11개 상위 요소에 대해서 식품 안전 감정에 어떤 영향을 미치는지 분석했다. 미디어 요인에서는 방송 요인이 가장 영향력이 컸다. 질병요인에서는 알레르기성질환, 사망, 기타질환은 부적 영향을 미쳐 식품이 위험하다는 감정에 영향을 미치는 것으로 나타났다. 폐해요인에서는 환경파괴, 건강위협, 정신건강위협, 사회불안이 식품이 위험하다는 감정에 대부분 영향을 미치는 것으로 나타났다. 인증제 요인은 대부분 정적인 영향을 미칠 것으로 가정했으나 식품관련 인증제도만 긍정적 영향을 미쳤다. 식품 안전 예방 요인으로는 식품관련 정책만이 긍정적인 감정을 형성하는 데 영향을 준 것으로 나타났다. 식품위해요소 요인 중에서는 GMO, 방사능물질, 방사선, 기생충, 식품첨가물, 동물용의약품, 화학조미료, 소독제, 자연독소, 부정불량식품, 오염, 광우병이 부정적 감정에 영향을 미치는 요소로 꼽혔다. 식품안전 관련 위험 예측에서는 미디어 요인에서는 방송요인이, 대상요인에 따라서는 환자 요인이, 질병요인에서는 사망요인이, 위해요인 중에서는 방사능물질요인 있을 때 불안한 감정이 가장 높았다. 예방 요인에서는 검사 요인이, 위생활동에서는 조리기구용이 요인이, 판매처 요인에서 직거래 요인이 있을 때 안전한 감정이 가장 높게 나타났다. 본 연구는 한국인의 식품안전 인식에 관해 소셜빅데이터를 수집하고 이를 분석해 식품안전에 대한 감정, 우려요인, 관계요인 등을 밝히고 식품안전에 대한 위험요인을 예측한 것에 의의가 있다. 기존의 설문지방식이나 질적연구방법과는 다른 대규모의 데이터를 바탕으로 했다는데 연구 결과의 신뢰성과 타당성이 있다. 하지만 연구 대상의 버즈가 4년간 매년 한 분기(3/4)분기(총 12개월)에 국한돼 있다는점, 분석에 사용할 수 있는 독립변수에 제한이 있다는 점 등에서 한계가 있을 수 있다. 그러나 빅데이터 분석은 국민의 식품 안전 감정이나 위험 요인을 실시간으로 파악할 수 있으며 향후 사건 사고 대처에 유용하게 쓰일 수 있다. 식품산업 활성화와 안전성 확보, 바람직한 식생활 영위 등을 위해서는 향후 빅데이터를 이용한 더욱 다양한 분석틀이 마련되어야 할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 272,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "빅데이터 분석을 활용한 지능형 예측 및 진단모델 개발에 관한 연구 ",
		"AUTHOR": "홍지선",
		"REGION": "경기도",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김영건 참고문헌 : p.49-51",
		"STORE_LOCATION": "경희대학교 국제캠퍼스 도서관,경희대학교 중앙도서관",
		"ABSTRACT": "디지털 경제의 확산으로 우리주변에는 규모를 가늠할 수 없을 정도의 많은 정보와 데이터가 생산되면서 ‘빅데이터’ 라는 용어에 관심이 쏠리고 있다. 이러한 빅데이터는 분석하기에는 어려움이 있으나 매우 큰 활용가능성을 내포하고 있기 때문에 빅데이터에서 의미있는 정보 또는 지식을 발견하는 것에 대한 관심이 고조되고 있다. 빅데이터에 관심이 고조됨에 따라 빅데이터의 일부라고 할 수 있는 민간분야외 정부나 공공기관으로부터 제공되고 있는 공공데이터를 활용해 국민의 삶의 질을 향상시키고, 효율적인 운영을 가능하게 하기 위한 필요성 또한 대두 되고 있으며, 빅데이터 분석을 통해 공공의 이익을 극대화하기 위한 연구가 활발히 진행 중이다. 우리나라 공공기관인 교통안전공단의 자동차 검사 결과 데이터와 교통정보센터 ITS(지능형 교통체계, Intelligent Transport System)에서 계측된 데이터 또한 빅데이터라 볼 수 있다. 그 이유는 먼저 교통안전공단(자동차 검사 결과 데이터)의 경우 각 차량에 대한 ABS, 배출가스 등 수 백 개의 검사 항목 결과와 검사차량정보, 피검사자 인적정보 등의 결합으로 인해 큰 규모의 데이터 군집이 형성되어 있고, 두 번째 교통정보센터(ITS에서 계측된 데이터)의 경우에는 각 도로구간의 교통정보들이 15분 단위로 수집되고 있기 때문이다. 본 연구에서는 이러한 빅데이터의 분석을 통해 공공의 이익을 증진시킬 수 있는 지능형 예측 또는 진단이 가능한 모델을 개발한다.",
		"KEYWORD": null
	},
	{
		"ID": 273,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "동의대학교 대학원",
		"TITLE": "빅데이터 기반 인공신경망을 이용한 초기 설계 단계에서의 건현 예측 ",
		"AUTHOR": "신승현",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 구남국 참고문헌: p. 46-47",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "All ships must build a ship that satisfied the requirements of the International Maritime Organization (IMO). IMO has adopted the International Convention on Load Lines (ICLL) regulations and ICLL has regulated the provision of buoyancy for the stability of ships through the minimum required freeboard. To calculate the minimum required freeboard, several parameter of information are required at the time the ship design is completed. Since the freeboard is directly related to the cargo load, estimating the freeboard at the initial design stage can be applied to ship designs that carry relatively heavy cargoes. In this study, we perform various analyzes using the data of existing ships to estimate a new equation of freeboard that can be calculated at the initial design stage. In the analysis, we performed regression analysis that expresses the relationship between the variables as a functional relation and artificial neural network analysis which forms a meaningful relationship through machine learning. As a result of analysis using two methods, analytical Model using artificial neural network analysis has relatively low error about analytical models for single type of ship and analytical models for all of ship. As a result, it was found that the overfitting problem occurred in the analysis of the single type of ship and that the error of the analysis model increased as the amount of data applied to the analysis increased. In order to solve the overfitting problem and to increase the reliability of the analytical model, each other 500 virtual data were generated for the Type A and Type B vessels defined by the ICLL using the data of existing ships. Among the virtual data, correlation analysis was performed on the variables affecting the freeboard calculation by ICLL and the freeboard of the container carrier. Based on this, the effect of each independent variable on the analysis model was confirmed by comparing regression analysis and ANN analysis model, and the final independent variable was selected considering the conditions of the initial design stage. The selected independent variables were transformed into nonlinear form, and nonlinear independent variables, which are closely related to freeboard, were searched and analyzed through correlation analysis. In order to verify the effectiveness of each analytical model, the margin of freeboard was calculated based on the data of existing ships. As a result, if the analysis is performed based on sufficient data of existing ships, the freeboard can be predicted from the limited information at the initial design stage through the ANN analysis model among the respective analysis models.",
		"KEYWORD": null
	},
	{
		"ID": 274,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "감시 시스템 기반 빅데이터 처리에 관한 연구 =A study on surveillance system-based big data processing ",
		"AUTHOR": "김희곤",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정용화 부록: 영상처리 결과 참고문헌: 장 111-114",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "감시 시스템에서 수집되는 데이터의 증가로 대용량의 영상 데이터에 대한 분석 및 분류에 대한 필요성이 높아지고 있다. 특히 24 시간 감시 시스템에서 수집되는 대량의 영상 데이터에 대한 분석을 수작업으로 하는 것은 쉽지 않은 일이고, 오랜 시간을 필요로 한다. 따라서 컴퓨터 비전의 응용분야에서 영상 데이터에 대한 객체 탐지 및 추적이 자동으로 수행되어지는 것에 대한 요구가 증가되고 있고, 연속적으로 수집되어지는 영상 데이터에 대하여 실시간으로 객체를 추적하는 방법이 필요하다. 기존의 지능형 감시 시스템에서는 영상 데이터 처리를 위해 객체를 탐지하고 추적하기 위한 여러 방법이 존재하지만, 다양한 환경에서 움직이는 객체를 자동으로 탐지하여 추적하는 것에는 많은 어려움이 존재한다. 특히 개별 객체의 분리를 위하여 객체의 근접 상황과 겹침 상황을 정확하게 분리하는 것은 쉽지 않은 문제이다. 따라서 본 연구에서는 24 시간 감시 시스템 기반의 대용량의 영상 데이터에서 객체를 개별로 탐지 및 추적하는 방법과 이기종 컴퓨팅 환경에서 효율적인 병렬처리 방법을 제안한다. 야간에도 수행 가능한 24 시간 감시 시스템을 위하여 조명 없이도 동작 할 수 있는 깊이 카메라로부터 깊이 데이터를 수집하여 객체를 탐지 및 추적하고 정확도를 향상시키기 위하여 움직임 정보를 추가적으로 사용한다. 객체 탐지를 위해 수집된 깊이 데이터에 공간 및 시간 보간법을 적용하여 정확한 깊이 데이터를 생성하고, 생성된 데이터로부터 객체의 상태를 구분하는 방법을 제안한다. 실험 결과, 픽셀 수 기준으로 80%, 객체의 수 기준으로 100%의 정확도로 객체를 탐지 할 수 있음을 확인하였다. 좁은 공간에 다수의 객체인 상황에서는 정확한 객체 추적이 어렵다. 따라서 탐지된 객체들 중에서 근접한 객체를 각각의 개별 객체로 분리하는 방법을 제안한다. 깊이 정보와 움직임 정보를 모두 사용하여 복잡한 상황의 근접 객체를 단계별로 분리하고, 단순한 상황의 근접 상황으로 변환한다. 단순화된 근접 객체는 움직임 예측을 사용하여 객체 분리를 수행한다. 실험 결과, 입력 영상에서 근접한 객체의 최대 개수가 12 개인 것과 비교하여 제안 방법을 사용하여 근접 상황을 단순화한 영상은 근접한 객체의 최대 개수가 5 개로 한정되고, 2 개의 객체가 근접한 상황이 70% 감소한 것을 확인하였다. 또한 두 개의 근접 돼지 시퀀스에 대해서 픽셀 수 기준으로 평균 86%의 정확도로 객체 분리가 가능함을 확인하였다. 객체 추적을 위해 움직임 정보를 사용하여 객체의 식별 번호를 추적하는 방법을 제안한다. 크기, 형태, 색상이 유사한 객체가 근접한 상황에서는 객체의 식별 번호가 서로 뒤바뀌어 객체 추적이 실패하는 경우가 발생한다. 이러한 문제점을 해결하기 위하여 과거 프레임과 현재 프레임을 합성하여 현재 프레임의 식별 번호를 확정한다. 실험 결과, 근접한 다수의 객체가 존재하는 상황에서 식별 번호가 뒤바뀌지 않고 다중 객체 추적이 연속적으로 가능함을 확인하였다. 또한 식별 번호가 뒤바뀐 상황이 발생한 경우에는 객체 추적 검증을 통해 객체 추적 오류를 탐지 할 수 있음을 확인하였다. 마지막으로 객체 추적의 정확도에 가장 큰 영향을 미치는 객체 탐지 부분에 대하여 이기종 컴퓨팅 환경에서 효율적인 병렬처리 방법을 제안함으로써 실시간으로 객체 탐지가 가능하도록 한다. 또한, 객체 탐지의 병렬성을 분석하여 효율적으로 디바이스에 태스크를 분배하여 병렬처리를 수행한다. 실험 결과, 한 개의 디바이스만 사용한 경우보다 제안 방법을 사용하여 최대 8.7배의 성능 향상이 있음을 확인하였다.",
		"KEYWORD": "객체분리,객체추적,객체탐지,병렬처리,이기종컴퓨팅환경,지능형감시시스템"
	},
	{
		"ID": 275,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "공주대학교 대학원",
		"TITLE": "검도의 유효공격패턴 분석을 위한 빅데이터 기반의 실시간 자바 브릿지 시스템 모델에 대한 연구 =A study on bigdata-based real time Java bridge system model for analyzing the effective attack pattern of kendo ",
		"AUTHOR": "김준용",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수:박구락 참고문헌 : 80-84장",
		"STORE_LOCATION": "공주대학교 도서관",
		"ABSTRACT": "In the fourth industrial revolution, there is Hadoop, which is a Bigdata analysis technique, and Hadoop is classified into batch type data analysis and streaming type Real Time analysis system. However, in order to build and analyze both systems, there is a constraint that require a technician who can generate another system construction cost and analyze it professionally. It is difficult for groups and individuals to utilize the Bigdata analysis. In addition, since intermittent data such as a kendo match between a batch processing system and a Real Time system is inputted in real time and the analysis result is confirmed, it is difficult to apply the data during the kendo game. Therefore, this is a necessary situation. In this paper, we provide the Java bridge model of the Bigdata- based that can be used by applying the analysis result of the effective attack pattern of the kendo match immediately. The proposed model is a MapReduce method of Hadoop that is excellent for processing batch type data and a Java-based bridge model that can send and receive data in real time. This is a Bigdata-based Real Time system that allows the user to check the results of real time analysis when a valid attack pattern data is entered. As a direction of future research, we should shorten the response time according to the performance of the computer and continue studying various forms of UI(User Interface) for stable and convenient use. In this paper, I consisted of five sheets as follows: In Chapter 1, the background of the research and the necessity of the research are described first. In Chapter 2, I describe the effective attack pattern of the Kendo, the Bigdata, and Hadoop, which are backgrounds of the study of the supply model, as a related research, Web server, Spring framework, and database. In Chapter 3, I describes the background and the architecture of the study of the proposed model and discusses the concept of the implementation of the proposed model, environmental constraints, etc. In Chapter 4, I explains verification of the results of implementing the system. In Chapter 5, I conclusions and future research directions are described.",
		"KEYWORD": null
	},
	{
		"ID": 276,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한국해양대학교 해양금융·물류대학원",
		"TITLE": "해운항만기업의 빅데이터 사용의도에 영향을 미치는 요인에 관한 연구 =A study on factors influencing intention to use big data in shipping and port companies ",
		"AUTHOR": "이준필",
		"REGION": "부산",
		"PROFESSOR": "한국해양대학교 논문은 저작권에 의해 보호받습니다. 지도교수:장명희 참고문헌: p.67-72",
		"STORE_LOCATION": "한국해양대학교 도서관",
		"ABSTRACT": "As global competition is intensified, more and more companies have tried to enhance their competitiveness by gaining insights through big data analysis. In particular, shipping and port companies which traditionally have focused on hardware expansion, are now actively driving themselves to introduce the new technology related to big data analysis. With the emergence of the fourth industrial revolution, it is for sure that these companies are now faced with unprecedented opportunities which ICT could create. Nowadays, it is evident that success heavily depends on how strategically and effectively the companies utilize and analyze this massive volume of data. As an effort to adopt big data system in the field of shipping and port companies increases, ways of enhancing intention to use big data are absolutely needed for the companies which have just employed this new technology or consider to do so. In this respect, the purpose of this study is as follows. Firstly, through prior research, the study identifies definition and characteristics of big data, its related technology, as well as the current status of the port and shipping companies. Secondly, based on the theory of TOE (Technology Organization Environment) and IDT (Innovation Diffusion Theory) this study is designed to indicate the factors which affect the companies` intention of using big data. Thirdly, this study is designed to empirically verify how those factors affect expected performance by and intention of using big data. To achieve the objective of this study, an empirical analysis has been conducted targeting for staff involved in the department of strategic planning and information technology in the related field. However, since the recognition of big data is relatively low in general and rarely applied to works, the analysis of factors affecting intention of using big data is heavily reliant upon staff having higher recognition on this area. In designing model of research, TOE is chosen considering that big data changes work process of the organization, support from top management level is critical in its adoption, and sometimes big data can be used as means of responding to outside pressure (not by company`s voluntary will), while IDT is chosen because big data can lead innovation of companies. The main reason of verifying an intention to use big data by individual level, is to take into account his or her separate intention, even though big data is adopted companywide. Variables of DOI (Diffusion of Innovation)`s are used instead of technology characteristic among technology characteristic, organization characteristic and environment characteristic of TOE model in this study. A relative advantage, complexity and compatibility are adopted as variables of the technology characteristic while a firm size and support from top management are adopted as variables of organization characteristic and a competitor pressure and regulatory support are adopted as environment characteristic. Eight hypotheses were set up in verifying relevance between variables of the above mentioned three characteristics, and expected performance and intention of using big data. A survey for hypothesis test had been conducted and collected for two weeks from 30th of October to 15th of November in 2017 by mail, e-mail and visit. Likert 5-pont scale was used to develop measurement instrument and fomulate questionnaire, 155 effective questionnaires out of 200 were gathered. SPSS 21.0 was used to analyze the demographic characteristic and frequency while Smart-PLS 3.0 was used to conduct hypothesis test, analysis of reliability and validity. The summarized result of this study is as follows. Firstly, from Technology Characteristic, relative advantage, complexity and compatibility reacted positively to the expected performance. Secondly, from Organization Characteristic, support from top management reacted positively but the firm size reacted not positively to the expected performance. Thirdly, from Environment Characteristic, competitive pressure reacted positively while the regulatory support reacted not positively to the expected performance. Uniqueness of this study can be found in empirically verifying various factors which could promote big data analytics for shipping and port companies, based on models of TOE and IDT. In addition, following practical implications are presented as result of this study. Firstly, if the big data has technical convenience and advantage, it has a positive effect on both expected performance and intention to use big data. In addition, if technology of big data analytics is as convenient as existing technology, can be easily employed in current works, and there is no extra burden in application, companies are positively likely to adopt this new technology. Therefore, to increase the intention to use big data technology, shipping and port companies have to make plans for enhancing relative advantage and compatibility while decreasing complexity. Secondly, in a view of organization characteristic, support from top management will have positive effect on intention of using big data because extra expenditure is required for operation and training both internally and externally. Size of the firms is found not to have statistically meaningful relevance with the expected performance. Therefore, support from top management is definitely required to develop the intention to use big data for the shipping and port companies. For future research it is suggested to clarify how the firm size is related to expected performance and intention to use big data conducted. Lastly, from environment characteristic, use of big data will increase if there is high level of competitor pressure and as a result company`s effort not to fall behind in the competition is followed. When it comes to regulatory support rejection, it might be explained that the respondent may do not know their company`s actual regulation well or even if they knew, due to limited awareness it might be difficult for them to respond with clarity.",
		"KEYWORD": "빅데이터,사용의도,해운항만기업"
	},
	{
		"ID": 277,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "시계열 빅데이터 분류 및 클러스터링 기법과 응용 =Techniques and applications of classification and clustering of big time-series data ",
		"AUTHOR": "오규협",
		"REGION": "경기도",
		"PROFESSOR": "경희대학교 학위논문은 저작권법에에 의해 보호받습니다. Techniques and Applications of Classification and Clustering of Big Time-Series Data 지도교수: 정재윤 참고문헌 : p.83-89",
		"STORE_LOCATION": "경희대학교 국제캠퍼스 도서관,경희대학교 중앙도서관",
		"ABSTRACT": "With the development of digital devices, a variety of information is being generated and the amount of data generated each year is increasing. All data generated in various categories are collected and stored for analysis, and these data are called `big data`. With the development of big data, time-series data are also variously generated and collected. Time series refers to a sequence of data arranged at regular intervals, and data collected at regular intervals is called time series data. However, as the data collection period increases then the size increases and it is difficult to extract the feature due to the different characteristics depending on the type of data. In this paper, classification and clustering techniques and geographic clustering techniques are presented to analyze time series data. In order to classify time series data, a CNN-based model and a 1-NN DTW-based model were proposed and the proposed model was verified using public transportation data and public data in Seoul. In order to clustering the time series data, a scheme using symmetric Kullback Libler and K-medoids was proposed. The proposed technique was analyzed using public transportation data of Seoul. Finally, we propose a geographic clustering method based on travel distance and travel distance and analyze it with Seoul public transport data.",
		"KEYWORD": "시계열 데이터,클러스터링"
	},
	{
		"ID": 278,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "명지대학교 대학원",
		"TITLE": "빅데이터 프레임워크를 활용한 효율적인 온톨로지 질의 처리 =Efficient ontology query processing by using big data framework ",
		"AUTHOR": "손창원",
		"REGION": "경기도",
		"PROFESSOR": "명지대학교 논문은 저작권에 의해 보호받습니다. 지도교수:전공훈",
		"STORE_LOCATION": "명지대학교 도서관(서울),명지대학교 도서관(용인)",
		"ABSTRACT": "본 논문에서는 HBase 기반의 RDF 저장소에서 효율적으로 추론질의를 처리하기 위해 기존의 Jena-HBase에서 제안한 테이블 스키마와 RDF 트리플의 저장 방식을 개선하여 효율적인 추론질의 처리가 가능하도록 하고, 기존의 질의 처리기를 개선하여 중첩 트리플 패턴형 질의에 대한 처리가 가능함을 보인다. 빅 데이터 환경에서 온톨로지 기반 추론질의를 처리하기 위해 수평적 확장으로 대용량의 데이터를 관리할 수 있는 HBase에 RDF 트리플을 저장하고 추론질의를 처리하는 Jena-HBase가 제안되었다. 그러나 특정 클래스 타입을 검색하기 위해서 테이블의 모든 로우를 검사해야 하는 비효율적인 저장 방식의 테이블 스키마. 그리고 HBase의 특성을 충분히 활용하지 못한 단순한 검색 방식과 중첩된 트리플 패턴을 포함하는질의를 처리하지 못하는 질의 처리방식으로 인해 효율적인 추론질의 처리가 불가능한 문제점을 안고 있다. 따라서 본 논문에서는 클래스 타입 검색이 용이하도록 각 노드의 클래스 타입에 prefix를 부여하여 저장하고, 온톨로지를 구성하는 클래스와 프로퍼티 각각을 컬럼 패밀리로 가지도록 테이블 스키마를 개선하여 세분화하였다. 이렇게 세분화된 스키마를 토대로 HBase의 필터들을 조합하여 질의를 구성하는 클래스와 프로퍼티에 해당하는 컬럼만을 접근하여 질의처리를 수행함으로써 질의처리 성능을 향상시킨다. 또한 기존 Jena-HBase에서 처리하지 못했던 중첩된 트리플 패턴을 포함하는 질의를 처리할 수 있도록 질의 처리기를 개선한다. 본논문에서 제안하는 개선된 HBase 기반 RDF 저장소와 질의 처리기를 사용함으로써, 추론질의 처리의완전성을 보장함과 동시에 질의응답에 소요되는 시간이 단축됨을 보인다. 본 논문에서 제안하는 개선된 트리플 저장 방식 및 테이블 스키마와 질의 처리기의 실용성과 우수성을 입증하기 위해서 LUBM(Lehigh University Benchmark)에서 제공하는 데이터 집합과 테스트 질의를 이용하여 실험을 실시한다. 실험을 통해 기존의 Jena-HBase의 Hybrid 스키마와 개선된 RDF 저장소에서의 질의 응답속도를 비교하여 얼마나 질의 응답속도가 개선되었는지 보이고, 또 기존의 질의 처리기에서 처리하지 못한 트리플 패턴형 질의를 개선된 질의 처리기를 통해 처리가 가능함을 입증하며 전체적으로 개선된 HBase 기반 RDF 저장소 및 질의 처리기의 우수성을 보인다.",
		"KEYWORD": "HBase,트리플저장소"
	},
	{
		"ID": 279,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "빅데이터 분석기법을 통한 N-스크린 서비스 활용에 영향을 미치는 요인 분석 :로지스틱 회귀분석과 의사결정나무 분석의 비교 ",
		"AUTHOR": "오유리",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김도훈 경희대학교 논문은 저작권에 의해 보호받습니다. 참고문헌: p. 37-41",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "스마트 디바이스의 확산으로 인해 정보통신 서비스의 다양성과 양이 크게 증가하고 있다. 이에 따라 사용자의 니즈에 따른 디바이스의 선택의 폭도 넓어지고 디바이스 간 상호연동도 확장 되었다. 이러한 현상은 사용자의 콘텐츠 소비방식에 영향을 주는데, 그 중심에 있는 것 중의 하나가 N-스크린 서비스이다. 본 연구에서는 KISDI에서 제공한 미디어패널 데이터를 바탕으로, N-스크린 서비스 이용에 영향을 미치는 핵심 요인들을 찾는다. 정확한 예측력을 위해 학습용 집합(train data set)과 비교용 집합(test data set)을 나누어 분석하여 비교한다. 학습용 집합에 로지스틱 회귀분석(Logistic Regression; LR)과 CART(Classification and Regression Tree; CR)를 각각 이용하여 모형을 구축한 뒤, 비교용 집합에 적용시킨다. 두 모형의 예측력을 비교하기 위하여 ROC 곡선 분석과 Confusion Matrix를 이용한다. 그 결과, LR의 모형의 예측력이 CR 모형보다는 좋았지만, CR이 영향력있는 변수를 LR보다 적게 추출하였다. 이는 분석할 환경에 따라 적절한 분석 방법을 고려해야 할 것으로 판단된다. 본 연구는 향후 N-스크린 가입자 특성이나 행태적 요인 등을 규명하거나 이에 관련된 마케팅 전략이나 정책 개발에서 이들 요인을 적극적으로 고려할 필요가 있을 것이다.",
		"KEYWORD": "CART,N-스크린 서비스,로지스틱 회귀분석"
	},
	{
		"ID": 280,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "디자인 사고 방법론을 활용한 빅데이터 주제 선정 프레임워크에 대한 연구 =(A)study on big data theme ideation framework adapting design thinking methodology ",
		"AUTHOR": "배소연",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 281,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "한세대학교 대학원",
		"TITLE": "이기종 미디어에서의 비정형 빅데이터 융합적 분석 연구 =(A)study on the convergence analysis for unstructured big data in heterogeneous media ",
		"AUTHOR": "전상권",
		"REGION": "경기도",
		"PROFESSOR": "지도교수:신승중",
		"STORE_LOCATION": "한세대학교 도서관",
		"ABSTRACT": "본 연구는 융합적 관점에서 이기종미디어 영역 중에서 감시영상미디어와 소셜미디어와 같은 대용량 데이터 발생이 반드시 존재하는 분야에서 빅데이터 에코시스템과 관련된 기술을 연구하였다. 즉 빅데이터를 ICT 융합 서비스 트랜드에서 새로운 서비스 관점에서 적용함으로써 미래 사회에 유용한 기술 가치로 기여하고자 한 것이 본 연구의 배경이자 목적이다. 본 연구의 구현을 위하여 감시영상미디어 산업 동향과 함께 관련 기술을 파악하였고, 감시영상 시스템에서 발생한 영상 이벤트를 내용 기반의 대표 영상과 함께 메타데이터를 분류하고 저장하였다. 또한 이미 전 세계적으로 패러다임의 혁신을 가져 온 페이스북이나 트위터처럼 소셜미디어의 배경과 동향 및 관련 기술을 이해하면서, 감시영상 이벤트 데이터와 연관이 있는 트위터 이벤트 데이터를 수집, 저장하고 융합적으로 분석하고자 하였다. 그리고 최근 이슈가 되고 있는 빅데이터의 산업 현황과 함께 관련 기술을 파악하면서, 앞서 수집된 정형, 비정형 데이터를 Hadoop 기반의 HDFS와 연동된 HBase에 저장하였다. 이어서 MapReduce를 적용한 Pig 플랫폼에서 데이터를 추출하고 분석하였다. 이어서 연구 대상의 감시영상 데이터와 트위터의 데이터가 전처리 과정과 빅데이터 플랫폼을 경유하면서 나타난 데이터간에 상호 연관성과 신뢰성을 파악하고자 연관성 규칙(Association Rule) 기반의 데이터 마이닝 알고리듬을 적용하였다. 그래서 데이터 마이닝 기술에 대한 관련 연구를 하여 최적의 알고리듬을 적용하였다. 즉 빅데이터 분석 기술의 적용으로 인해 개별적으로 각각 발생했던 사건(event)들이 상호간에 어떤 연관성을 갖고 있는지 연구하였다. 마지막으로 연관성 분석을 마친 결과를 시각화하여 본 연구의 목적대로 발견한 연구 성과의 결과를 직관적인 형태로 표시하였다. 결론적으로 본 연구 논문을 정리하면 화재, 교통사고, 폭행 사건 등 사회적 이슈가 될 수 있는 감시영상미디어 데이터와 함께, 트위터와 같이 실시간으로 빠르게 확산되는 소셜미디어의 비정형 빅데이터를 수집 및 저장하고 융합적 관점에서 분석하였다. 그것을 위해 빅데이터를 포함한 기반 기술을 연구하고 관련 과정을 구현하였다. 그래서 분석된 데이터는 의미가 나타나는 내용으로 재평가되었다. 이번 연구 결과를 활용해서 적용한다면 사회적 안전망 구축에 기여할 것으로 전망된다. 또한 연구 과정에 나타난 클라우드 개념과 결합된 새로운 감시영상 통합관제 시스템인 ‘빅데이터 노드’ 방식을 제안한다.",
		"KEYWORD": "비정형,빅데이터"
	},
	{
		"ID": 282,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충남대학교 대학원",
		"TITLE": "빅데이터 분석을 통한 뇌전증 치료제 연구동향에 관한 연구 ",
		"AUTHOR": "권상조",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김철희 참고문헌 : p. 49-54.",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "Epilepsy is one of the major neurological diseases characterized by recurrent seizures, and is highly prevalent in elderly and children. The research on the onset mechanism of epilepsy is still in progress. This study was carried out to investigate the research trend of anti-epileptic drug through big data analysis. The research subjects were patents filed from 1996 to 2015, and about 6,506 cases were analyzed. Quantitative and qualitative analysis were carried out based on the information described in the patent documents. As a result, the number of patent applications related to anti-epileptic drug had been increased from 1996 to 2007, but it had gradually decreased since 2007, and more than 50% of all patent applications were filed in the US. Patent applications by pharmaceutical companies based on the US and Europe, including Pfizer, Neurosearch A/S and Sanofi S.A. were active, and the top five applicants showed a high level of patent activity in four major countries (Korea, Japan, Europe, and the United States). On the other hand, patent application activity of Korea pharmaceutical companies was relatively low. And this study revealed that the US is leading the development of technology related to anti-epileptic drug, and research activities centering on pharmaceutical companies are being actively carried out. PFS is a market reach index used in patent analysis. In European countries, PFS are relatively high and in Korea, PFS is lower than the average. And then through the patent portfolio analysis, this study confirmed that the technology position of the US patent was at the maturity stage, and the technology positions of Korea, Japan, and European patents, were at a declining stage. In conclusion, the technology position of the anti-epileptic drug is located at the maturity stage, and research activity and market dominance are dominated by multinational pharmaceutical companies based on the US and Europe. Korea`s research activity and market reach index are poor, and the proportion of patent activities of public institutions and universities is higher than other countries. As a result of selecting and analyzing key patents, multinational pharmaceutical companies had the key patent rights and key patents were cited by other pharmaceutical companies. In order to enter the epilepsy drug market, patent avoidance design is expected to be necessary. And the efficacy of retigabine was clearly confirmed in an experiment using zc4h2 knock-out zebrafish screening system. zc4h2 knock-out zebrafish is very useful for testing or screening anticonvulsant compounds. In this study, we could confirm the level of domestic technology and the technology gap between domestic and foreign countries. When considering domestic research conditions, the joint research by companies, public institutions and universities for the development of anti-epileptic drug is expected to be a good opportunity for domestic technology to penetrate the epilepsy drug market, where generic drug has entered in earnest.",
		"KEYWORD": null
	},
	{
		"ID": 283,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "스마트팩토리 구축을 위한 중소제조공정 빅데이터 분석 적용방안 =Big data analysis for smart factory implementation in small and medium manufacturing process :자동차 부품 제조공정을 중심으로 ",
		"AUTHOR": "김재성",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.102-108",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "The introduction of a big data platform for ICT-based large volume production data integration is accelerating in a situation where the complexity of recent manufacturing processes has increased and a high level of efficiency is required. Meanwhile, various software platforms for smart factory have been proposed. These kinds of automated systems for the manufacturing industry have been being implemented, each of which is a fusion of ICT and manufacturing industry, and manufacturing processes can also be optimized in Industry 4.0. In order to implement a smart factory, it is necessary to have an integrated platform that is optimized the automation process to match with process Life-Cycle. This is also a fusion of IoT(Internet of Things)-based CPS(Cyber Physical System) technology and ICT technology. In case of large enterprises, ICTs are actively utilized, but small and medium-sized manufacturers are difficult to introduce systems due to problems of industrial structure and factors of vulnerability that small and medium-sized manufacturers themselves have. In this paper, we provide an application method of 4M data-based big data platform and analysis which can be flexibly applied to the application considering the extensibility necessary for smart factory implementation of small and medium manufacturing enterprises. 1. Manufacturing data in small and medium manufacturing enterprises in automobile parts industry was collected, classified into a 4M (Man, Machine, Material, Method) data, and stored in a database (an integrated operational data store). 2. We built a cloud-based big data analysis system for large volume data processing. Big data analysis system has been implemented by using open source SWs for making low cost platform. 4M database is periodically stored in the Hadoop Ecosystem and can be analyzed using Spark R. The result can be published in the Web interface by using R Shiny library. 3. With the big data analysis system, we analyzed process pattern defects, 4M data analysis, reliable base equipment failure prediction, overall equipment efficiency analysis, and found 4M factors that affect productivity. The results of the analysis are summarized as following. As result of pattern analysis of the process defact status, defect it was found that there were many defects due to the worker factors. 4M data analysis result shown that there was a difference in defective quantity depending on workers, materials, working method. In the overall equipment efficiency analysis, the productivity impact from equipment failure was small. It indicated that the decrease in productivity effect is large due to insufficient workers’ response to idling and momentary stopping of facilities. Through 4M data analysis, we can quickly identify problems, obtain improvement strategy in production and quality control. Futhure more, it can also support process optimization and smart decision making.",
		"KEYWORD": "4M data analysis,Big data analysis,Smart factory"
	},
	{
		"ID": 284,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "뉴스기사 빅데이터 분석을 통한 아파트 전세가격 예측모형 ",
		"AUTHOR": "강호준",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:신도형 참고문헌 : p.80-84",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "주택 자체의 거래가격이 다른 재화보다 매우 높기 때문에 주택시장의 가격 변화가 사회?경제적으로 미치는 영향은 다른 시장보다 크다. 전세는 이러한 주택시장에서 가장 보편적인 주택임대차 유형 중 하나로서 전세가격은 서민 주거안정과 긴밀한 관련성을 가진다. 이러한 관점에서 전세가격 예측은 주거안정을 위한 정책 수립을 위해 선행되어야 하는 필수적인 과정이라고 할 수 있다. 기존에는 이러한 전세가격과 같은 주택가격의 결정과정이 시장경제원리에 의한 접근방법이나 내외적 요인에 의한 접근방법에 의해 추정되곤 했다. 즉, 주택의 위치나 규모와 같은 주택 자체적인 특성인 내부적 요인과 경제정책과 같은 외부적인 요인에 의하여 주택의 수요와 공급이 결정되며, 이러한 수요와 공급이 균형을 이루는 지점에서 주택가격이 결정된다고 본 것이다. 하지만 이러한 일반적인 추정방법으로는 설명할 수 없는 급격한 가격변동이나 가격과 거래량 간의 강한 양(+)의 상관관계가 나타나는 등의 현상들이 주택시장에서 발견될 때가 있다. 기존 연구자들은 이와 같은 현상의 원인으로 전망이론(Prospect theory)에서 제시한 손실회피성(Loss aversion)을 지목하였다. 손실회피성이란 동일한 금액에 대해 이익보다는 손실을 훨씬 크게 느끼는 현상을 뜻하는데, 손실회피성을 기반으로 한 이러한 연구들은 인간의 심리적 태도가 주택매매시장에서 중요한 역할을 하는 요소임을 시사한다. 몇몇 연구들은 뉴스기사가 인간의 심리적 태도를 반영한다고 보고 뉴스기사와 주택가격 사이의 관계성을 실증적으로 분석하고 규명하였다. 이러한 연구들은 부동산시장 안정을 위한 정책적 선제 대응이라는 측면에 있어 뉴스기사의 활용가능성을 제안했다는 점에서 시사하는 바가 크다. 하지만 부동산시장 분석에 있어서의 뉴스기사의 잠재적 활용가능성이 확인되었음에도 불구하고 이를 통한 부동산 가격예측에 대한 연구는 아직 본격적으로 수행된 적이 없다. 이에 대한 주요 원인은 뉴스기사라는 정보를 변수화하는 것이 어렵기 때문인 것으로 판단된다. 실제로 기존의 연구들은 뉴스기사 수집 도구가 갖는 한계로 인해 단순히 특정 뉴스기사의 건수를 이용하여 부동산시장과의 관계를 규명한 것에 그치고 있다. 따라서 본 연구는 기존 연구들이 갖고 있는 문제점들을 극복하기 위하여 빅데이터 분석을 이용하여 뉴스기사를 분석하고 이를 통해 전세가격을 예측하는 모형을 제시하는 것을 그 목적으로 하였다. 예측의 대상이면서 예측모형의 반응변수가 되는 전세가격의 선정은 국토교통부의 실거래가 공개시스템에서 제공하는 전국 실거래가 아파트(전월세) 월별 통계자료를 대상으로 한 빅데이터 분석을 통해 수행되었다. 해당 자료의 대상기간은 2011년 1월부터 2016년 7월까지로서 총 3,214,315건의 계약이 기록되어 있다. 예측 대상지역은 예측모형이 갖는 설명력을 증명할 수 있도록 해당 기간 중 변동성이 가장 두드러진 것으로 나타난 판교 지역을 그 대상으로 하였다. 대상으로 한 아파트는 예측모형이 갖는 특성을 고려하여 자료의 보유량이 많아 결측치에 대한 대체 및 보완이 가능한 판교원마을9단지(한림풀에버) 아파트 전세가격을 반응변수로 선정하였다. 이는 예측모형에 예측력을 부여하기 위해 시차(Time shift) 개념을 적용하였는데, 이러한 시차 개념을 고려하여 회귀분석이 수행되기 때문에 일반적인 회귀분석과 달리 결측치에 대한 보완이 필요했기 때문이다. 예측모형의 설명변수로는 뉴스기사 키워드의 인터넷 검색빈도를 이용하였다. 이는 뉴스기사가 주택가격에 미치는 영향력이 기존 연구에서 확인되었기 때문에, 뉴스기사 키워드의 인터넷 검색도 전세가격과 상관관계를 가질 것으로 보았기 때문이다. 뉴스기사 키워드는 뉴스기사 빅데이터 분석도구인 빅카인즈 프로(BIG KINDS-PRO)를 이용하여 추출하였다. 추출된 키워드를 바탕으로 네이버 데이터랩과 네이버 검색광고의 키워드 분석도구를 활용하여 기간별 절대 검색빈도를 구하였다. 가장 현실과 흡사한 키워드의 변동추이를 예측모형에 적용하기 위하여 인터넷 트래픽을 고려하였으며, 이러한 인터넷 트래픽은 한국진흥원에서 조사한 2011년 ~ 2015년의 인터넷 사용자수로부터 추정하였다. 예측모형의 개념에는 2가지가 고려되었다. 첫째로 단순회귀모형은 하나의 설명변수로 이루어져 있기 때문에 추출된 뉴스기사 키워드의 검색빈도를 일원화하는 과정이 필요했다. 이를 위해 시차별로 반응변수와 상관계수가 높은 뉴스기사 키워드들을 추출한 후 추출된 뉴스기사 키워드의 검색빈도들을 합쳐서 하나의 설명변수로 만들었다. 둘째로 예측모형에 예측성을 부여하기 위해서 시차(Time shift)의 개념을 적용하였다. 주어진 데이터를 훈련집합(Training set)과 검증집합(Validation set)으로 나눈 후 훈련집합의 데이터에 1개월 ~ 12개월의 시차를 발생시켜 각 설명변수별 예측모형을 생성하였다. 이후 검증집합에서 정확도가 가장 우수한 모형을 최종 예측모형인 뉴스기사 기반 예측모형으로 선정하였다. 뉴스기사 기반 예측모형은 시차가 10개월일 때의 키워드 ‘김포한강’, ‘수도권’, ‘경기도’, ‘분양가’ 등 4개의 뉴스기사 키워드의 인터넷 검색빈도를 합쳐서 만든 설명변수를 이용하여 생성되었다. 본 연구에서 제안한 뉴스기사 기반 예측모형의 성능 검증은 부동산 가격 예측에 많이 사용되는 시계열 분석을 이용한 결과값과의 비교를 통해 수행하였다. 시계열 분석에는 해당 시계열 자료의 차수를 결정하기 위한 모형 식별 결과를 바탕으로 ARIMA(1,1,1) 모형을 이용하였다. 검색빈도 기반 예측모형과 시계열 분석 기반의 예측모형의 검증집합에서의 평균절대백분비오차(MAPE)는 각각 3.84%와 5.51%로 전자의 예측정확도가 더 우수한 것으로 나타났다. 또한, 비교대상인 시계열모형의 경우 예측 대상 시점보다 한 시점 전의 자료를 사용하는 반면, 본 연구의 검색기반 예측모형은 10개월 전의 자료를 사용함으로써 예측 선행시점 측면에서도 우수한 모형이라 할 수 있다. 본 연구의 뉴스기사 기반 예측모형을 이용하여 전세가격 관련 정책수립이 더욱 효과적으로 수행될 수 있을것으로 기대한다.",
		"KEYWORD": "뉴스기사,빅데이터,아파트,예측,전세가격"
	},
	{
		"ID": 285,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한세대학교 대학원",
		"TITLE": "환경정보 구축실태 조사를 통한 빅데이터 활용방안에 대한 연구 =A study on the big data utilization plan through the actual survey of environmental information construction ",
		"AUTHOR": "이호균",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 김선집 교수",
		"STORE_LOCATION": "한세대학교 도서관",
		"ABSTRACT": "국 문 요 약 4차산업혁명은 모든 분야에 급속하게 다가오고 있으며 환경부문도 예외 될 수 없으므로 이에 대한 연구와 적극적인 대응이 필요하다. 환경부와 지자체에서는 일찍부터 전국의 대기·수질 오염 현황 등 환경관련 정보를 조사하고 있으며, 정보공개 정책에 따라 조사 자료를 공표하고 있으나 그 활용은 미흡한 상태다. 특히 삶의 질 향상에 따라 쾌적한 삶에 대한 국민의 요구는 증가하고 있으나 과학의 발전으로 환경오염물질 종류가 다양해지고 경제발전에 따라 그 발생량이 증가하고 있는 추세에 있으며, 근래 자주 발생하고 있는 미세먼지는 생활의 불편과 불안을 주고 있어 환경정보의 조사 범위를 넓히고 조사방법을 다양화하여 환경정보 활용성을 강화 할 필요가 있다. 본 연구는 공개되고 있는 환경관련정보(빅데이터)의 실태를 고찰하고 이를 기반으로 환경 정보화 추진 방향과 생성된 정보의 활용 방안에 대하여 검토하고 의견을 제시코자 하였다. 이를 위하여 환경법상 정보화에 대한 내용과 환경자료의 측정·검사 규정을 조사하고 빅데이터와 환경정보를 연계 검토하기 위하여 정보환경의 변화된 내용을 검토하였으며, 변화된 정보환경에 따라 추진하고 있는 국가 전체의 정보화 추진 내용도 조사하였다. 환경분야 중 기후대기환경 분야, 물환경 분야, 자원순환 분야, 환경보건분야 등에 대하여 매체별로 정보화 구축 상황과 환경정보(빅데이터) 생성 및 활용 현황을 고찰하였으며, 환경영향평가분야시 빅데이터의 생성 내용과 정보체계 구축 및 활용 내용을 조사하였다. 결론 부분으로는 환경정보화의 체계적·실천적 추진 방안, 대기환경정보의 정밀성 향상 등 환경정보화 추진에 대한 의견을 제시하였으며, 환경영향평가시 수집된 정보의 활용이 미흡한 문제점 개선을 위하여 환경영향평가시 생성된 정보와 공공데이터의 융합, 환경영향평가시 정보생산 다양성 제고, 관련규정 현실화 등을 제언하여 환경분야의 정보체계가 더욱 발전하고 빅데이터 활용이 제고되기를 도모하였다.",
		"KEYWORD": null
	},
	{
		"ID": 286,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "경상대학교 대학원",
		"TITLE": "빅데이터 분산처리시스템을 이용한 기계학습 알고리즘에 관한 연구 =(A)study on machine learning algorithms using distributed processing system of big data ",
		"AUTHOR": "정병호",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 임동훈",
		"STORE_LOCATION": "경상대학교 도서관",
		"ABSTRACT": "It is almost impossible to store or analyze big data increasing exponentially with traditional technologies, so Hadoop is a new technology to make that possible. In recent R is using as an engine for big data analysis based on distributed processing with Hadoop technology. In this paper, we address the problem of implementing the machine learning algorithms such as multiple linear regression and logistic regression based on MapReduce framework with RHadoop and RHIPE that integrate R and Hadoop environment applicable to large scale data. We implement machine learning algorithms with various data sizes of actual data and simulated data. We compare the computing speeds of pseudo-distributed and fully-distributed modes for configuring Hadoop cluster for the multiple linear regression, and also compare the performance of our Cost Minimization algorithm and Newton-Raphson algorithm with existing Gradient Descent algorithm. The Newton-Raphson algorithm does not require a learning rate, while Gradient Descent and Cost Minimization algorithms need to manually pick a learning rate. The experiments demonstrated that our learning algorithms using RHadoop and RHIPE can scale well and efficiently process large data sets on commodity hardware. We showed fully-distributed mode for the multiple linear regression was faster than pseudo-distributed mode and computing speeds of fully-distributed mode were faster as the number of data nodes increases. We also showed that our Newton-Raphson algorithm appeared to be the most robust to all data tested.",
		"KEYWORD": "Hadoop,RHadoop,RHIPE,머신러닝"
	},
	{
		"ID": 287,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경상대학교 대학원",
		"TITLE": "RHadoop 플랫폼을 이용한 빅데이터 K-평균 클러스터링 =K-means clustering for big data using RHadoop platform ",
		"AUTHOR": "신지은",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 임동훈",
		"STORE_LOCATION": "경상대학교 도서관",
		"ABSTRACT": "Data clustering is a common technique used in data analysis and is used in many applications, such as artificial intelligence, pattern recognition, economics, ecology, psychiatry and marketing. K-Means clustering is a well-known clustering algorithm aiming to cluster a set of data points to a predefined number of clusters. In this paper, we implemented K-Means clustering algorithm based on MapReduce framework with RHadoop to make the clustering method applicable to large scale data. RHadoop is a collection of R packages that allow users to manage and analyze data with Hadoop. Our main idea introduced a combiner as a function of our map output in order to decrease the amount of data needed to be processed by reducers. We also implemented RS(R-squared) and Elbow methods with MapReduce for finding the optimum number of clusters for K-Means clustering on large dataset. The experimental results demonstrated that K-Means clustering algorithm using RHadoop can scale well and efficiently process large data sets on commodity hardware. Comparison with MapReduce implementation of RS, Elbow methods and classical K-Means clustering processing on small data showed similar results. We also showed that our K-Means clustering algorithm using RHadoop with combiner was more faster than regular algorithm without combiner as the size of data set increases.",
		"KEYWORD": "Hadoop,K-평균 클러스터링,MapReduce,RHadoop,빅데이터"
	},
	{
		"ID": 288,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "실시간 스트리밍 빅데이터 분석 시스템 설계 및 개발 =(A)design and development of real-time streaming big data analysis system ",
		"AUTHOR": "백창원",
		"REGION": "경기도",
		"PROFESSOR": "아주대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박기진 참고문헌: p.33-35",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "본 논문에서는 빅데이터 분야의 주요 이슈인 실시간 빅데이터 처리를 위하여 In-Memory 기반 클러스터 컴퓨팅 기술인 Spark을 활용한 빅데이터 분석 시스템을 설계 및 구현하였다. 아파치(Apache Software Foundation)에서 오픈 소스 형태로 서비스 중인 Spark은 MapReduce를 대체하는 범용적 목적의 분산 고성능 클러스터 컴퓨팅 기술이며, 현재 빅데이터 처리 선두 기업에서 강력히 채택하고 있는 차세대 빅데이터 컴퓨팅 프레임워크라 볼 수 있다. 또한 실시간 메시지 전달 프레임워크인 Kafka를 이용하여 대용량 데이터 수집에 필요한 확장성을 확보하였으며, Spark에서 제공하는 라이브러리인 Spark-Streaming을 이용하여 수집 된 대용량 데이터를 실시간으로 처리 할 수 있도록 하였다. 구축된 시스템의 성능 평가에서는 In-Memory 기반 Spark 프레임워크가 기존의 MapReduce 배치 처리 기반의 Hive SQL 보다 최대 20배 이상 빠른 처리 시간을 보였으며, 이를 통해 제안된 분석 시스템이 Smart Factory(제조 공정)에서 발생하는 대용량 센서 데이터 실시간 분석에 기여할 수 있음을 확인하였다.",
		"KEYWORD": "Real-time Streaming,Smart factory,Spark,SQL"
	},
	{
		"ID": 289,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울과학기술대학교 IT정책전문대학원",
		"TITLE": "동시인용분석을 활용한 빅데이터 연구 동향 탐색 =Exploring the big data research trend with co-citation analysis ",
		"AUTHOR": "권신혁",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이학연",
		"STORE_LOCATION": "서울과학기술대학교 도서관",
		"ABSTRACT": "최근 빅데이터 분야가 4차 산업혁명의 핵심 기술로 인식됨에 따라 기업과 학계에서 빅데이터에 대한 연구 활동과 기술 개발이 급속히 증가하고 있다. 이에 본 연구는 동시인용분석을 통해 현 시점까지의 빅데이터 관련 문헌을 분석하여 주요 연구 분야를 도출하고, 빅데이터 연구의 진화 과정을 탐색한다. 빅데이터 관련 논문의 동시 인용 관계를 바탕으로 네트워크 형태의 빅데이터 연구 지도를 생성하고, 클러스터링 분석을 수행하여 빅데이터 분야의 유망 연구 분야(research fronts)를 도출한다. SCOPUS에서 2009년부터 2016년 현재까지 “big data” 키워드가 포함된 약 2만 건의 빅데이터 관련 문헌을 수집한 후, 동시인용 분석을 통해 최종적으로 484개의 노드로 구성된 빅 데이터 연구 지도를 추출하였다. 클러스터링 분석을 통해 빅데이터의 유망 연구 분야로써 Cloud Computing, ETL(Extraction, Transformation, Loading), Privacy and Security, Big data Analytics in Social Science, Data Visualization, Data Clustering, Hadoop MapReduce, Semantic Analysis, Trends in Big Data Analytics, Pattern Recognition, Distributed Storage System, Deep Learning, Machine Learning, MapReduce Technology, Sentiment Analysis and Opinion Mining, Review and Survey of Big Data Research, Decision Tree, Online Aggregation, Overview of Big Data Analytics, Image Feature Extraction, Community Detection in Large Networks, Collaborative Filtering의 22개 군집을 도출하였다. 또한 빅데이터 수집, 빅데이터 공유, 빅데이터 저장, 빅데이터 처리, 빅데이터 분석, 빅데이터 시각화의 6개 세부 분야별로 네트워크를 구축하여 핵심 문헌을 탐색하였다. 본 연구를 통해 빅데이터 분야의 연구 현황과 기술 발전 특성을 파악할 수 있으며, 이는 기업 및 대학, 정부의 빅데이터 관련 주요 연구 과제 발굴 및 향후 연구 방향 수립에 활용될 수 있을 것으로 기대된다.",
		"KEYWORD": "Bibliometrics,Big Data,Co-citation analysis,Research fronts"
	},
	{
		"ID": 290,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "IoT 센서 기술을 적용한 빅데이터 기반 작업환경 유해인자 모니터링 시스템 개발 및 적용 방안 연구 =(A)study on development and application of evaluation system for work-expose monitoring based on big-data with IoT sensor technology ",
		"AUTHOR": "정문호",
		"REGION": "경기도",
		"PROFESSOR": "아주대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박범 참고문헌: p.91-102",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "“산업재해”란 근로자가 업무에 관계되는 건설물·설비·원재료·가스·증기·분진 등에 의하거나 작업 또는 그 밖의 업무로 인하여 사망 또는 부상하거나 질병에 걸리는 것을 말한다. 산업 재해에 관한 안전의식이 높아지고, 안전을 지킬 수 있도록 각종 보조하는 설비 등이 보조를 해 주고 있어 계속적으로 산업재해율은 조금씩 떨어지고 있는 실정이다. 하지만, 매년 안전보건공단 산하 산업안전보건연구원의 산업재해원인조사 보고서를 살펴보면 산업재해의 절대적이고, 상대적인 숫자 모두 떨어지고 있지만 산업재해로 인한 피해액은 큰 폭으로 증가되고 있는 실정이다. 산업재해에 따른 치료나 장례 보상 등의 직접적인 손실뿐 아니라, 통계에서 밝히지 않은 숙달 근로자의 상실로 인한 생산성 저하와 한 가정에 가장으로서의 노동력 상실이 가지는 가치로 인한 가족이 갖는 2차, 3차 피해 등 파생되는 추가 비용을 고려하면 산업재해를 줄이는 당위성이 크다고 하겠다. 본 연구에서는 이러한 산업재해를 줄이기 위해 다양한 사물인터넷(IoT) 센서 기반의 시스템을 이용하여 산업재해와 관련된 데이터를 수집과 분석을 하여 미리 재해 가능성을 미리 방지하는 시스템을 구축하는 것을 제안하고자 한다. 본 시스템은 소음, 누전, 가스 누출 등 다양한 위험 요소를 간단하게 구현된 시스템을 이용하여 데이터를 수집, 분석하여 관련 법률이 정하는 범위의 값이 넘어서면 경고하는 방법으로 근로자를 산업재해로부터 보호하는 시스템이다. 또한 본 연구에서는 세부적으로 중소기업에서 기본적인 저비용의 작업 환경의 모니터링, 기존의 센싱 시스템의 설치된 것을 지역 시료 채취법과 이동 시료 채취법을 적용하는 시스템, 그리고 개발도상국에서 자주 일어나는 생명을 잃는 사고인 가스나 전기 안전과 관련된 고위험 작업 환경에서의 저비용의 안전 시스템 구축에 관한 방안 등 3가지의 세부 시스템을 제안한다. 이를 통해 산업 현장에서 산업 재해 요소의 지속적인 모니터링과 알람, 경고를 통해서 산업 재해의 발생 가능성을 낮추어서 근로자의 안전한 근무환경 도모 및 산업 재해로 인한 사회적 비용을 줄 일 수 있을 것이다. 또한 본 시스템의 효과를 극대화하여 산업 재해를 줄이기 위해 본 연구에서 다룬 이외의 분야에 적용을 하고, 장기적으로 지속적인 모니터링 및 시스템 가동을 통해 효과를 더 높일 수 있을 것이라 예측된다.",
		"KEYWORD": "IoT센서,빅데이터,산업재해,작업환경 유해인자"
	},
	{
		"ID": 291,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "동국대학교 문화예술대학원",
		"TITLE": "콘텐츠산업부문 빅데이터 특성화 인력 양성 방안에 관한 연구 ",
		"AUTHOR": "이선아",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권법에 의해 보호받습니다. 지도교수: 정달영 서지적 각주 및 참고문헌(p. 55-57) 수록",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "In this study, the necessity analysis and training method of BigData expert in the Contents Industry are examined. First, we explored the characteristics and theories of the contents industry and big data technology to understand the necessity and possibility of the contents industry and big data convergence. The theoretical exploration was conducted based on characteristics of the contents industry, trend analysis, value of big data technology and data analysis method. Understanding the Theory Next, we have derived a big data application model for each stage of the content chain in the contents industry. After summarizing the current status of the use of Big Data in the domestic and overseas contents industry, I found out the necessity and value of introducing big data technology into the contents industry. Next, we analyzed the keywords of `Seoul Arts Center`, and found out the importance of value selection. The analysis has been conducted twice in total and proved that understanding of the contents industry is necessary for valuable data extraction. After analyzing the impact of big data in the contents industry, we have summarized the obstacles to introducing big data. Barriers include big data technology perception, big data technology education, and contents industry image issues. The measures to overcome the obstacles suggested transition of big data related awareness, strengthening of big data education, and influx of big data experts. As for the big data related perception conversion method, we refer to the medical industry and the financial industry, which are big data advanced industries. The two industries spontaneously pursued the policy of accepting big data, while the contents industry was indifferent to the big data. We have stepped up the process of training big data experts in big data training method. It is designed to include understanding of contents industry in curriculum. Based on the above analysis, it is urgent to recognize the contents agencies and workers to nurture the big data manpower for contents industry. In addition, in the contents industry, it is necessary to take aggressive efforts to find out the people who are willing to engage in the contents industry among the big data experts. In the future, it will be necessary to establish a department for the training of big data analysts who are specialized in contents industry and study the curriculum. If you systematically train contents industry data analysts for four years in college, it will be easier to predict content market and find content creation materials. If people engaged in the contents industry are actively studying big data and expanding policies to cultivate human resources, it will be possible to foster big data professionals specialized in the contents industry.",
		"KEYWORD": "빅데이터,콘텐츠산업"
	},
	{
		"ID": 292,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 기술경영전문대학원",
		"TITLE": "빅데이터 기술이 플랫폼 비즈니스 혁신에 미치는 영향 =(The)impact of bigdata technology to the platform business innovation ",
		"AUTHOR": "최승혁",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金永埈 참고문헌: 장 81-84",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "인터넷과 스마트폰이 등장한 이후 세상은 하루가 다르게 급변하고 있다. 인터넷이 등장하면서 Network과 Open을 기반으로 수많은 정보들이 폭발적으로 생겨나고 있고 스마트폰으로 인해 시공간의 제약 없이 다양한 정보들을 실시간, 양방향으로 소통하며 편익을 제공하고 있다. 이런 환경 변화에 따라 다양한 새로운 서비스들이 생겨나고 있다. 특히 과거에는 인식하지 못했던 잠재적 가치들을 발굴하여 이를 다수의 공급자와 소비자에게 직접 연결시켜주는 플랫폼 비즈니스들이 빠른 속도로 성장하고 있다. 이러한 연결형 비즈니스가 가능했던 것은 바로 네트워크 인프라 등 연결 가능한 환경이 그 기반이 되겠지만 그 중심에는 빅데이터 기술이 Key Enabler로서 큰 역할을 했다고 볼 수 있다. 미국을 중심으로 한 소프트웨어 및 인터넷 서비스 기업들은 온오프라인의 정보를 디지털화하고 빅데이터 시스템을 적극 도입하여 새로운 혁신을 이룩했을 뿐만 아니라 ICT 생태계의 주도권을 쥐고 막대한 부가가치를 창출하고 있다. 본 논문에서는 플랫폼 비즈니스 기업은 어떤 빅데이터 전략으로 무슨 혁신을 이루어내었는지 연관 관계를 살펴본다.",
		"KEYWORD": "빅데이터,플랫폼 비즈니스,혁신"
	},
	{
		"ID": 293,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "강원대학교 대학원",
		"TITLE": "하둡 기반의 빅데이터 영상 처리를 통한 차량 이동경로 추적 시스템의 설계 및 구현 =Design and implementation of vehicle route tracking system using hadoop-based big data image processing ",
		"AUTHOR": "양성은",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 최황규",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "최근 CCTV의 활용이 증가하면서 CCTV의 설치가 급증하고 있다. CCTV의 증가로 CCTV에서 수집하는 영상 데이터의 양이 폭발적으로 증가하여 점점 빅데이터로 되고 있다. 그러나 아직까지 국내 CCTV 분야에서 대규모 영상 데이터를 처리하고 활용하는 응용 시스템은 거의 존재하지 않는다. CCTV를 응용하는 차량 번호판 인식 시스템의 대부분은 데이터의 실시간 처리를 요구하며, 한꺼번에 많은 양의 영상 데이터를 처리하는 데는 한계가 있어 분산 병렬 처리가 가능한 빅데이터 기술의 적용이 필요하다. 본 논문에서는 차량 번호판 인식 시스템의 실시간 처리 방식을 보완하여 대규모 영상 데이터를 처리하는 방법으로 하둡 기반 VRT(Vehicle Route Tracking) 시스템의 설계를 제안한다. 차량 번호판 인식 기술을 결합한 VRT 시스템은 하둡의 분산 병렬 처리 기법으로 대규모 CCTV 영상 데이터를 빠르게 인식하여 차량 번호를 출력하고, 구글 맵을 통해 특정 차량의 이동경로를 추적한다. 그리고 VRT 시스템의 성능 실험으로 단일 PC와 하둡 환경의 번호판 인식 시간을 측정, 비교하였다. 하둡 환경의 데이터 노드가 32대 일 때, VRT 시스템의 처리 속도가 단일 PC보다 최대 27배 빠르게 측정되었으며, 초당 187개의 번호판을 인식 할 수 있었다.",
		"KEYWORD": "CCTV,구글 맵,빅데이터,차량 번호판 인식 시스템,하둡"
	},
	{
		"ID": 294,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "인하대학교 물류전문대학원",
		"TITLE": "빅데이터 분석기법을 활용한 택배서비스 고객의 소리 (VOC) 분석 - H사 택배VOC 자료를 중심으로 - =Home Delivery service VOC Analysis using Big Data - focusing on H company case - Home Delivery service ",
		"AUTHOR": "신정철",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 295,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "국방 빅데이터 분석 시간 예측 및 자원 최소화를 위한 하둡 시스템 제어 기법 ",
		"AUTHOR": "김보배",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정종문",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "cloud computing,Failure probability,job estimation,MapReduce,resource provisioning"
	},
	{
		"ID": 296,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "실시간 군사작전 증강현실 적용을 위한 빅데이터 Hadoop 분산플랫폼 기술 ",
		"AUTHOR": "유재명",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정종문",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "augumented reality,big-data,face recognition,Hadoop,얼굴인식,증강현실"
	},
	{
		"ID": 297,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "동국대학교 대학원",
		"TITLE": "오용 탐지 방식의 네트워크 침입탐지시스템을 위한 빅데이터 보안 이벤트 분산 처리 ",
		"AUTHOR": "한효준",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권법에 의해 보호받습니다. 지도교수: 김양우 참고문헌(p. 46-47) 수록",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "Internet-based services such as Internet of Things (IOT) and cloud computing are rapidly evolving and usage is steadily increasing. These Internet-based services process the data generated by the sensor to exchange information, or take offline server tasks to an online server for processing. As a result, a large number of packets have been generated quickly and the number of security events that administrators have to check for information security has increased dramatically. Most of the many packets coming and going to the server are normal packets. However, if you can not quickly identify and handle malicious data that may be present in a packet, it may cause leakage or serious loss of critical data. These damages are not only limited to data but also can cause financial damages, so careful management is needed. Many companies introduce intrusion detection systems to handle malicious data. Traditional intrusion detection systems are based on relational databases. A relational database stores and manages relationships between data when storing data. Relational databases have the advantage of ensuring data consistency and high performance through functions such as normalization and indexing. However, it is difficult to store and process big data because it is physically and costly to expand horizontally and vertically. Therefore, performance degradation occurs because unstructured data generated in various devices must be processed and processed. Therefore, relational databases are not suitable for handling big data security events. In this paper, we apply NoSQL, which is specialized for unstructured data and big data analysis, to intrusion detection system to solve the above problem. Because NoSQL can use a distributed processing system through horizontal scaling, it can process big dataized security events cheaply and quickly. NoSQL is also well suited to handling big data security events because it can process unstructured data without processing. Among the NoSQL with various data models, I built an intrusion detection system using MongoDB which processes the big data security events most quickly. The amount of security events that an intrusion detection system has to process varies and is unpredictable from time to time. Therefore, when the intrusion detection system is constructed in a general server environment, it may be difficult to determine the performance of the system. If you configure a low-performance system, you may not be able to react quickly when a large number of security events occur. Conversely, when configuring a high-performance system, it is difficult to manage efficiently because a large amount of resources are wasted when a small amount of security events occur. In this paper, we constructed an intrusion detection system using cloud computing environment. Cloud computing can easily lease and return resources, so it can immediately respond to the amount of security events that occasionally change and process security events quickly without wasting resources. In order to verify the superiority of the proposed MongoDB?based intrusion detection system, a prototype system of intrusion detection system based on MongoDB and an intrusion detection system based on relational database was constructed and evaluated for speediness. Therefore, it is confirmed that the performance of distributed processing intrusion detection system based on MongoDB is excellent.",
		"KEYWORD": "MongoDB,MySQL,Snort,보안 이벤트,빅데이터,오용 탐지,침입탐지시스템"
	},
	{
		"ID": 298,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한남대학교 대학원",
		"TITLE": "빅데이터 기반의 IT프로젝트 제안 평가의 가능성에 대한 연구 =A study on feasibility of evaluating IT project proposals based on big data analysis ",
		"AUTHOR": "김홍삼",
		"REGION": "대전",
		"PROFESSOR": "한남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김종수 참고문헌: p. 55-59",
		"STORE_LOCATION": "한남대학교 도서관",
		"ABSTRACT": "정부 발주의 IT 프로젝트에 대한 제안서 평가는 평가위원의 정성적 판단 기준으로 점수를 부여하는 평가 체계로 인하여 평가 결과에 대한 공정성, 신뢰성에 대해 많은 어려움을 격고 있다. 본 논문은 빅데이터 분석 기반의 오피니언 마이닝 기법을 이용하여 평가위원의 검토의견에서 제안서 평가에 영향을 미치는 주요 요인을 도출하고 인과관계를 분석한다. 이를 통해 빅데이터 기반의 IT 프로젝트 제안서 평가 방법론을 개발하는 것을 목표한다. 이를 위하여 정부 조달 기관인 조달청에서 관리되고 있는 평가 시스템에서 약 1만 건의 평가위원 검토의견과 평가 점수를 수집하였다. 대부분의 정보는 디지털 데이터 형태로 존재하지만, 종이로 되어 있는 자료도 존재 하였고, 다양한 방법을 이용하여 데이터를 수집 하였다. 수집된 데이터에 대해서는 오피니언 마이닝 분석을 위해 다양한 도구를 이용하여 데이터 사전 처리를 수행하였다. 초기 추출된 키워드로부터 제안서 평가 경험이 많은 전문가 검토를 통해 주요 요인 키워드를 추출 하였고, 이를 다시 이해력, 수행력, 관리력 3개의 차원으로 분류하였다. 이렇게 추출, 분류된 주요 요인 키워드 및 차원을 기반으로 인과관계 분석을 진행하였다. 분석 결과 다른 키워드들에 비해 계획, 전략, 기술, PM과 같은 키워드가 평가결과에 보다 큰 영향을 미치며, 차원기반 연구 모형보다는 키워드 기반 연구 모형이 인과관계 분석에 보다 적합한 모형임을 알 수 있었다. 또한 보다 정교한 한글 감정 사전 구축을 통해 검토의견을 수치화 하고, 이를 IT 프로젝트 제안 평가에 이용할 수 있는 가능성도 확인할 수 있었다. 본 연구의 결과는 향후 빅데이터 기반 IT프로젝트 제안서 평가를 진행하기 위한 기초 자료로 사용될 수 있다. 아울러 다양한 분야에서 비정형 형태로 입력된 의견을 실제 점수로 수치화 할 수 있는 방법론 수립의 기초가 될 것으로 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 299,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "빅데이터 기반의 미래 기술 탐색 연구 =Research on exploring future technology based on big-data ",
		"AUTHOR": "김현우",
		"REGION": "서울",
		"PROFESSOR": "",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "미래 기술은 기술 기반의 조직이 지속 가능한 성장을 위해 필수적으로 탐색해야 될 핵심 요소이다. 많은 연구자들에 의해 미래 기술을 탐색하는 방법론들이 개발되고 연구되어 왔으나, 대부분의 연구가 미래의 기술을 예측하는데 한정되어 왔다. 미래의 기술 트렌드를 예측하고, 이에 발빠르게 대응하는 것은 국가 차원의 과학기술정책 수립에 기여하는 바가 크지만, 그 하위 집단인 지방자치단체나 기업체의 경우, 단순히 유망한 기술을 예측하는 데에서 벗어나 해당 사용자의 역량을 바탕으로 한 맞춤형 미래 기술 탐색 활동이 필요하다. 본 연구에서는 기술 트렌드 관점과 사용자 관점에서의 미래 기술 탐색에 대해 정의하고, 이를 기반으로 빅데이터를 활용한 증거 기반의 정량적 접근법을 이용하여 맞춤형 미래 기술을 탐색하는 모델을 제시하고자 한다. 본론의 각 장에서는 지방자치단체의 관점과 기업체의 관점에서 미래 기술을 탐색하는 방법을 고찰한다. 방대한 양의 특허 데이터에 대하여 특허 네트워크 분석, 연관 규칙 분석, 링크 예측 분석 등이 실시되었으며, 최종 결과물로 맞춤형 미래 유망 산업군 및 맞춤형 미래 유망 제품군이 추출되었다. 본 연구에서 제안된 미래 신사업 발굴 및 탐색에 대한 방법은 체계적인 프로세스와 정량적 결과물을 바탕으로 시행되었다는 점에서 학술적?실무적으로 유의미한 의의를 가진다. 본 연구의 결과물이 향후 사용자 중심의 미래 과학기술 정책, 미래 기술 탐색 방법론 개발 및 실무 적용에 공헌할 수 있기를 기대한다.",
		"KEYWORD": "계량분석,네트워크분석,링크 예측,미래기술,미래기술정책,미래기술탐색,빅데이터,연관 규칙 분석,특허분석"
	},
	{
		"ID": 300,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "한국외국어대학교 대학원",
		"TITLE": "Squall: 실시간 이벤트와 마이크로-배치의 동시 처리지원을 위한 실시간 빅데이터 처리 프레임워크 =Squall: a real-time big data processing framework for real-time events and micro-batch processing ",
		"AUTHOR": "손재기",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 301,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 기술경영전문대학원",
		"TITLE": "DBMS 연계 기술이 기업의 빅데이터 시스템 도입에 미치는 영향에 관한 연구 =(A)study on the impact of the introduction of big data system of companies by DBMS connection technology ",
		"AUTHOR": "김성열",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金永埈 참고문헌: 장 45-46",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근의 IT 시장은 클라우드 컴퓨팅, 빅데이터, 모바일, IOT 기술을 축으로 하여 모든 IT기기들과 데이터가 통합되고 기술들 간의 융합으로 보다 큰 시너지를 얻어가고 있는 흐름이다. 그 중에 빅데이터는 기술이 처음 소개되고 몇 년 동안 시행착오와 함께 여러 변화를 겪어왔다. 이런 변화 가운데 관련 기술들이 자리를 잡아가고 있으며 이제는 실질적인 사업들이 준비되어 가고 있는 단계이다. 기업에서는 빅데이터를 도입하려는 가장 큰 이유는 최적화된 Information Governance을 얻고자 함이다. 이를 통해 기업은 경쟁기업 보다 빠른 의사결정을 통해 경쟁우위에 설 수 있다. 빅데이터가 이런 이점을 기업에게 줄 수는 있지만 기업에서는 여러 장애 요소로 인해 쉽게 빅데이터 시스템을 쉽게 도입할수 가 없었던 것이 사실이다. 본 연구는 기업의 빅데이터 시스템 도입에 장애로 지적되어 온 높은 기술장벽, 개인정보 보호규정, 전문가 부재 문제에 대한해결 방안으로 DBMS와의 연계를 제시한다. 제시된 DBMS와 빅데이터 간의 연계 기술이 기업의 빅데이터 시스템 도입에 어떤 영향을 미치는지를 검증하고, 또한 빅데이터 시스템 도입 프로젝트에서 표준기술로 채택 가능 여부를 검증하고자 한다. 그 분석 결과로써 DBMS 연계기술이 빅데이터 시장에 어떤 영향을 미치는지를 파악할 수 있고, 빅데이터 시스템을 도입하려는 기업에게 향후 빅데이터 기술 아키텍처에 대한 시사점을 제공하는 것이 목표이다.",
		"KEYWORD": "bigdata,DBMS 연계기술"
	},
	{
		"ID": 302,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "R을 이용한 빅데이터 분석에 관한 연구 =(A)study on big data analysis using R ",
		"AUTHOR": "알리야곱",
		"REGION": "전라북도",
		"PROFESSOR": "지도교수: 황인수 참고문헌: p. 56-59",
		"STORE_LOCATION": "전주대학교 도서관",
		"ABSTRACT": "As an area that is of the interested target in almost industries, big data is not just a new basic data that has never existed before but it can be described as a new start of real problem solution by utilizing various types of mass data accumulated from the internet, SNS, ICT (Information, and Communication Technology) etc. Economically, according to its high potential advantage, big data has been spreading throughout medical science and technology. In the proportion to the expansion of the demand for big data analysis, the complexity of techniques and methods for big data analysis has been increased as well. Therefore, in most of the big data analysis studies, generally, propose new techniques and methods. In this research, R open source programming language has been used to analyze the National Health and Nutrition Examination Survey in 2013 based on big data. After describing the technical concepts and components, features, processing technology, analysis method, visualization tools etc., R’s statistical analysis functions, and visualization function have been implemented. Then, we analyzed the association rules on diabetes and lifestyle’s habit, smoking, drinking, sex, age, sleep and so on. Finally, we presented the result in a text format. Also, we visualized the association between lifestyle habits with diabetes and proposed a decision tree model as well. As a result, a major effect of diabetes issues was found to be age-related and lifestyle-related such as sleeping, drinking, and smoking. Especially, as sleeping has been analyzed as the most important factor, it is required an aggressive examine and treatment of diabetes.",
		"KEYWORD": "프로그램"
	},
	{
		"ID": 303,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "건국대학교 정보통신대학원",
		"TITLE": "빅데이터 기반 비즈니스 인텔리전스 시스템의 정보 보호를 위한 감리 프레임워크 연구 =Audit of framework research in order to maintain the quality of the data security which is the business intelligence based on bigdata ",
		"AUTHOR": "윤석용",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 서희명",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "기업들이 치열한 경쟁 환경에서 축적한 상당기간의 대량 데이터를 기업의 의사결정에 유용한 정보로 가공하여 활용하는 능력은 기업의 경쟁력이다. 많은 기업들이 전사적 자원 관리(Enterprise Resource Planning)를 도입하여 경영활동을 통해 발생하는 데이터를 유기적으로 연계, 관리하고 입력된 정형화된 정보를 제공하고 있다. 최근 기업은 데이터에 접근， 가공， 분석，공유를 통해 기업의 의사결정을 지원하고 더 발전된 사용자의 환경에 빠른 정보를 제공하기 위해 비즈니스 인텔리전스(BI, Business Intelligence)를 도입하고 있다.[1] 이러한 비즈니스 인텔리전스는 웹 2.0의 등장으로 기존의 호스트 중심의 웹으로부터 사용자 참여 중심의 웹 환경으로 변화됨에 따라 그 정보의 생산 속도가 점차 가속화되어 가고 있다. 특히 트위터나 페이스북과 같은 소셜 네트워크를 기반으로 한 서비스들이 일상화 되고, 적극적인 참여 의도를 가진 사용자가 늘어남에 따라 사용자에 의해 생성되는 데이터와 활동 기록으로 인해 엄청난 규모의 데이터가 생성되고 있다. 2014년 조사된 자료에 따르면 트위터는 하루에 2억3.000만 개의 트위터 메시지를 생성하며 계정이 무려 2억 개 이상이나 된다. 또한 인터넷에서 보다 빠르게 정보를 확산시키고 축척시키는 또 다른 요인 중 하나는 인터넷에 상시 연결이 가능한 스마트폰이라 불리는 모바일 기기의 보급이다. 실례로 페이스북에 접속하는 사용자의 과반수 이상이 모바일 애플리케이션을 통해 접속하고 있다. 이와 같이 디지털 환경에서 사용자의 참여 기회가 증가되고, 보다 쉬운 접속성을 가진 IT기술의 발전으로 인해, 데이터의 양이 급속히 증가하고 있다. IDC 디지털 유니버스(IDC Digital Universe)의 보고서에 따르면 2011년에 생산되고 복제된 정보의 양이 1.8제타바이트(Zettabytes)에 달하고 있으며, 매 2년마다 그 양이 2배씩 증가하고 있다. 이러한 엄청난 양의 데이터의 축적은 웹에서뿐만 아니라 일반적인 기업에서도 현재 동일하게 발생하고 있다. 시만텍(Symantec)의 보고서에 따르면 많은 산업영역에서 2012년을 기준으로 기업들의 평균 저장된 데이터의 양이 2.2페타바이트(Petabytes)에 이르는 것으로 조사되었다. 이와 더불어 수백만 개의 네트워크 구조로 연결되어 정보를 생산해내는 센서 영역과 게놈 지도와 같은 의료 및 공공의 영역 등 다양한 영역에서 현재 방대한 양의 데이터가 축적되고 있다. 이상에서 기술한 것과 같이 경제 사회 영역을 비롯하여 다양한 영역에서 엄청난 양의 정보가 축적되어 왔으며, 또한 새롭게 생성되고 있다. 이에 따라 최근의 BI 시스템은 단기간 활용되거나 한 번의 구축으로 종료되는 시스템이 아니라 기업의 비즈니스 요건과 사용자의 요건에 맞춰 EUC(End User Computing), 하둡(Hadoop)를 직접 연결하는 빅데이터 기반의 BI 시스템 또한 많이 등장하고 있다. BI시스템의 빅데이터 기반으로 하는 비즈니스 인텔리전스 시스템은 기업의 정보 및 개인정보 등을 다루게 되며 BI시스템의 특성상 노출될 수 있는 불안 요소가 존재한다. 즉 기업이 보유한 개인정보는 정보사회에서 중요한 경제적 가치를 갖고 있는 재화로서의 의미를 갖고 있을 뿐만 아니라, 다양한 정보 중에서도 정보주체의 인격권 보호와 사생활의 자유를 보장하는데 있어서 출발점으로서의 의미 또한 갖고 있다. 이러한 개인정보의 이중적 의미는 기업의 영업활동 보장과 정보주체의 인격권 보호라는 두 가치를 상충적인 관계로 설정한다. 즉, 기업의 개인정보 활용은 정보주체의 인격권을 침해하는 부작용을 낳게 되고, 반대로 정보주체의 개인정보보호는 기업의 영업활동을 제한하게 된다. 따라서 많은 기업이 빅데이터를 통하여 BI시스템을 구축하는 과정에서 개인정보를 다루는 일이 많아지며 이는 새로운 정보유형을 이용한 정보산업의 발전과 막대한 경제적 가치 창출을 이룰 수 있다 따라서 BI 시스템은 정보시스템으로 분류되어 효율성을 향상시키고 안정성을 확보하기 위하여 정보시스템 감리를 수행하고 있으며 감리기준에는 사업에 대한 기능성, 준수성, 효율성, 보안성, 안전성 등 여러 가지 감리 관점에 따라 세부 검토 항목을 제시하고 있다. 이러한 지침에는 정보보호에 관련된 점검항목이 부족한 경우가 많다 전통적인 BI시스템의 경우 마트의 데이터를 사용하기 때문에 DW에 의존하였지만 빅데이터 기반의 BI시스템의 경우 데이터를 직접 가공하고 추출하는 특성상 세부적인 개인정보를 가공하거나 민감한 비즈니스 정보를 취급하게 된다. 따라 체계적인 보안 감리가 필요하며 감리 점검항목의 일관성과 적절한 보안 투자가 필요한 상황이다. 본 연구는 BI 시스템이 빅데이터 시대를 맞아 갖춰야 할 요건을 살펴보고 BI시스템의 정보시스템 보안 감리프레임워크 및 기업(조직)이 각종 위협으로부터 주요 정보자산을 보호하기 위해 수립ㆍ관리ㆍ운영하는 종합적인 체계(정보보호 관리체계)의 적합성에 대해 인증을 부여하는 제도인 ISMS를 기반으로 보안점검 항목을 도출하여 보안 취약점을 제거함으로써 시스템의 안정성 및 신뢰성을 확보하여 품질을 향상을 위해 하는데 목적이 있다",
		"KEYWORD": "감리,비즈니스 인텔리전스,정보시스템"
	},
	{
		"ID": 304,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "동국대학교 국제정보대학원",
		"TITLE": "오픈소스 기반의 빅데이터 보안로그 분석시스템 구축에 관한 연구 :(A)study on construction of bigdata security log analysis system based on opensource :위험징후 탐지 시나리오를 중심으로 =focusing on scenario of security threat detection ",
		"AUTHOR": "유근영",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권법에 의해 보호받습니다. 지도교수:신수정 인터넷 배포 반대(사유:업무관련 내용이 있어 외부공개가 어렵습니다)",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "",
		"KEYWORD": "보안로그,빅데이터"
	},
	{
		"ID": 305,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "빅데이터 분석에 의한 유방암에 특이적 microRNA 발굴 및 검증 =Big data mining and validation study of microRNAs as a potential target for breast cancer prevention ",
		"AUTHOR": "정수지",
		"REGION": "전라북도",
		"PROFESSOR": "부록 지도교수:이정상 참고문헌: p.34-39",
		"STORE_LOCATION": "전주대학교 도서관",
		"ABSTRACT": "The known classes of tumor suppressor genes and oncogenes have recently been expanded to include the microRNA (miRNA) family as small non-coding molecules. The miRNAs negatively regulate the stability and translation of target messenger RNAs (mRNA) by selectively occupying. Also it has been implicated in diverse processes such as cellular differentiation, cell-cycle control, apoptosis, and carcinogenesis. Examination of tumor-specific miRNA expression profiles has revealed wide spread dysregulation of these molecules in diverse cancers. Although studies addressing their role in carcinogenesis are at an early stage, it is apparent that loss- or gain- of-function of specific miRNAs contributes to cellular transformation and carcinogenesis. The available genomic bulk evidences were extracted from The Cancer Genome Atlas (TCGA) by using IluminaGA_miRNASeq platform in human breast cancer patient samples. After mining among collected data, group of each miRNA ID was analyzed through five D/Bs (RNA22, miranda, mirDB, mirWalk, and TargetScan) on predicted and validated miRNA targets. Then, the correlation between the target gene and miRNA ID was double-checked throughout the published papers. In previous research, oncogenes known to have a high correlation with breast cancer related oncogenes (BRCA1, BRCA2, Cyclin D1, N-RAS, FGF-3, FGF-4, c-Myc, HER2) and those oncogenes are subject in this study to select relevant miRNA. Research method is not only applied to breast cancer, can be applied to select relevant miRNAs in several other tumors and cancers. Function of miRNA regulation will be essential to achieve a complete understanding of carcinogenesis and these miRNAs would be potential target for breast cancer prevention. Keyword : Breast cancer, microRNA, data mining, Chemoprevention, targetgene",
		"KEYWORD": "내과학"
	},
	{
		"ID": 306,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 정보경영공학전문대학원",
		"TITLE": "빅데이터 로그를 이용한 실시간 예측분석시스템 설계 및 구현 =Real time predictive analytic system design and implementation using bigdata-log ",
		"AUTHOR": "이상준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 李東勳 참고문헌: 장 54-55",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "빅데이터는 미래 경쟁력을 좌우하는 21세기 원유로 비유되고 있으며, 기업들은 다가오는 데이터 경쟁시대를 이해하고 이에 대비해야 한다며 가트너는 기업의 생존 패러다임에 많은 변화를 요구하고 있다. 또한 통계 알고리즘 기반의 예측분석(Predictive Analytics)을 통한 비즈니스 성공 사례들이 발표되면서, 과거 데이터 분석에 따른 사후 조치에서 예측 분석에 의한 선제적 대응으로의 전환은 앞서가고 있는 기업의 필수품이 되어 가고 있다. 이러한 경향은 보안 분석 및 로그 분석 분야에도 영향을 미치고 있으며, 실제로 빅데이터화되고 있는 대용량 로그(빅데이터 로그)에 대한 분석과 지능화, 장기화되고 있는 보안 분석에 빅데이터 분석 프레임워크를 활용하는 사례들이 속속 발표되고 있다. 그러나 빅데이터 로그 분석 시스템에 요구되는 모든 기능 및 기술들을 하둡 기반의 빅데이터 플랫폼에서 수용할 수 없는 문제점들이 있어서 독자적인 플랫폼 기반의 빅데이터 로그 분석 제품들이 여전히 시장에 공급되고 있다. 본 논문에서는 이러한 독자적인 빅데이터 로그 분석 시스템을 위한 실시간 및 비실시간 예측 분석 엔진을 탑재하여 사이버 공격에 선제적으로 대응할 수 있는 프레임워크를 제안하고자 한다. 또한 제안 시스템의 활용 사례를 소개하고, 그 중에서도 프로파일링 기법에 활용하는데 있어 회귀분석이 적합함을 측정 및 분석을 통해서 제시하고자 한다.",
		"KEYWORD": "Advanced bigdata analytics,Bigdata,Log Management,Predictive analytics,Preemptive Countermeasure,Regression Analysis"
	},
	{
		"ID": 307,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "빅데이터 처리 프로세스의 위험요인에 관한 연구 =(A)study of risk factors for big data processing ",
		"AUTHOR": "이지은",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 빅데이터 도입으로 긍정적인 결과를 얻음으로써 빅데이터 활용 가치가 높이 평가되고 있다. 따라서 빅데이터를 활용하여 이윤을 창출하고자 하는 기업 및 기관이 점차 증가하고 있다. 그러나 빅데이터로 인해 발생 가능한 위험에 대해서는 의식과 인지가 부족하다. 또한 구체적 이론연구도 미미한 실정이다. 따라서 본 연구는 빅데이터에 관한 위험요인을 심층적으로 파악함으로써, 효율적인 빅데이터 활용을 위한 고려요인을 분석한다. 향후 성공적인 빅데이터 구축과 활용을 위해 빅데이터 처리 프로세스의 위험요인을 최소화하고 최적화하기 위한 방향을 제시하고자 한다. 모델을 설정하기 위해 기존 빅데이터 관련 문헌연구를 통해 위험요인을 도출하고 개념을 정립한다. 추출한 요인은 빅데이터 처리 프로세스인 데이터 수집, 데이터 저장, 데이터 분석, 분석 데이터 가시화 및 활용 별로 발생할 수 있는 위험요인을 분류한다. 설정된 모델은 전문가 대상으로 설문조사를 통한 결과 값을 분석하여 모델의 신뢰성을 확보한다. 또한 위험요인의 우선순위를 평가하기 위해 실질적인 위험도를 부여하여, 프로세스별 도출된 위험요인과 위험도를 파악한다. 연구결과, 빅데이터 처리 프로세스 4개 영역에 25개의 위험요인을 도출하였으며, 전체 프로세스에서 발생할 수 있는 공통 위험요인 3개를 도출하였다. 따라서 본 논문을 통해 실제 빅데이터 활용 현장에서 빅데이터의 위험에 인지하고 위험도에 따라 순차적 회피를 할 수 있는 기회를 제공한다.",
		"KEYWORD": null
	},
	{
		"ID": 308,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "HiL 테스트 기반 CAN 통신을 이용한 차량용 빅데이터 수집 기법 =(A)method for collecting big automotive data using CAN bus in HiL test environment ",
		"AUTHOR": "이정우",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이정원",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "차량용 전자장치에 탑재되는 소프트웨어의 크기와 복잡도가 증가함에 따라 주변 하드웨어와의 상호작용을 통해 기능들이 적절히 구현되었는지 확인하기 위해 Hardware-in-the-Loop(HiL) 테스트를 수행한다. 하지만 HiL 테스트는 블랙박스 테스트로 진행되며, 일반적인 디버깅 포트의 활용이 보장되지 않아 보편적인 디버깅 기법을 활용할 수 없다. 이때, 모든 Electronic Control Unit(ECU)에서 사용하는 통신 포트인 Controller Area Network(CAN)을 이용하여 프로그램이 메모리를 사용하는 현상을 관찰하여 디버깅 정보로 활용할 수 있다. 하지만 만약 32KB 크기의 메모리를 10ms의 주기로 관찰할 경우, CAN으로 전송할 수 있는 데이터의 크기는 1.25KB로, 매 주기마다 약 96%의 데이터가 손실된다. 따라서 이를 극복하기 위하여 본 논문에서는 CAN 통신으로 ECU의 메모리에서 발생하는 대용량의 데이터를 외부로 전송하기 위해 우선 통신 환경을 고려하여 메모리를 여러 영역으로 분할한다. 그 다음, 분할된 영역만큼 시뮬레이션을 반복하여 각 시뮬레이션이 수행될 때마다 서로 다른 영역을 관찰하여 데이터를 수집한다. 본 논문에서 제안하는 방법을 통해, CAN 통신을 이용하여 HiL 테스트가 수행중인 ECU와 Host PC에 데이터 전송 및 수집을 위한 모듈을 설계하여 탑재하였고, 테스트를 수행하며 생성되는 대용량의 메모리 데이터를 매 주기마다 수집하였다. 수집된 데이터는 일반적인 디버거를 활용하여 임의의 시간에 캡처된 메모리와 수집된 데이터를 비교하여 검증을 수행하였고, 그 결과 손실 없이 성공적으로 수집됨을 확인하였다. 이를 이용하여 데이터를 취득 후 추후에 적절히 가공한다면, 추가적인 시스템 자원의 활용과 하드웨어의 수정이 제한적인 HiL 테스트 환경에서 개발자에게 디버깅에 활용할 수 있는 정보를 제공할 수 있다.",
		"KEYWORD": "Controller area network (CAN),Hardware-in-the-Loop (HiL) 테스트,데이터 수집,차량 소프트웨어 테스팅,차량용 데이터"
	},
	{
		"ID": 309,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "전북대학교 대학원",
		"TITLE": "빅데이터 순환 처리 응용을 위한 MapReduce 기반 분산 시스템의 설계 및 구현 =Design and implementation of a MapReduce-based distributed system for iterative processing applications on big data ",
		"AUTHOR": "장성재",
		"REGION": "전라북도",
		"PROFESSOR": "전북대학교 논문은 저작권에 의해 보호받습니다. 지도교수:장재우 참고문헌 : p.32-37",
		"STORE_LOCATION": "전북대학교 중앙도서관",
		"ABSTRACT": "Recently, the growing of scientific technique and information technology demand for large-scale data mining and data analysis applications has led both industry and academia to design new types of highly scalable data-intensive computing platforms. MapReduce programming model is a popular platforms in which the dataflow has takes the form of a directed acyclic graph of operators. This platforms lack built-in support for iterative programs, which arise naturally in many applications including data mining, web ranking, graph analysis, model fitting, and so on. On the other hand, MapReduce programming model has simplified the implementation of many data parallel applications. The simplicity of the programming model and the quality of services provided by many implementations of MapReduce attract a lot of enthusiasm among distributed computing communities. However, many data analysis techniques require iterative computations, including PageRank, HITS (Hypertext-Induced Topic Search), recursive relational queries, clustering, neural-network analysis, social network analysis, and network traffic analysis. These techniques have a common trait: data are processed iteratively until the computation satisfies a convergence or stopping condition. The MapReduce framework does not directly support these iterative data analysis applications. Instead, programmers must implement iterative programs by manually issuing multiple MapReduce jobs and orchestrating their execution using a driver program. This paper design and implement MapReduce-based Distributed System for Iterative Processing Applications which is a modified version of the Hadoop MapReduce framework designed to serve these applications. This system not only extends MapReduce with programming support for iterative applications, but also dramatically improves their efficiency by making the task scheduler loop-aware and by adding various caching mechanisms. I evaluated our distributed system on three typical iterative applications.",
		"KEYWORD": "Cloud Technologies,Iterative Algorithms,MapReduce,Parallel Programming"
	},
	{
		"ID": 310,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "통계적 방법을 활용한 반복적 연관성 분석 프레임워크에 관한 연구 :모바일빅데이터를 중심으로 ",
		"AUTHOR": "김주성",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임춘성",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "최근 빅데이터는 IT 뿐만 아니라 기업, 사회, 국가 전반의 의사결정에 중요한 화두로 떠오르고 있다. 다양한 분야에서 천문학적인 숫자의 빅데이터들이 쏟아져 나오고 있으며, 이를 분석하여 비즈니스나 의료, 공공 사업의 의사결정의 기준으로 삼으려는 일련의 노력들이 진행 중이다.하지만, 이러한 빅데이터들로 부터 의사결정에 필요한 인사이트를 찾아내기 위해서는 다양한 분야의 경험과 창의력, 수학 및 통계적 지식뿐만 아니라, IT 기술 모두를 잘 이해하고 있는 데이터 과학자들의 힘이 필요하다.본 논문에서는 빅데이터를 통해 얻어지는 인사이트를 몇몇 소수의 데이터 과학자들에 의존하기 보다, 자동화된 방법으로 찾아내는 프레임워크를 제안하고 구현하였다. 본 논문에서 제안하는 프레임워크를 ‘반복적 연관성 분석 프레임워크(ICAF: Iterative Correlation Analysis Framework)라 명명하였으며, 모바일 어플리케이션에서 발생하는 빅데이터를 대상으로 사전에 설계되지 않은 빅데이터들 간의 연관성을 반복적으로 찾아내는 실험을 하였다.그 결과 실험에 사용한 어플리케이션의 경우 광고의 게시 시기나 시간대의 조정을 통해 매출을 향상시킬 여지가 있다는 점과 안드로이드나iOS 등 운영체제의 변경에 빠르게 대응 하는 것이 비즈니스 적으로 큰 의미를 갖지 않으므로 특별한 오류 수정 이외에 별도의 작업의 우선순위는 높지 않다는 점, 신규 사용자의 증가가 고정 사용자로 전환되지 않고 있으므로 보다 편리하고 직관적인 사용자 환경으로의 개선이나 적절한 사용법 안내를 제시하는 것이 고정 사용자 확보에 도움이 된다는 정보를 얻을 수 있었다.[핵심 되는 말]빅데이터, 연관성 분석, 프레임워크, 모바일, 어플리케이션, 사용성, 통계적 방법, 일원 분산 분석",
		"KEYWORD": "application,big data,correlation (association) analysis,framework,mobile,one-way ANOVA,statistical method,usability,모바일,빅데이터,사용성,어플리케이션,연관성 분석,일원 분산 분석,통계적 방법,프레임워크"
	},
	{
		"ID": 311,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "청주대학교 대학원",
		"TITLE": "Efficient integration of NoSQL databases and third party big data solution =NoSQL 데이터베이스와 제삼자 빅데이터 솔루션의 효율적인 통합 ",
		"AUTHOR": "AaronNichie",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 312,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서강대학교 언론대학원",
		"TITLE": "고급 찌라시와 기존 매체의 의제 유사성 :Text mining을 통한 고급 찌라시와 뉴스 콘텐츠 빅데이터 분석을 중심으로 ",
		"AUTHOR": "배소명",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임종섭 참고문헌 수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Advanced rumors have a huge impact on society. However, there is a constant controversy over the selection of advanced rumors. The ripple effect is similar to those of the existing media. Advanced rumors can also be viewed as a para-news media, or media outlet that delivers and exchanges information and distributes specific information and issues. The press agenda becomes increasingly similar as it is shared among the media. Through the analogy of the agenda, we discuss whether advanced rumors training can be media. The research has been conducted on the subject of traditional media outlets, which were established by conventional media outlets and the media, but the illegal content is excluded from the subject. The distinction criteria for the medium were derived from the polling Council in 2015 to extract the advanced milestones for the accuracy of the thesis comparison. The data for analysis included the six most frequent issues derived from 133 high-quality advanced rumors and 7,000 stories from newspapers, television, and Internet-only media. The data consisted of 1.3 million keywords. This study extracted the most frequent nouns by using the Korean Morphological Analyzer and visualized them with WordCloud. Specifically, the rankings of the contents were compared between the rumors and the news media, and their spearman correlation coefficients were calculated. Out of 36 correlations, 38% were significant. Keywords of newspapers were the most frequently correlated with those of the rumors, followed by Internet-only media and television. Among the news media, 83.3% of the keywords were significantly correlated with one another. Politics constituted 58.3% of the keyword agendas covered by bois th the rumors and news media, while there was no economic agenda. Politics constituted 75.0% of the keyword agendas covered by the news media and economics was the common agenda covered by the news media. This is a timely study given that advanced rumors have such impact on the public opinion of the overall society that people need to evaluate the implications of its impact.",
		"KEYWORD": null
	},
	{
		"ID": 313,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Bitrate and task scheduling for multimedia big data analysis in mobile clouds =모바일 클라우드에서의 멀티미디어 빅데이터 분석을 위한 비트레이트와 작업 스케줄링 ",
		"AUTHOR": "Choi,ByeongOk",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 314,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "Analysis of the relation between land moisture and land surface temperature using big data =빅데이터 자료를 이용한 지표온도와 토양수분의 관계 분석 ",
		"AUTHOR": "KyoungjinSeong",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 315,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "공주대학교 대학원",
		"TITLE": "Molecular genetic study in Pakistan epilepsy patients by exome big data analysis =엑솜 빅데이터 분석을 이용한 파키스탄 뇌전증 환자의 분자유전학적 연구 ",
		"AUTHOR": "유다혜",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 316,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "초등돌봄교실 정책이슈의 출현과 변동과정 분석 :빅데이터 분석 및 소셜 네트워크 분석을 중심으로 ",
		"AUTHOR": "양윤정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신현석 부록: 1. 초등돌봄교실 관련 검색 화제어, 2. 데이터 정제 후 시기별 언론자료 수, 3. 워드 클라우드 통계량 외 참고문헌: p. 145-160",
		"STORE_LOCATION": "고려대학교 도서관",
		"ABSTRACT": "Abstract Analysis of the Emergence and Change Process of Policy Issues in Elementary Aftercare Classroom : Focusing on Big Data Analysis and Social Network Analysis Yang, Yoon-Jung Department of Education Graduate School Korea University Advised by Prof. Shin, Hyun-Seok The purpose of this study is to analysis policy issues in elementary aftercare classroom, to examine how the policy issues of aftercare program in elementary school is emerging in the media and to suggest policy implications. The elementary aftercare classroom is a policy that reflects the change of social paradigm and demands for child care by the transition of the welfare society. As the socialization of care accelerates, the demand for policy implementation of the elementary aftercare classroom is increasing, and the importance of the operation of the elementary aftercare classroom becomes more and more important as the social necessity grows. However, due to the uncertainty of the specific issue of the elementary aftercare classroom, the emphasis on the justification of the policy has been emphasized and the viewpoints about various problems in the policy implementation are not diversified. Therefore, it is necessary to examine what is required for the policy for better quality policy implementation and service provision, focusing on policy issues. In the past, it was difficult to reflect social demands, but recently, science technology and information devices have been developed. So the policies that reflect the social needs of the public can be implemented. Various social demands are not reflected smoothly, and sometimes policy issues are create conflict situations. In the elementary aftercare classroom, policies are implemented reflecting these social changes and demands, but various issues have arisen due to the urgent expansion of the quantitative scale according to the necessity of the policy. From this point of view, this study analyzed what is the policy issue of the elementary aftercare classroom in the media, how the policy issues appear in the policy issue network, and how the policy in elementary aftercare program has been changed according to changes in policy issues in elementary aftercare classroom. As a research method, Big Data Analysis method and Social Network Analysis method were applied to analysis of policy issue and policy issue network for analysis of policy issue in elementary aftercare classroom. The research data used in the analysis are the policy data of the elementary aftercare classroom reported by the Ministry of Education and the articles related to the elementary aftercare classroom reported by the media. As the results of the analysis of policy issues, ‘budget’ and ‘expansion’ policy issues in the elementary aftercare classroom on word cloud analysis and appearance frequency analysis and trend analysis were highest in each analysis result and showed high trend change. In analysis of policy issues network in the elementary aftercare classroom, ‘Enforcement Decree’ is located at the center as the results of centrality analysis, so that the connection relation with other policy issue is closely related. The ‘expansion’ policy issue from the results of closeness analysis in the elementary policy issue network appeared as high impact issue. The results of the sub-group analysis could be divided into two groups: the operation such as ‘the five-day workweek’, ‘caring dedicated’, and the management such as ‘education budget’ and ‘competitiveness’. In addition, the elementary aftercare classroom policy issues were analyzed to be highly influenced by social factors, and the social interest in policy issues. And the policy issues on the operation of elementary aftercare classroom, it is analyzed that contents and meaning may be different by the time of media report even though the policy issue is the same word. Furthermore, the policy issues in the elementary aftercare policy network has a great meaning of the other policy issue linked with the social issues and social problems that occur at the related policy issues. And it was analyzed that it influenced the content and meaning of the media reports on the control of policy issues according to the policy and policy direction of elementary aftercare classroom at that time. These results are also reflected in policy changes due to the elementary aftercare classroom policy issues. The process of change in the elementary aftercare classrooms changed according to the emergence of new policy issues or relation with another related policy issues. Therefore, the policy issue have words of constant expression such as ‘budget’ and ‘expansion’, and there are words that appear according to social demands such as ‘the five-day workweek’ and ‘vacation’, and other words that appear according to social problems such as ‘weather’ and ‘MERS’. Also, the elementary aftercare classroom policy issues showed changes in policy issues at each stage of raising, discussion, progression, and transformation. At the stage of progression, the policy-making element is the social significance, social maturity, complexity and technicality. And as depending on whether or not the policy-making elements are satisfied, the elementary aftercare classroom policy issue has been changed like annulled, shelved, influence on policy or become a new policy. The conclusions drawn from the analysis of policy issues in the elementary aftercare classroom are as follows. First, the emergence and change process of the elementary aftercare classroom policy issue proceed in a cyclical structure. From 2011 to 2016, the elementary aftercare classroom policy issues that appeared in the media appeared and spread according to the cyclical structure, and they were structurally transformed, reflecting policy changes and policy changes. Structural transformation appeared in four stages of raising, discussion, progression, and transformation. The emergence of the policy issues was made according to social change and social demands at the stage of raising. It was confirmed that social change and demands influenced the elementary aftercare classroom policy issues through the operation of elementary aftercare classroom, support the children for low-income families and single-parent families, and expansion of the elementary aftercare classrooms due to increase in double-income families. In the discussion stage, it is appeared the dispersion of the elementary aftercare classroom policy issue through the intervention of the government and the media. In the stage of progression, it was confirmed whether or not the elementary aftercare classroom policy issues met the elements for policy making according to the social significance, social maturity, complexity and technicality. In the transformation stage of the elementary aftercare classroom, the policy issues were transformed due to be dissipated, be shelved, influence on policy or become a new policy. However, despite of the policy issue change in a cyclical structure there were announced the policy constantly to solve the occurred problem not because of considering the disparity between the intrinsic purpose of the elementary aftercare classroom and the reality that occurred during the implementation process. Therefore, when examining the elementary aftercare classroom policy issues, it should be approached from the viewpoint of child care and education in order to meet the policy objectives while taking into the policy issue change and the cyclical structure. Second, the elementary aftercare classroom policy issue implies characteristics of social significance, social maturity, complexity and technicality. Based on the results of the analysis of the policy issues and the policy issue network in the elementary aftercare classroom, the elementary aftercare classroom policy issues are reflected the social significant such as the change to the welfare society and the concern of the care deficit because of the change of the family form-‘double income families’, ‘low income class’, ‘multicultural families’. It also reflects social issues such as ‘MERS’ and ‘temporary holidays’. Policy issues such as ‘caring lecturer’, ‘caring workforce’, ‘caring dedicated’, ‘NURI curriculum’, and ‘traffic safety’ showed a small number of appearances but gradually increased to reflect social maturity to some degree. In the case of ‘the five-day workweek’ and ‘NURI curriculum’, they are the policy issue that are not directly related to the elementary aftercare classroom, but the effect of the policy is influencing the elementary aftercare classroom as well. Meanwhile, the results of this study also suggest that the policy issue characteristics of the elementary aftercare classroom policy issues are closely related to the policy reflection. Because the satisfaction of the elements of the policy issues-the social significance, social maturity, technical of the issue- means that the elementary aftercare policy issue are appropriate as policy issue. Third, the role of media in the process of dispersion of the elementary aftercare classroom policy issues appeared to be very big and it was determined whether the elementary aftercare classroom policy issues were reflected the policy according to media interest. In other words, depending on whether the policy issues were reported in the media or not, the social significant and maturity of the policy issues appeared. And it was determined whether or not influence on the policy change. The issues with higher frequency in media are more comprehensive and ambiguous like ‘expansion’, reflecting social changes and demands. The policy issues related to the elementary aftercare classroom such as ‘caring dedicated’ and ‘NURI curriculum’ changed their positions in the elementary aftercare classroom policy issue network depending on whether they were reported by the media, and the results on reflection of the policy was changed. As the result of analysis of the reported by the media, it is possible to understand clearly what the elementary aftercare classroom policy issues are, why they appear, how they relate to other policy issues, and how they are changing. It is also possible to draw up policy issues and other policy issues related to the policy issues. Therefore, when analyzing the elementary aftercare classroom policy issue, it is necessary to look at related issues and solution, focusing on the policy issues that appear in the policy issue network other than frequency of occurrence or trend analysis and the group of policy issues. In conclusion, the elementary aftercare classroom policy issues are closely related to the media and the policies that reflect social needs and social interests and demands. The purpose of the elementary aftercare classroom for social changes and demands, and the policy characteristics of ‘welfare’ and ‘childe care’ are reflected in the policy issues. As these purpose and the characteristics of the policy, the emergence and change process of the policy issue showed the cyclical structural through the change of each stages. Although the elementary aftercare classroom started with government initiative, it is significant to broaden educational policy by accepting social demands. Based on the results of the study and conclusions, there are suggested for educational policy recommendations and follow-up studies. First of all, the educational policy suggestions for the qualitative improvement of the elementary aftercare classroom are as follows. It is necessary to adopt policies for improvement of quality in consideration of social change, social demands, and the purpose of operation of elementary aftercare classroom rather than temporary problem solving. And the elementary aftercare classroom policy issue should take into account not only child care but also educational and social issues. Organic cooperation among various social members is necessary for solving social problems(Shin, Hyun-Seok, Jung, Yong-Joo, 2014:53). Therefore the necessity of the elementary aftercare classroom should be re-established and social consensus about the basis and direction of the elementary aftercare classroom should be formed. And Active linkage with local community should be made in the operation of elementary aftercare classroom. Socialization of care is not limited to the space of school. The community should not only participate in a program of the elementary aftercare classroom but also act as the subject of the elementary aftercare. Next are suggestions for follow-up research. Since this study deals with the overall structure of the adaptation, emergence and change process of the policy issues in the elementary aftercare classroom in order to achieve the purpose of the research, it is necessary to carry out an exploratory study on individual policy issues. In other words, it is expected a study on how each policy issues at specific time periods are reflected in the policy process. And it is possible to make a comprehensive analysis on the contents of the elementary aftercare classroom policy at the relevant period by looking at the issue classification of the elementary aftercare classroom policy issues and the issue of the elementary aftercare classroom policy which plays a role of intermediary. Lastly the policy issues that have not been presented at the 1% frequency of the elementary aftercare classroom policy issues but are being presented recently should be identified. Because although the frequency of occurrence in the elementary aftercare classroom policy issue network is low, policy issues have emerged that can predict influence or ripple effect. The Ministry of Education’s 2016 elementary aftercare classroom management plan suggests the needs for the elementary aftercare classroom, which is par of after-school education policy, to raise the conditions for raising children more safely in accordance with the expansion of women’s social advancement and the increase of double-income families(The Ministry of Education, 2016:1). It is emphasized as the national policy that child care should be carried out based on the overall social structure and systematic policy for stable care of children. Although many policy issues and practices have been reflected and improved since the beginning of the past 10 years of the elementary aftercare classroom, there have been a lot of social conflict factors such as budget conflict with local government. This study was conducted under the recognition that various conflicts arose due to issues surrounding the elementary aftercare classroom and that a comprehensive analysis of the policy issues is needed. It is expected that it will be able to solve the social conflict through the comprehensive analysis of the policy issues and to operate the policy with improved quality in the elementary aftercare classroom.",
		"KEYWORD": "big data analysis,elementary aftercare classroom,policy issue,social network analysis,socialization of care,빅데이터 분석,소셜 네트워크 분석,정책이슈,초등돌봄교실"
	},
	{
		"ID": 317,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "스마트미터가 전력사용량에 미치는 영향 :온도·경기지표 및 전력사용량 빅데이터 중심으로 ",
		"AUTHOR": "김기용",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원,연세대학교 학술정보원 언더우드 기념도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 318,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Wind power generation forecasting based on big data analysis =빅데이터 분석에 기반한 풍력 발전 예측 기법 ",
		"AUTHOR": "Mendrycka,Marta",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 319,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Big data in public organizations :공공기관의 빅데이터 :an examination of factors influencing IT innovation adoption process =IT 혁신 도입의 프로세스에 영향을 미치는 요인들에 대한 연구 ",
		"AUTHOR": "Park,Junyoung",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 320,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "Big data-based network analysis and structural equation modeling omni-channel O2O service comparison of online-loyalty and offline-loyalty =빅데이터 기반 네트워크 분석과 구조방정식 모형을 활용한 옴니채널형 O2O 서비스의 소비자 충성도 분석 연구 : online-Loyalty와 offline-Loyalty 비교 분석 ",
		"AUTHOR": "Ji-yunLee",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 321,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국교통대학교 대학원",
		"TITLE": "(The) development of big data analysis system and app system by snow melting in poor environment on bridge and road =열악한 다리 및 도로 환경에서 스노우멜팅을 통한 빅데이터 분석 및 App 시스템 개발 ",
		"AUTHOR": "UmarovJamshid",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 322,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "대구경북과학기술원",
		"TITLE": "(A) distributed in-situ analysis method for large-scale scientific data =분산 환경 기반 시스템에서 과학 기술 빅데이터 in-situ 분석 방법 ",
		"AUTHOR": "DongHyoungHan",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 323,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "유전자 가위 기술의 사회적 영향과 법제도 운영 방안에 대한 고찰 :빅데이터 분석과 전문가 인터뷰 결과를 중심으로 ",
		"AUTHOR": "김성은",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김소윤",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "Today, ‘Customized Medicine’ is a main agenda of treatment for patient. some researches have focused on data based medicine for qualified health service. Gene editing technology is a representative theme due to moderating origin of disease and abnormal phenomenon to body. Existing studies have limited on criticism to gene editing and positivistic view on evolution of technology. However, recently, there is an increasing number studies and reviews that lay emphasis on the needs of CRISPR for the treatment of rare diseases and other variety of complications. On the others hand, CRISPR has been argued as a cause of intervention of eugenics and social polarization. This study is conducted to analyse of macro-environment related to gene editing technology and represent vision of technological breakthrough by mining social opinion in online environment and interviewing experts. We surveyed critical issues and nature of conflicts among stakeholders. Based on this survey results, the current study has reflected the introduction scenario of CRISPR technology on more various and detailed perspectives.",
		"KEYWORD": "CRISPR,customized medicine,gene editing,유전자 가위,유전자 가위 기술,유전자 편집,유전자 편집 기술,유전체 맞춤의학"
	},
	{
		"ID": 324,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "광주과학기술원",
		"TITLE": "(A) comparative study of programming environments exploiting heterogeneous systems for big data processing =빅데이터 계산을 위한 이종 프로그래밍 환경 비교 ",
		"AUTHOR": "BongsukKo",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 325,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경북대학교 대학원",
		"TITLE": "(A)power-efficient framework based on big-data for disaster monitoring in wireless sensor networks =무선 센서 네트워크 환경에서 재난감시를 위한 빅데이터 기반의 효율적인 전력 프레임워크 ",
		"AUTHOR": "UzohPaulChiedozie",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 326,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "Applications of Sim-hash and big data analysis in spam email detection system =SIM-HASH와 빅데이터 분석을 이용한 스팸 메일 탐지 시스템 ",
		"AUTHOR": "Phue-TranHo",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 327,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "Determining optimal capacity of waste treatment facilities based on deep learning and spatial big data =딥러닝과 공간 빅데이터 기반의 폐기물 소각 시설의 최적 용량 결정 ",
		"AUTHOR": "JeonghyunKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 328,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "(A)research typology of big data technology =빅데이터 문헌 분석과 분류에 관한 연구 ",
		"AUTHOR": "Lee,Seunghoon",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 329,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "명지대학교 대학원",
		"TITLE": "(A)study on a real-time detection and monitoring system for abnormal fire occurrences based on big data mining =빅데이터 마이닝에 기반한 화재사고 이상징후 모니터링 및 감지 시스템 연구 ",
		"AUTHOR": "KidonJoo",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 330,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "(A)study on big data analytics for nation-wide livestock farm management system in cloud computing environment =클라우드 컴퓨팅 환경에서 전국 규모의 축사 관리를 위한 빅데이터 분석 ",
		"AUTHOR": "JongukLee",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 331,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "동서대학교 대학원",
		"TITLE": "PCMR :PCMR : 클라우드 환경에서의 빅데이터 처리를 위한 개선된 병렬 컴퓨팅 맵리듀스 프레임워크 ",
		"AUTHOR": "AhmedAbdulhakimAl-Absi",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 332,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "이용자 관점에서 모바일 퍼스트 전략 평가 :빅데이터 분석을 중심으로 ",
		"AUTHOR": "서민영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임종섭 참고문헌: p. 69-75",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 333,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "중국의 국민해외여행자 소란행위관리정책 변동분석 :An analysis on the policy change of outbound tourists` uncivilized behavior management policy in China : focusing on the issue attention cycle model utilizing big data analysis ",
		"AUTHOR": "이사원",
		"REGION": "서울",
		"PROFESSOR": "권두 국문요지, 권말 Abstract 수록 지도교수: 이연택 참고문헌: p. 98-108",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "중국은 세계 최대의 해외여행자 송출국으로 성장하고 있다. 그러나 해외여행 수요의 급격한 증가는 해외여행자의 소란행위라는 부작용을 가져왔다. 중국 정부는 이에 대응하기 위하여 국민해외여행자 소란행위관리정책을 시행하였다. 본 연구는 정책과정론적 관점에서 중국의 국민해외여행자 소란행위관리정책의 정책변동과정을 분석하는데 연구의 목적을 두었다. 이론적 고찰에서는 중국 국민해외여행자 소란행위관리정책, 정책변동, 이슈관심주기모형에 대한 개념과 관련 연구를 고찰하였다. 분석의 틀은 이슈관심주기모형을 바탕으로 중국의 국민해외여행자 소란행위관리정책의 특징이 반영된 분석의 틀을 제시하였다. 연구문제는 ‘중국의 국민해외여행자 소란행위관리정책과 관련하여 이슈관심주기단계는 어떻게 형성되었는가?’, ‘중국의 국민해외여행자 소란행위관리정책과 관련한 이슈관심주기단계에 따라 정책변동은 어떻게 나타났는가?’로 설정하였다. 또한 이론적 고찰을 기반으로 본 연구는 중국의 국민해외여행자 소란행위관리정책의 계기가 ‘여기왔다 사건’, ‘아시아항공 사건’, ‘방콕공항 사건’을 선정하고 분석요인으로 이슈관심주기 특성요인과 분석요인(사회적 관심요인, 정책변동요인)을 설정하였다. 연구방법은 문헌연구법, 사례연구법, 빅데이터 분석법을 적용하였다. 분석결과, ‘여기왔다 사건’, ‘아시아항공 사건’, ‘방콕공항 사건’의 연쇄적인 사건은 이슈관심주기모형을 적용하기에 적합하며, 모든 사건이 이슈관심주기의 다섯 단계를 거치는 것을 확인할 수 있었다. 이슈관심주기 유형은 반복형으로 나타났다. 또한 이슈관심주기의 2단계, 3단계, 4단계에서 정책집행이 이루어지며, 정책변동은 5단계인 관심쇠퇴단계에서 발생한 것에서 비추어 봤을 때 중국 정부의 국민해외여행자 소란행위관리정책에 대한 민감성은 높은 것으로 판단되었다. 이에 중국의 국민해외여행자 소란행위관리정책 이슈관심주기단계가 일관성, 포괄성의 특성을 지니고 있음을 확인할 수 있었다. 이슈관심주기단계에 따라 정책변동이 나타나며, 정책변동의 형태는 정책혁신, 정책유지로 확인되었다. 분석결과를 통한 본 연구의 이론적 기여는 일반이론인 이슈관심주기가 소란행위정책이 형성되는 일련의 과정에서도 적용된다는 점을 확인한 것을 들 수 있다. 실무적 기여는 정부대응에 있어 이슈관심에 대한 종합적인 접근이 필요하다는 것을 제시할 수 있다. 연구의 한계로는 연구범위에 따른 제한된 일반화의 한계가 지적되었으며, 향후 연구대상의 확대 및 비교사례연구와 같은 연구방법의 다원화가 요구된다. 이러한 관점에서 관광정책에 대한 이슈관심주기모형 연구가 지속적으로 이루어지길 기대한다.",
		"KEYWORD": "관광"
	},
	{
		"ID": 334,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "(An) implementation of web-enabled OLAP system for healthcare bigdata linkage platform =보건의료 빅데이터 플랫폼에서 웹 기반 OLAP 시스템 구현 ",
		"AUTHOR": "PichponreayLy",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 335,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "NoSQL and real-time big data processing :NoSQL과 실시간 빅데이터 처리 :an approach to enable EPCglobal based internet of things =EPCglobal 기반의 Internet of Things을 위한 접근 방법 ",
		"AUTHOR": "Le,DinhTuan",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 336,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "연세대학교 정경대학원",
		"TITLE": "빅 데이터의 소셜 네트워크 분석을 이용한 소셜 미디어 활용전략 :우정사업본부 사례를 중심으로 ",
		"AUTHOR": "정지은",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 신택수",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "big data,Korea Post,post office,social media,social network analysis,social network service,빅 데이터,소셜 네트워크 분석,소셜 네트워크 서비스,소셜 미디어,우정사업본부,우체국"
	},
	{
		"ID": 337,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "중부대학교 대학원",
		"TITLE": "빅 데이터 환경을 고려한 데이터마이닝 기법을 이용한 서버 장애 예측 모델 =(A)prediction model of server failure using data mining in big data environment ",
		"AUTHOR": "임복출",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 김순곤",
		"STORE_LOCATION": "중부대학교 중앙도서관",
		"ABSTRACT": "정보통신기술의 발달과 가속화된 디지털 혁신으로 현대 사회는 무수히 많은 데이터가 실시간으로 발생하고 있다. 데이터량의 급속한 증가는 2007년 아이폰 도입을 시작으로 확산된 스마트폰(Device)과 모바일 플랫폼(Platform)을 통해 다양한 콘텐츠(Contents)와 애플리케이션(Application)에 접근하게 되면서 더더욱 빨라졌다. 빅 데이터(Big Data)의 영향력이 증대되는 환경에서 시대적 상황에 맞춰 정보시스템 모니터링 시스템도 변화가 필요하다. 실시간으로 발생되는 대량의 데이터 기반의 성능 관리가 가능해야 한다. 실시간 대처를 위하여 ①시스템 복잡도 및 규모의 확대에 따라 확장성 있는 서버 성능 모니터링 시스템의 설계를 어떻게 할 것인가, ②이질적 환경에 이식성 있는 시스템을 어떻게 설계할 것인가, ③서버 성능 모니터링을 위하여 발생되는 수많은 데이터를 수집, 분석하여 어떻게 실시간으로 대처할 수 있는가가 중요한 고려사항이다. 성능 모니터링 시스템은 감시항목별 장애 이력 데이터와 임계치 관리 등을 통하여 장애 발생을 인지하거나 장해 발생 후 대응 수준의 기능을 지원하는데 그치고 있다. 본 논문에서는 기존의 서버 모니터링 감시의 단점을 보완하고 빅 데이터 환경을 고려한 모니터링, 또한 장애 발생 이전에 예측이 가능하도록 빅 데이터 환경을 고려한 서버 장애 모니터링 방안의 연구를 진행하였다. 도출된 감시항목 및 가설의 적용 및 검증을 위하여 실시간 서버 모니터링 시험 환경을 구축하였다. 이를 통하여 가상의 서비스 환경에서 시계열 분석과 예측의 결과를 검증하여 구축된 환경을 빅 데이터 환경을 고려한 서버 장애 모니터링 시스템 아키텍처로 제안하였다. 본 논문에서의 연구 과정 및 결과는 다음과 같다. 국내·외 학자들의 관련연구와 상용 및 오픈소스 기반의 솔루션들을 분석하여 실시간 감시항목을 도출하였다. 1차 감시항목 도출을 위하여 정보시스템 운영·관리 지침과 상용 및 오픈소스 기반의 솔루션 기준의 감시항목을 비교하였다. 비교 결과를 종합하여 CPU, Memory, 디스크, 프로세스, 네트워크, 응용 프로그램의 6개 분야에 25개 감시항목을 1차로 도출하였다. 실제 A사의 모니터링 솔루션의 데이터를 이용하여 서버 모니터링 감시항목을 2차로 도출하였다. 실제 A사의 모니터링 데이터를 수집하여 SPSS를 이용한 빈도 분석 및 교차 분석을 진행하였다. 분석은 모니터링 시스템이 관리하는 모든 서버가 아닌 실제 장애 수준이 높은 Interface #1, #2에 대하여 진행하였다. 분석 결과를 종합하여 동일한 6개 분야에 35개 감시항목을 2차로 도출하였다. 2차 도출된 감시항목은 1차와 비교하여 프로세스 분야에 2개항목, 네트워크 분야에 4개 항목, 응용 프로그램 분야에 4개항목이 추가되었다. 실시간 서버 모니터링을 위하여 1차, 2차의 기존 감시항목을 기준으로 정보시스템 운영·관리 지침과 상용 및 오픈소스 기반의 솔루션에서 제시하는 임계치와 감시수준, 빈도를 종합하여 기본 가설을 수립하였다. 수립한 가설은 ‘CPU, Memory, Disk 등에 관한 가설’, ‘Process, Queue 등에 관한 가설’, ‘네트워크 Node, Port 등에 관한 가설’, ‘Web, WAS 등에 관한 가설’ 4개 분야에 12개 가설을 수립하였다. 실제 A사의 모니터링 상세 데이터를 통하여 12개 가설 검증을 진행하였다. 가설 검증을 통하여 가설 제외, 수정 및 대체작업 후 4개 분야에 5개 항목으로 최종(3차) 감시항목을 종합적으로 도출하였다. 최종 도출된 감시항목을 통하여 장애 발생 이전의 장애 인지를 위하여 시계열 분석을 진행하였다. 감시항목 중 빅 데이터 환경을 고려한 서버 장애 대응 예측 구축 환경에 적합한 항목으로 ‘Peak 시간 CPU 사용율’에 대한 임계치를 선택하였다. 실제 환경과 동일한 환경 구성이 어려운 시험 환경에 장애 예측이 가능한 항목만을 선택하였다. 장애 발생 이전에 장애 인지를 위하여 실제 A사의 감시 데이터를 통하여 시계열 분석을 진행하였다. 초기에는 2013년 11월부터 2014년 4월까지의 데이터 중 정상 기준의 전후 1일씩과 장애시의 전후 1일씩의 데이터를 중첩되지 않도록 선택하였다. 이 데이터를 가지고 시계열 분석과 마지막일 이후의 3일치에 대한 예측값을 추출하였다. 시계열 예측 모형은 추세와 계절 효과가 없고 시간에 따라 일정한 계열에 적합한 단순계절 모형의 특징을 보였다. 해당 모형이 2014년 5월 이후의 시계열 분석과 유사한지 검증하기 위하여 추가적으로 2014년 5월부터 7월까지의 감시 데이터를 추출하였다. 4월까지의 시계열 예측값과 5월이후의 시계열 분석값을 비교하였다. 비교 결과, 장애가 발생할 가능성이 높은 3군데 지점에서 실제 1군데에서 장애가 발생하였음을 검증하였다. 예측 모형 적용 실험 및 결과를 분석하였다. 실제 서비스 환경에서의 시계열 예측 모형을 적용하고, 결과를 분석하기 위하여 실험 환경을 구축하였다. 오픈 OS인 Ubuntu를 설치하였고, 서버 모니터링을 위하여 오픈소스 기반의 Ganglia를 설치하였다. 모니터링 감시 항목별 수집 데이터 실시간 전송을 위한 Esper를 적용하였다. 수집 데이터 분석을 위하여 Hadoop 기반으로 분석처리를 하였으며, M",
		"KEYWORD": "데이터마이닝,빅 데이터,서버 모니터링,시계열 예측,장애 예측"
	},
	{
		"ID": 338,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "이질적 데이터 통합을 이용한 빅 데이터 실시간 이벤트 탐지 시스템 ",
		"AUTHOR": "이준희",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:배해영 참고문헌 : p.31-32",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "최근 소셜 미디어의 발달과 스마트폰의 급격한 확산으로 SNS(Social Network Service)가 활성화가 되면서 데이터양이 폭발적으로 증가하였다. 빅 데이터는 현재 시스템으로 처리 가능한 범위를 넘어서는 데이터로 정의 되며, 이를 활용하기 위한 많은 방안이 연구되고 있다. 빅 데이터의 가치창출을 극대화하기 위해 빅 데이터의 분석뿐 아니라 기존 데이터와의 융합이 필요하며, 각 데이터는 이질적 데이터이므로 물리적, 논리적 저장구조가 달라 이를 통합하고 관리하기 위한 시스템이 필요하다. 이질적 데이터의 융합처리를 위해 기존의 데이터스트림 관리 시스템을 확장한 복합 이벤트 처리 시스템이 있다. 하지만 복합 이벤트 처리 시스템의 경우 빅 데이터의 정보를 관리하지 않아 데이터를 처리하기 위해서는 많은 비용이 추가되어 효율적이지 못하다. 맵리듀스의 경우 데이터 집합에 대해 질의를 병렬로 분산처리를 하여 빅 데이터를 처리하기에 유리한 이점을 가지고 있어 단일 이벤트 탐지에 빠른 성능을 보일 수 있으나 이질적 데이터를 입력받아 데이터, 스키마를 통합하고 관리하는 기능이 없어 복합 이벤트 탐지를 하기 위해선 추가적인 시스템이 요구된다. 본 논문에서는 복합 이벤트 처리 시스템에 빅 데이터를 위한 맵리듀스 기능을 추가하는 방법을 제안한다. 기존의 복합 이벤트 처리 시스템은 빅 데이터를 위한 데이터 소스정보를 관리하는 부분이 없으므로 이를 위한 자료구조를 추가하고, 효율적인 처리를 위하여 맵리듀스를 활용하여 키워드 값을 중심으로 군집화 한다. 맵리듀스를 통한 결과 값은 시스템에서 질의처리와 이벤트 탐지를 위하여 정형화된 자료구조로 추상화하여 이벤트 처리 서버로 보낸다. 실험을 통해 제안 기법을 사용한 시스템이 기존의 복합 이벤트 처리 시스템 보다 빅 데이터를 처리하는데 효율적인 것을 확인하였다. SNS와 기존 데이터들의 분석을 통해 사용자의 행동 패턴, 이력, 선호도, 주변 상황에 따라 적절한 지식을 서비스 형태로 제공할 수 있을 것으로 기대된다.",
		"KEYWORD": null
	},
	{
		"ID": 339,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한서대학교 대학원",
		"TITLE": "빅데이터를 이용한 가뭄발생지역과 가뭄심도 분석 =(A)study on drought area and severity by big data analysis ",
		"AUTHOR": "이희섭",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 박무종",
		"STORE_LOCATION": "한서대학교 도서관",
		"ABSTRACT": "최근 인터넷, 스마트기기의 발달과 소셜 미디어의 등장으로 데이터가 기하급수적으로 증가하는 빅데이터(Big Data) 시대가 도래하였다. 빅데이터는 IT 기기 및 사회발전과도 상호 연관적이며, 기존에 예측, 분석이 불가능하였던 데이터들을 여러 분석방법을 통하여 의미 있는 데이터를 획득하기 위하여 여러 분야에서 연구되어지고 있다. 가뭄의 경우 발생범위와 심도를 예측하기 어려운 자연재해 중 하나이다. 본 연구에서는 가뭄심도를 파악하기 위하여 빅데이터 분석기법 중 데이터 마이닝(Data Mining)과 구글 트랜드(Google Trend)를 적용하였다. 이때, 구글 트랜드는 가뭄과 관련된 키워드(가뭄, Drought)를 분석하였고, 데이터 마이닝은 국내 4개 언론매체(조선일보, 경향신문, 매일신문, 연합뉴스)의 자료를 토대로 하였다. 빅데이터를 이용한 가뭄해석의 적정성을 평가하기 위하여 전국 6개 광역시, 2개 특별자치지구의 최근 4년간의 강수량을 바탕으로 3개월, 6개월, 9개월, 12개월 표준강수지수(SPI)를 산정하였다. 단기 가뭄특성을 분석하기 위하여 3개월 표준강수지수(SPI(3))를 사용하였으며, 산정된 가뭄지수와 구글 트랜드 분석결과, 언론매체의 기사자료를 비교분석 하였다. 본 연구를 통해 가뭄에서의 빅데이터 활용 가능성을 확인하였고 향후 가뭄을 비롯한 각종 자연재해와 관련된 연구 및 방재정책수립에 기초자료로 활용 가능하다.",
		"KEYWORD": "가뭄,가뭄심도,데이터마이닝,빅데이터,표준강수지수"
	},
	{
		"ID": 340,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "강원대학교 산업대학원",
		"TITLE": "DW와 OLAP을 이용한 상호작용적 비식별화 기반 빅데이터시스템에 대한 연구 =Study on big data system using DW and OLAP an interactive de-identification based ",
		"AUTHOR": "고영범",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:권호열 참고문헌 : L. 67-69",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "21세기 들어 모든 개인은 각자 1개이상의 스마트 기기를 보유하고 있으며, 이에 보유한 스마트 기기는 끊임없이 서버와 통신을 하면서, 수많은 데이터를 생성하고 있다. 또한 스마트 사용자가 자기가 원하는 웹사이트를 접속하게 되면, 접속하는 순간부터, 로그인, 검색, 페이지를 보는 과정까지 로그파일등에 정보로 그 기록이 남게 된다. 여러 사용자가 접속하게 되는 경우 그 데이터의 양의 크기는 기하급수적으로 커지게 된다. 우리는 이를 빅데이터라고 부르고 있다. 대규모로 생성되는 데이터로 시스템관리자는 주기적으로 데이터를 삭제함으로써, 시스템의 부담을 줄이고 있다. 그러나 이 정보에는 사용자의 접속기록, 패턴이나 관심사항등의 정보를 포함하고 있으며, 이는 사용여부에 따라 엄청난 가치를 가지고 있음을 알고 있다. 그러나 빅데이터는 그 가치에 비하여, 그 사용성이 떨어진다. 하루에도 수백테라급으로 생성되는 빅데이터가 활용되지 못하고 버려지는 경우가 발생하고 있는 것이다. 빅데이터 시스템을 구성하기 위해 투입되는 노력과 비용에 비하여, 얻어낼 수 있는 가치가 떨어지기 때문이라고 할 수 있다. 그 원인을 분석하고, 해결방안을 제시하여, 빅 데이터의 활용성을 높이는 방법을 연구 한다. 또한 추출된 소중한 데이터에는 중요한 개인정보가 포함되어 있어 사용하고자 하는데도 적지 않은 부담으로 작용하고 있다. 이에 정부에서는 비식별화 방법을 제시하여, 비식별화된 빅데이터는 사용가능하도록 허가하였다. 그러나 비식별화된 데이터를 이용한다고 하여도 그 잠재되어 있는 가치를 활용하는데 제한이 발생되어 지게 된다. 이에 개인정보를 보호하면서 잠재 가치를 활용할수 있는 방안을 연구한다. 빅데이터시스템을 도입을 고민하는 조직 또는 기업의 상당수는 이미 기존에 웹 시스템과 연계시스템 및 OLAP과 데이터웨어하우스(Data warehouse)등의 통계관련 시스템을 구성되어져 있다. 여기에 빅데이터시스템을 다시 도입하고자하는 경우에 적지않은 비용적 시간적 투입이 필요하게 된다. 빅데이터시스템의 특성상 파일의 크기가 크기 때문에(적게는 기가(GB)단위에서 많게는 테라(TB)단위의 크기를 갖는다) 별도의 저장장치가 필요한 경우가 발생한다. 또한 파일이 용량이 큰 관계로 분석하는 과정도 적지 않은 시간이 소요되며, 복잡한 분석을 위하여, 고성능의 시스템을 요구한다. 이에 또한 적지 않은 비용이 소요되게 되며, 도입에 또한 적지 않은 시간이 소요된다. 이에 조직을 운용하는 최고책임자로서는 적지 않은 부담으로 작용하게 된다. 또한 도입후에도 여러 가지 이유로 도입에 대하여 확신을 가지지 못한다. 그래서 본 연구에서는 완벽한 빅데이터 분석 시스템을 구성하지는 못하지만, 기존의 보유하고 있는 시스템을 이용하여, 주요 빅데이터 자료인 로그인정보, 페이지 뷰정보, 검색정보, 로그인한 시스템정보등의 정보를 이용하여, 따로 빅데이터 시스템을 구성하지 않아도 빅데이터 시스템을 구성하는 프로토타입의 시스템을 구성하는 방안을 연구한다. 빅데이터의 특성상 빅데이터에는 다량의 개인정보를 포함하고 있는 경우가 많다. 빅데이터로부터 추출된 데이터를 활용하고자 해도 개인정보보호법등으로 인해 사용에 제약이 많이 이루어 지고 있다. 이에 기존의 연구에서는 데이터를 비식별화하여, 이용하는 방법을 주로 제시하였다. 그리고 이를 근거로 최근 정부에서는 빅데이터 사용시 비식별화를 통한 빅데이터 사용을 적극 권장하고 있다. 그러나 비식별화하는 방법은 개인정보 누출을 방지할 수 있는 장점이 있으나, 빅데이터의 사용성이 떨어지는 것은 막을 수가 없다. 비식별화에서 제안하는 5가지 처리기법(가명처리, 데이터 값 삭제, 총계처리, 데이터마스킹, 범주화)의 방법은 통계등의 결과를 보고자 할 때는 유용하나, 직접적인 영업이나 대상자에 대한 파악, 그리고 보건,복지등에서 복지서비스를 제공해야할 대상자를 파악하고자 할때는 대상 파악에 어려움이 발생할 수가 있다. 즉 적시적소에 서비스를 필요로 하는 대상자를 파악하는데 비식별화된 정보는 서비스의 필요성은 파악할 수는 있지만, 누구한테 서비스를 제공해야 하는지 알수 없는 상황이 발생하게 된다. 이에 본 논문에서는 비식별화된 정보를 재식별화하는 과정을 연구하여, 빅데이터의 안전하게 활용가치를 높인다.",
		"KEYWORD": "olap,개인정보,데이터웨어하우스,비식별화,상호작용,재식별"
	},
	{
		"ID": 341,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "동의대학교 대학원",
		"TITLE": "교육 이슈 빅 데이터에 대한 자동 분류 처리 기술에 관한 연구 ",
		"AUTHOR": "손정은",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다 부록: 불용어 리스트...등 수록 p. 64-89 참고문헌: p. 90-92",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "최근 정보통신의 발달과 함께 스마트 단말기의 급속한 보급, 모바일 인터넷의 발전 및 소셜 미디어와 같은 다양한 정보 채널의 등장으로 인하여 기하급수적으로 데이터가 생성 및 소비되고 있다. 생성되는 데이터 종류도 매우 다양해짐에 따라 그에 따른 처리 기술이 ICT(Information & Communication Technology) 분야의 중요한 이슈가 되고 있다. 이러한 빅 데이터를 분석함으로써 해당 데이터에 내재되어 있는 새로운 사실을 발견하고 이를 활용하는 분야가 정치, 의료, 교육, 비즈니스, 문화 등 사회 제반 분야로 확산되고 있다. 특히 분석되는 데이터에서 사용자가 원하는 정보를 선별하고, 재가공을 통해 도출된 새로운 정보를 전략적으로 활용하려는 기술이 발전하고 있다. 그러므로 데이터 분석에 대한 핵심 기술의 확보는 매우 중요하며, 본 연구는 키워드 추출, 분류, 유사도 계산 등 빅 데이터 분석의 기반 기술 연구에 초점을 두고 있다. 분석 대상 데이터로 교육 분야를 선정하였다. 이는 교육 분야 자체가 우리나라에서 매우 관심 있는 주제이고 많은 정보가 발생하고 있지만 세부 분야도 많고, 네티즌의 의도 파악이 시스템적으로 이루어지지 않았기 때문이다. 교육 분야 이슈는 이메일, 블로그, SNS(Social Network Service)와 같은 비정형 데이터가 주류를 이루고 있어 분석 자체가 정보 검색 기술을 기반으로 운영하고 있다. 본 연구에서는 SNS에 게재된 글에 대한 초기 주제 (수동) 분류를 통하여 비 교육 분야 데이터를 필터링하고, 데이터의 키워드 정선 과정, (자동) 재 분류, 그리고 분류된 글의 유사도 측정 기술을 개발하여, 이를 통하여 새로운 글을 자동으로 주제 분류할 수 있는 기술을 개발하였다. 개발된 분류기는 테스트 과정을 통하여 주제 분류의 정확도가 약 91.67% 정도로 이르는 것을 확인하였다. 이는 초기 자동분류기 개발을 위하여 대상이 된 글이 1,003개로 해당 집단이 늘어나면 정확도가 더 늘어날 것으로 예측되고 있다. 본 연구에서 연구된 키워드 추출, 단어 사이 패턴 분석, 주제 정보 기술은 게시자의 의도(Intention)를 파악하며, 데이터의 자동 요약(Summary) 등에 활용할 수 있으며 이를 통하여 빅 데이터로부터 더 많은 분석 정보를 도출할 수 있을 것으로 사려 된다.",
		"KEYWORD": null
	},
	{
		"ID": 342,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "호서대학교 대학원",
		"TITLE": "신뢰성 확보를 위한 빅 데이터 시스템의 시험 평가 방법에 관한 연구 =(A)study on the testing evaluation method of big data system for secure the reliability ",
		"AUTHOR": "강상원",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 양해술",
		"STORE_LOCATION": "호서대학교 중앙도서관,호서대학교 중앙도서관(천안캠퍼스)",
		"ABSTRACT": "최근 ICT(Information & Communication Technology, 정보 통신 기술) 분야에서 빅 데이터가 중요한 이슈로 부각되고 있다. 디지털 정보량이 기하급수적으로 증가함에 따라 수많은 데이터를 어떻게 활용하는지, 그리고 그 많은 데이터를 통하여 새로운 가치 창출이 기업을 포함한 국가의 경쟁력으로 평가되고 있다. 기존과 차별된 대용량 데이터의 분석과 전망을 통해 새로운 서비스를 개발할 가능성은 매우 높다고 볼 수 있다. 시장조사 전문기관인 IDC는 ‘전 세계 빅 데이터 기술 및 서비스 전망보고서’에서 2011년 한 해 동안 새롭게 생성되거나 복제된 정보의 양이 1.9 제타바이트(1조 9천억 기가바이트)를 넘어섰고, 향후 5년 내 거의 9배까지 증가할 것이라고 예측하였다. 또한 세계적으로 빅 데이터 시장은 계속 커질 것이며, 연평균 40% 성장 및 정보통신기술(ICT) 시장 성장률의 약 7배에 달할 것으로 전망하고 있다. 그러나 앞으로 빅 데이터 시장은 점차 커져가지만, 그에 비해 빅 데이터의 품질평가체계가 아직 미흡한 실정이다. 따라서 본 논문에서는 먼저 빅 데이터 시스템의 기술 개요, 특징, 시장현황과 기술 동향을 분석하고, 이를 기반으로 빅 데이터 시스템의 신뢰성 확보를 위해 국제품질평가 표준인 ISO/IEC 9126과 ISO/IEC 12119를 참조하여 총 6가지 평가항목을 도출하였으며, 도출된 평가항목을 통해 평가모델을 개발하였다. 그리고 개발된 메트릭의 타당성을 검증하기 위하여 빅 데이터 시스템을 선정하여 시험 평가하였다. 본 논문에서는 적용된 결과를 분석하여 빅 데이터 시스템의 품질평가체계를 구축하고 평가 실시하여 빅 데이터 시스템의 신뢰성을 확보하기 위한 평가를 수행할 수 있는 방법에 대해 구축하고자 한다. 따라서 본 논문의 연구결과는 빅 데이터 시스템의 신뢰성 향상 측면에서 많은 기여를 할 것으로 기대하고 표준화가 어려운 상황에서 개발된 제품에 대해서 본 논문의 평가모델인 메트릭을 적용함으로서 신뢰성이 높은 시스템을 확보할 것으로 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 343,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "목포대학교 대학원",
		"TITLE": "빅 데이터의 효율적인 저장을 위한 SSD 기반 하이브리드 스토리지 시스템 =Hybrid storage system of SSD-based for an efficient stores in big data ",
		"AUTHOR": "조성희",
		"REGION": "전라남도",
		"PROFESSOR": "지도교수: 박경우",
		"STORE_LOCATION": "목포대학교 도서관",
		"ABSTRACT": "In this research, we propose solid state drive (SSD) based hybrid storage system for saving big data effectively. The proposed system is low-cost high-performance hybrid storage system which combines a low-speed large scale hard disk drive (HDD) storage and high-speed solid state drive (SSD). The proposed system uses SSD as a buffer so that it classifies hot data and cold data when it stores big data. In this paper, we realize cost-effective system by applying classification method which classify hot data and cold, and by saving hot data into SSD and cold data into HDD before saving big data processed by hadoop. In our experiment, there is performance improvement because hot data is read and written in high speed SSD. In order to evaluate the effectiveness of the proposed system, we saved the backup data from big data, which is processed by de-duplication method through the network such as WAN and LAN. For this evaluation, we measured speed of backup, rate of de-duplication, and network bandwidth, CPU performance, memory usage, and DIS I/O. Our experimental results show that backup speed of our system is thirteen times faster than general backup speed. The rate of de-duplication is 98% so that only less than 2% of data is saved. Network bandwidth is 50 to 60 MB/SEC, which means that the network traffic is reduced comparing to conventional approaches. As we applied multi-core CPU on our backup server, the CPU usage of our backup client is reduced. The average was less than 5% even it showed variations slightly according to environment situation. The memory usage of backup client was within 10%, and the memory usage of backup server was about 2% because it was applied into hard disk directly. The average of Disk I/O was 20MB (MB/Sec) at backup client, and it was not occurred from the second process. All experimental results show that usage of CPU and memory was the same measurement, but saving time and disk IO showed improvement. In future, we have plan to study on big data operating process in details, and on privacy problem in big data technology.",
		"KEYWORD": null
	},
	{
		"ID": 344,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "홍익대학교 영상대학원",
		"TITLE": "SNS빅데이터를 활용한 디지털사이니지 영상콘텐츠 디자인 연구 :(A)study on digital signage visual communication design utilizing SNS big data :디지털사이니지 매거진TV를 중심으로 =focus on digital signage magazine TV ",
		"AUTHOR": "이진우",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 장인규 부록: 1차 FGI 결과. -- 2차 FGI 결과 리스트 참고문헌(p. 101-104) 수록",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "오늘날 광고미디어는 급속도로 다양화 되고 첨단화 되고 있다. 소셜 네트워크를 기반으로 한 광고미디어, 모바일 네트워크를 기반으로 한 광고미디어를 넘어 전통적인 옥외미디어까지 첨단화 되고 있다. 디지털사이니지도 그 한 부분으로서 더 진보된 기술로 광고 효율성을 높이고 있다. 하지만 하드웨어적인 발달에 비해 소프트웨어인 광고 영상콘텐츠를 디자인하는 방법은 첨단화 되지 못하여, 기술의 발달만큼 광고 효율성을 높이고 있지 못한 것이 현실이다. 본 연구는 첨단화 된 미디어에 맞추어 요구 되고 있는 새로운 형태의 영상콘텐츠 디자인 방법을 SNS빅데이터를 활용해서 연구하는 것이다. 타겟의 인사이트를 세밀하게 파악하고, 설득할 수 있는 수단으로서 SNS빅데이터를 활용한 결과 더 효율적인 광고 영상콘텐츠를 디자인 할 수 있었다. 기존 AIDMA모델을 디지털사이니지에 맞추어 발전시킨, 단계적인 설득프로세스를 통하여 타겟을 더 효과적으로 설득 시킬 수 있는 모델을 제시 하였다. 또 광고의 몰입도를 높이는 인게이지먼트 이론을 세분화하고 확장하는 방법을 제시하여, SNS빅데이터를 분석하여 얻어진 결과를 바탕으로 좀 더 몰입할 수 있는 영상콘텐츠 디자인 방법을 제시하였다. 전체적인 영상콘텐츠 디자인에서 SNS빅데이터를 활용하여 좀 더 효율적으로 타겟을 설득하고 광고 메시지를 전달하는 프로세스에 대한 모델을 제시하였다. 제시한 모델을 매거진TV를 중심으로 시뮬레이션을 진행하여 실무적인 적용 사례로 참고 할 수 있도록 하였다. 본 연구는 SNS빅데이터 분석을 광고 영상콘텐츠 디자인에 도입하여 광고효율성을 높이는 새로운 계기를 마련하였다. 앞으로 실무에서 더욱 더 발전적인 연구를 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 345,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 영상대학원",
		"TITLE": "빅데이터를 활용한 영화마케팅 연구 :SNS 이용자(특성) 중심으로 ",
		"AUTHOR": "김진욱",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김학순 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "본 연구는 기본적으로 영화마케팅에 있어 필요한 정보들의 집합의 정리 ‘SNS를 통한 빅데이터의 수집’ 라는 기본전제로 시작한다. 단위 시간당 데이터의 양이 증가한 배경에는 SNS의 확산이 있다. SNS이라는 강력한 플랫폼을 활용하여 영화에 대한 수용자의 태도와 성향을 파악하는 것은 영화 개봉 전 관객들을 끌어오는 마케팅을 하기 위해 필요한 정보다. 영화는 감성적 소비재로써 객관적인 정보뿐만 아니라 주관적인 구전 정보들이 관객들에게 주는 신뢰감이 더 크기 때문에 데이터의 수집 및 분류작업은 필수적이다. 예를 들어 SNS에서 평가한 한 개인의 영화에 대한 정보 즉, 영화의 구전커뮤니케이션을 데이터화하여 분류작업을 한다면 소비자들의 영화에 대한 기대감과 만족도를 구체적으로 파악할 수 있다. 기존의 영화마케팅에 대한 연구들은 제작사나 배급사의 입장에서 과거의 성공사례를 이용하여 흥행요인을 찾고자하는 연구가 대부분이었다. 그러나 영화는 예술성과 더불어 3D 등 첨단기술과 융합에 의해 이루어진 종합예술이므로 관객들은 여러 가지 요인에 의해 영화를 선택하며 영화흥행은 몇 개의 요소로 결정되지 않는다. 따라서 본 연구는 영화선택의 높은 예측을 하는 관객의 관람 전 SNS 커뮤니케이션에 의한 기대요인을 선행연구로 설정하고, 관람 후 만족도를 통한 SNS의 영향력을 살펴본 후, 그에 따른 SNS 이용자들의 심리요인들을 분석한다. 이렇게 지각된 정보요인들을 가지고 빅데이터를 활용해 영화마케팅 전략을 위한 새로운 연구모형의 틀을 제시한다. 연구방법으로는 기존 영화마케팅의 사전연구와 함께 심층인터뷰를 통한 정성적 연구와 설문지를 통한 실증분석을 병행하고, 무작위로 선별된 영화들을 비교분석하여 빅데이터화 한다. 첫째, 사전연구에서는 대중문화와 산업적인 측면에서 영화상품 자체의 특성과 영화마케팅의 기존연구, 관객수용자연구 등을 고찰한다. 이를 토대로 홍보용 영화 SNS 내 이용자 특성을 선행변수로 하고, 결과변수인 관람 전·후 홍보용 영화 SNS 커뮤니케이션을 통한 영화에 대한 기대감과 만족도 등에 대한 이론적 고찰을 시도한다. 둘째, [Study-1]으로 영화 관람 전·후 홍보용 영화 SNS 내 이용자 특성을 심층적 인터뷰를 통한 정성적 연구와 그에 따른 설문을 작성하여 설문지법을 이용한 실증연구를 한다. 셋째, [Study-2]로 SNS 이용자들의 지각된 특성들이 매개변수인 홍보용 영화 SNS 정보품질에 어떠한 영향을 미치는지 살펴보고, 지각된 정보품질들이 구전효과에 어떠한 결과를 가져오는지 빅데이터를 통해 시기별로 영화들을 분석하여 영화흥행에 미치는 영향을 검증하고자 한다. 또한 영화관람 이후, ‘후감상’ 등 특성요인들이 SNS 내에서 어떠한 방식으로 구전커뮤니케이션을 할 것인지를 데이터화하고, 연령별과 직업별, 시간대별 추이까지 트렌드 분석하여 기존의 관계형 데이터와 비정형데이터들의 엄청난 양의 검색조회수를 빅데이터화 한다. 이는 영화의 이미지분석(브랜드분석), 트렌드분석, 리스크(위기)관리, 스토리텔링의 도구, 마케팅 활용까지 실증분석되어 영화흥행을 예측한다. 논문구성은 총 6장으로 구성되어 있으며 내용은 다음과 같다. 제1장은 서론으로 연구의 필요성에 대한 연구배경과 연구목적, 연구방법 및 구성에 대하여 기술한다. 제2장은 본 연구의 모형이 되는 이론적 배경으로 첫째, 대중문화적 측면과 산업적인 측면으로 나누어 영화상품 자체의 특성을 살펴보고, 영화마케팅의 기존연구를 토대로 관객수용자연구를 고찰한다. 둘째, 관람 전·후 SNS커뮤니케이션을 통한 영화에 대한 기대감과 만족도에 미치는 요인이 어떤 것이 있는지를 살펴보기 위해 기존 연구를 정리한다. 셋째, 홍보용 영화 SNS 내 이용자특성을 살펴보기 위해 요인정보를 영화에 대한 심리학적 측면과 기대의 성과, 만족도 등을 정리한다. 이는 본 연구의 가장 기본적인 부분으로 영화흥행요소에 관한 기존의 사전연구를 중심으로 재정리한다. 넷째, 빅데이터에 대해 알아보고 영화마케팅의 활용방안을 제시한다. 제3장은 이론적 배경을 토대로 연구모형의 틀을 제시하고, 연구문제별로 연구가설을 파일럿 테스트를 통해 설정한다. 제4장은 정성적인 심층인터뷰조사와 정량적인 실증분석을 위한 자료수집 및 분석방법을 기술하고, 설문지 구성과 변수의 조작적 정의와 측정방법, 그리고 분석결과를 제시한다. 제5장은 영화정보의 획득경로와 SNS 접속경로, 측정 항목별 평가에 따른 가설을 검증하고, 빅데이터를 통해 시기별로 45편의 영화를 무작위로 선별, 분석하여 결과를 기술한다. 제6장은 결론으로 본 연구의 결과를 요약하고 연구의 시사점, 그리고 연구의 한계 및 향후 연구방향을 제시하였다. 실증분석 결과를 요약하면 다음과 같다. 첫째, 본 연구에서는 홍보용 영화 SNS 내 이용자들의 특성요인이 매개변수에 어떤 영향을 미치는지 확인해 보았다. 이에 신뢰성, 정보성, 관여성은 지각된 정보품질에 각각 긍정적인 영향을 미치는 것이 확인되었으나(가설 1-1, 가설 1-3, 가설 1-6) 그 외에 반응성, 친밀성, 상호작용성은 SNS 정보품질에 영향을 미치지 않은 것으로 나타났고(가설 1-2, 가설 1-4, 가설 1-5), SNS 정보품질이 후감상 등 정보요인에 미치는 구전효과(가설 2)은 낮은 중간 값이 나왔다. 이러한 결과는 홍보용 영화 SNS 내 이용자들이 제공하는 정보의 신뢰성, 정보성, 관여성이 크게 나타난 것으로 볼 수 있었다. 이는 대량의 검색조회수에 의한 영화흥행을 예측할 수 있는 빅데이터가 될 수 있음을 보여주었다. 둘째, 빅데이터를 보다 정밀하게 분석하기 위하여 분산병렬시스템인 하둡처리와 오피니언 마이닝, 정확도 검사를 통해 빅쿼리 소프트웨어로 분석하였다. 또한, 2012년 12월부터 2014년 6월까지 무작위로 선정된 45편의 개봉영화들을 중심으로 흥행에 성공한 영화들과 실패한 영화들을 장르별, 시기별로 나누어 비교분석하였다. 이렇게 검증된 결과, 빅데이터 트렌드 분석을 활용하면 영화흥행을 예측하는데 직접적인 영향을 미치게 되고, 기존의 마케팅 분석보다 가장 적은 ±7%의 오차범위를 이끌어냈다. 셋째, 이렇게 분석된 결과는 규모가 큰 영화들의 경우, 종전대로 대규모 마케팅을 하다가 개봉 후부터 일주일 정도 SNS 바이럴 마케팅을 중점적으로 해야 흥행에 성공할 수 있고, 규모가 크지 않은 영화들은 개봉 전부터 철저한 온라인(바이럴) 마케팅을 하다가 개봉 후 3~5일 정도 트렌드 분석을 조사한 후 새로운 마케팅 전략(ex: 유명인의 트윗글, 역사적 배경의 이슈 등)을 세워야 한다는 결과가 도출되었다. 이는 최소한 같은 시기에 개봉되는 영화들의 마케팅 전략의 준거자료가 될 뿐만 아니라 이를 벤치마킹하면 타 장르의 문화예술 측면에도 큰 기여가 될 것이다. 마지막으로 본 연구는 영화학계의 영화연구 뿐만 아니라 경영학계의 영화마케팅연구에서도 빅데이터를 활용한 초석이 되는 연구가 될 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 346,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "호서대학교 대학원",
		"TITLE": "R을 이용한 빅 데이터 사례 분석 ",
		"AUTHOR": "김현근",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 한상태",
		"STORE_LOCATION": "호서대학교 중앙도서관,호서대학교 중앙도서관(천안캠퍼스)",
		"ABSTRACT": "ABSTRACT Big Data Case Study by Using R Hyun Geun Kim Department of Informational Statistics, The Graduate School Hoseo University Asan, Korea (Supervised by professor Sang Tae Han) With the advancements of information and communication, spread of mobile internet and social media, growth with geometrical progression of information quantity, the big data and the technology of big data is emerging as trend of information and communication field. The research is visualized by making matrix table, extracts the data without preconditioning process. Anybody can view this by interpreting easily. Noun extracting method from Korean text data is used R program.",
		"KEYWORD": null
	},
	{
		"ID": 347,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "빅데이터가 기업의 경쟁력에 미치는 영향에 관한 연구 ",
		"AUTHOR": "김성원",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 성태경",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "최근 스마트폰과 SNS(Social Networking Service)의 비약적인 발전으로 인해 동영상 및 음성 등의 비정형 데이터의 양이 급격히 증가하여 기존의 시스템으로 처리하기 어려운 상황에 이르렀다. 정확히 합의된 정의는 없지만 공통적으로 이러한 막대한 양의 비정형 데이터를 빅데이터라 부르며, 넓게는 이러한 데이터를 지원하기 위한 기술 및 아키텍처 역시 빅데이터라 부른다. 빅데이터 시대의 도래와 함께 막대한 데이터를 효과적으로 활용하고 대응하는 것은 기업 뿐 아니라 국가의 경쟁력 강화와 직결되고 있다. 많은 기업들이 빅데이터를 활용하기 위해 전문인력, 기술이외의 소스를 통해 엄청난 볼륨의 데이터들이 여기저기서 빠른 속도로 쏟아져 나오고 있다. 이를 두고 일부 전문가들은 데이터 쓰나미라고 부르기도 한다. 이처럼 기업들은 매일 실시간으로 쏟아져 나오는 정형 및 비정형 빅데이터를 잘 분석해 고객들이 어떤 직종에 종사하며, 특정 시간에 어디서 무엇을 하며 어느 분야에 관심을 가지고 있는지 등에 대한 정보를 분석함으로써 특정 고객에게 맞는 개인화된 광고와 마케팅 자료들을 수집할 수 있게 되었다. 또한 특정 제품이 어느 지역, 어떤 연령층의 고객에게 어느 시점에 잘 팔리는지 등을 분석하여 해당 제품에 대한 생산 계획을 세우고, 이들 제품에 들어가는 수십∼수백 가지의 원료 및 부품들을 미리 적절한 수준에서 주문함으로써 최소 비용으로 최대의 효과를 얻을 수 있도록 의사결정을 하기도 한다. 그러나 빅데의터의 성공사례가 적지않지만 아직 빅데이터에 관한 연구는 데이터 분석 기술, 개인정보 보안문제, 빅데이터 인력 양성 등 특정한 카테고리 내에서만 연구가 진행되고 있으며 특히 기술 분야에만 중점적으로 논문이 게제되고 있으며, 아직 빅데이터를 분석하기 위한 일반화된 연구모델이 없다. 따라서 본 연구에서는 빅데이터가 기업의 경쟁력에 미치는 영향을 알아보기 위해 전 세계 기업의 빅데이터 활용 사례들을 문헌연구들 통해 살펴보고, 활용사례들을 분석하기 위해 경영학에서 가장 많이 사용되는 연구모델인 포터의 경쟁세력모델과 가치사슬모델을 통해서 분석 하였다. 본 연구를 통해서 빅데이터가 기업의 경쟁력에 미치는 영향력을 알아보기 위해 2가지 연구 모델유효성을 살펴보고, 빅데이터가 기업의 비즈니스 활동에 있어 어느 분야에 가장 많이 활용 되었는지 분석해 보고, 이를 통해 빅데이터가 기업의 경쟁력에 어떠한 영향을 미치는지 연구하여 보았다. 빅데이터 사례 연구를 포터의 경쟁세력 모델과 포터와 밀라의 가치사슬 모델에 근거하여 분석한 결과를 요약한 것으로, 두 연구 모델이 상당히 유용한 것으로 나타났다. 22 가지의 빅데이터 활용 사례 중 경쟁세력모델에서는 18가지 사례가 구매자와의 교섭력에서 유효해 가장 많이 영향을 받는 것으로 나타 났으며, 가치사슬 모델에서는 생산활동에서 16가지 사례가 유효해 가장 많이 영향을 받는 것으로 나타났다. 반대로 경쟁세력 모델에서는 신규진입 활동에서 3가지 사례가 유효해 가장 작게 영향을 받는 것으로 나타났으며, 가치사슬모델 에서는 지원활동에서 7가지의 사례가 유효해 가장 작게 영향을 받는 것으로 나타났다. 이를 통해 빅데이터 기업의 경쟁전략에 있어서 경쟁세력모델을 통한 분석결과 구매자와 교섭력에서 많은 영향을 미치는 것으로 나타났지만, 신규진입 활동에서는 영향을 많이 미치지 못하는 것으로 나타났다. 또한 가치사슬모델을 통한 분석결과 생산활동에서 가장 많은 영향을 미치는 것으로 나타났지만, 지원활동에서 아직 많은 영향을 미치지 못하는 것을 알 수 있었다. 이처럼 기업의 빅데이터 활용사례를 통하여 살펴본 결과 경쟁세력과 가치사슬 두가지 연구모델에서 상당히 유효하는 것으로 나타났다. 그만큼 빅데이터는 기업의 비즈니스 분야에서 전략적으로 활용하여 높은 가치를 창출하고 있었다. IT분야만이 아닌 신제품개발·생산·재고관리·마케팅·서비스·고객관리·업무지원 등의 다양한 사업 분야에서 활용 가능한 것으로 나타났고, 업무의 효율성과 과학적으로 정확한 데이터 분석을 통해 경영상의 문제점 발견과 해결 하는데 전략적으로 효력이 있는 것으로 나타났다.",
		"KEYWORD": "가치사슬,경쟁세력,경쟁우위,빅데이터"
	},
	{
		"ID": 348,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "상품추천시스템의 빅데이터속성과 서비스특성이 소비자의 수용의도에 미치는 영향에 관한 실증적 연구 =(An)empirical study of the effects of bigdata attributes and service characteristics of product recommendation system on consumer`s acceptance intention ",
		"AUTHOR": "엄경순",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "빅데이터 시대가 도래하면서 기업들이 이를 활용하여 고객에 대한 통찰력을 확보하고 고객 맞춤형 상품을 제공해 고객 충성도를 높이고 새로운 수익원을 확보하려는 시도가 강화되고 있다. 기존의 인구통계학적인 고객분석에 의존하여 제공되던 상품추천방식은 고객 개개인의 취향이나 개성의 차이를 무시하고 집단으로만 상품정보를 제공해 왔다. 이에 반해, 빅데이터기반 상품추천서비스는 고객 개개인의 최근 관심사, 실시간 검색과 이벤트, 위치 및 시간 등을 빅데이터기반 기술로 분석하여 마치 PB(Private Banker)가 개별고객을 관리하듯 지능적으로 최적화된 상품을 추천하는 것이다. 하지만, 빅데이터기반 상품추천서비스가 향후 기업의 중요한 경쟁력이 될 것임에도 불구하고, 최신 기술기반의 빅데이터와 관련된 연구가 부족하여 기업관점에서 이를 활용한 서비스 품질이 미흡한 편이다. 이로 인해 빅데이터기반 상품추천서비스에 대한 소비자의 인식이 낮고, 전반적인 만족도가 떨어지는 편이다. 따라서, 본 연구는 상품추천시스템의 빅데이터속성과 서비스특성이 소비자의 수용의도에 어떤 영향을 미치는지를 검증하고자 하였다. 기존 기술수용모델을 기반으로 빅데이터속성과 일대일 마케팅 특성, 혁신기술에 대한 수용특성, 관계 마케팅 특성 및 서비스 품질이 고려된 연구모델을 제안하여 기업의 상품추천시스템과 관련한 고객 서비스 수행전략에 이론적 토대를 제공하는 것을 목적으로 한다. 이를 위해 빅데이터속성과 상품추천서비스의 특성을 파악하고 이러한 특성이 인지된 사용용이성과 인지된 유용성에 미치는 영향을 밝히고, 이를 통해서 수용의도에 어떻게 영향을 미치는지에 대한 요인을 규명하고자 하였다. 본 연구는 실증적 연구로, 기업에서 제공하는 상품추천서비스를 이용한 경험이 있는 일반인을 대상으로 설문조사를 실시하였다. 검증결과, 빅데이터속성과 상품추천서비스 특성은 모두 인지된 유용성에 긍정적인 영향을 미치는 것으로 나타났으며, 빅데이터속성 중 다양성과 서비스특성 중 상대적 이점은 인지된 사용용이성에 유의하지 않은 것으로 나타났는데, 이는 다양성과 상대적 이점이 인지된 사용용이성보다 인지된 유용성에 기반한 요인이기 때문인 것으로 해석할 수 있다. 또한 인지된 사용용이성 및 인지된 유용성 모두 수용의도에 긍정적인 영향을 미치는 것으로 나타났다. 연구의 시사점은 빅데이터기반 상품추천시스템의 성과를 높이기 위해서 고객과 관련된 빅데이터를 빠르게 분석하여 실시간성으로 고객 채널환경에 맞게 개인화된 상품추천서비스를 제공하는 것이다. 본 연구결과는 빅데이터기반 상품추천시스템을 구축 또는 고도화하고자 하는 기업들에게 상품추천서비스의 고객 수용요인에 대한 정보를 제공해 서비스 활성화에 기여할 수 있으리라 여겨진다.",
		"KEYWORD": "Analytics,Big Data,Product,Recommendation,Service"
	},
	{
		"ID": 349,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "빅데이터를 위한 분석기술 활용방안 연구 =(A)study on application methods of analytical technologies for analyzing big data ",
		"AUTHOR": "박준규",
		"REGION": "서울",
		"PROFESSOR": "지도교수:백성욱",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "본 논문은 국내의 대학 및 연구기관, 기업 및 정부를 대상으로 빅데이터를 위한 분석기술 활용 방안을 제시 하였다. 최근 스마트폰과 SNS(Social Networking Service)의 비약적인 발전으로 인해 동영상 및 음성 등의 비정형 데이터의 양이 급격히 증가하여 기존의 시스템으로 처리하기 어려운 상황에 이르렀다. 정확히 합의된 정의는 없지만 공통적으로 이러한 막대한 양의 비정형 데이터를 빅데이터라 부르며, 넓게는 이러한 데이터를 지원하기 위한 기술 및 아키텍처 역시 빅데이터라 부른다. 이처럼 빅데이터 시대의 도래와 함께 막대한 데이터를 효과적으로 활용하고 대응하는 것은 기업 뿐 아니라 국가의 경쟁력 강화와 직결되고 있다. 따라서 본 논문은 해외의 대학 및 연구기관의 연구 현황과 기업 및 정부 차원의 활용사례 들을 조사 및 분석하여 국내 실정에 적합한 빅데이터 분석기술 활용 방안을 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 350,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "데이터 시각화를 이용한 미디어아트 :Media art using data visualization :빅 데이터 시각화 작품 〈Earth〉를 중심으로 =focused on big data visualization art, 〈Earth〉 ",
		"AUTHOR": "손진석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김규정",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "스마트폰과 컴퓨터, 인터넷은 현재 인간의 생활에서 필수 조건이 되었다. 인터넷은 단지 정보를 전달하는 매체가 아니라 개인의 감성을 표현하는 매체가 되었고, SNS, 인터넷 카페 등의 인터넷 공간은 오프라인 공간과는 또 다른 사회를 형성하고 있다. 카카오톡 메시지, 페이스 북의 댓글 그리고 끊임없이 발생하는 위치정보 등 소셜 웹 등을 통해 만들어지고 매일 주고받는 정보들은 이미 인간이 공식적으로 기록해 남기는 역사적 사료와 아날로그 기록들의 양과 규모를 넘어서고 있다. 이와 같은 사회를 빅 데이터 사회라고 하는데, 빅 데이터는 현재 미래사회를 이끌어 갈 새로운 ‘연료’로 부상하고 있다. 빅 데이터를 이용한 연구는 현재의 정보소통 유행 방식을 넘어 인간의 집단행동이나 발생 가능한 미래 사회 현상 등을 예측할 수 있다. 또한 빅 데이터의 특성은 많은 산업분야와 문화, 예술, 공공 분야 등에 활용되어지고 있으며, 새로운 데이터 생태계를 조성하여 새로운 가치를 창출하는 기회를 제공하고 있다. 본 연구에서 디지털 데이터 환경의 개념과 특성에 대해서 알아보고, 디지털 데이터 환경아래에 도래한 빅 데이터의 특성과 활용된 사례 등을 분석하였다. 특히 빅 데이터의 시각화를 중심으로 기존 정보 소통 환경에서 데이터시각화의 중요성과 빅 데이터 시각화의 조형적 특성을 분석하였다. 또한 빅 데이터 시각화를 활용한 미디어 아트 작품을 연구자가 직접 만들어 적용시킴으로서 새로운 예술 형식으로서의 가능성을 탐구하고, 빅 데이터의 예술적 가치에 대해서 밝혀보고자 하였다.",
		"KEYWORD": null
	},
	{
		"ID": 351,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한신대학교 대학원",
		"TITLE": "빅데이터에 기반한 기록정보서비스의 방향 =Archival reference services based on big data ",
		"AUTHOR": "윤철",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 안병우",
		"STORE_LOCATION": "한신대학교 장공도서관,한신대학교 중앙도서관",
		"ABSTRACT": "Recently the explosive growth in widely penetrated smart gadgets, mobile internet, and social media has led for them to be perceived as economic asset and a new paradigm of ‘Big Data’ has come about. Time is changing from the past society where, with lack of information, it was quite difficult to make a good decision because of lack of information to the present society where it has become quite easy to gain enough good necessary information right at a proper moment. This research intends to suggest a new direction of archival reference services based on ‘Big Data’. The activities involved in it(‘big Data’) are already being revitalized both domestically and internationally and the governmental level efforts are also being made in that it perceives the importance of ‘Big Data’ and providing it with strategy and support. However, in the area of record management, the concern for it is quite low. This is because the concept that it belongs to informational technology is dominant. Users’ information being accumulated through the increased public record and request of Information Disclosure and record reading is valuable data and valuable material in archival reference services at the same time. The change in the paradigm of record management shifting from the collection and preservation centered method to the user centered method is acting as a factor making people to have concern for that. In this sense, it is quite certain that the ‘Big Data’ will affect the archival reference services and we should be well prepared to cope with that situation realizing such a change surely exits. Therefore the social archive service which is a archival reference services based upon ‘Big Data’ has been suggested. The key word of social archive is the users of it. The first phase for the user centered service is to build database of users’ information. The second one is the analysis of users’ information and it should be made through conducting the ‘Big Data’ analysis. Especially it is worth noting that the social data which can be gained through social media from users’ information enables us to analyze the users’ attitudes and disposition. The final purpose is to provide individually tailored service which finds out the information that the users want based on the ‘Big Data’ analysis with the information collected this way. To this end ‘Big Data’ and CRM and user focused record management service were theoretically examined. Besides, using social analysis tool the concept about social analysis was looked into and through the case of the election of the president Obama, the process of ‘Big Data analysis was also examined. In addition, in an effort to secure ‘big Data’ the social media strategy and its solution of revitalization and user tailored service were examined to come up with a direction of archival reference services based on ‘Big Data’",
		"KEYWORD": "기록정보서비스,빅데이터"
	},
	{
		"ID": 352,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "효율적 웹 서비스 구성을 위한 하둡 기반 빅 데이터 처리 기법 설계 및 구현 =Design and implementation of a hadoop-based big data processing technique for efficient web services ",
		"AUTHOR": "김현주",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 논문은 저작권에 의해 보호받습니다. 지도교수:申仁澈 참고문헌(73-77장)과 설명적 각주 있음",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 353,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "강남대학교 대학원",
		"TITLE": "빅 데이터 환경에서의 통합보안관리시스템 개선에 대한 연구 =(A)study on improvement of integrated security management system in big data environment ",
		"AUTHOR": "박현석",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 양형규",
		"STORE_LOCATION": "강남대학교 도서관",
		"ABSTRACT": "본 논문은 지난 2012년 이후 떠오른 개념인 ‘빅 데이터’의 등장으로 정보보안 환경이 어떻게 변화되고 있는지 소개하고, 빅 데이터 분석 기술을 바탕으로 보안위협으로부터 어떤 통합보안시스템을 구축해야 하는지 제안하고자 한다. 빅 데이터 분야에 대해서는 최근 활용 분야에 대한 연구가 활발히 진행 중이며 특히 APT(Advanced Persistent Threats) 공격과 같은 보안 위협으로부터 시스템을 보호하기 위해 빅 데이터 기반 통합보안관리시스템에서 보완해야 할 두 가지 측면에서의 개선사항을 제안하고자 한다. 끝으로 개선사항을 적용한 통합보안관리시스템과 기존 시스템과의 비교를 통해 본 논문에서 제안하는 시스템의 기대 효과를 도출하였다.",
		"KEYWORD": null
	},
	{
		"ID": 354,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "빅 데이터 플랫폼을 이용한 풍력 발전기 SCADA 데이터 분석의 시각화 기술 연구 =(A)study on visualization of the wind turbine SCADA data analysis using big data platform ",
		"AUTHOR": "박상준",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수:양재수 참고문헌 : 47장",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "빅데이터의 기술은 이미 보편화 되었다. 생각보다 일생 생활에 가까이 다가와 있다. 최근에는 데이터의 시각화 기술이 주목받기 시작하면서 빅데이터의 기술 또한 같이 발전하고 있다. 향상된 시사점과 더 나은 의사 결정을 위해 사용되는 빅데이터의 기술은 효율성이 높은 대용량의 다양성을 가지고 급속하게 증가하는 정보의 양을 정확한 정보로 전달하기 위해 시각화의 기술이 발전하고 있다. 풍력발전기에서 매 초 쏟아지는 다양하고 많은 양의 SCADA 데이터에서 효율적인 분석을 위한 키워드를 찾은 결과 빅데이터와 시각화라는 단어를 찾았다. 이 두 개의 키워드로 하둡이라는 빅 데이터 플랫폼에 시각화 도구인 D3의 JavaScript Library를 적용하기 위하여 문헌 조사 및 연구를 실시하였다. 이에 본 논문에서는 빅데이터의 플랫폼의 구축 방법과 시각화의 기법에 대해 분석하고 풍력발전기의 SCADA 시스템에서 데이터를 모델링한 후 빅데이터 플랫폼에서 활용할 수 있는 방안을 제시하였다. 오픈 소스인 하둡과 D3의 활용으로 이 시스템을 설계하고 구현함으로써 SCADA에서의 데이터 조회, 다운로드, 엑셀 변환, 그래프 변환에서 분석과 같은 일련의 작업을 효율적으로 다양하게 비교할 수 있게 되었다.",
		"KEYWORD": null
	},
	{
		"ID": 355,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한세대학교 대학원",
		"TITLE": "빅데이터를 활용한 공공기관 관리에 관한 연구 =(A)study on supervision of public institution using big data ",
		"AUTHOR": "전경숙",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 신승중",
		"STORE_LOCATION": "한세대학교 도서관",
		"ABSTRACT": "빅데이터라고 하는 것은 규모가 크고, 생성 주기도 짧으며, 형식도 수치 뿐만 아니라 문자와 영상 데이터를 포함하는 대규모 데이터를 말하고 있으며, 데이터의 규모가 방대하고, 데이터의 종류가 다양하고, 데이터 처리 및 분석을 적시에 해결할 수 있는 특성을 가지고 있으며, 새로운 가치를 창출해 낼 수 있어야 하다. 본 연구는 국가정책사업의 주민갈등 사례 분석을 위하여 홍천군 소수력발전소를 대상으로 하였는데, 개발사업 추진과 추진과정에 대한 정책분석과 주민갈등요인이 무엇이며, 시사점과 주민갈등을 해소할 수 있는 방안을 제시하는데 본 연구의 목적이라고 할 수 있다. 빅데이터 활용 활성화를 위한 정부 정책지원과 제도 개편에 관한 논의도 가급적 빠른 시일 내에 결정할 필요가 있으며, 유용하고 많은 데이터들이 산재되어 있는 만큼, 데이터를 활용한 국민의 편익을 높이며 새로운 가치를 창출하여 국제 사회의 경쟁력을 강화할 수 있도록 체계적이고 명확한 빅데이터 기준을 정할 필요가 있으며, 빅데이터의 효과적인 활용으로 정부와 기업의 네트워크를 더 치밀하고 정교하게 구축하여 글로벌 사회에서 경쟁력을 확보하는 정책이 병행되어야 한다. 국가정책을 추진하는 중에 주민들 간 갈등은 사업 이행에 장애물로 부각이 되고 있으며, 정책 입안자들은 효율적이고 능률적인 사업의 성공을 보장하기 위하여 정책 형성과 사업집행 과정을 변경할 필요가 있는데, 사업이 지역에 성공적으로 정착되기 위해서는 지역 주민의 입장에서 이해하고 소통하는 계기가 마련되어야 할 것이다. 국가 신재생에너지 정책추진 중 홍천군 소수력발전소라는 하나의 사례를 분석한 것인데, 연구의 객관성을 확보하기 위해서는 분석 틀과 정밀한 사례분석을 실행하였지만, 국가 정책 실패사례를 모집단으로 하는 연구가 실행된다면 하나의 사례연구보다는 좀 더 객관성 있는 연구결과를 기대할 수도 있을 것이다.",
		"KEYWORD": "Big Data"
	},
	{
		"ID": 356,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅 데이터 환경에서 안전한 분산파일시스템을 위한 그룹키 관리 시스템 설계 =(A) design of group key management systems for secure distributed file systems in big-data environment ",
		"AUTHOR": "유한나",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 전문석",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근에 이동통신기술의 발전과 스마트 단말기의 보급인해 데이터가 폭발적으로 증가하는 이른바 빅 데이터 시대를 맞이하고 있다. 하둡 분산파일시스템은 빅 데이터를 처리하는 가장 대표적인 기술 중 하나로 많은 기업에서 사용 중이다. 그러나, 파일에 대한 권한 설정 문제, 세션키 유출 문제, 네임노드와 데이터노드의 키 공유 문제, 블록 접근 토큰의 재전송 공격과 가장 공격에 대한 취약점을 가지고 있다. 따라서 본 논문에서는 이러한 취약점을 해결하면서 성능을 최대한 유지하기 위해 그룹키 관리 시스템을 이용한 분산파일시스템과 동작과정들을 제안하였다. 그룹키 관리 시스템은 클라이언트와 데이터노드를 각각 논리적인 그룹으로 묶어, 클라이언트의 비밀키과 그룹키, 데이터노드의 그룹키를 관리한다. 클라이언트의 비밀키는 클라이언트 인증 및 세션키 유출 문제를 해결하는데 사용하고, 클라이언트의 그룹키는 파일에 대한 권한을 확인하는데 사용한다. 데이터노드의 그룹키는 저장된 데이터를 안전하게 관리하고, 블록 접큰 토큰을 생성하는데 사용함으로써, 하나의 비밀키를 공유하는 문제와 블록 접근 토큰의 재전송 공격 문제를 해결하였다. 성능평가에서는 그룹키 관리 시스템을 적용한 분산파일시스템과 하둡 분산파일시스템의 다양한 버전을 비교분석하여, 제안하는 시스템이 하둡 분산파일시스템에서 발생하는 다양한 문제점들을 해결하면서, 성능이 크게 저하되지 않는 것을 확인하였다. 따라서, 본 논문에서 제안하는 안전한 분산파일시스템을 위한 그룹키 관리 시스템은 대용량 데이터를 처리하기에 적합하며, 성능이 크게 저하되지 않으면서 기존 하둡 분산파일시스템에서 존재하는 문제점과 보안 위협으로부터 안전하다.",
		"KEYWORD": "Big-Data,Hadoop,그룹키 인증,빅 데이터,하둡"
	},
	{
		"ID": 357,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "울산대학교 산업대학원",
		"TITLE": "스마트 교육의 사물인터넷 활용 방향에 관한 연구 :(A)study of smart education based on internet of things :빅데이터를 기반으로 =based on big data ",
		"AUTHOR": "김두일",
		"REGION": "울산",
		"PROFESSOR": "참고문헌(p. 49-50) 수록",
		"STORE_LOCATION": "울산대학교 도서관",
		"ABSTRACT": "스마트교육은 스마트 기술에 기반을 둔 교육서비스이다. 초연결사회로 발전을 가능하게 하는 신산업인 사물인터넷, 클라우드 컴퓨팅, 빅데이터 등의 IT기술의 발전과 스마트기기의 급속한 확산에 따라 개인 특성에 맞는 차별화되고 창의적인 학습 수요가 증가하였다. 그러나 아직까지 교육현장에서 학습자의 흥미, 특성과 요구를 고려한 맞춤형 학습이 적용된 사례가 많이 소개되지 않았다. 학생들은 개인마다 선행 속도, 능력, 관심해결 방법 등에서 서로 다른 차이를 가지고 있다. 이에 본 논문에서는 사물인터넷, 클라우드 컴퓨팅, 빅데이터 기술을 적용하여 새로운 플랫폼 모델을 정립하고 그것을 통해 개개인의 교육성과를 쉽게 파악하고 더 나은 교육을 받을 수 있도록 하며 더 나아가 미래의 교육을 성장시키는데 일조하고자 하였다. 본 논문은 3가지의 신성장동력 기술을 각각 파악 및 분석하여 사례를 토대로 스마트 교육에 적용시켜보자고 하였다. 사물인터넷을 기술을 이용한 스마트 교육에서의 플랫폼 활용을 통해 교실의 환경 개선과 온라인 학습을 통해 수집된 빅데이터를 활용하여 온라인 학습효과 분석, 콘텐츠 개발, 교육과정 및 교육정책 개선, 학생 지도에서의 활용 방안과 그 기대효과를 제시하였다. 제시한 스마트교육에서의 사물인터넷 활용 방안을 통해 학생에게 쾌적한 학습 환경 조성과 빅데이터를 활용하여 개별적인 맞춤형 교육을 제공할 수 있으며, 이로 인해 학생들의 학업 성취도 및 교사의 교육 효과를 높일 수 있으리라 기대한다. 끝으로 이러한 활용 방안을 통해 향후 스마트교육의 향후 방향을 제시함으로써 본 논문의 연구를 마무리 하였다.",
		"KEYWORD": null
	},
	{
		"ID": 358,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "텍스트마이닝, 복잡계 네트워크, 인터넷 빅데이터를 활용한 미래예측 관련 중요 키워드 도출 모델 =(A)new method of key word extraction from foresight based on textmining, complexity network analysis, and internet big data ",
		"AUTHOR": "정철우",
		"REGION": "서울",
		"PROFESSOR": "국문요지: p. v-vii Abstract: p. 128-129 지도교수: 김재준 부록: 1. 미래예측방법, 2. 복잡계의 개요, 3. 텍스트마이닝 관련 분석툴 외. 참고문헌: p. 81-87 서지적 각주 수록",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "",
		"KEYWORD": "미래학"
	},
	{
		"ID": 359,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "빅데이터를 이용한 의학도서관 웹사이트 이용행태에 관한 연구 =(A)study on users` behavior of medical library website using big data ",
		"AUTHOR": "홍윤미",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김성희",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 연구에서는 빅데이터를 이용한 의학도서관 웹사이트 이용행태 분석을 통한 개선방안 제안에 목적이 있다. 이를 위하여 웹 트래픽 정보인 세션, 사용자, 페이지뷰 수, 세션당 페이지수, 평균 세션 시간, 이탈률의 측정지표를 기준으로 이용자 일반적 특성, 사용자환경 분석, 방문 분석, 유입분석, 사이트 분석 별로 분석하였다. 연구 방법은 서울에 소재한 A의학도서관 웹사이트를 대상으로 2014년 4월 1일부터 2014년 9월 30일까지 6개월 동안 빅데이터 분석 툴(tool)인 구글 애널리틱스(Google Analytics)를 사용하여 데이터를 수집하였다. 이상의 내용을 바탕으로 A의학도서관 웹사이트 이용자의 실제 이용행태 분석 결과 도출된 이슈들을 기반으로 제안된 웹사이트 개선방안 결과를 요약하면 다음과 같다. 첫째, 이용자 일반적 특성 분석 결과 의학도서관 웹사이트를 이용하는 이용자들의 성별은 남자가 56.37% 여자가 43.63%가 보다 12.74% 높은 것으로 나타났으며, 연령은 20대 중반에서 40대 중반(62.06%)이 주 이용자층으로 나타났다. 접속 위치는 대한민국(97.83%)이 가장 높게 나타났으며 미국(1.59%)에서도 일부 사용자들이 접속하는 것으로 나타났다. 이에 따라 향후 영어 버전 및 다국어 지원 서비스를 추가할 필요가 있을 것으로 보인다. 둘째, 사용자 환경을 분석에서 기기 종류는 아직까지 모바일(2.61%) 및 태블릿(1.80%) 트래픽이 높지는 않지만 평균 세션 시간은 데스크톱(95.59%)보다 오래 머무는 것으로 나타났다. 즉 사이트 고착성을 나타내는 지표 중의 하나인 평균 세션 시간이 태블릿 기기가 5분 21초로 가장 긴 것으로 나타났다. 태블릿 기기의 평균 세션 시간이 다른 기기보다 높은 점을 감안하였을 때 태블릿 기기의 웹사이트 화면해상도 및 사양을 지원함으로써 이용자의 사이트 고착성을 높이고 이용자의 만족도를 이끌어 낼 수 있을 것이다. 셋째, 방문 현황으로는 이용자의 평균 세션 시간은 4분 39초로 나타났다. 이에 따라 평균 머문 시간 및 페이지뷰 수를 증가시키기 위해서 웹사이트 콘텐츠를 개발하여 이용자들의 니즈와 호기심을 충족시킴으로써 사이트 고착성을 증가시킬 수 있을 것으로 판단된다. 요일별 방문 분석에서는 평일 평균 세션은 1,132 세션, 주말 평균 세션이 499 세션으로 트래픽이 2배 이상 감소하는 것으로 나타났다. 이에 따라 웹사이트 업데이트 및 정기점검, 관리 작업을 주말에 하여 이용자의 불편을 최소화할 수 있도록 하고 방문이 가장 적은 요일, 시간대를 파악하여 공지 또는 이벤트를 하거나 메일링을 통한 홍보를 함으로써 방문을 유도할 수 있을 것이다. 넷째, 유입 매체 분석 결과 직접 유입(74.68%)이 가장 높게 나타났다. 이에 따라 검색 엔진을 통해 이용자의 방문을 유도하기 보다는 웹사이트 URL주소를 기억하기 쉽게 만들고 URL주소를 홍보함으로써 기관내 홍보를 활성화 시켜야할 것이다. 또한 병원, 대학 웹사이트에서 연결 링크를 통해 접근할 수 있도록 설계하고 방문 경로 단계를 짧게 하여 이용자의 웹 접근성 및 이용편의성을 향상시켜줄 필요가 있다. 마지막으로, 사이트 페이지 분석결과 최다 페이지뷰를 차지한 페이지는 메인페이지 다음으로 E-Journals 페이지로 나타났다. 의학도서관 웹사이트 이용자들이 원하는 콘텐츠가 학술 전자저널이라는 것으로 미루어 보아 이에 대한 콘텐츠를 좀 더 풍부하게 하고 품질관리를 지속적으로 해야 할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 360,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "빅 데이터 플랫폼 기반 감시 데이터 큐브의 설계 및 구현 =Design and implementation of a surveillance data cube based on big data platform ",
		"AUTHOR": "오승근",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 朴大熙 참고문헌: 장 59-62",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 공공장소나 주요 시설물에서의 도난과 같은 단순 범죄부터 위험물 투기 및 방치 등과 같은 특수 범죄에 이르기까지 다양한 형태의 범죄들이 빈번히 발생하고 있다. 특히 2001년의 9.11테러 발생 후, 유동인구가 많은 공항, 버스정류장, 지하철역 등과 같은 공공장소에서의 응급상황이나 보행자 안전 문제 등이 크게 대두 되어졌다. 또한 범죄 뿐만 아니라 재난?재해의 규모와 피해가 커짐에 따라 세계적으로 보안 감시 분야에 대한 지속적인 연구와 투자가 증가되고 있다. 최근의 연구 동향에 따르면 소리 센서 데이터와 영상 데이터 등 다양한 멀티미디어 센서를 이용하여 위험상황을 탐지 및 식별하거나 특정 개체를 트래킹하거나 식별함으로써, 신속하게 이상 상황에 대처할 수 있도록 하는 실시간 상황인식 시스템과 관련된 연구가 활발히 진행되고 있다. 하지만 이 같은 실시간 상황인식 시스템은 사건이 발생하는 순간을 빠르게 탐지 및 식별하여 대응에 도움을 주는 사후 처리 방식으로써, 사전에 비정상 상황 발생 가능 여부를 분석하여 대응 체계 수립과 관련된 정보를 제공해주기는 어려운 실정이다. 따라서 본 논문에서는 실시간 상황인식 기능뿐만 아니라 비정상 상황과 관련된 데이터를 지속적으로 수집 및 가공하고, 분석하여 비정상 상황 대응 체계 수립에 도움을 줄 수 있는 정보도 제공 가능한 지능형 통합 감시 시스템을 제안 및 구현하고자 한다. 본 논문에서 새롭게 제안하는 지능형 통합 감시 시스템은 먼저 센서네트워크 환경에서 영상 및 소리 데이터를 취득하여 실시간으로 비정상 상황을 탐지 및 식별하고, 알람 경고를 울려준다. 그리고 탐지 및 식별된 비정상 상황에 대한 메타데이터와 분산되어 있는 공공 데이터를 수집 및 가공하고 데이터 큐브를 구축하여 기초 통계 분석 및 OLAP 연산과 데이터 마이닝 등의 분석 결과를 제공함으로써 관리자가 신속하고 체계적으로 비상상황에 대응할 수 있도록 지원해준다. 본 논문에서 제안된 지능형 통합 감시 시스템은 크게 4 부분으로 구성되며 다음의 구조를 갖는다 : 1) 실시간 비정상 상황 탐지 및 식별 시스템; 2) 이벤트 메타 데이터 및 공공 데이터 수집 시스템; 3) 분산 데이터 큐브 시스템; 4) 감시 데이터 분석 및 이벤트 검색 시스템. 실시간 비정상 상황 탐지 및 식별 시스템은 센서 네트워크환경에서 실시간으로 유입되는 영상 및 소리 센서 데이터로부터 비정상 상황 발생 여부를 빠르게 탐지 및 식별하고 추후 이벤트 검색 지원을 위한 이벤트에 대한 메타데이터를 저장하는 시스템이다. 이벤트 메타 데이터 및 공공 데이터 수집 시스템은 사전처리를 위한 데이터 큐브를 구성하기 위해서 공공 기관에 분산되어 있는 감시 시스템 관련 데이터들을 수집하고 정규 형태로 가공하고 이를 미리 모델링된 데이터 큐브로 전송한다. 분산 데이터 큐브 시스템에서는 전송된 감시 데이터를 입력으로 Surveillance Cube를 구축함으로써, OLAP 연산 등의 다차원적인 분석이 가능하도록 지원한다. 이 때 Surveillance Cube를 구축하는 데이터 큐브 시스템은 분산화 되어 있는 대용량 데이터임을 고려하여 하둡 기반의 빅 데이터 플랫폼을 사용하며, 최적 업데이트 보장을 위하여 OLAP 작업에 필요한 OLAP 작업에 필요한 데이터 조합을 고려하여 MapReduce 작업을 통하여 빠르게 조합 연산(Aggregation Calucation)을 수행한다. 감시 데이터 분석 및 이벤트 검색 시스템에서는 구축된 데이터 큐브를 이용하여 통계 분석 및 OLAP 연산과 함께 데이터 마이닝 기법 및 네트워크 분석 등을 통하여 비정상 상황 이벤트 별 패턴, 비상 상황 발생 가능 여부와 환경 요인과의 상관관계 등을 다양하게 분석하여 감시 시스템 관리자에게 제공함으로써, 관리자가 보다 체계적이고 효율적으로 사전에 비상 상황에 대한 대응 체계를 마련할 수 있도록 지원해준다. 본 논문에서 제안하는 지능형 감시 시스템은 멀티미디어 데이터 분석 및 패턴인식 기술 등을 이용하여 정확하고 빠르게 비정상 상황을 탐지 및 식별하고, 데이터 큐브와 데이터 마이닝 기법을 통하여 다차원 검색과 심층적 분석을 지원한다. 본 논문에서 제안된 시스템의 타당성 검증을 위하여 본 논문에서는 벤치마크 데이터와 각 지역 기관에서 제공하는 공공 데이터에 대한 실제적인 실험을 수행하여 보다 객관적이고 과학적인 근거로서 활용될 수 있음을 보였다.",
		"KEYWORD": "Big Data Analysis,Data Cube,Hadoop,Pattern Recognition,Surveillance"
	},
	{
		"ID": 361,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "성균관대학교 정보통신대학원",
		"TITLE": "빅 데이터 환경에서의 안전한 개인정보 활용 방안 =(A)study on the safe utilization of personal information in big data environment :小賣 流通의 마케팅 活用 觀點에서 ",
		"AUTHOR": "홍민성",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 원동호 참고문헌: p. 44",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "본 논문은 빅 데이터 환경에서 개인정보의 수집·활용에 있어 현행 법률에서의 동의 방식을 개선하여 분석 시 활용하는 데이터의 수준을 정보 주체가 사전에 동의 한 범위에서 활용이 이루어지도록 변경하고 각 데이터가 결합하여 식별 가능한 정 보가 되는 것을 약화 시킬 수 있도록 각 데이터에 식별 능력을 점수화하여 일정 점수 이상이 되는 정보에 대해 데이터 변조와 익명화 처리를 통해 결합력을 약화시켜 개인정보가 오남용 되거나 식별 가능한 정보로 변화되는 것을 통제하는 역할을 한다.",
		"KEYWORD": "Big Data,Retail,개인정보보호,빅 데이터,소매 유통"
	},
	{
		"ID": 362,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "남서울대학교 대학원",
		"TITLE": "빅 데이터 기반의 건설사업관리 업무프로세스 모델 개발을 위한 기초적 방안 연구 =(A)basic study for development of construction management business process model based on big data ",
		"AUTHOR": "유형석",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 민경석",
		"STORE_LOCATION": "남서울대학교 도서관",
		"ABSTRACT": "최근 스마트폰이 대중화됨으로 인해 SNS활동의 이용자수가 대폭 늘어나고, 문자메시지가 아닌 데이터메신저가 상용화됨으로 인해 개인과 개인 간의 오고가는 정보가 기하급수적으로 많아지고 있다. 이러한 막대한 양의 데이터들 안에서 기존의 데이터 분석 기법으로는 가치 있는 무언가를 얻는 것이 점점 어려워 이고 있다. 이러한 이유에서 각광 받고 있는 산업이 빅 데이터이고, 빅 데이터를 통해 얻어진 데이터들은 현재 유통, 판매, 제조 분야 등 여러 분야 에서 소비자의 패턴을 예측하여 기업에게 수많은 이익을 창출해 주고 있다. 건설사업의 규모는 커짐으로 인해 사업을 관리하는데 있어서 예측치 못한 리스크가 발생. 이로 인해 건설사업관리업체(CM업체)들은 발주자에게 성공적인 사업물을 제공하는데 어려움을 느끼고, 이는 곧 발주자의 신뢰하락으로 수주확보와 수익에 직접적으로 연결이 되고 있는 실정에 놓여있다. 이러한 이유에서 성공적인 사업물을 완수하는데 있어 리스크를 사전에 예측, 관리, 방지할 수 있는 방안이 절대적으로 필요하며 그러기 위해서는 기존의 수많은 사업데이터들을 수집 및 분석하여 그 안에서 공통된 패턴을 찾아 미리 사업의 리스크를 예측할 수 있는 방안이 절대적으로 필요한 상황이다. 이에 본 연구에서는 건설사업관리를 진행하는데 있어 리스크를 사전에 예측할 수 있는 방안으로 빅 데이터 기반의 CM업무프로세스 개발에 대한 연구를 진행하고자 한다. 본 연구는 사전에 리스크를 예측 및 계획하여 관리할 수 있는 방안으로 빅 데이터의 활용가능성 여부와 더 나아가 빅 데이터 기반의 새로운 건설사업관리(CM) 프로세스 메뉴얼을 제안하는 것으로 연구를 진행하였다. 미국 및 국내의 CM시장 현황을 비교 분석하여 CM시장의 특성을 파악하였고, 빅 데이터 기반의 업무 프로세스를 개발하기 위하여 건설업 종사자들을 대상으로 빅 데이터의 인식도와 기존의 사업 데이터 구축 현황 및 활용성을 조사하고, 빅 데이터를 활용했을 시 효과적으로 수행할 수 있는 업무단계는 무엇인지 AHP 중요도 분석기법으로 상위 3가지의 업무단계를 도출하여 선행연구를 실시하였다. 마지막으로 상위3가지 중요업무단계가 파악되면 빅 데이터가 적용되어진 새로운 CM프로세스의 기초적 메뉴얼을 제안하였다. 키워드 : BIG DATA, 건설사업관리(CM at risk), 건설사업관리 업무단계",
		"KEYWORD": null
	},
	{
		"ID": 363,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "빅 데이터 분석 방법을 활용한 관광기반시설과 지역관광수요 관계 연구 =(The)study on the relationship between tourism infrastructure and regional tourist demand by applying big data analysis ",
		"AUTHOR": "김낙원",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김남조",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "빅 데이터 시대가 개막했다. 최근에 관련된 처리 기술들이 증가하면서 관련 연구가 활발하게 진행되고 있다. 또한 빅 데이터 시대와 더불어 오픈 데이터 운동이 활발하게 진행되면서, 가용할 수 있는 데이터의 범위는 점차 확대되고 있다. 이는 관광학 내에서도 적용된다. 스마트 기기와 관광 관련 플랫폼 등을 통해 생산된 관광객의 정보들이 실시간으로 수집됨에 따라, 기존에는 알 수 없었던 관광객의 동기, 행태 등을 분석할 수 있는 데이터들이 양산되기 시작한 것이다(Xiang, Vincent, Daniel, 2015). 이제 관광에서도 빅 데이터의 분석은 피할 수 없는 과정으로 자리 잡고 있는 것이다. 본 연구는 빅 데이터 분석 방법을 적용하여 2013년 9월 1일부터 2014년 8월 31일까지 한국을 방한한 외국인의 로밍데이터와 관광 기반시설자료들을 매쉬업하여 둘 간의 관계를 통계적 방법과 공간 패턴 분석을 통해 규명하는 연구를 진행하였다. 연구 결과, 관광 기반 시설 중에서 특히 관광자원과 숙박시설이 지역내 방문한 관광객의 수와 상관성이 높은 것으로 분석되었으며, 식당, 편의시설, 접근성 등은 낮은 것으로 분석되었다. 하지만 미국과 대만의 경우에는 식당시설 역시 지역 내 방문한 관광객 수와 상관성이 나타나는 것으로 분석되었다. 자연관광자원의 경우 유치에 거의 영향이 낮은 것으로 분석되었다. 본 연구는 빅 데이터 분석 방법을 활용하여 실증적인 관계를 규명하였으며, 향후 추가 연구에 기초자료로서 활용방안이 높은데 의의가 있다.",
		"KEYWORD": "공간패턴분석,관광기반시설,로밍 데이터,빅 데이터"
	},
	{
		"ID": 364,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "빅데이터를 이용한 한국·중국·일본의 레스토랑 브랜드 개성에 관한 연구 =(A)study of Korea, China and Japan restaurant brand personality by using big-data ",
		"AUTHOR": "도해용",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이애주",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "본 연구의 목적은 빅데이터를 이용하여 브랜드 개성 측정항목을 추출하여 한국, 중국, 일본의 레스토랑 브랜드개성을 측정하고, 이를 활용하여 상권과 업종의 브랜드개성을 연구하는 것이다. 빅데이터 수집을 위해 전용 웹크롤러를 개발하였으며, 한국, 중국, 일본 대표 레스토랑 평가 사이트로부터 분석에 필요한 표본을 수집하였다. 연구에 사용된 유효 표본은 한국 서울 8,608개 레스토랑과 223,365개 리뷰, 중국 베이징 39,550개 레스토랑과 3,158,623개 리뷰, 일본 도쿄 41,985개 레스토랑과 1,101,319개 리뷰로 총 90,143개 레스토랑의 4,483,307개 리뷰가 연구에 사용되었다. 수집된 리뷰는 구글 번역기를 통해 영어로 번역한 후 형태소분석기와 품사추출기를 통해 단어를 추출한 후 내용분석을 통해 브랜드개성을 측정하였다. 측정된 브랜드개성은 SPSS를 이용하여 기술통계, 평균의 차이분석(Oneway Anova), 다중회귀분석을 실시하였다. 연구결과 3개국 모두에서 빅데이터를 이용하여 리뷰에서 내용분석기법으로 브랜드개성 측정이 가능하였으며, 측정된 브랜드개성은 국가간, 상권간, 업종간 유의한 차이가 있는 것으로 나타났다. 본 연구는 정성적 데이터인 소비자의 리뷰에서 데이터를 추출하고 가공하여 정량적 분석을 해냈다는데 의의가 있다.",
		"KEYWORD": "내용분석(content analysis),레스토랑 브랜드개성(restaurant brand personality),빅데이터(big data),텍스트마이닝(text mining)"
	},
	{
		"ID": 365,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한라대학교 정보산업대학원",
		"TITLE": "빅데이터와 R을 이용한 의료정보 분석 =Analysis of medical data using the big data and R ",
		"AUTHOR": "최기용",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 366,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 신문방송대학원",
		"TITLE": "빅데이터를 활용한 뉴스 콘텐츠가 기사의 차별성에 미치는 영향 :경제뉴스 콘텐츠를 중심으로 ",
		"AUTHOR": "김욱원",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이민규 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "The rapid development of the internet and smart device technology has brought a large reform in the media environment after the 2000s. The media environment which was structured in the existing printed media and broadcasting media, has changed in how information has been relayed on online media and portal site, as well as, internet social network services. This quantitative explosion of the media environment brought severe competition of ‘click’ through rate, which has been criticized as‘abusing article mass production’. These changes caused not only loss of customer’s trust, but also a vicious circle of financial difficulty. The Media struggled with the production of competitive contents as a way to survive and utilize the Big Data in journalism which has attracted much attention recently. In this study, it tries to depict how the Utilized Big Data in the economic news contents, can present the differences in terms of: reliability, objectivity, depth, as well as an easy read, which is compared with existing general articles, that only provide a consistency of text or text combined with pictures. Firstly, I had struggled with traditional ways of news produce and Big Data journalism, by examining this previous study and I suggested this subject of inquiry builds on earlier work. This study concludes on three types of articles that consist with text only, and combination with pictures, as well as, the combination of Big Data. They also include to the first-line journalists and examination of which these articles were more specific among them in terms of reliability, objectivity, depth, and legibility. The results indicated that the economic news contents by using Big Data has different influence on all the entries that provided reliability, objectivity, depth, and readability. This study showed that experts’ content by Utilized Big Data in economic news, affect considerably the internet media environment. Overall, this study has great significance. It presents that the comparison of existing journalism practices and news contents do Utilize the Big Data by the aiming at the front-line journalist groups and making the bigger headlines. Furthermore, a follow-up study, I am certain the success results of the differences in news contents are not only by Utilizing Big Data, but are also on various points of view.",
		"KEYWORD": null
	},
	{
		"ID": 367,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "한국항공대학교 대학원",
		"TITLE": "빅 데이터 검색을 위한 원 클래스 서포트 벡터 머신 =Large scale one-class support vector machine for big data retrieval ",
		"AUTHOR": "김기주",
		"REGION": "경기도",
		"PROFESSOR": "지도교수:최영식",
		"STORE_LOCATION": "한국항공대학교 도서관",
		"ABSTRACT": "빅 데이터 기술은 대량의 정형 또는 비정형 데이터로부터 가치를 추출하고 결과를 분석하는 기술을 의미 한다. 빅 데이터에는 다양한 응용 분야가 있지만 본 논문에서는 빅 데이터 검색에 초점을 둔다. 대표적 사례로 구글의 ‘음성인식 서비스’를 들 수 있다. 구글에서는 ‘데이터가 많으면 많을수록 더 좋은 음성 인식 서비스를 제공할 수 있다’는 것을 대용량 데이터와 검색의 정확도 상관관계를 분석함으로써 증명하고 있다. 이러한 흐름에 맞추어 본 논문에서는 빅 데이터 검색 문제를 1-Class 문제로 해석하여 접근한다. 긍정(positive)과 부정(negative) 데이터를 필요로 하는 2-Class 또는 n-Class 문제와는 다르게, 1-Class 문제는 주어진 학습데이터의 분포를 측정하고 분포에 가장 적합한 표현 체를 찾는다. 1-Class Support Vector Machine은 이러한 문제를 해결하기 위한 잘 알려진 접근 방법이며 대표적인 연구로써 standard one-class SVM와 LS(Least Squares) one-class SVM이 있다. LS one-class SVM는 상대적 거리 측정 (proximity measure) 성능이 뛰어 나지만 역행렬 계산이 필요하기 때문에 계산량이 많고 빅 데이터인 경우 계산 자체가 불가능 하다. 반대로 standard one-class SVM은 빠르게 계산할 수 있으며 계산 방식이 학습데이터들에 대한 독립성을 제공하고 있어 병렬처리가 가능하지만 학습 데이터에 대한 최적의 경계를 구할 뿐 경계 내부의 데이터 분포에 대해서는 고려하지 않는다. 이러한 성질은 분류(classification)나 특이성 검출(novelty detection)에 적합하지만 상대적 거리 측정 방법으로는 성능이 LS one-class SVM 보다 떨어진다. 본 논문에서는 standard one-class SVM의 계산 방식으로 LS one-class SVM의 상대적 거리 측정 성능에 근접하는 새로운 one-class SVM을 제안한다. 제안하는 one-class SVM은 평행하는 두 개의 평면으로 데이터들이 존재하는 최소영역을 표현 하고 두 평면의 중간에 위치한 평면을 상대적 거리 측정 기준으로 사용함으로써 LS one-class SVM 근접한 성능을 얻는다. 또한, DH one-class SVM의 구현을 맵리듀스(Mapreduce)와 BSP(Bulk Synchronous Parallel)방식으로 설계함으로써 분산 환경에서 빅 데이터를 병렬로 처리하는 알고리즘의 확장성(scalability)를 얻는다. 실험을 통하여 제안하는 알고리즘의 분류 성능은 standard one-class SVM 보다 떨어지지만 상대적 거리 측정 성능은 standard one-class SVM, kernel mean, kernel PCA 보다 우수하고, LS one-class SVM에는 근접한 결과를 보여 주었다.",
		"KEYWORD": "Big Data,One Class SVM,Retrieval,SVM"
	},
	{
		"ID": 368,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Integration of DBMS and distributed file system for big data management and analytics =빅 데이터 관리 및 분석을 위한 DBMS와 분산 파일 시스템의 통합 ",
		"AUTHOR": "Kim,Jun-Sung",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 369,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "빅 데이터 保安이벤트 相關分析을 통한 APT 攻擊探知 方案에 관한 硏究 =(A)study on the methods to detect APT attacks through correlation analysis on big data security event ",
		"AUTHOR": "손경호",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 원동호 참고문헌 : p. 124-131",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "최근 들어 국내에서는 잇따른 개인정보 유출, 해킹 등 보안사고가 연이어 발생됨에 따라, 사이버 보안에 대한 우려와 이에 대응하기 위한 여러 가지 기술적, 정책적 방안들을 모색하고 있다. 그러나 최근에 기존의 사이버 위협이 점차 고도화·지능화 되고 있는 시점에서 기존의 보안기술로 새로운 위협에 대처하기에는 한계점이 존재하고 있는 상황이다. 일례로 2009년에 발생한 7.7 DDoS 공격과 2011년 3.4 DDoS 공격과 같이 다수의 주요 기관을 대상으로 공격이 발생하거나, 2011년 4월 은행 전산망 해킹사고, 7월 통신사 개인정보 유출사고와 2013년 3.20 방송사·금융사 전산망 마비사고와 그해, 6.25 청와대 해킹사고는 기존의 사이버 공격이 해킹 실력 과시, 단순 정보유출의 성격을 갖는 것과 달리, 점차 금전적 이득을 취하거나, 정치·이념적 성격을 지닌 사이버테러 형태로 변화되고 있음을 보여준다. 이러한 사이버 공격은 웜·바이러스, 백도어, 루트키트(Rootkit) 등 악성코드를 통해 이뤄지고 있으며, 이런 악성코드들이 과거에는 호스트기반으로 제작되고 배포되었으나, 최근에는 공유의 기능과 네트워크 전파기능이 결합하여 지능화되어, 강력한 위협으로 나타나고 있다. 또한, 기존의 악성코드는 대부분 패턴 시그니처(Signature) 방식으로 탐지하고 차단되었으나, 최근에는 하루에도 수만에서 수십만 개씩 쏟아져 나오는 모든 악성코드를 탐지·차단하는 것은 거의 불가능하고 악성코드가 신규 취약점을 이용한 제로데이 공격(Zero Day Attack)을 발생시켜 기존 보안장비로 대응하기에는 현실적으로 불가능한 실정에 이르고 있다. 최근에 발생한 이런 공격들을 ‘APT(지능형지속위협)’ 공격이라 부르며, 이러한 진보된 지속적인 위협을 어떻게 탐지하고 대응해야 하는지가 새로운 보안 문제로 떠오르고 있다. APT 공격대응을 위해서는 알려지지 않은 신종 악성코드에 대한 탐지/분석 기술이 기본적으로 필요하며, 악성코드 침투 시점에 대응하지 못하더라도 공격자가 좀비PC를 통해 원하는 목적을 달성하기 위해서는 감염PC 내부 확산, 계정정보 등 주요정보 습득, 실제 공격수행까지 많은 시간이 소요되므로, 이러한 과정에서의 공격 이상징후를 탐지하는 기술이 필요하다. 이를 위해, 기존의 보안 장비(방화벽, IDS/IPS 등) 및 IT장비(웹서버, DB서버 등)에서 발생되는 로그 등을 통합/상관분석을 통해 공격 징후를 탐지하는데서 벗어나, 네트워크 및 호스트(PC 등) 행위 전체를 수집하고 이상행위에 대한 조사/분석 기술이 필요하지만, 네트워크 대용량 및 고속화(1G망 환경에서 통상 방화벽 로그는 수천만 건에 이르고, 웹 로그는 수백만 건이 발생)로 인해 대용량 데이터를 수집하고 상관 분석하는 것은 기술적으로 쉽지 않은 문제이다. 본 논문에서는 내부로 악성코드가 침투하는 주요 경로인 웹, 이메일을 대상으로 악성코드 탐지 및 분석을 통해 내부 감염PC를 탐지하고, 감염된 PC를 대상으로 접속하는 C&C 서버 탐지, C&C 서버로 접속하는 감염된 좀비PC 탐지 등을 통해 대응하는 한편, 미처 탐지하지 못한 악성코드로 인한 공격징후 탐지를 위해 빅 데이터 분석 기술을 사용한다. 이를 통해, 내/외부 간 모든 통신 트래픽, 보안 장비, 웹/이메일, 시스템 로그를 모두 수집/저장하고, 장기간 데이터에 대한 상관분석을 통해 침투 시점에서 탐지하지 못한 이상 공격 징후를 탐지하기 위한 방법 및 알고리즘과 모델을 제안하고, 실제 검증을 통해 APT 공격을 탐지할 수 있는 방안을 제안하고자 한다.",
		"KEYWORD": "APT,빅 데이터 보안이벤트,악성코드,이상징후"
	},
	{
		"ID": 370,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "SNS 빅 데이터 분석을 통한 텔레비전 프로그램 시청률 예측에 대한 연구 =Do big data support to forecast TV viewer rating in Korean TV drama case? :국내 드라마 사례 중심 ",
		"AUTHOR": "마경란",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 이욱 권두 국문요지, 권말 Astract 수록 참고문헌 : p. 36-38",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 몇 년 간 한국 드라마 콘텐츠의 파워가 참으로 무섭다. 미디어 시장에서 시청률 상위 프로그램의 대부분은 한류 스타들과 다양하고 참신한 소재들로 무장한 드라마들로 채워지고, 일본과 중국을 비롯한 동남아시아 시장은 물론이고, 중동 유럽까지 한국 드라마의 매력이 꾸준하게 퍼져가고 있다. 이러한 미니시리즈 드라마를 제작하는 데에 있어서 회 차(Episode) 당 제작비는 약 2억에서 5억 원 가량이 소요되며 보통 16편에서 20편 정도 제작되므로 보통 한 타이틀을 제작 하는 데에 있어 약 30억에서 100억 원 이상의 비용이 소요된다. 이렇듯 막대한 제작비가 투자가 되는 콘텐츠의 성과를 측정할 수 있는 유일한 정량적 측정치는 시청률(viewer rating data)인데, 투자자들이 손해 리스크를 줄일 수 있고, 마케팅 효과를 극대화 시킬 수 있는 전략을 적절하게 반영 시킬 수 있는 분석 시스템이 나온다면, 양질의 콘텐츠 생산에 큰 도움을 줄 수 있을 것이다. 본 논문은 기존의 시청률 예측에 대한 연구 방법으로 SNS Data(소셜 네트워크 서비스 데이터)를 포함한 미디어 빅 데이터(Big Data)와 시청률의 상관 관계에 초점을 두고 있다. 국내에서 방영된 20부작의 드라마(신사의 품격, 2012 SBS)와 관련된 온라인 상의 미디어 데이터들을 모아서 이를 바탕으로 시청률이나 점유율에 유효한 영향을 주는 변수가 무엇인지를 회귀분석을 통해 분석하였다. 결과는 CGM(Consumer Generated Media : SNS및 블로그, 게시판, 클럽, 지식검색 등의 미디어)이라 정의한 변수가 시청률과 점유율 모두 회귀 분석의 결정계수를 통해 64%만큼 설명하는 것으로 나타났다. SNS 항목만을 보면 분석된 세 가지 서비스 중 국내 기반의 미투데이와 다음요즘이 시청률에 유의하였고 트위터는 유의하지 않은 것으로 나타났다. 이러한 연구결과는 시청률 예측에 좀 더 정교한 기반이 될 수 있다는 점에서 시사점을 제공한다.",
		"KEYWORD": "미디어"
	},
	{
		"ID": 371,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "위치정보 데이터가 포함된 빅 데이터 환경에서 시공간 인덱스 갱신 효율을 위한 MapReduce의 확장 ",
		"AUTHOR": "최용권",
		"REGION": "인천",
		"PROFESSOR": "지도교수:배해영 인하대학교 논문은 저작권에 의해 보호받습니다. 참고문헌 : p.65-67",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "최근 스마트폰, 실내외 내비게이션, PMP등과 같은 GPS를 장착한 다양한 모바일 기기들이 급속히 대중화 되면서 기존에는 접근하기 어려웠던 위치 정보를 매우 쉽게 이용할 수 있게 됨으로써 친구 찾기, 길 찾기, 위치 기반 SNS 등과 같은 위치기반 응용 서비스들의 사용자들이 급격하게 증가 하고 있다. 그 결과 위치 기반 응용 서비스가 거대화 되고 있고 이에 따라 이 서비스에서 처리해야 하는 이동객체들의 데이터의 양도 매우 커지고 있어 기존의 처리 방법이 아닌 새로운 방법이 필요하게 되었다. 지금까지 대규모의 이동객체 관리를 위해 갱신 비용을 감소시킬 수 있는 많은 인덱스 기법들이 제안되었다. 이동객체 인덱스는 빈번하게 위치정보가 변화하는 이동객체를 관리하기 위해 주기적으로 갱신되어야 하기 때문이다. 그러나 이러한 기법들은 위와 같이 서비스의 크기가 커지고 이동객체의 수가 현저히 증가함에 따라 갱신 횟수가 증가하는 경우 인덱스의 갱신 가능범위를 초과하는 부하가 발생한다. 따라서 이처럼 증가하는 갱신 횟수를 감소시킬 수 있는 방법이 필요하다. 본 논문에서는 이처럼 기존의 처리 가용량을 초과하는 빅 데이터 크기의 이동객체에서 발생하는 갱신요청들을 기존의 인덱스에서 처리 할 수 있도록 MapReduce를 확장하여 갱신 횟수를 감소시키는 기법을 제안한다. MapReduce는 대용량의 갱신요청 데이터를 분산 환경을 이용하여 빠르게 처리 할 수 있고 무엇보다 각각의 정렬되지 않은 이동객체의 갱신요청 데이터를 각각의 이동객체별로 그룹화를 가능하게 해준다. 이는 이 후 제안하는 알고리즘에서 갱신요청 데이터를 쉽게 이용할 수 있도록 해준다. 그 다음으로 각 이동객체 별로 그룹화된 데이터들의 최신의 데이터와 가장 오래된 데이터를 선택하여 이동객체가 가지고 있는 시공간 정보를 이용하여 갱신 여부를 결정하도록 하여 전체 입력된 갱신요청 데이터 중 실제 갱신할 데이터만 선택하게 하여 전체 갱신 횟수를 크게 감소시킨다. 그리고 갱신이 지연된 경우 지연된 갱신요청 데이터를 가지고 있는 해시 테이블에 일정기간 보관하여 지연된 갱신요청이 분실 되지 않도록 한다. 마지막으로 갱신이 결정된 갱신 데이터 리스트의 데이터를 갱신요청 데이터의 시간 정보를 비교하여 비슷한 갱신 시간을 가지는 데이터끼리 묶어 관리하게 하여 갱신 데이터 리스트에서 사용되는 메모리의 양을 감소시킨다. 본 논문은 실험을 통해 제안한 기법을 적용한 경우와 적용하지 않은 경우를 비교하여 전체 갱신 횟수 및 갱신 비용이 감소되는 것을 확인하였다. 본 논문의 알고리즘을 적용한 경우 빅 데이터와 같이 갱신 횟수가 많아질수록 갱신요청 데이터가 감소되는 비율이 커짐을 확인 할 수 있고 실제 감소된 갱신요청 데이터를 실제 R-tree 및 LUR-tree에 적용할 경우 감소된 데이터의 양으로 인해 인덱스에서 발생하는 갱신 비용도 감소됨을 알 수 있다.",
		"KEYWORD": "Bigdata,MapReduce,Spatial-temporal index"
	},
	{
		"ID": 372,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "영남대학교 대학원",
		"TITLE": "SNS상의 비정형 빅 데이터로 부터 감성정보 추출방법 ",
		"AUTHOR": "백봉현",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 373,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "빅데이터를 활용한 사용자 경험디자인 요소 추출 방법에 관한 연구 =(A)study on the user experience design element extraction method that utilizes big data ",
		"AUTHOR": "홍민석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이재환",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "디자이너는 사용자 경험을 통해 제품에 요구되는 디자인요소로 형태, 색상, 소재에 대한 트렌드 및 콘셉트 도출을 위한 여러 조사 방법들을 사용한다. 사용자 경험을 통한 디자인요소를 추출하기 위해서는 사용자들의 데이터를 추출해야 하는데 이는 정량적 조사와 정성적 조사로 이루어진다. 하지만 이러한 조사 방법들은 사용자의 데이터를 수집하는데 상당한 시간이 소모되며 연구자의 의도에 따라 다른 결론을 가져올 수 있다. 또 사용자 경험 데이터는 축적 되어 있지 않고 제품을 개발할 때마다 프로세스를 매번 수행해야 하며 다수의 군집 모형을 수집하기까지 많은 시간과 비용이 소모된다. 이러한 문제를 해결하고 사용자의 선호와 감성, 라이프스타일을 분석하기 위해서는 신속하고 경제적이며 방대한 데이터를 활용한 사용자 경험 디자인 요소 추출이 필요한 실정이다. 본 연구는 사용자가 제품에 대한 사용 후기 및 선호도, 사용자 감성, 라이프스타일의 데이터를 활용해 디자이너가 제품을 디자인하는데 필요한 사용자 경험 요소를 추출하고 결과를 통해 제품디자인 콘셉트를 도출하는 것을 연구의 목적으로 진행하였다. 사용자의 경험이 데이터로 축적 되어있는 빅데이터를 활용하여 디자인에 적용 가능한 범위를 알아보고, 디자인 콘셉트 도출에 적용시킬 수 있는 방법을 도출하기 위한 연구의 배경, 연구목적, 연구의 방법, 연구범위를 기술하였다. 연구의 이론적 고찰로 연구의 정의와 개념을 선행연구 및 사례분석을 통해 빅데이터와 사용자 경험디자인 요소 추출에 대한 활용반안 모색과 본연구의 기초가 되는 개념을 기술하였다. 본론으로 빅데이터 분석툴의 정제 키워드와 사용자 경험디자인 요소 활용에 대한 실험 설계를 설정하고 빅데이터 분석툴을 통한 키워드 수집 및 분류와 퍼소나의 IDEA 분류를 통해 사용자 경험을 추출하고 요인분석을 통해 제품 디자인콘셉트 도출을 하였으며 전문가 검증을 실시하였다. 디자인 실무자와 Focus Group Interview를 통해 제품디자인 프로세스에서 디자인콘셉트 도출 중 중요하게 생각하는 요소로 사용자, 심미성, 차별화, 사용성, 양산단가 등의 순으로 영향이 있는 것으로 나타났다. 사용자의 요인분석과 공통성에 대한 결과를 컨셉도출에서 사용자의 행동패턴이나 기능성에 대한 차별화와 사용성 요소를 충족시킬 수 있을것으로 판단되었다. 일반적인 데이터 마이닝으로는 주관적인 해석이 있을 수 있으나 디자이너가 해결 할 수 있는 방법으로 빅데이터의 정성적 데이터를 퍼소나를 통해 사용자의 경험과 요인들을 추출해 사용자의 요구가 적용된 디자인 콘셉트를 추출 할 수 있을 것 이라는 디자이너 그룹 Focus Group Interview를 통해 검증하였다. 빅데이터 분석툴을 통해 추출되는 사용자 경험 키워드를 주관적인 디자이너의 해석이 아니라 사용자의 요구를 구체화하고 충족시킬 수 있는 방법을 제시하였다.",
		"KEYWORD": "경험디자인,디자인콘셉트,빅데이터"
	},
	{
		"ID": 374,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "실시간 교통빅데이터 시뮬레이션을 위한 IoT 시뮬레이터 설계 및 구현 =Design and implementation of IoT simulator for real-time traffic bigdata simulation ",
		"AUTHOR": "안상희",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 조완섭 참고문헌 : p.56-57",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "As the various types of devices that collect IoT-based traffic stream data increase, the amount of real-time data is increasing every year. Due to these characteristics, it is difficult to save, manage and analyze with existing traffic management systems. Therefore, big data technology should be employed in the traffic management systems. However, there is plenty of risks in the transition into the big data system because of the mission-critical traffic management systems in the sites. For this reason, it is necessary to implement IoT simulator based on the actual traffic data to test the stability of the big data platform, real-time analysis without interfering with the existing traffic management systems. In this research, based on the IoT protocol MQTT, we implemented a web based IoT simulator and designed to be able to simulate using actual traffic data in Cheongju city. The execution time of the simulator and the message transfer amount per second has been measured, and the original performance evaluation was carried out. As a result of the performance evaluation, the IoT simulator generates and transfers 120 messages per second and it can cover 10 million of DSRC messages per day, which seems to be sufficient capability for Cheongju city. Moreover, we implemented a visual interface based on Marey graph for real-time bus operation monitoring, and several patterns of bus operation have been found in the city.",
		"KEYWORD": "IoT,MQTT,교통 빅데이터,시각화,시뮬레이터"
	},
	{
		"ID": 375,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "빅 데이터 분석 기법을 이용한 기후변화 복원탄력성 지표 개발 ",
		"AUTHOR": "김연수",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김형수 참고문헌 : p.351-373",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "지구 온난화에 따른 기후변화의 영향으로 전 세계는 홍수, 가뭄, 태풍과 같은 자연재난으로 몸살을 앓고 있고, 그 피해규모도 점점 커지고 있다. 국가와 도시 그리고 관련 기관들은 이러한 기후변화로 인해 발생하는 자연재해에 대응하고 예방하기 위한 노력을 지속적으로 기울이고 있다. 이러한 노력은 지역사회의 안전성과 방재기능 강화를 나타내는 복원탄력성 지표와 복원탄력성에 대한 평가를 토대로 이루어져야 한다. 따라서 본 연구에서는 최근 관심이 부각되고 있는 빅 데이터(Big Data) 분석 기법을 이용하여 기후변화를 고려한 복원탄력성 지표를 개발하고 평가하고자 하였다. 이를 위하여 다양한 형태의 데이터들을 정형 데이터(Structured Data)와 비정형 데이터(Unstructured Data)로 구분하였다. 과거 관측 기후자료와 기후변화 시나리오인 대표농도경로(RCP) 시나리오를 이용한 정형 데이터(Structured Data) 분석을 통해 미래 일 기상자료를 생성하고 극한지수의 변동성을 모의하였으며 이를 복원탄력성 지표로 이용하였다. 그리고 연관 검색어 및 재난/재해의 예방, 대비, 대응, 복구와 관련된 학술논문 및 전문보고서의 비정형 데이터(Unstructured Data)에 대하여 텍스트 마이닝 분석을 통해 복원탄력성에 활용 가능한 상세지표와 가용변수를 선정하고, 요인 분석과 신뢰도 분석을 통해 국내적용 가능한 11가지 요인에 대한 36가지 복원탄력성 지표를 선정·개발하였다. 엔트로피 기법 및 정형 데이터 그리고 텍스트 마이닝 기법 및 비정형 데이터를 이용하여, 개발한 복원탄력성 지표별 가중치를 각각 산정하였고, 두 가중치의 결과를 이용하여 혼합 가중치를 산정하였다. 최종적으로 기후변화가 복원탄력성에 미치는 영향을 평가하기 위하여 비정형 데이터 분석기법으로 개발된 지표의 적정성을 검토하고, 정형 데이터를 이용한 미래 강우관련 극한지수를 지표로 적용하여 기후변화에 따른 복원탄력성의 변화양상을 모의하였다. 본 연구에 의하면 미래 강우의 극치사상은 증가하고, 지점별 강우의 변동성 또한 커질 것으로 예측되어 기후변화에 따른 자연재해의 취약여건은 더욱 높아질 것으로 판단된다. 지표별 가중치는 방법별로 차이를 보였지만, 전체적으로 시설 인프라, 생태계 및 환경 지표가 높게 산정되었으며, 자연재해 빈도와 경제적 활동 지표는 낮게 산정되었다. 개발 지표와 가중치의 적용을 위한 복원탄력성 산정 모형을 제시하였고, 서울과 경기지역의 경안천, 중랑천, 안양천 유역을 포함하는 지자체를 대상으로 모형의 적용 및 평가를 수행하였다. 지역안전도를 통해 정성적인 수준에서 적용성을 검토한 결과, 대부분 비슷한 등급에 해당하는 것으로 분석되었다. 빅 데이터 분석기법을 통해 개발한 복원탄력성 지표의 적용성을 확인하였고, 미래 기후변화 기반의 복원탄력성을 산정하고 평가하였다. 물리적, 경제적, 제도적 범주는 현재와 비슷한 수준을 유지할 것으로 보이나 사회적, 자연적 범주는 연도별, 지역별로 차이가 발생할 것으로 나타나 복원탄력성 강화를 위한 방안이 필요할 것으로 판단된다. 본 연구를 통해 비정형 데이터에 의한 텍스트 마이닝 방법은 새로운 지표를 제시하기 위해 이용될 수 있고, 데이터 정보량에만 의존하는 엔트로피 방법과 특정 지표의 가중치가 크게 나타날 수 있는 설문조사에 의한 방법을 보완하는 대안으로 활용이 가능할 것으로 판단된다. 본 논문에서 제시된 정형 데이터와 비정형 데이터의 적용방안 및 분석기법은 재난의 변화양상과 풍수해 대응방안 수립을 위한 기초자료로 활용될 수 있을 것으로 생각되고, 특히, 기후변화를 고려한 미래의 효과적인 수자원 관리와 복원탄력성을 평가하는데 유용할 것으로 판단된다. 또한, 본 연구는 기존의 공학적 접근을 탈피하고, 수자원 및 재난분야에 대해 빅 데이터(Big Data)의 활용성을 제시하였다는 점에서 큰 의미가 있다고 사료된다.",
		"KEYWORD": "Big Data Analysis,Climate Change,Resilience,Structured Data,Unstructured Data,기후변화,복원탄력성,비정형 데이터,빅 데이터 분석,정형 데이터"
	},
	{
		"ID": 376,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "빅 데이터 분석을 위한 지지벡터기계 =Support vector machines for big data analysis ",
		"AUTHOR": "박혜원",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박창이",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "최근 산/학계에서 주목받고 있는 빅 데이터는 정의상 한꺼번에 자료를 메모리에 올려 분석할 수 없기 때문에 기존의 데이터마이닝 시대에 개발된 일괄처리 (batch processing) 방식의 알고리즘을 적용할 수 없게 된다. 따라서 가장 시급히 해결해야 하는 문제는 기존의 여러 가지 기계학습방법을 빅 데이터에 적용할 수 있도록 분산처리 (distributed processing)를 수행하는 적절한 알고리즘을 개발하는 것이라 볼 수 있다. 본 논문에서는 분류문제에서 각광받는 지지벡터기계 (support vector machines)의 여러 알고리즘을 살펴보고자 한다. 특히 빅 데이터 분류문제에 유용할 것으로 예상되는 온라인 타입 알고리즘과 병렬처리 알고리즘에 대하여 소개하고, 이러한 알고리즘들의 성능 및 장단점을 선형분류에 대한 모의실험을 통해서 살펴본다.",
		"KEYWORD": "분산처리,온라인 알고리즘,일괄처리,합의"
	},
	{
		"ID": 377,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "공간빅데이터로서 소셜미디어 자료를 활용한 공간정보 추출 및 표현 시스템 개발 =Development of a spatial information extraction and representation systems utilizing social media as spatial big data ",
		"AUTHOR": "이주용",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 고준환",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "사회 문제가 점점 더 복잡해지고, IT기술의 급격한 발달 및 모바일 기기들의 보급으로 인해 빅데이터 및 공간빅데이터에 대한 사회적인 관심 및 활용의 필요성이 증대되고 있다. 빅데이터 중에서 간편하게 생산되어지고 있으며 일반 사용자들이 쉽게 접할 수 있는 데이터는 소셜미디어 자료이다. 이러한 소셜미디어 자료들은 대부분, 데이터가 생성될 당시부터 위치정보를 포함하고 있기 때문에 공간빅데이터로서의 가치도 있고, 사회의 여러 가지 문제를 해결하는 데에 활용될 수 있다. 만약 이러한 소셜미디어 데이터들을 모바일 상에서 검색하고 게시물의 공간정보까지 확인할 수 있다면 공간빅데이터로서 소셜미디어의 활용도는 더욱 높아질 것이다. 따라서 본 연구에서는 일반 대중들이 자발적으로 가장 많이 생산해 내는 데이터인 소셜미디어 데이터로부터 검색을 통해 원하는 자료를 찾고, 그 데이터들이 생성된 위치정보를 웹지도상에 표현하는 모바일 시스템을 개발했다. 본 연구를 통해 공공기관 및 기업체 등에서 운용중인 계정들이 통폐합 됨을 통해 시민들이 보다 편리하게 이용할 수 있고, 소셜미디어 자료들을 검색을 통해 주요 이슈에 대한 여론 분포 등을 신속하게 확인할 수 있으므로 의사결정 등에도 활용할 수 있을 뿐만 아니라, 기존의 소셜미디어를 쉽게 생산하고 접하는 일반 사용자들도 소셜미디어 검색을 어렵지 않게 이용할 수 있게 되어 공간빅데이터가 일반 대중들에게 쉽게 사용되고 전파될 수 있을 것으로 기대한다.",
		"KEYWORD": "공간빅데이터,매쉬업,모바일시스템,소셜미디어,오픈API"
	},
	{
		"ID": 378,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "Critical factors affecting adoption of big data system for improving public policy making in Ecuador =에콰도르의 공공정책 수립 개선용 빅 데이터 시스템 도입에 영향을 미치는 핵심 요인 연구 ",
		"AUTHOR": "ElizabethHaro",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 379,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "빅 데이터를 활용한 한류 분석 엔진 설계 및 알고리즘 연구 =(A)Korean wave analysis engine design and algorithm research utilizing big data ",
		"AUTHOR": "정경진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박재표",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "스마트 미디어 시대로 접어들면서 한류 콘텐츠 정보를 쉽게 접할 수 있는 환경이 만들어지면서 발생한 다양한 콘텐츠 소비활동과 소셜미디어 의 등장은 텍스트, 사진, 동영상 등 분석에 활용할 수 있는 다양한 대용량 데이터를 발생시키고 있다. 이러한 다양한 데이터 중에서 한류문화를 분석하고 활용 할 수 있는 데이터를 수집하여 분석이 가능해지면 의미있는 결과가 도출 될 수 있다고 판단하여 한류라는 범주 안에서 시스템적으로 성공요인을 분석하고 증명 할 수 있는 한류분석엔진을 설계 및 구현하고자 한다. 따라서 본 논문에서는 여러 분야 중 한류 문화를 빅데이터 환경에서 분석 할 수 있는 방안을 모색하고자 공개API 및 오픈소스를 기반으로 수집, 저장, 관리, 처리, 분석, 표현 6단계 프로세스로 구성된 KWA엔진을 구현하였다. 또한 수집된 비정형 데이터를 가공하여 분석 할 수 있는 정형데이터로 변환시켜주는 알고리즘인 스코어링 알고리즘을 설계하였다. 그리고 KWA엔진의 성능을 향상시키기 위해 색인 및 검색 기술을 적용시켜 수집 키워드별로 다중스레드로 처리하도록 하였고, 분석에 특화된 컬럼기반 데이터베이스시스템을 추가적으로 구성하여 분석시간을 단축 시킬 수 있도록 하였다. 본 논문에서 제시한 KWA엔진의 성능 분석을 통해 분석의 정확도 및 속도 측면에서 우수한 성능을 보였다.",
		"KEYWORD": null
	},
	{
		"ID": 380,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "홍익대학교 국제디자인전문대학원",
		"TITLE": "클라우드와 빅데이터를 이용한 헬스케어 서비스 플랫폼 디자인 :사물 인터넷을 기반으로 ",
		"AUTHOR": "이은혜",
		"REGION": "서울",
		"PROFESSOR": "홍익대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김승인 참고문헌 (p.36-37)포함",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "미래 사회는 사람과 사물, 동물, 데이터, 프로세스 등 모든 것이 서로 연결 되어 정보를 주고받는 초 연결사회(Hyper Connected Society)로 빠르게 변화되고 있다. 그에 따라 신성장동력이자 인터넷 신산업인 사물인터넷(Internet of Things), 클라우드 컴퓨팅(Cloud Computing), 빅데이터(Big Data)가 화두되고 있다. 특히 ‘정책연구, 창조경제 실현을 위한 사물인터넷 기반 유망시장 전망 및 과제, 2013’에 따르면 사물인터넷 제품기기/애플리케 이션/서비스 시장은 현재에는 시장규모가 작지만 미래에 발전 가능성이 큰 분야로 창조경제 실현을 위한 ICT(Information and Communication Technology) 신시장으로서 주목받고 있다. 이에 본 논문은 이러한 3가지의 ICT 신성장동력을 각각 파악하고 분석하여 사례를 토대로 헬스케어 서비스 산업 시장에 적용시켜보고자 하였다. 연구의 주된 목적은 미래의 초 연결사회에 부합되는 신성장동력들을 기반으로 한 헬스케어 서비스의 새로운 플랫폼 디자인을 통해 개개인의 건강을 스스로 쉽게 파악할 수 있고 더 신속하고 정확한 의료 서비스를 받을 수 있도록 하며 더 나아가 미래의 선진 의료 산업으로 성장시키는데 일조하고자 한다. 본 연구의 진행은 앞에서 언급한 ICT 신성장동력 3가지의 분석과 사례 조사로 시작하여 현재 헬스케어 서비스 시스템의 현황을 파악하여 연구의 기반을 마련하였다. 또한 사용자 설정과 헬스케어에 관련한 의학 이론 조사를 바탕으로 편리한 이용 방안을 연구하여, 신성장동력인 ‘사물인터넷, 클라우드, 빅데이터’를 기반으로 한 새로운 헬스케어 서비스 플랫폼을 새롭게 제안하고 디자인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 381,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "빅 데이터를 이용한 Monte-Carlo Tree Search 기반 인공지능 성능 강화 연구 =(A)study for enhancing performance of A.I based on Monte-Carlo tree search using big-data ",
		"AUTHOR": "강재원",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 정기철 참고문헌: p. 39-40",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "빅 데이터 처리 기술의 발달은 다양한 산업분야에서의 데이터의 활용가치에 대해 주목하게 하는 계기가 되었다. 특히 인공지능에 빅 데이터를 적용함에 따라 기존 알고리즘만으로 풀기 어려웠던 문제를 해결하며, 인공지능 분야에서의 빅 데이터 활용의 중요성이 대두되고 있다. 본 논문에서는 넓은 상태 공간을 가지는 문제에 대해 최적화 된 인공지능 알고리즘인 Monte-Carlo Tree Search에 도메인 지식의 빅 데이터를 휴리스틱으로 활용하여, 인공지능의 성능을 강화하는 방안을 제안한다. 현재 Monte-Carlo Tree Search 알고리즘이 가장 활발히 적용되고 있는 바둑 인공지능에, 빅 데이터 처리 플랫폼인 Hadoop Ecosystem을 이용한 대량의 바둑 대국 데이터베이스를 연동하여 Monte-Carlo Tree Search 알고리즘이 트리 탐색 과정 중 탐색 시간과 컴퓨터 자원 부족으로 인해 부적절한 해를 도출하는 단점의 극복을 통해 인공지능의 성능을 강화하였다. 본 연구를 통해, 향후 지속적인 하드웨어의 발전 및 데이터 수집 및 축적을 통해 인공지능의 성능 강화의 새로운 방법론을 제시한다.",
		"KEYWORD": "인공지능"
	},
	{
		"ID": 382,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "하둡 에코시스템 기술을 적용한 교통 스트리밍 데이터의 저장 및 처리기술 설계 및 구현 =A design and implementation of storage and processing method for traffic streaming data using Hadoop ecosystem ",
		"AUTHOR": "김진혁",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 조완섭 참고문헌 : p.55-56",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "청주시 교통빅데이터 분석시스템은 청주시 전역에서 발생하는 BIS, ATMS, 교통카드 정보를 일단위로 수집하고 분석하는 배치 형태의 시스템이다. 본 연구는 청주시 교통빅데이터 분석시스템에서 스트리밍 빅데이터의 실시간 수집?저장 시스템과 처리 시스템을 설계하고 구현하였다. 교통 빅데이터 수집은 카프카를 사용하며, 배치형태의 저장과 처리를 위해 Hadoop를 활용한다. 또한 실시간 처리를 위해 스파크 스트리밍 기술을 활용한다. 또한 제안된 시스템의 성능을 평가하기 위해 카프카를 이용한 데이터 수집능력, 표준화된 밴치마킹 방식인 TPCx-HS를 활용한 저장능력, 스트리밍 데이터 처리능력 세가지로 구분하여 성능을 평가하였다. 수집능력의 경우 메시지셋의 크기를 환경에 적절하게 결정하는 것이 성능에 큰 영향을 미치며, 저장능력의 경우에는 스캐일아웃 방식이므로 노드수의 증가에 따라 개선될 수 있으며, 처리능력은 초당 200건 정도 처리할 수 있어 청주시 교통데이터를 처리하는 데는 충분하며, 필요한 경우 노드수를 증가하면 된다.",
		"KEYWORD": "스트리밍 데이터 프로세싱,스파크 스트리밍,하둡 에코시스템"
	},
	{
		"ID": 383,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "산업체 이슈 저장소 데이터 특성을 고려한 버그담당자 배정 방안 ",
		"AUTHOR": "허민재",
		"REGION": "서울",
		"PROFESSOR": "중앙대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 이찬근 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "최근 소프트웨어의 품질 향상이 중요해지면서 관련된 연구들이 주목받고 있다. 그 중에서도 소프트웨어 저장소의 데이터 수집인 MSR(Mining Software Repository)가 주목받고 있다. MSR을 이용한 다양한 연구는 소프트웨어의 개발 및 유지보수에 들어가는 비용과 시간을 절약할 수 있어 많은 연구자들이 연구를 진행하고 있다. 그러나 대부분의 연구가 오픈 소스 소프트웨어를 대상으로 한 연구에 그쳤다. 때문에 실제 산업 환경에서 같은 효과를 보이는지 알 수 없고, 산업 환경에서 동일한 조건의 데이터를 구할 수 있는지 알 수 없다. 본 논문은 기업체의 데이터를 기반으로 산업체 환경의 이슈 저장소 데이터를 이용한 버그 담당자 배정 방안에 대해 다룬다. 이 과정에서 산업 환경에서 데이터를 선정하는 방법과 기업체 데이터의 이점을 소개한다. 또한 데이터 분석을 통해 오픈 소스 소프트웨어와의 차이점은 무엇이며 산업 환경에서 데이터 분석 및 수집에 유의해야 할 점을 소개한다. 수집한 데이터를 통해 기존의 연구 방법들을 적용한 사례 연구를 진행하여 오픈 소스 소프트웨어를 이용한 연구 결과와 차이점이 있는지 살펴보고, 산업 환경에서 발생하는 특수한 환경에 대해서도 살펴본다.",
		"KEYWORD": "기계학습,마이닝 소프트웨어 리파지토리,버그 트리아지"
	},
	{
		"ID": 384,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "고려대학교 기술경영전문대학원",
		"TITLE": "빅 데이터 구축이 기업에 미치는 영향 실증 연구 =Study on business impact from integrating of big data ",
		"AUTHOR": "이기정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金永埈 참고문헌: 장 48-49",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "급속한 정보기기의 발달로 인하여 현대사회는 방대한 데이터를 생성시키고 처리하고 있다. 이러한 데이터를 활용하여 정보를 만들고 그것을 기반하여 사업분야에 적용할 뿐만 아니라, 생활의 편의성 향상에도 많은 기여를 하고 있다. 따라서 정보의 활용은 경쟁력의 발로이며 이를 잘 활용할 수 있다면 타 기업보다 선도적으로 전략을 수립하고 시장을 점유해 나갈 수 있을 것이다. 또한 성공적인 기업을 이끌기 위해서는 기술에 기반한 경영이 중요한 만큼 근래 들어 부각되고 있는 빅 데이터 기술에 대해 관심을 가졌고 이에 대한 기반 조사 및 사례연구를 실시하였다. 빅 데이터 기술은 갑자기 탄생된 기술은 아니며, 예전부터 각 기업에서는 고객만족과 가치창출을 위해서 기존 관리하고 있는 데이터를 분석하여 영업이나 사업전략에 이용을 하였다. 그러나 과거에는 하드웨어, 소프트웨어 등 관련 인프라 기술 및 데이터 분석기술의 부족으로 한계가 있었으나, 현대사회는 이러한 부족한 점을 모두 충족할 수 있는 환경이 구축이 되고 있다. 이러한 시대적 변화에 따라 빅 데이터 기술이 수년 전부터 각 기업과 연구소 및 관련 공급자 등에서 관심과 각광을 받고 있으나, 그 효과성에 대해서는 다양한 의견이 나오고 있는 실정이다. 따라서 본 논문에서는 이러한 빅 데이터에 대해 정의와 현황을 기반으로 사례중심으로 그 효과성에 대해 검증하였다.",
		"KEYWORD": "가치창출,기술경영,빅데이데"
	},
	{
		"ID": 385,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "빅데이터환경에서 이슈분석을 위한 디지털 큐레이션 프레임워크 연구 =Digital curation framework research for analyzing issues based on big-data ",
		"AUTHOR": "김홍기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한상용 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "In these days, also called ‘the era of Big-Data’, many data have lost their meanings because so many data are made and used only once. These data should be analyzed. Especially a social network service, the Twitter, has a significant value in issue analysis. But traditional issue analysis methods have some problems that it shows duplicated issues and needs second searching. So, this research suggests a digital curation platform, the issue curator system. The issue curator system extracts issue keywords from social network service data, group some keywords that imply a same issue among them and suggest a description about that. It also regenerates a curated data formed with XML document format and preserves it. According to the result of evaluation of the issue curator system, it is demonstrated that the system has a meaning in recognizing issues. In future work, the system based on various data source and machine learning methods should be considered.",
		"KEYWORD": null
	},
	{
		"ID": 386,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "유전알고리즘을 이용한 국소가중회귀분석기반 빅데이터의 점진적 앙상블 학습 =Local weighted regression based incremental ensemble learning of big data using genetic algorithm ",
		"AUTHOR": "김상훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이건호",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "IT산업과 정보통신의 발달로 인해 데이터의 양은 해마다 늘어가고 수많은 데이터를 실시간으로 만들어 내고 있다. 이러한 환경에서 다양한 실시간 대용량 데이터를 분석하는 빅데이터에 대한 관심도 높아지고 있다. 본 연구에서는 국소가중회귀를 기반으로 점진적 앙상블기법을 활용하여 대용량 데이터 처리에 대응 가능한 구조로 개선한다. 분석된 모델을 해집단화하고, 이를 기반으로 유전알고리즘을 이용하여 최적화한다. 본 연구에서 제시하는 학습방법은 특정시점에서 데이터 샘플을 추출하고, 국소가중회귀를 통해 모델을 생성하도록 한다. 이후 모델을 해집단으로 만들어 유전알고리즘을 이용하여 최적화한다. 만약, 특정시점 이후 데이터가 추가되면 추가 분석을 통해 새로운 해집단을 생성한다. 이 때 새로운 해집단에는 최초 해집단의 우수한 모델을 결합하여 유전알고리즘을 이용하여 최적화 한다. 제시한 학습방법에 대한 검증을 위해 분석방법을 구현하고, 다양한 문제와 크기에 따른 CPU시간과 에러율, 다중회귀분석과의 비교검증을 수행한다. 또한, 다변수 문제를 대상으로 회귀분석모델과의 비교를 통해 실효성 검증을 한다. 향후, 본 연구의 분석절차를 응용한 데이터 패턴 예측에 관한 방향도 제시한다.",
		"KEYWORD": "국지가중회귀,빅데이터,유전알고리즘,점진적앙상블기법,패턴분석"
	},
	{
		"ID": 387,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "BMS 빅데이터를 이용한 중앙버스전용차로 운영효과 분석 :Analysis of exclusive median bus lane operation effectiveness using BMS big data :강남대로 사례를 중심으로 =case study at Gangnam-daero ",
		"AUTHOR": "정다운",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김영찬",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "2004년 서울시는 도시 내 혼잡을 해소하고 버스 서비스 질의 향상을 위해 주요 간선도로 중앙에 버스통행을 위한 중앙버스전용차로를 도입하였다. 그런데 2014년 기준으로 중앙버스전용차로를 이용하는 버스 통행속도는 19.9km/h로 일반차로를 이용하는 버스 통행속도 20.2km/h 보다 낮게 나타났다. 이러한 서울시 중앙버스전용차로의 평균통행속도 감소는 중앙버스전용차로 내 정류장 정차용량 초과에 의한 것이라는 견해가 대다수이나 그에 관한 연구는 많이 진행되지 않고 있는 실정이다. 그래서 본 논문에서는 서울시 BMS 빅데이터를 이용하여 강남대로 중앙버스전용차로 내 정류장들의 정차면 용량 초과 현상을 분석해 보았다. 또한 용량 초과 현상이 통행시간과 정시성에 영향을 미치는지 분석해 보기위해 BMS 빅데이터를 이용하여 통행시간, 정시성 분석을 수행하였다. 정차용량 초과 분석 결과 강남대로 양방향 모두 대부분의 정류장에서 정류장 정차면 용량초과 현상이 나타나는 것을 알 수 있었으며 양방향 모두 강남역 정류장에서 평일 정차면 용량 초과 현상이 가장 심하게 나타나는 것을 알 수 있었다. 통행시간을 분석한 결과 강남대로 양방향 모두 대부분의 정류장에서 중앙버스전용차로를 이용하는 버스의 통행시간(초/km)이 일반차로를 이용하는 버스 통행시간보다 짧게 나타났는데 강남역 부근에서만 역전된 현상을 나타내는 것을 알 수 있었다. 정시성 분석 결과 양방향 모두 0~1사이의 정시성을 가지고 있어 다른 지역의 버스차로 정시성과 비교했을 때 나쁘지 않은 정시성을 가지고 있음을 알 수 있었다. 정차면 용량초과 현상과 통행시간, 정시성간의 상관관계 분석을 한 결과 정차면 용량초과와 통행시간의 상관관계는 0.38로 나타났고 정차면 용량초과와 정시성의 상관관계의 경우 0.36으로 나타났다. 즉, 정차면 용량초과와 통행시간, 정시성의 상관관계는 있는 것으로 분석되었다. 정차면 용량초과 현상은 정시성보다 통행시간에 미비하지만 조금 더 영향을 미치는 것을 알 수 있었다. 녹색시간비율(g/C), 정차시간, 정차대수와 정차면 용량 초과 현상과의 상관관계도 분석해 보았는데 그 결과 정차대수가 가장 많은 영향을 미치는 것을 알 수 있었고 그 다음으로 정차시간이 정차면 용량초과현상에 영향을 미치는 것을 알 수 있었다. g/C의 경우에도 음의 상관관계를 갖고 있음을 알 수 있었다. 본 연구의 경우 5월 한 달 자료를 이용하여 강남대로 중앙버스전용차로만 분석하였기 때문에 향 후 연구에서는 시간적 공간적 범위를 확장하여 서울시 전체 중앙버스전용차로에 대한 보다 정확한 운영평가 분석이 이루어져야 할 것이라 판단된다.",
		"KEYWORD": "BMS 데이터,버스 정시성 분석,버스 정차면 용량 초과 분석,버스 통행시간 분석,빅데이터 분석,중앙버스전용차로"
	},
	{
		"ID": 388,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "인메모리 공간 빅데이터를 위한 3차원 가시화 =Three-dimensional visualization for in-memory spatial big data ",
		"AUTHOR": "문홍직",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 류관희 참고문헌: p.36-37",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Today, It was easier to take advantage of spatial data production and spread of personal smart devices. Therefore, research and service to take advantage of spatial data has been developed. In this paper, we defined spatial data. The data is combined of Topography, Location data and Statistical numeric data. We are using several types of data : topography data and, geometric data and, moving object data(in a particular zone). Our visualization system consists of three major components: application part, browser part, and Data Base Management Service(DBMS). The final result is realized with object rendering techniques. We also use moving object visualization methods, and design a new visualization system required in the new spatial Big data environment. Systematical visualization system is designed based on spatial data, “In-Memory DBMS” and real-time text.",
		"KEYWORD": "Spatial,Visualization,가시화,공간데이터,시각화"
	},
	{
		"ID": 389,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "보건의료 빅데이터의 연계 데이터셋 추출 기법 =Extraction techniques for linked datasets from healthcare bigdata ",
		"AUTHOR": "박다정",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 조완섭 참고문헌 : p.43-45",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "In recent years, since the data was released in the healthcare field, the range of healthcare services have expanded by analyzing Bigdata actively. Accordingly, it is necessary to create new values by linking various healthcare data existing in many institutions and sharing that linked data sets. Liking data(matching data) allows us to obtain more information than when it is used as a single data, so we can expect great synergy effects. This study proposes methods to extract the linked datasets by linking healthcare data. Linked datasets are extracted by using SQL queries in the data warehouse, using the Open API created on the web and using the LOD constructed by defining the ontology. We also compared the advantages and disadvantages of each methods for extracting linked datasets.",
		"KEYWORD": "LOD,Open API,데이터 매칭,데이터 연계,데이터웨어하우스,보건의료 빅데이터"
	},
	{
		"ID": 390,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "인제대학교 대학원",
		"TITLE": "빅데이터를 이용한 텍스트마이닝 기법의 성능 비교 ",
		"AUTHOR": "어동선",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 석경하",
		"STORE_LOCATION": "인제대학교 백인제기념도서관",
		"ABSTRACT": "텍스트마이닝은 비정형 텍스트 자료를 분석하는 데이터마이닝의 한 분야로, 이에 관련된 많은 연구가 지속적으로 증가하고 있다. 본 연구에서는 비정형 신문기사 자료를 주어진 범주로 분류함에 있어서 베이지안 방법, k-NN, 의사결정나무, SVM, 그리고 신경망의 방법을 적용하여 이들의 분류 성능을 비교하였다. 그 결과, SVM 모형이 다른 모형들에 비해 높은 F-측도값을 갖고, 정분류율과 재현율에서도 안정된 결과를 나타냈으며 좀 더 세분화된 목록의 분류에서도 높은 F-측도값을 보여주었다. k-NN과 의사결정나무는 SVM에 비해 수행 능력은 조금 낮지만 변수의 해석이나 학습시간에 강점을 가지므로, 텍스트마이닝을 활용한 분류에 적절한 모형이라는 결론을 내릴 수 있었다.",
		"KEYWORD": "k-NN,SVM,단어-문서 행렬,베이지안,빅데이터,신경망,의사결정나무,텍스트마이닝"
	},
	{
		"ID": 391,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "비즈니스 분석에 정형데이터와 비정형데이터가 미치는 영향에 대한 비교 연구 ",
		"AUTHOR": "김정훈",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김도훈 참고문헌: p. 65-71",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "빅데이터 분석에 적합한 다양한 알고리즘이 개발되면서, 빅데이터를 활용한 성공사례가 늘어나고 있다. 또한 기업에서도 이에 발맞추어 빅데이터를 활용하여 기업의 성과를 올리려는 노력을 보이고 있다. 하지만, 빅데이터가 갖는 복잡성 때문에 기업에서 이용하는데 어려움을 겪고 있다. 본 연구에서는 빅데이터내에 정형데이터 속성 과 비정형데이터 속성을 각각 이용하여 예측하여 예측 성과를 비교하고, 두가지 속성을 결합하여 나오는 예측 성과의 우수성을 검증하고자 한다. Episode1에서는 IT기업의 뉴스기사 댓글이 얻는 공감/비공감수를 Method1(정형데이터 속성만을 이용한 성과예측), Method2(비정형데이터 속성만을 이용한 성과예측), Method3(정형데이터 속성과 비정형데이터속성 결합한 성과예측)의 각각의 성능을 비교한다. Episode2에서는 실제 모공공기관의 VOC데이터를 활용하여 서비스처리시간을 Episode1과 동일한 방법으로 예측 성과를 비교한다. 본 연구의 결과는 Episode1, Episode2의 결과는 결합모형의 성능이 가장 뛰어났고, Episode1에서는 정형데이터 속성의 예측결과가 결합모형과 거의 유사한 성능을 나타냈으며, Episode2에서는 비정형데이터속성의 예측결과가 결합모형과 거의 유사한 성능을 나타냈다. 비교적 적은 속성을 사용하여 만든 예측 모형이 뛰어나다고 볼 수 있지만, 보다 안정적인 성능을 나타내기 위해서는 본 연구에서 제안하는 Method3의 방법을 사용하는 것이 좋다고 할 수 있다.",
		"KEYWORD": "비정형데이터,비즈니스 분석,빅데이터,텍스트마이닝"
	},
	{
		"ID": 392,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "전남대학교 산업대학원",
		"TITLE": "빅 데이터 로그분석 활용사례에 관한 연구 ",
		"AUTHOR": "김동곤",
		"REGION": "광주",
		"PROFESSOR": "전남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 이칠우 참고문헌 : p. 39",
		"STORE_LOCATION": "전남대학교 중앙도서관",
		"ABSTRACT": "자신의 의사를 표현하는 수단은 과거에 비해 점점 다양해지고 있다. IT 기술의 지속적인 발전과 스마트폰, 스마트패드 등의 모바일 기기의 증가로 개인들 뿐 만 아니라 기업 및 정부도 무수히 많은 정보들을 생산하고 있다. 이에 따라 해당 시스템의 로그양이 기하급수적으로 증가하고 있다. 관련 담당자들은 관리와 의사결정을 위하여 로그들을 분석해 왔는데 이제는 분석 불가능한 정도로 많은 양이 쌓여가고 있다. 관리가 거의 불가능한 대용량 데이터를 분석하는 기법에 대한 관심이 높아지고 있는 시점에서 기존의 분석 체계로는 해결할 수 없는 막대한 정보의 분류 방법으로 Big Data를 이용한 분석 방법이 한 대안으로 떠오르고 있다. 본 논문에서는 급증하는 데이터 관리에 대한 사용자들의 요구사항을 파악하여 빅 데이터를 이용한 민간기업의 로그분석 사례를 살펴보고 빅 데이터 처리의 효율성을 공공부문에서 활용하는 방안에 대해 고찰한다. 차세대 정부통합전산센터의 고객지원 서비스를 위한 빅 데이터를 이용한 웹 마이닝 기법에 활용하는 방안에 대하여 기술하고 있다. 빅 데이터 로그분석 실 사례를 통해 실시간 처리, 확장성, 유연성, 효율성을 확인하고 정부통합전산센터 웹 마이닝에 활용 방안을 제시하여 웹사이트 운영전략 수립에 필요한 실질적인 지식정보를 고객기관에 제공하고 국가 IT 전문기관으로의 역할 등에 대해서 중점적으로 기술하였다. 빅 데이터는 혁신의 동력이자 비즈니스의 플랫폼이고 새로운 비즈니스 모델의 견인차이다. 빅 데이터에 대한 학계, 기업의 다양한 전망에서 알 수 있듯이 모든 산업 분야에 파급효과가 기대된다. 과거 반도체, 초고속 통신망 등 IT 기술이 그러했던 것처럼 빅 데이터는 국가의 새로운 성장 동력이 될 것으로 예상된다. 우리정부는 스마트전자정부의 융합 지식 창출을 위해 빅 데이터 기술로 대민서비스에서 국민 중심의 방향으로 변화하여 정부 운영 효율화 및 투명성 제고의 기반을 마련하려 하고 있다. 안전행정부의 소속기관인 정부통합전산센터 또한 정부의 중요 데이터의 보안을 강화하여 정보를 보호하는 한편 정부의 정보공개의 원칙에 따라 운영 데이터에 대한 빅 데이터 웹 마이닝 서비스를 제공함으로써 한 단계 발전 된 차세대 정부통합전산센터의 밑거름이 될 것이다.",
		"KEYWORD": "로그분석,빅데이터"
	},
	{
		"ID": 393,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "남서울대학교 대학원",
		"TITLE": "교통 빅 데이터와 GIS공간분석 기법을 적용한 도시철도역의 대중교통 연계서비스 평가 방법 연구 =A study on evaluation method for service of connection as public transportation to urban railway station applying traffic big data and GIS spatial analysis ",
		"AUTHOR": "진상규",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 394,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "호서대학교 벤처전문대학원",
		"TITLE": "온라인 마케팅과 오프라인 마케팅에 빅데이터가 미치는 영향 =(A)study on the effect of online and offline marketing on the big data ",
		"AUTHOR": "김윤겸",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 김선배",
		"STORE_LOCATION": "호서대학교 중앙도서관(천안캠퍼스)",
		"ABSTRACT": "본 논문은 온라인 마케팅과 오프라인 마케팅에 빅데이터가 미치는 영향에 관하여 연구하는데 그 목적이 있다. 연구의 목적 달성을 위하여 먼저 빅데이터와 온라인 마케팅, 오프라인 마케팅의 이론적 고찰을 통하여 빅데이터와 마케팅을 살펴보았다. 그리고 본 연구의 마케팅 분류 기준인 온라인 마케팅과 오프라인 마케팅으로 양분하고 그에 따른 빅데이터 활용 유형을 탐구하였다. 활용 유형에 따라 실제 활용 중인 국내?외 기업들의 활용 사례를 찾아보고 비교, 연구하였다. 그리고 활용 사례를 토대로 효율적인 마케팅 성과를 위한 빅데이터 활용방안을 제시하였다. 또한 온라인 마케팅과 오프라인 마케팅에 빅데이터가 미치는 영향에 대한 연구를 통해 효율적인 빅데이터 마케팅 기법을 발견하고자 마케팅의 국외 선도 기업의 활용을 검토하였다. 국외 빅데이터 마케팅 활용사례를 통해 국내기업의 빅데이터 마케팅 활용에 있어 착안해야 할 시사점을 도출하고 유념해야할 사항들을 기술하였다. 연구결과, 기업들은 마케팅에 있어 빅데이터를 활용하는 것에는 전적으로 공감하지만, 여전히 일부 기업들을 제외하고는 활용에 소극적이며 그 효과에 의구심을 품고 있다는 것을 알 수 있었다. 빅데이터 마케팅에 있어 국외의 대표적 선도 기업들은 빅데이터의 등장 이전부터 데이터의 수집, 저장, 처리, 분석, 활용에 이르기까지 전 과정에 걸쳐 철저한 대비를 해왔으며, 현재에 이르러 괄목만할 한 성공적인 경영성과가 나타나고 있었다. 온라인 마케팅의 빅데이터 활용은 온라인의 특성에 걸맞게 오프라인 마케팅에 비해 상대적으로 축척되어진 데이터를 기반으로 활용사례도 더 많았으며 활용범위 또한 넓은 것으로 나타났다. 오프라인 마케팅에서 빅데이터 활용은 많은 관심과 연구가 필요할 것으로 나타났으며 끊임없는 데이터의 수집을 시작으로 활용가치가 높은 양질의 데이터의 축척이 요구되는 것으로 나타났다. 최종적으로 빅데이터는 온라인과 오프라인의 분류를 떠나 마케팅 활동에 있어 반드시 필요하되 전문 인력과 시스템의 구축, 고객 개인 정보보호, 빅데이터를 통한 마케팅 대상 선정, 공공 데이터의 전략적 활용이 수반되어야만 효율적인 마케팅 성과를 기대할 수 있을 것으로 보인다.",
		"KEYWORD": "마케팅,빅데이터,오프라인,온라인"
	},
	{
		"ID": 395,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "아웃소싱 교육용 컨텐츠 보호를 위한 데이터 블록 기반의 상호 인증 프로토콜 =Enhanced authentication for outsourced educational contents through provable block possession ",
		"AUTHOR": "한창희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 허준범, 김대원 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "최근 고품질 포맷을 지원하는 멀티미디어 기술이 발전함에 따라 멀티미디어 데이터의 크기가 급격하게 증가하고 있다. 게다가 여러 온라인 채널을 통해 멀티미디어 데이터를 제공하는 추세에 따라, 단일 서버에서 데이터를 저장 및 처리하기가 어려워지고 있다. 이에 많은 서비스 공급 업체들은 클라우드 저장소와 같은 외부 업체에 데이터 아웃소싱을 통한 비용 절감 효과를 기대하고 있다. 하지만 아웃소싱 데이터에 접근하려는 사용자를 안전하고 효율적으로 인증할 수 있을지는 선결과제로 남아있다. 비밀번호 기반 인증은 안전성 측면에서 많은 문제점을 가진다. 생체인식이나 SMS, 하드웨어 토큰과 같은 채널을 이용한 다중 인증 기법은 안전성을 강화하지만 사용자 편의성 (usability)을 감소시킨다. 이에 본 논문에서는 안전성과 편의성을 모두 보장하는 블록 기반 상호 인증 기법을 소개한다. 추가적으로 본 논문에서 제안하는 기법은 효율적인 사용자 취소 (user revocation) 기능을 제공한다. 본 논문은 상용 클라우드 서비스인 아마존 EC2에서 직접 실험을 설계 및 구현하였고, 실험 결과를 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 396,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인제대학교 대학원",
		"TITLE": "빅 데이터에서 나타나는 텍스트 감정 분류 연구 ",
		"AUTHOR": "최정용",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 배화수",
		"STORE_LOCATION": "인제대학교 백인제기념도서관",
		"ABSTRACT": "본 논문에서는 트위터에 사용되는 텍스트 자료를 이용하여 이용자의 감정 상태를 기쁨, 분노, 슬픔 그리고 즐거움의 네 가지 감정 유형으로 분류하는 감정 분석(emotion analysis)에 대해 다루었다. 트위터 텍스트 자료에서 검색 키워드를 추출하고 필터링하여 고빈도 감정 단어를 추출하고 회귀분석, 라소 (lasso) 회귀분석, 능형 (ridge) 회귀분석 그리고 엘라스틱 넷(elastic net) 회귀분석을 이용하여 감정 단어 사전을 생성하였으며 네 종류의 감정 단어 사전을 이용하여 분류해본 결과 엘라스틱 넷 회귀분석 방법이 가장 좋은 결과를 보였다. 엘라스틱 넷 회귀분석으로 생성된 감정 사전을 이용하여 갤럭시와 아이폰에 관련된 트위터 자료에 적용해본 결과 갤럭시에 관련된 텍스트 자료가 아이폰에 관한 텍스트 자료보다 긍정적인 반응을 보임을 알 수 있었다.",
		"KEYWORD": "감정 단어 사전,감정 분석,검색 키워드,능형 회귀분석"
	},
	{
		"ID": 397,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "빅 데이터 분석 서비스 개발을 위한 웹 서비스 조합 프레임워크 ",
		"AUTHOR": "최경석",
		"REGION": "부산",
		"PROFESSOR": "",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "In recent years, demand for big data analysis service has increased in Korea and abroad. However, big data service development requires substantial amount of time and human resources. In this paper, I suggest a service composition framework for the development of a new service that combines various web services. Users can easily develop a big data analysis service through such framework. Earlier studies on service composition already exist, but the proposed framework has a specific structure for executing a composite service in order to solve problems adapting to big data. I present the framework structure and execution method, in addition to an application for this framework in the transportation domain. In the future, I will attempt to solve problems related to expenses and human resources when developing big data analysis service by applying the ser vice composition framework to various domains.",
		"KEYWORD": "서비스 명세,서비스 조합,워크플로우,프레임워크"
	},
	{
		"ID": 398,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 컴퓨터정보통신대학원",
		"TITLE": "기지국(통신) 로그 빅데이터를 활용한 유동인구 추정방법 연구 =A study on the floating population estimation method using log big data ",
		"AUTHOR": "유종필",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최진영 참고문헌: 장 36-37",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "본 연구에서는 기지국에서 수집되는 통신 로그 빅데이터를 활용하여 마케팅이나 공공의 서비스에 활용 할 수 있는 유동인구를 추정 할 수 있는 방법에 대하여 연구를 진행 하였다. 이를 위하여 유동인구를 추정의 기초데이터와 분석 방법에 대하여 공간빅데이터 및 공공에서 제공하는 데이터를 활용하여 유동인구 추정 방안에 대하여 연구를 진행 하였다. 또한 본 연구에서는 텍스트기반의 빅데이터와 공간정보(Spatial information) 빅데이터를 통합하기 위한 기준을 정의하고 결합방법까지 연구해 일반데이터와 공간데이터를 결합방법까지 제시 하였다.",
		"KEYWORD": "분석,빅데이터,유동인구"
	},
	{
		"ID": 399,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "빅 데이터 기반의 항공 여행객 단기 수요 예측 모형 개발 =Development of a short-term forecasting model of air passenger demand based on big data ",
		"AUTHOR": "김성도",
		"REGION": "인천",
		"PROFESSOR": "지도교수:신도형 인하대학교 논문은 저작권에 의해 보호받습니다. 참고문헌 : p.64-66",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "여러 산업 분야에 걸쳐 운영 계획은 매우 중요한 사항이며 올바른 운영 계획을 수립하기 위해서 예측 모형을 사용한다. 항공 산업 분야 역시 운영 계획을 위해서 예측 모형을 사용하는데 특히 공항에서는 공항 운영을 위해서 항공 여행객 수요 예측이 필수적이다. 공항은 체계적인 공항 운영을 위해 장기 계획과 단기 계획을 수립하며 이를 위해서는 각각 장기 수요 예측과 단기 수요 예측이 필요하다. 하지만 대부분의 공항은 장기 수요 예측만 시행하고 있으며, 별도의 단기 수요 예측은 시행하고 있지 않다. 한편 단기적인 계획의 수립은 일반적으로 단기 수요 예측에 기반하기 보다는 주로 경험에 의존하고 있는 실정이다. 이는 공항운영에 있어서 보다 체계적인 항공 여행객 단기 수요 예측이 필요함을 보여준다. 단기 예측은 장기 예측에 비해 변동성에 민감하기 때문에 예측의 정확도를 높이기 위해서는 단기적 변동성을 반영할 수 있는 변수를 포함할 필요가 있다. 이러한 단기적 변동성을 파악하여 반영할 수 있는 방법의 하나로 빅 데이터 분석(Big Data Analysis)을 고려할 수 있다. 빅 데이터 분석을 통하여 단기 변동성을 나타내는 변수를 찾아내어 반영한다면 보다 정확한 항공 여행객 단기 수요 예측 모형의 개발이 가능할 것이다. 본 연구는 빅 데이터 기반의 항공 여행객 단기 수요 예측 모형의 개발을 목적으로 한다. 이를 통하여 공항운영에 있어서 보다 체계적인 단기 계획의 수립이 가능할 것으로 보인다. 본 연구의 항공 여행객 단기 수요 예측 모형은 회귀분석에 기반을 두며 인천국제공항의 출발 여행객 수를 대상으로 한다. 항공 여행객 수요 데이터로는 인천국제공항의 월별 출발 여행객 수 데이터를 사용하였다. 또한 빅 데이터 자료로는 데이터의 접근성과 수집의 편리성을 고려하여 PC기반 인터넷 검색엔진에서 제공하는 인터넷 검색어 빈도 데이터를 사용하였다. 한편 모형에 예측성을 부여하기 위해서 인터넷 검색어 빈도의 시점이 항공 여행객 수요의 시점 보다 선행될 필요가 있었다. 이를 위하여 항공 여행객 수요의 시점보다 과거 시점의 인터넷 검색어 빈도를 대응시켜서 모형을 형성하는 시간차를 도입하였다. 본 연구에서는 시간차를 0개월부터 12개월까지 1개월 단위로 발생시켜 예측 모형을 만들어 비교하였고 최종적으로 최적의 결과를 나타내는 모형을 선택하였다. 모형간의 정확한 비교를 위해서 하나의 모형에 대한 데이터에서 훈련집합과 검증집합의 구성을 다르게 하여 교차검증하는 K-겹 교차검증(K-Fold Cross Validation)을 시행하였다. 각 시간차별 예측 모형의 비교 결과, 6개월 시간차의 예측모형이 가장 우수하게 나타났고 최종 예측 모형으로 선택되었다. 최종 예측 모형의 핵심 검색어는 총 25개의 검색어로 구성되어 있으며 인천국제공항 출발 여행객 수와의 결정계수는 0.8 이상으로 나타났다. 최종 예측 모형을 사용하여 2014년 9월에서 11월까지의 수요를 예측한 결과, 예측값과 실제값 간의 오차는 각각 1.56%와 10.89% 그리고 2.85%로 나타났으며, 평균 오차율은 5.11%로 양호한 결과를 보였다.",
		"KEYWORD": "빅 데이터,항공 수요"
	},
	{
		"ID": 400,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "논문의 중요성 및 품질을 이용한 학술 전문가 검색 기법 =Academic expert search method using importance and quality of papers ",
		"AUTHOR": "이서희",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 유재수 참고문헌 : p.47-49",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "과학기술의 끊임없는 발전과 함께 다양한 분야의 연구가 지속적으로 수행되고 있다. 사용자들은 새로운 기술을 적용하거나 현재의 기술을 개선, 발전시키고 이를 활용하기 위해 다양한 연구결과물을 활용한다. 이에 따라, 사용자들에게 필요한 대표적인 연구 결과물과 조언을 제공하는 학술 전문가 검색 기법에 대한 연구가 요구되고 있다. 본 논문에서는 사용자의 질의에 알맞은 분야의 지식과 경험을 가진 전문가를 검색하는 분야별 학술 전문가 검색 기법을 제안한다. 분야별 전문가를 검색하기 위해 각 논문들을 온톨로지로 그룹화 하고, 각 저자가 쓴 논문들의 우수성을 평가하기 위하여 중요성 및 품질을 이용하여 논문 점수를 계산한다. 계산된 논문 점수를 이용하여 전문가 지수를 도출한 후, 전문가 검색을 수행한다. 논문의 중요성은 각 분야별로 희소성이 있는 연구와 저자관계를 이용하여 저자 기여도를 판별하고, 논문의 품질은 인용 수, IF, 최신성을 이용해 판별한다. 제안하는 기법의 우수성을 보이기 위해 기존기법과 정확률과 재현율 관점에서 성능평가를 수행한다.",
		"KEYWORD": null
	},
	{
		"ID": 401,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "Spark 환경에서 통신 비용을 고려한 분산 SPARQL 질의 처리 기법 =Distributed SPARQL query processing scheme considering communication costs in Spark environments ",
		"AUTHOR": "김병훈",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 유재수 참고문헌 : p.52-54",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "시맨틱 웹 서비스의 증가로 인해 RDF 데이터가 대용량화되고 있다. 대용량 RDF 데이터를 효율적으로 활용하기 위하여 다양한 분산 저장 및 질의 처리 기법들이 연구되고 있다. 본 논문에서는 Spark 환경에서의 통신비용을 고려한 분산 SPARQL 질의 처리 기법을 제안한다. 제안하는 기법은 분산 환경에서 SPARQL 질의를 처리할 때 발생하는 디스크의 I/O 비용을 감소시키기 위하여 분산 In-Memory 환경인 Spark 환경에서 질의를 처리한다. 또한 분산 저장된 RDF 데이터를 질의 처리하기 위해 WHERE절을 기준으로 해당 질의를 여러 개의 서브 질의로 분할한다. 제안하는 기법은 분할된 서브 질의들을 인덱스를 통해 연관 노드들끼리 그룹화하여 처리함으로써 데이터 통신비용을 감소시키며 그룹화된 서브 질의들은 효율적인 질의 수행 경로를 선택하기 위해 모든 수행가능한 질의 수행 경로들의 비용을 계산한다. 모든 수행가능한 질의 수행 경로들의 데이터 파싱 비용, 노드 별 데이터 통신량 및 대기 시간을 고려한 알고리즘을 통하여 효율적인 질의 수행 경로를 선택한다. 다양한 성능평가를 통해 제안하는 기법이 기존기법보다 우수함을 보인다.",
		"KEYWORD": "분산 질의 처리"
	},
	{
		"ID": 402,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "소셜 정보 추천 기법을 위한 빅 데이터 모델 ",
		"AUTHOR": "HanXiaoyue",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 403,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "영남대학교 대학원",
		"TITLE": "스팸과 중복 데이터 제거를 통한 비정형 빅 데이터의 감성분석 ",
		"AUTHOR": "박형락",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 안병철",
		"STORE_LOCATION": "영남대학교 도서관",
		"ABSTRACT": "Instead of uploading individual preferences or opinions, SNS(Social Network Service) is widely applied to many areas such as marketing, analyzing public opinions, sharing ideas and so on. Sentimental data can be extracted from a lot of social media and applied to many areas such as business decision making, personal service, social, economy, and politics and so on after analyzed data. However, spam data and duplicate data such as commercial advertisements have had a lot of influence on processing time and storage to analyze big data. Therefore, it is necessary to filter out spam and duplicate data which are not appropriate to extract sentimental information. This paper presents a fast sentimental analysis of informal big data by removing spam and duplicate Data using Hadoop Distributed File System(HDFS). This method collects informal data after filtering out the duplication and spam data and uses the MapReduce with the machine learning method and the dictionary method to extract sentimental data. In experiments, we verified that the accuracy of the proposed method is 85.7% for the polarity of positive, negative and neutral. The processing time of the sentimental analysis is reduced by 71% based on the dictionary method and by 29.2% based on the machine learning method by removing spam and duplicate data.",
		"KEYWORD": null
	},
	{
		"ID": 404,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "유사 연산과 중복 연산을 고려한 효율적인 복합 이벤트 처리 기법 =Efficient complex event processing scheme considering similarity and duplication operations ",
		"AUTHOR": "김대윤",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 유재수 참고문헌 : p.46-48",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "최근 IOT 시대가 발전함에 따라 빅데이터의 ‘실시간 분석’ 에 대한 필요성이 급증하고 있다. IOT 시대의 실시간 처리는 수많은 센서나 소셜 미디어에서 생성되는 시계열 데이터, 여러 기업의 공장에서 지속적으로 생성되는 입력되는 데이터, 시간 순서가 중요한 데이터, 끝이 없는 스트림 데이터를 주로 사용한다. 지속적으로 데이터를 발생시키는 시스템들이 많아지고, 발생하는 데이터 양 또한 점점 늘어가고 있는 상황에서 다양하고 많은 양의 스트림 데이터를 통해 사용자에게 의미 있는 데이터를 실시간으로 데이터를 어떻게 추출하고 처리하느냐에 대한 연구가 진행되고 있다. 기존 연구는 연산자의 유사성과 중복성을 고려하지 않기 때문에 연산들을 개별적으로 처리하게 되어 많은 연산과 많은 메모리를 소비하는 문제점이 있다. 이러한 문제점을 해결하기 위하여 본 논문에서는 유사 연산과 중복 연산을 정의하고 개별적으로 처리하는 유사연산과 중복 연산을 하나의 가상연산자로 결합하여 한 번만 처리함으로써 감소시킨다. 유사연산과 중복연산을 검출하기 위해 복합이벤트를 등록하고, 유사연산과 중복연산을 하나의 가상연산자로 결합하여, 가상연산자를 가지는 질의트리를 생성하여 복합 이벤트 규칙에 등록하고 이벤트가 입력되면 규칙에 따라 복합이벤트를 검출한다. 기존 기법과의 성능 비교를 통하여 전체 연산 처리량 측면에서 제안하는 기법의 성능이 우수함을 보인다.",
		"KEYWORD": "복합 이벤트 처리"
	},
	{
		"ID": 405,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "동국대학교 국제정보대학원",
		"TITLE": "빅 데이터 분석기술을 활용한 APT 대응방안에 관한 연구 =(A)study on the response scheme of APT using the big data analysis technology ",
		"AUTHOR": "박성웅",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권법에 의해 보호받습니다. 지도교수:이재우",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "본 논문은 기업이 일반적인 보안시스템을 빠짐없이 구축했음에도 불구하고 점차 지능화, 일반화되어 가고 있는 APT공격에 대한 효과적인 대응방안이 없는 현실에서 새로운 정보보호 체계 구축을 위한 방향성 제시를 위하여 HP의 BDSA시스템을 개선한 BDSS시스템 구축방안을 제안하고자 한다. 초기 연구과정에서 “서버접속현황”같은 단위 노드만 가지고는 악성코드를 찾아내기 힘들었지만 VMTJ Summer2에서 제시한 노드간 상관관계 알고리즘을 바탕으로 빅 데이터기반의 7가지 분석방법(룰)을 만든 후 “서버접속현황-송수신비율-DNS쿼리분포-데이터양-시간-Port” 라는 노드 간 상관관계 분석을 통하여 악성코드를 탐지한 결과, SIEM, ESM, DLP, F/W 및 APT대응시스템 등 상용 보안시스템에서 탐지 못한 드로퍼(Dropper)들을 탐지할 수 있었고 또한 패킹되어 백신에서 탐지 못하는 백 도어를 다수 발견할 수 있었다. 이러한 이론적 실증적 연구결과를 바탕으로 빅 데이터 분석기술을 활용한 APT대응 시스템인 BDSS시스템의 구축방안으로 첫 번째, SIEM시스템이 이미 도입된 기업은 SIEM시스템과 빅 데이터 보안배치분석시스템(Pre BDSS)과 상호보완체계를 구축하여 SIEM시스템은 실시간 탐지를 담당하고 Pre BDSS시스템은 새로운 시그니처 분석 및 생성을 담당함으로써 각각 역할을 분담하는 방안을 제시하였고 두 번째, SIEM이 도입되지 않은 기업의 경우 통합보안관리 역할을 하는 BDSS시스템의 구축을 제안하였다. 마지막으로 오픈 소스를 활용한 빅 데이터보안시스템의 확장이 불가피한 경우 사용편의성 및 전문업체 부족 그리고 가용성을 보장하지 못하는 하둡의 독립구축 보다는 BDSS의 병행구축을 권고하였다. 연구를 마치면서 느낀 점은 효과적인 정보보호를 위해서는 정보보호시스템을 도입하는 것도 중요하지만 해당 기업의 전체적인 시스템구조와 보안체계를 잘 아는 정보보호담당자가 해당 기업에 맞는 보안알고리즘을 개발하고 그에 합당한 로그를 관리하는 것이 날로 지능화되어 가고 있는 새로운 공격에 능동적으로 대처할 수 있는 최선의 방법이라고 생각하였다. 이를 위하여 빅 데이터솔루션의 활용은 불가피 할 것으로 사료된다. 아쉬웠던 점은 검증을 위하여 실질적으로 1년 정도의 빅 데이터를 가지고 좀 더 다양한 시나리오와 알고리즘을 사용하여 테스트를 진행했어야 하나 운용중인 보안시스템 접근제한 및 로그의 사용제한 등으로 부득이하게 검증을 위한 악성코드를 임의로 작성하여 실행기간인 3주 만의 실 데이터를 분석 한 점이 아쉬움으로 남는다. 마지막으로 향후 연구가 필요한 부분은 룰 마이닝 모듈의 추가와 실시간 스트리밍 처리를 위한 룰 인덱싱 방법에 대한 연구와 더불어 Suricata룰과 같은 공개 룰의 BDSS시스템에서의 활용방안을 연구함으로써 빅 데이터를 이용한 통합 이상 징후 탐지 시스템이 매우 효과적으로 운영되기를 기대한다.",
		"KEYWORD": "APT,BDSS,Big data,Information Security,security system,SIEM"
	},
	{
		"ID": 406,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "충북대학교 경영대학원",
		"TITLE": "SNS 빅 데이터 다차원 분석 기반 스마트폰 선호도 분석 ",
		"AUTHOR": "김재성",
		"REGION": "충청북도",
		"PROFESSOR": "",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Thanks to rapid improvement of information technology, the emergence of various information channels such as mobile devices and social media have been producing tremendous amount of data. The evolution of smartphones and social network services(SNS) leads to the big data revolution. Not only the amount of data have been growing up exponentially, but also more diverse types (structured, semi-structured, and unstructured) of data are emerging. In case the of Twitter and Facebook, there should be several analytical methods depending on the types of data. In the case of online shopping, the log data can be used to analyze consumer`s purchase pattern by measuring the time on how long they purchase items since they logged in the web. Collection and analysis of large and varied data presents a challenge, as compared to the standard and conventional data. Even though the same data was used to extract the meaning, it can be interpreted in various ways depending on how it was pre-filtered and what kind of data mining methods was used. So the importance of pre-filtering and appropriate data mining techniques should be considered in mining the semantics of large and various data. The research for unstructured data, large and varied data, have been started for a more systematic and appropriate ways of collection and analysis. In this study, Twitter data has been collected, stored and analyzed in a multi-dimensional fashion on top of Hadoop platform, widely used for distributed computing, in order to find out what kind of factors can affect the preference of smartphones. The data, which is around 600,000 tweets or 2.5 GB, has been collected for one month using smartphone-related keywords. The results affecting the preference of smartphones are processed in multi-dimensional analysis after pre-filtering and natural language processing. The most serious problem is the quality of the result that comes largely from the shortage of samples due to a short period of collection (one month). Another big problem comes from the synonyms including acronyms in Internet or smartphones. However, these problems can be moderated as the data collection time and the number of synonyms/acronyms in the dictionary increase.",
		"KEYWORD": null
	},
	{
		"ID": 407,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "소셜 네트워크에서 신뢰성을 고려한 사용자 영향력 판별 기법 =User influence discrimination scheme considering reliability in social networks ",
		"AUTHOR": "박윤정",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 유재수 참고문헌 : p.51-52",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "SNS는 장소와 시간에 관계없이 빠른 전파력을 가졌다는 편의성이 부각되면서, 사용자가 급증하였다. 이에 SNS는 간단한 정보공유뿐만 아니라 마케팅, 소셜 추천, 전문가 찾기 등 여러 분야에 활용 되어졌고, 정보의 빠른 전파를 위해 높은 영향력을 가진 사용자를 찾게 되었다. SNS데이터를 통한 사용자 영향력 판별 연구가 활성화 되었으나, 정보 공유의 대상이 불특정하고 방대한 정보의 양 때문에 신뢰성 없는 정보를 공유하는 문제가 발생하게 되었다. 이에 따라 제공 정보의 신뢰성이 고려된 사용자 영향력 판별 기법이 요구되고 있다. 본 논문에서는 기존 기법을 통해 사용자의 신뢰성을 기준으로 사용자 집단을 필터링 하였다. 그 결과 제공 정보의 신뢰성이 보장된 사용자만을 대상으로 영향력을 판별하였다. 신뢰성이 보장된 사용자들로 신뢰성 네트워크를 구축함으로써 사용자 영향력 판별의 신뢰성과 효율성 향상에 기여한다. 또한, 사용자 영향력 판별의 객관성을 보장하기 위해 소셜 행위, 차원, 시간, 사용자간 연결정도를 추가 고려한다. 제안하는 기법에서는 사용자의 소셜 행위 데이터를 수집하여 신뢰성 점수를 측정한다. 목적에 맞는 신뢰성 임계치를 정한 후 임계치 이상의 사용자들로 신뢰성 네트워크를 구축한다. 간소화된 네트워크에 속한 사용자들의 SNS데이터를 통해 추가요소를 분류하고 가중치를 부여한다. 부여된 가중치를 통해 영향력 점수를 측정하여 최종 사용자 영향력 결과와 랭킹을 도출한다. 이를 통해 사용자 영향력 판별함으로써 사용자 영향력의 정확성을 향상시킨다. 제안하는 기법의 우수성을 보이기 위해 제안하는 기법과 기존 기법을 신뢰성과 사용자 영향력에 대한 비교 성능평가를 수행한다.",
		"KEYWORD": "사용자영향력,소셜네트워크,신뢰성,신뢰성네트워크,영향력판별"
	},
	{
		"ID": 408,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "온라인 소셜 네트워크 환경에서 사용자와 콘텐츠의 신뢰도를 고려한 추천 기법 =Recommendation scheme considering reliabilities of users and contents in online social networks ",
		"AUTHOR": "고건식",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 유재수 참고문헌 : p.51-53",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "스마트폰의 보급과 온라인 소셜 네트워크 서비스를 이용하는 사용자들이 증가하면서 사용자들은 많은 콘텐츠를 생산하거나 서로 공유한다. 이로 인해 사용자는 그들의 기호에 맞지 않거나 만족도가 떨어지는 콘텐츠를 받아본다. 이와 같은 문제를 해결하기 위해 소셜 네트워크 사용자에게 적합한 콘텐츠를 추천하기 위한 기법에 대한 연구가 활발하게 진행되고 있다. 하지만 콘텐츠 추천 기법에서 콘텐츠 추천을 받기 위해서 사용하는 사용자의 데이터에 대한 신뢰도 문제가 발생하였다. 따라서 사용자의 신뢰도를 분석해서 사용자 신뢰도에 대한 연구가 진행되었고 사용자의 신뢰도를 고려한 추천 기법이 등장하였다. 본 논문에서는 신뢰도가 떨어지는 사용자의 데이터를 제거하기 위해 사용자 필터링을 수행하고 신뢰도 있는 사용자의 데이터를 활용해서 콘텐츠를 추천한다. 사용자 필터링을 위해서 소셜 행위 분석, 콘텐츠 이용 분석, 소셜 관계 분석을 수행한다. 또한 콘텐츠 추천 우선순위를 판정하기 위해서 콘텐츠가 지닌 신뢰도를 고려한다. 콘텐츠의 신뢰도를 계산하기 위해서 사용자 전문성 분석, 암시적 행위 분석을 수행한다. 앞에서 계산된 각 신뢰도를 바탕으로 협업필터링을 수행해서 추천 콘텐츠를 선별한다. 콘텐츠 신뢰도에 따라서 해당 사용자에게 콘텐츠를 추천한다. 다양한 성능평가를 통해 제안하는 기법이 기존 기법보다 우수함을 보인다. 성능평가 결과, 제안하는 기법은 기존 기법에 비해 추천 정확도와 정밀도가 향상됨을 확인하였다.",
		"KEYWORD": "빅데이터,소셜 네트워크,콘텐츠 추천"
	},
	{
		"ID": 409,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "세명대학교 대학원",
		"TITLE": "토지이용 및 부동산 관련 빅 데이터를 통한 중소도시의 변화 분석 :Analysis of small and medium-sized cities change using the land use and real estate related big data :충청북도 제천시를 중심으로 =focusing on the Chungbuk Jecheon ",
		"AUTHOR": "박사랑",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 권기욱",
		"STORE_LOCATION": "세명대학교 민송도서관",
		"ABSTRACT": "본 연구는 충청북도 제천시를 중심으로 시계열적으로 토지이동의 전환, 주택유형의 변화, 인구와 세대수의 변화, 공시지가의 변화 등의 빅 데이터를 분석하여 도심 중핵부와 주변부 간에 변화를 분석하는 논문으로서 공간적 범위로서 충청북도 제천시의 9개 행정동을 대상으로 하며, 시간적 범위로서는 2006년 1월 1일부터 2015년 12월 31일까지의 자료를 활용한 토지이동, 주택유형, 인구 및 세대, 공시지가 등의 빅 데이터를 분석하였다. 내용적 범위에서 토지이동은 지목변경, 토지분할, 토지합병, 등록전환 등을 조사하였고 주택유형은 다세대, 다가구, 아파트, 단독주택의 신축, 증축, 개축 등을 조사하여 분석하였다. 그 결과 토지이동, 주택의 유형, 인구수 및 세대수, 공시지가에서 주변부인 교동, 신백동, 영서동, 의암동, 용두동, 화산동이 중핵부인 남현동, 인성동, 청전동에 비해 많은 변화가 있음을 확인할 수 있었고 향후 충청북도 제천시의 2015년 이후 제천시의 발전가능한 동을 예측할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 410,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "순천향대학교 대학원",
		"TITLE": "차세대염기서열 빅데이터의 생물정보학적 분석을 통한 멸종위기 나비 3종(왕은점표범나비, 깊은산부전나비, 쌍꼬리부전나비)의 유전체 및 전사체 분석에 관한 연구 =Bioinformatic analysis of three endangered butterflies(Fabriciana nerippe, Protantigius superans, Spindasis takanonis) genome and transcriptome data ",
		"AUTHOR": "황희주",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 이용석",
		"STORE_LOCATION": "순천향대학교 도서관",
		"ABSTRACT": "본 연구는 국내 멸종위기생물로 지정된 생물종 중 멸종위기Ⅱ 등급이며, 적색목록집 상 취약에 해당하는 나비 3종(species)인 왕은점표범나비(Fabriciana nerippe), 깊은산부전나비(Protantigius superans), 쌍꼬리부전나비(Spindasis takanonis)에 대한 유전체와 전사체를 NGS 장비를 이용하여 염기서열을 해독하고 분석한 연구로 국내 나비에 대한 최초의 유전체 연구이며, 국내 멸종위기 등급의 생물 중 무척추동물군에서는 최초의 연구이다. 왕은점표범나비(F. nerippe)는 네발나비과(Nymphalidae)에 속하는 종으로 주로 산지의 숲 주변과 하천의 둑, 경작지 주변 등 초지에 서식하며, 표범나비아과 중 대형종으로 날개 아래쪽에 은색무늬의 변이가 다양하게 나타난다. 깊은산부전나비(P. superans)는 부전나비과(Lycaenidae)에 속하는 종으로서 중북구 산지를 중심으로 국지적으로 분포하며, 높은 산지의 잡목림이나 그 주변 계곡에 서식하면서 높이 매달린 참나무의 잎 위에 서식한다. 쌍꼬리부전나비(S. takanonis) 역시 부전나비과(Lycaenidae)에 속하는 종으로 경기도, 강원도, 충청도 일부지역에서만 국지적으로 분포하며, 뒷날개에 한쌍의 미상돌기를 가지고 있다. 이 종의 특이점은 유충시기에 개밋과(Formicidae)의 한 종인 마쓰무라꼬리치레개미(Crematogaster mastsumurai)의 서식지에서 이들과 공생(symbiosis)을 통해 먹이교환을 하는 것으로 알려져 있다. 본 연구 대상종들은 멸종위기생물로 허가없이 채집 및 포획이 불가능하기 때문에 우선 각 대상종들이 서식하는 지역의 지역환경유역청으로부터 허가를 받은 후 채집하여 날개를 제거한 몸통부분만을 이용하여 DNA와 RNA를 추출한 후 라이브러리를 구축하여 Illumina HiSeq 2500을 이용하여 염기서열을 해독하였다. 시퀀싱 후 assembly 결과 왕은점표범나비 유전체에서 257,505,716개의 약 31 Gb 서열, 42,597개의 contigs(>500 bp)를 얻었고, 전사체에서는 약 30 Gb의 241,305,349개 read, 114,405개의 Unigenes를 얻었다. 깊은산부전나비(P. superans) 유전체에서는 257,132,821개 raw read의 약 31 Gb 서열, 259,409개의 contigs(>500 bp)를 얻었으며, 전사체는 254,340,693개의 약 31 Gb 서열, 107,950개 unigenes을 얻었다. 쌍꼬리부전나비(S. takanonis)는 유전체에서 266,874,799개, 약 32 Gb 서열과 317,010개 contigs(>500 bp)를 얻었고, 전사체에서 약 30 Gb의 245,110,582개의 서열을 얻었다. Transcriptome 서열들은 기능분석 등을 위해 BLAST를 통해 annotation한 결과, 왕은점표범나비에서는 전체 unigene의 41.2%에 해당하는 47,131개의 결과를 얻었고, 깊은산부전나비에서는 43.3%에 해당하는 44,529개의 결과를, 쌍꼬리부전나비에서는 42.8%에 해당하는 51,908개의 결과를 얻었다. 그리고 KOG, GO를 통해 유전자들을 기능별로 분류하였으며, InterProScan, KEGG pathway 및 SSR 분석 등 생물정보학적 분석을 통하여 다른 기능을 가진 분류군들을 찾았다. 그리고 이러한 멸종위기종에 대한 환경적응 유전자 스크리닝을 통해 AMPK, COL1A1, IRS1, AQP2, HSP70, ILGF1 등의 유전자들을 검색하였다. Genome 해독을 통해 얻어진 서열들의 assembly 결과와 jellyfish 프로그램을 이용하여 각 개체의 genome size 예측 결과, 왕은점표점나비 약 1.7 Gb, 깊은산부전나비 약 700 Mb, 쌍고리부전나비 약 700 Mb로 예측되었고, 10Kb 이상의 large contig 들의 대상으로 한 유전자예측을 통해 얻어진 서열들을 annotation한 결과, 각각 79.5%, 48%, 51% 정도의 매치율를 보여주었다. 그리고 염색체별 분석이 가능한 누에나방(Bombyx mori) chromosome data를 이용해서 3 종의 유전체서열과 synteny 분석을 실시한 결과 왕은점표범나비와 깊은산부전나비의 assembly 결과 쌍꼬리부전나비에서는 scaffold47654 등과 같이 긴 서열에서 유전자군이 형성되어있는 결과를 볼 수 있었으며, 17번 chromosome에서도 특정 enzyme 관련 유전자 군 일부를 확인할 수 있었다. 이러한 국내 멸종위기종 3종 나비에 대한 유전체 및 전사체 분석은 국내에서는 최초로 수행되어진 결과로 이를 통하여 나비목 유전자원을 대량으로 확보하였으며 이를 통해 나비 3종의 국내 생물자원 및 유전자원의 생물주권를 확보하였고, 멸종위기 원인 및 보전과 복원을 위한 전략을 수립하는데 기여할 수 있을 것이다. 그리고 현재 존재하는 다양한 나비목 유전체 서열 및 assembly data들을 기반으로 국내 유일한 나비목 유전체 지도 작성이 가능할 것이며, 이를 통해서 나비목 유전체에 대한 기반을 마련할 수 있을 것으로 사료된다.",
		"KEYWORD": "깊은산부전나비,나비,멸종위기,쌍꼬리부전나비,왕은점표범나비,유전체,전사체,차세대염기서열분석"
	},
	{
		"ID": 411,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "순천향대학교 대학원",
		"TITLE": "차세대염기서열 빅데이터의 생물정보학적 분석을 통한 한국산 육산 연체동물 4종에 대한 유전체 및 전사체의 비교분석 연구 =Genome and transcriptome characterization of the four Korean land snails using NGS and bioinformatics databases ",
		"AUTHOR": "강세원",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 이용석",
		"STORE_LOCATION": "순천향대학교 도서관",
		"ABSTRACT": "본 연구는 우리나라에 서식하고 있는 육산 연체동물들 중에서 거제외줄달팽이 (Satsuma myomphala), 북한산달팽이 (Koreanohadra kurodana), 제주배꼽달팽이 (Aegista chejuensis) 제주배꼽털달팽이 (Aegista quelpartensis) 4종에 대한 NGS를 사용한 최초의 유전제 및 전사체 분석 연구이다. 거제외줄달팽이는 한국과 일본에 출현하는 동북아시아 특산종이지만, 국내에는 거제도의 한정된 곳에서만 출현하는 고립종이다. 반면에 북한산달팽이는 한국 고유 속 의 종이지만, 한반도 중북부 지역에 넓게 분포하는 특징을 보인다. 또한 배꼽달팽이속의 제주배꼽달팽이와 제주배꼽털달팽이는 제주도를 중심으로 한정된 지역에 분포하고 있다. 따라서 본 연구는 이러한 지리적 분포 특성을 지니는 육산 연체동물 4종을 대상으로 각 종의 유전체 및 전사체 분석을 통하여 유전자원의 선점, 종의 보존을 위한 기초데이터 확보, 유용자원으로서의 기능유전자 탐색을 등을 진행하고자 하였다. 4종의 육산 연체동물을 채집하여 유전체 및 전사체 분석을 하기 위하여 DNA 및 RNA를 추출한 뒤 라이브러리를 구축하여 Illumina HiSeq 2500을 사용하여 시퀀싱하였다. 분석 결과 거제외줄달팽이 유전체에서 약 120 Gb의 raw 데이터와 1,255,442 개의 contigs, 전사체에서 약 33 Gb의 raw 데이터 및 103,774 개의 unigenes을 얻었다. 북한산달팽이 유전체에서는 약 31 Gb의 raw 데이터와 42,066 개의 contigs, 전사체에서는 약 30 GB의 raw 데이터와 191,071 개의 unigenes을 얻었다. 제주배꼽달팽이의 경우 유전체에서는 약 32 GB의 raw 데이터 및 258,618 개의 contigs를 얻었으며, 전사체에서는 약 32 Gb의 raw 데이터와 198,531 개의 unigenes을 확보하였다. 제주배꼽털달팽이 유전체 분석에서는 약 30 Gb의 raw 데이터와 245,566 개의 contigs를 얻었고, 전사체 분석에서는 약 30 Gb의 raw 데이터와 230,497 개의 unigenes 서열들을 확보하였다. 또한 이렇게 생산된 raw data 들은 NCBI SRA 에 등록을 완료하였다. Annotation 분석시간의 단축 등을 위하여 PANM 데이터베이스를 구축하였고 검증 결과 연체동물 NGS 데이터 분석에 있어서 좋은 데이터베이스로 활용이 될 것이라고 확인되었다. PANM 데이터베이스 및 공공 데이터베이스들을 활용하여 전사체의 unigenes에 대한 annotation 결과 거제외줄달팽이에서는 전체의 약 40%에 해당하는 41,670 개의 annotation 결과를 얻었고, 북한산달팽이에서는 약 36%, 69,303 개의 결과를 얻었다. 제주배꼽달팽이와 제주배꼽털달팽이의 경우 각각 약 35%, 69,088 개, 약 34%, 78,494 개의 annotation 결과를 확인하였다. 또한 KOG와 GO 를 이용하여 유전자들을 기능별로 분류하였으며, InterProScan, KEGG pathway 및 SSR 분석을 실시하였다. 그리고 환경적응과 관련된 유전자를 스크리닝하여 AMPK, HSP70, IRS1, TLR4, AQP2 등의 유전자를 확인하였다. 유전체분석 결과 유전체의 크기는 거제외줄달팽이가 약 4.9 Gb, 북한산달팽이 2.9 Gb, 제주배꼽달팽이 약 2.5 Gb, 제주배꼽털달팽이 약 2.2 Gb 로 예측되었다. Large contigs 에 대하여 반복서열 검색 및 SSR 분석을 실시하였으며, 유전자예측을 통하여 얻은 유전자에서 약 30% 이상의 annotation 결과를 얻을 수 있었다. 또한 예측된 유전자의 KOG 분석을 통하여 유전자를 기능별로 분류하였다. 본 연구 이후 추가적으로 deep sequencing 등을 통하여 더 많은 데이터를 축적하게 되면, 본 연구에 의해 얻어진 데이터들과 함께 분석하여 각 4종의 육산 연체동물의 유전체와 전사체와의 상관관계, 또는 다른 종들의 유전체 및 전사체와의 유연관계 등을 자세히 연구할 수 있을 것이다. 또한 본 연구의 데이터들은 많은 연구자들과 공유하여 이들 4종의 육산 연체동물에 연구에 있어서 매우 중요한 기초자료가 될 것이라 사료된다.",
		"KEYWORD": "NGS,거제외줄달팽이,북한산달팽이,유전체,육산 연체동물,전사체,제주배꼽달팽이,제주배꼽털달팽이"
	},
	{
		"ID": 412,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "모델트리 기법을 이용한 소득구간 중심의 주택수요예측 =Housing demand forecast based on income section using model tree technique ",
		"AUTHOR": "임형선",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 최상현",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Mankiw and Weil model, which is used to forecast housing demand using population data, has been modified to overcome the limitation that it does not include major variables such as income and cost. However, it is pointed out that the added variables do not have a linear relationship with age - specific housing demand. In this study, we propose an M-W modification model using the Model Tree technique to complement the prediction and explanatory power of the existing model. Also, since many of the poor and low-income families are in the form of abnormal housing, a separate analysis is needed to understand their characteristics. In this study, we tried to avoid this problem by reflecting income section. In 2005, we analyzed using Population and Housing Cencus data in 2010, and compared the performance of the analysis using the existing linear regression method and the analysis using the proposed model tree method.",
		"KEYWORD": "Housing Demand Forecast,Mankiw and Weil,Model Tree"
	},
	{
		"ID": 413,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "모바일 P2P환경에서 피어의 신뢰성 판별 기법 =Trust discrimination scheme of peers in mobile P2P environments ",
		"AUTHOR": "최민웅",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 유재수 참고문헌 : p.47-49",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "최근 모바일 기기와 근거리 무선 통신 기술 등의 발달로 기존 중앙 집중 처리 시스템의 한계를 개선하기 위해 모바일 P2P 네트워크에 대한 연구가 활발하게 진행되고 있다. 모바일 P2P 네트워크에서 안전한 콘텐츠 공유를 위해서는 피어의 신뢰성이 판별되어야 한다. 본 논문에서는 콘텐츠 평가 정보와 네트워크 요소를 동시에 고려하여 신뢰성을 검증하는 기법을 제안한다. 각각의 평가 정보는 테이블로 저장하며 피어의 평가 정보를 수집하기 위해서 테이블의 최근 업데이트 시간을 사용한다. 콘텐츠 평가를 사용하여 악성 콘텐츠를 제공하는 피어를 배제하며, 네트워크 평가를 사용하여 네트워크상에서 콘텐츠를 전달하지 않는 피어들을 배제할 수 있다. 피어의 콘텐츠 신뢰 값은 직접 평가 값과 직접 평가 값을 이용하여 만들어진 간접 평가 값으로 계산한다. 네트워크 신뢰 값은 데이터 전송 시 발생하는 데이터 패킷과 메시지 전송 시 발생하는 컨트롤 패킷의 수를 이용하여 계산한다. 최종적으로 피어의 콘텐츠 신뢰 값과 네트워크 신뢰 값을 합산하여 피어의 최종 신뢰 값을 계산한다. 성능 평가를 통해 제안된 기법이 기존 기법보다 성능이 향상된 것을 입증한다.",
		"KEYWORD": "모바일P2P,악성피어,판별,평판"
	},
	{
		"ID": 414,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "호서대학교 벤처전문대학원",
		"TITLE": "빅데이터를 활용한 자동차판매량 예측방안 연구 =(A)study on the big data applications for the forecasting of automobile sales ",
		"AUTHOR": "이영환",
		"REGION": "충청남도",
		"PROFESSOR": "",
		"STORE_LOCATION": "호서대학교 중앙도서관(천안캠퍼스)",
		"ABSTRACT": "자동차 연비에 대한 실시간 키워드 검색 데이터 분석을 통해 자동차 단기 판매량의 예측이 가능할 것인지를 연구하고, 비전문가도 활용이 가능한 네이버 트렌드를 활용하여 빅데이터가 전문적인 영역이 아니라는 것을 설명함. 연구결과는 실시간 데이터의 확보 및 다양한 이벤트 요소의 조합으로 실시간 빅데이터 모니터링을 통해 자동차 판매예측이 가능하고, 결과 데이터를 생산계획에 반영한다면 자동차 제조사 입장에서 오더 예측의 정합성이 향상될 것이며, 완성제품의 운영재고를 현격히 최소화 할 수 있음. 또한, 즉시 생산/ 판매의 가능성 향상으로 현금흐름이 빨라짐에 따라 경영성과의 향상을 기대할 수 있음. 그리고, 상시 오픈된 빅 데이터를 활용하여 우리 생활속의 다양한 예측이 가능함.",
		"KEYWORD": null
	},
	{
		"ID": 415,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "실시간 노면상태 예측을 위한 빅 데이터 분석 및 시스템 연구 =A study of real-time big data analysis and system for predicting surface condition ",
		"AUTHOR": "조연주",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 함유근",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "There is a new era in the 4th industrial revolution. Various types of data are generated exponentially by the connection between devices, and attempts to utilize them in various fields are increasing. Technologies that can smoothly process data in accordance with these trends are continuously being developed. Typically, it is possible to build a system that can utilize data based on the Hadoop system. However, it is not easy to build a system in accordance with the characteristics of data in the business environment, and if it fails, it causes a huge cost. In addition, there are many cases that are still unavailable, and it is unclear what possibilities exist. In this study, we attempted to develop an analysis and system for real - time road surface condition classification prediction analysis by collecting meteorological climate data and road surface condition data generated in real time in accordance with the above social flow. This study explores the process of designing a system capable of collecting, storing, and analyzing large amounts of data in real time, and finding a statistical model that can increase the prediction accuracy of the road surface condition. Respectively.",
		"KEYWORD": "도로 기상,머신러닝,실시간 분석,하둡 시스템"
	},
	{
		"ID": 416,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "명지대학교 대학원",
		"TITLE": "빅 데이터를 활용한 서비스 이용 패턴 및 특성에 관한 연구 :Korail 서비스 상품 `내일로` 적용 사례 ",
		"AUTHOR": "전명진",
		"REGION": "경기도",
		"PROFESSOR": "명지대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김창은",
		"STORE_LOCATION": "명지대학교 도서관(서울),명지대학교 도서관(용인)",
		"ABSTRACT": "Big data means extracting data collected and analyzing the results by collecting all data that are generated, distributed, stored in everyday life. Through the results analyzed, big data can be utilized in the managerial aspects such as distribution, production management, service, and inventory management, and also can be used as a tool of marketing strategy in various industrial sectors and government agencies. Therefore, many business enterprises are increasingly interested in big data for strengthening differentiated competitiveness and efficient decision making, and its importance also tends to be more highlighted. Also, with the rapid growth of social media today, diverse opinions of the consumers are appearing on the social media. The consumers post their views on social media in the forms of service reviews and comments, communicate with other consumers and potential consumers, and share their opinions. As this culture becomes gradually common, businesses are now able to keep a great amount of data that were not available in the past, and by means of various analyses, they use them for strengthening their competitiveness and efficient decision making. Based on this observation, the present study turned the consumer opinions of ‘Railro’, a service product of ‘Korail’ (Korea Railroad Corporation) into big data and tried to analyze prediction of demand of the product, consumer behavior and consumer pattern. ‘Railro’ is a service package for the youths of 20 to 25 years old that can be used freely for all railroads nationwide except KTX. The product can be purchased according to the period of use, and ‘Korail’ is selling 5 days ticket and 7 days ticket. Because it has the advantage that the consumers can purchase tickets that suit their schedules and travel around the country freely, the package is getting very popular among the youths recently. But since most of the information on use of the railroad of ‘Korail’ is computerized, the pattern of consumer behavior and use can be easily analyzed; on the other, in case of ‘Railro’, due to its product feature of free use, it is not easy to analyze how the consumers use the train on what routes. Therefore, this study tries to verify the utilization of value of big data by analyzing the pattern of using ‘Railro’ and their characteristics through big data analysis of the service reviews and comments posted on social media by consumers. Based on the results of this study, 104 rules between stations were drawn through analysis of association rules to analyze the use pattern of customers. This shows that the use pattern of each station were comprehended and proves that the consumption pattern can be analyzed. Also, through analysis of key word network, the characteristics of 15 stations and emotions for them were drawn so that it can prove that the characteristics of the travelers’ use of each station and their emotions and opinions can be analyzed. The results of analysis show that in the industry in which the diversity of products increasingly grows and the consumption of patter of consumers is also being diversified, demand can be predicted by using pattern analysis of big data so that it can lead to provision of customized services and qualitative improvement of services, and further, to improvement of the management performance of businesses. Also, this study could contribute to comprehending the needs of consumers who tend to become more demanding.",
		"KEYWORD": "내일로,빅 데이터,연관성 분석,키워드 네트워크 분석"
	},
	{
		"ID": 417,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "소셜 빅데이터를 활용한 자동차 제조사 서비스품질 분석에 관한 연구 =(A)study on the case analysis of customer reputation and service quality based on social big data ",
		"AUTHOR": "배성환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최재영",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "스마트 기기의 발달과 IT기술의 발전은 트위터, 페이스북, 인스타그램 등의 SNS(Social Network Service) 상에서 유통되는 정보량의 폭발적 증가로 연결되고 있다. 또한 IOT(Internet of Things)라고 일컬어지는 사물인터넷의 기기 개발이 활성화 된다면 인터넷상의 정보량은 사람이 분석할 수 있는 범위의 양을 벗어나게 된다. 역변의 시장구조변화와 심화되어가는 기업 간의 경쟁에서 시시각각 변화하는 고객(시장)의 자발적인 목소리를 담고 있는 소셜 빅데이터(Social BigData)는 효율적 경영지표 설정을 위한 나침반이라 할 수 있다. 수집 및 확보된 소셜 빅데이터(Social BigData)는 『소셜 미디어 분석 모니터링』 이라는 시스템을 통해 기업, 정부, 공공기관이 갈급해 하는 정보로 탄생하게 된다. 본 연구에서는 『소셜 미디어 분석 모니터링』시스템에 대한 고찰과 SERVQUAL(service-quality) 모형을 적용한 국내 자동차 제조 5개사를 대상으로 실제 소셜 데이터를 적용, 고객의 반응을 분석하여 개선점을 찾아보고자 한다.",
		"KEYWORD": "소셜빅데이터"
	},
	{
		"ID": 418,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "빅 데이터를 이용한 개체명 학습 코퍼스 자동 생성 기법 =Automatic training corpus generation method of named entity recognition using big data ",
		"AUTHOR": "김예진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 서정연",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Named entity is a phrase that clearly identifies one item from a set of other items that have similar attributes such as person, organization, location etc. Named entity recognition is a subtask of information extraction that seeks to locate and classify elements in text into predefined categories. Named Entity Recognition is used for various departments which receives natural language inputs. In previous work, supervised learning method is used to recognize Named entities which needs human annotating. Recently semi-supervised learning methods are used to reduce the cost of labeling which makes extract a large amount of the labeled corpus using small seed data. In this paper, we propose the two methods which can generate named entity training corpus automatically using knowledge base. One of the methods attaches named entity labels to data using Wikipedia. The other method crawls data from web and labels named entities to web data using Freebase. We evaluate labeled corpus generated in proposed way. we extract sentences randomly from two corpus which called Wikipedia corpus and Web corpus then label them by hand annotating. Our labeling performance shows high precision in both corpus evaluation. we also compare the performance of named entity recognizer trained by ontoNotes corpus which is labeled by human with our automatic generated labeled corpus from Wikipedia and Web. The result showed that proposed named entity recognizer adapted well with new corpus which reflects diverse sentence structures and the newest entities.",
		"KEYWORD": null
	},
	{
		"ID": 419,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "계명대학교 대학원",
		"TITLE": "행정서비스에서 빅 데이터 활용의 결정요인에 관한 연구 :데이터 품질관리를 중심으로 ",
		"AUTHOR": "박귀희",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 손달호",
		"STORE_LOCATION": "계명대학교 동산도서관",
		"ABSTRACT": "빅 데이터가 국가경쟁력 및 신성장동력으로 자리매김해 나가고 있다. 이러한 빅 데이터는 그동안 민간 부문을 중심으로 활발히 이루어져 오다가, 공공부문으로 확산이 진행되고 있다. 빅 데이터에 대한 학술적인 연구들이 최근 급속히 이루어지고 있으나, 빅 데이터 구축 및 활용에 대한 사례 연구나 개념 및 특성 등 기초적인 수준으로 빅 데이터 활용에 관한 결정요인에 대한 심층적인 실증연구는 미흡한 실정이다. 민간 부문과 달리 공공부문의 빅 데이터 활용과 확산은 법제도 및 기술 요인과 같은 빅 데이터 인프라 측면과 데이터 품질 측면을 중심으로 진행되는 특징을 지니고 있다. 따라서 공공부문에서의 빅 데이터의 활용을 위해서는 빅 데이터를 핵심 자원으로 인식하고 필요한 정보를 쉽게 획득할 수 있는 자원 능력의 배양과 데이터 품질의 확보가 필수적인 과제라 할 수 있다. 본 연구의 혁신기술의 내적 속성에 기반을 두는 이용자의 수용 모델인 TAM 이론과 혁신의 확산을 압박하는 외적 속성을 강조하는 DOI 이론 및 TOE 이론의 논리를 바탕으로 공공부문에 있어서 빅 데이터 활용의 결정요인을 규명하고자 한다. 빅 데이터 혁신의 내적 속성은 데이터 품질 요인에 초점을 두고, 외적 환경 속성은 빅 데이터의 인프라 요인을 중심으로 이들이 TAM의 핵심 변수인 지각된 유용성과 지각된 용이성을 통해 빅 데이터의 활용 의도에 미치는 영향을 실증적으로 규명하는 것이 본 연구의 목적이다. 이를 통해서 공공부문에 있어서 성공적인 빅 데이터의 활용 및 확산을 위한 정책적 방향을 모색해보고자 한다. 연구 목적을 달성하기 위해서 개념 및 특징, 유형 및 활용 사례를 중심으로 빅 데이터의 개념적 이해를 정리하였다. 또한 Defusion of Innovation(DOI), Technology Organization Environment(TOE), Technology Acceptance Model(TAM), 그리고 Unified Theory of Acceptance and Use of Technology(UTAUT) 등의 빅 데이터의 활용의 결정요인에 대한 이론적 논리를 확립하고 빅 데이터 활용에 대한 기존 선행 연구를 고찰하였다. 이를 통해 법 제도적 요인, 행태적 요인, 기술적 요인 등의 빅 데이터 인프라 요인과 데이터 구조 설계관리, 데이터베이스 관리, 데이터 활용관리 등의 데이터품질 요인을 중심으로 공공부문의 빅 데이터 활용의 결정요인에 관한 실증 연구모형과 연구가설을 수립하였다. 실증 연구 방법은 빅 데이터 관련 분야에 종사하고 있는 공무원 600명을 대상으로 설문 조사를 실시하여 최종 370부를 분석에 활용하였다. 이들 370개의 데이터를 통해 measurement model에 대한 적합도, 신뢰도 및 타당도를 검증하고, structural equation model을 활용하여 빅 데이터 활용의도에 관한 구조적 관계를 분석하였다. 실증분석 결과를 요약하면 다음과 같다. 첫째, 인프라 요인 중 행태적 요인이 높을수록 이용자의 지각된 유용성이 높아지게 된다. 둘째, 데이터 품질 요인 중 데이터구조 설계관리와 데이터베이스 관리가 잘 이루어질수록 이용자의 지각된 용이성이 높아진다. 특히 데이터베이스 관리가 지각된 용이성에 미치는 영향이 강하다. 셋째, TAM2 이론에 따라서 데이터 품질 요인에 의해 영향을 받은 이용자의 지각된 용이성은 지각된 유용성과 빅 데이터의 활용의도를 제고시켜 준다. 넷째, 인프라 요인 및 지각된 용이성에 의해 강화된 지각된 유용성은 빅 데이터의 활용의도에 긍정적으로 작용한다. 다섯째, 빅 데이터의 활용의도는 지각된 용이성 보다 지각된 유용성에 의해 상대적으로 더 강한 영향을 받는다. 공공부문의 빅 데이터의 활용의 결정요인에 관한 본 연구는 다음과 같은 이론적 시사점을 지닌다. 첫째, 혁신의 내적 속성을 강조하는 혁신 수용에 관한 TAM 이론과 혁신 확산을 중심으로 외적인 요인을 강조하는 TOE 이론을 통합하여 공공부문을 중심으로 빅 데이터 활용에 미치는 구조적 관계를 규명하였다는 점에서 이론적 의의를 지닌다. 둘째, 공공부문에서 빅 데이터 활용과 관련된 인프라 요인과 데이터 품질 요인에 대한 측정 항목을 개발하고 이에 대한 신뢰성과 타당성을 검증하였다는 점에서 향후 빅 데이터 연구를 위한 이론적 토대를 제공하고 있다. 본 연구는 실무적으로 다음과 같은 시사점을 제공한다. 첫째, 인프라 요인과 데이터 품질 요인을 중심으로 공공기관의 성공적인 빅 데이터 도입에 대한 가이드라인을 제시하고 있다. 둘째, 빅 데이터의 유용성을 제고하기 위해서는 빅 데이터에 대한 행태적 요인의 중요성에 대해서 실증적인 근거를 제공하고 있다. 셋째, 지각된 용이성을 통해 빅 데이터 활용을 제고하기 위해서는 빅 데이터의 데이터베이스 관리의 중요성을 실무적으로 규명하였다. 넷째, 공공부문의 빅 데이터 활용도를 높이기 위해서는 결국 TAM이론을 기반으로 이용자들이 빅 데이터 사용에 따른 유용성을 높이는 것이 가장 중요하다는 점을 시사한다. 따라서 공공부문에서 빅 데이터의 활성화를 위해서 조직 전반에 빅 데이터에 대한 이해도를 높이고 이에 대한 필요성을 인식시키는 행태적 전환을 위한 적극적인 홍보와 빅 데이터 구축부터 데이터베이스 관리에 대한 철저한 관리가 중요하다는 것을 본 연구의 결과에서 보여주고 있다. 마지막으로 본 연구는 다음과 같은 한계점을 지닌다. 첫째, 이론적인 측면에서 빅 데이터 활용에 대하여 인프라 요인과 데이터 품질 요인 이외의 다양한 요인들을 포괄하지 못한 한계가 있다. 둘째, 연구방법론 상에서 빅 데이터가 아직 초기 상태이기 때문에 관련 이용자의 한계와 전문적인 지식의 부족으로 인해 제한된 표본과 낮은 이해도에 의존함에 따라 연구 결과의 일반화에 한계가 존재한다.",
		"KEYWORD": "데이터 품질관리,빅 데이터"
	},
	{
		"ID": 420,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 경영전문대학원",
		"TITLE": "빅데이터와 데이터 매쉬업의 디자인에서의 활용 :Application of bigdata & data mash-up to design :도서관 디자인 사례 =a case of designing library ",
		"AUTHOR": "최형선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진화 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 421,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "빅데이터를 활용한 이차원 보증데이터 분석 연구 =(A)study on the analysis of warranty data under two dimensional policy using big data analytics ",
		"AUTHOR": "성기우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김종걸 참고문헌 : p. 75-79",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "본 연구는 자동차 보증데이터의 현황파악, 문제원인파악, 수명예측에 대한 분석방법을 제시하였다. 현황분석에는 자동차 보증데이터 특성에 맞게 수정된 주행거리를 이용한 생명표법, 랭크법 그리고 사용일과 주행거리를 동시에 고려한 새로운 분석방법(2-DDM,Two-Dimensional Distribution Method)을 개발하고 각 분석방법이 성능을 비교하여 다양한 조건에서 최적의 현황분석방법을 찾았다. 원인분석에는 다변량 모형 중 Tree와 Cox(Cox Proportional Hazard Model)모형을 적용 하였고 이 두 방법의 장점을 이용하여 최적의 결과를 도출하였다. 수명예측 방법은 AFT(accelerated failure time)모형을 통해서 생존 시간 자체에 대한 설명변수의 효과를 모형화 하고 필드 부품의 수명을 예측하였다. 또한 본 연구에서 제시한 최적화된 분석방법을 빅데이터 기술을 통해 구현하여 보증데이터를 효과적으로 처리하는 프로세스와 분석 방법을 제시하였다. 최적화된 분석방법을 찾기 위해서 인공(Artificial) 보증클레임 데이터를 사용하였고 다양한 조건에서 기존 방법 대비 새롭게 개발한 2-DDM(Two-Dimensional Distribution Method) 의 정확성을 확인하였다. 더 나아가 빅데이터 분석 시스템을 통한 보증데이터 분석의 효율성 보였고 차량개발에 활용 방법을 제시하였다. 향후 자동차 차량개발에 적용하여 내구 신뢰도 향상에 도움이 될 것으로 기대한다.",
		"KEYWORD": "Big Data,Cox Proportional Hazard Model,Two-Dimensional Distribution Method (2-DDM),Warranty Data"
	},
	{
		"ID": 422,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "토픽모델링과 인공신경망에 기반한 온라인 쇼핑몰 리뷰 데이터 분류 및 응용 =Classification and application of online review data based on topic modeling and neural networks ",
		"AUTHOR": "박상현",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김재경 참고문헌: p. 42-51",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "온라인 쇼핑몰은 매년 꾸준한 성장률을 보이고 있으며, 전체 쇼핑 시장 규모에서 차지하는 비중 또한 매년 증가하고 있다. 구매자들은 구매를 결정할 때, 쇼핑몰에 작성된 상품의 리뷰와 함께 평점을 중요한 구매 결정 척도로 사용한다. 리뷰와 함께 평점을 고려하는 구매자도 있으나, 평점만을 고려하여 전체 리뷰의 경향을 판단하여 구매를 결정하기도 한다. Ebay와 같은 온라인 몰에서는 상품의 첫 페이지에서 오직 평점만을 보여주기도 한다. 하지만, 모든 온라인 리뷰 작성자가 리뷰를 작성할 때 평점을 부여하지 않는다, 이러한 상황에서 평점이 존재하지 않는 리뷰를 읽어 직접 평점을 부여하기에는 시간적 ? 인적 자원의 한계가 명확하다. 본 연구에서는 Amazon.com에서 1996년 5월부터 2014년 7월까지 수집된 온라인 리뷰의 데이터를 사용하였다. 총 24개의 카테고리에서 스포츠 & 아웃도어 용품과 건강 & 개인 용품 등 5개의 카테고리를 선정하였다. 리뷰의 개수는 각 카테고리당 2500개를 사용하였고 각 점수당 500개씩 무작위 샘플링되었다. 본 연구는 평점을 입력하지 않은 리뷰의 평점을 예측하는 모델이다. 먼저, 여러 가지 토픽모델링 중에서 리뷰의 잠재적인 토픽들을 추출하여 토픽들이 리뷰를 설명하는 확률값을 계산하는 LDA 알고리즘을 적용하였다. 그 후, 인공신경망에 토픽의 벡터값과 평점을 입력하여 학습시켰다. 마지막으로 모델의 성능을 측정하기 위하여 평점을 제거한 리뷰의 토픽 벡터들을 모델에 입력하여 평점을 예측하였고, 실제 평점과 비교하였다. 본 연구의 결과로 모든 카테고리에서 각 점수를 분별하는 정확도는 평균 30%를 나타냈다. 1점과 2점을 부정적인 리뷰로 분류하고 4점과 5점을 긍정적인 리뷰로 분류한 후, 부정적인 리뷰와 긍정적인 리뷰를 판단하는 결과는 평균 55%를 나타냈다. 본 연구는 수많은 리뷰들을 바탕으로 평점이 존재하지 않는 리뷰에 평점을 부여할 수 있는 새로운 접근법을 선보였다는데 의의가 있다. 또한, 본 연구의 결과를 통하여 리뷰 작성자로부터 평점을 부여받지 않은 수많은 리뷰들에 대한 평점을 예측하여 상품의 전체 평점을 형성하는데 도움을 주고 이는 구매자들에게 구매에 영향을 줄 것으로 보인다.",
		"KEYWORD": "온라인 리뷰,인공신경망,토픽모델링,평점"
	},
	{
		"ID": 423,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한국해양대학교 대학원",
		"TITLE": "빅 데이터의 차원축소 기법인 Relief 알고리즘의 민감도 분석 =(A)sensitivity analysis of relief algorithm for reducing the dimensionality of big data ",
		"AUTHOR": "금호연",
		"REGION": "부산",
		"PROFESSOR": "한국해양대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김재환",
		"STORE_LOCATION": "한국해양대학교 도서관",
		"ABSTRACT": "Most of the real-world data mining applications are characterized by high dimensional data, where not all of the features are important. High dimensional data can contain a lot of irrelevant and noisy information that may greatly degrade the performance of a data mining process. Feature selection methods are the techniques that select a subset of relevant feature for building robust learning models by removing most irrelevant and redundant features from the data. Many feature selection methods have been developed to reduce the dimensionality of big data. Among them, the Relief algorithm is general and successful attribute estimator. The main idea of Relief algorithm is to compute ranking scores for every feature indicating how well this feature separates neighboring samples. In this study, we do perform the sensitivity analysis to find the optimal number of features and also suggest the two-stage method to design the optimal feature subset.",
		"KEYWORD": null
	},
	{
		"ID": 424,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "교통 빅데이터를 이용한 청주시 교통혼잡지도 구현 =(An)implementation of traffic congestion map using traffic big data ",
		"AUTHOR": "송성호",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 425,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "수원대학교 대학원",
		"TITLE": "빅 데이터 정보 처리를 위한 최적화된 뉴로-퍼지 알고리즘 기반 패턴분류기에 대한 연구 :(A)study on pattern classifier based on optimized neuro-fuzzy algorithm for big data information processing :기상레이더 영상 처리를 중심으로 =focused on meteorological radar image processing ",
		"AUTHOR": "고준현",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 오성권",
		"STORE_LOCATION": "수원대학교 도서관",
		"ABSTRACT": "본 연구에서는 기상레이더 빅 데이터를 사용함으로써 뉴로-퍼지 알고리즘, PSO, 및 퍼지 클러스터링 알고리즘과 같은 컴퓨터를 사용한 지능형 기술의 합성으로 강수와 비강수 패턴 분류의 설계 방법론을 제안한다. 강수와 비강수를 효과적으로 분류하기 위하여, 데이터 특징의 관점에서 기상레이더 빅 데이터 정보의 구조를 분석한다. 또한 기상레이더 빅 데이터에 대한 데이터 정보의 질적 뿐만 아니라 양적인 특성을 이용함으로써 패턴 분류기를 설계하기 위한 다양한 입력변수들을 고려하고 각 입력변수들의 특성을 분석한다. 선호되는 패턴 분류기는 모델 구조뿐만 아니라 출력 성능에 결정적인 영향을 미치는 필수적인 입력변수들로 설계된다. 빅 데이터인 기상레이더 데이터를 학습하기 위하여 새롭게 제안된 Recursive polynomial Radial Basis Function Neural Networks(RpRBFNN)을 설계한다. RpRBFNN의 조건부에서는 Fuzzy C-Means(FCM) 클러스터링을 사용하여 입력 데이터 정보의 특성을 고려한 적합도를 구하며, 결론부에서의 연결가중치는 상수, 선형, 변형된 2차함수와 같은 세 가지 형태를 사용함으로써 고려된다. 빅 데이터의 학습을 수행하기 위하여 RLSE를 사용함으로써 다항식 함수의 계수를 추정한다. 추론부에서는 퍼지 추론 방법으로 최종출력을 계산한다. RpRBFNN에서 퍼지화 계수, 퍼지 룰 수, 입력 수, 다항식 형태와 같은 파라미터들은 입자군집 최적화(PSO)를 사용하여 최적화 된다. 사례 분류기와 에코 분류기는 RpRBFNN을 이용하여 설계되며, 전체 시스템 구조에서 두 개의 분류기가 연속적으로 동작된다. 사례 분류기는 강수와 비강수 사이의 사례를 확인하기위해 사용된다. 사례 분류기로 분류된 강수 데이터 정보는 부분적으로 비강수 데이터 정보를 포함하기 때문에 에코 분류기로 강수 에코와 비강수 에코를 분류한다. 분류기 성능의 우수성을 입증하기 위하여, 제안된 분류기는 기존 QC 방법과 비교하여 평가되고 분석된다.",
		"KEYWORD": null
	},
	{
		"ID": 426,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "빅데이터를 활용한 은행권 고객 세분화 기법 연구 ",
		"AUTHOR": "장민석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 21-22",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "대부분의 은행은 고객 세분화를 위해 성별, 나이, 직업, 주소 등 인구통계정보만을 사용하고 있으나, 이는 고객의 다양한 금융행동 패턴을 반영하지 못하는 단점이 있다. 본 연구에서는 은행 내 다양한 빅데이터를 활용하여 문제점을 해결함과 동시에 향후 많은 은행에서 폭넓게 활용될 수 있는 고객 세분화 방법을 개발하는 것을 목표로 한다. 본 연구에서 제안한 블록을 만들어 이 블록을 클러스터링하는 상향식 방식의 세분화는 기법을 제안한다. 이 방식은 기존의 인구통계정보 뿐만 아니라 다양한 거래패턴, 채널접촉패턴에 기반을 둔 고객의 다양한 금융니즈를 정교하게 반영할 수 있다는 장점이 있다. 세분화를 통해 고객의 금융니즈를 보다 정교하게 반영한 적정 동료그룹을 찾아 이를 기반으로 상품추천, 금융니즈 등급 산출, 고객이탈 예측 등 다양한 마케팅 모델을 개발하여 실제 농협은행 마케팅에 활용할 것이다.",
		"KEYWORD": "고객세분화,빅데이터,클러스터링"
	},
	{
		"ID": 427,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "상담 STT(Speech to Text) 키워드를 활용한 민원 예측 모델 설계 및 검증 :콜센터 상담 VoC(Voice of Customer) 데이터 분석을 중심으로 ",
		"AUTHOR": "이준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "civil prediction model,consultation STT data,financial supervisory service,integrated model,machine learning,금융감독원,머신러닝,민원 예측 모형,상담 STT 데이터,통합 모델"
	},
	{
		"ID": 428,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "데이터 재사용을 고려한 효율적인 그래프 스트림 처리 기법 =Efficient graph stream processing scheme considering data reuse ",
		"AUTHOR": "조중권",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 유재수",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "최근 소셜 미디어, IoT 등에 대한 활용이 증가됨에 따라 대용량의 그래프 스트림이 생성되고 있으며 그래프 스트림을 실시간으로 처리하기 위한 많은 연구들이 진행되고 있다. 본 논문에서는 스트림 환경에서 데이터 재사용을 고려한 효율적인 그래프 스트림 처리 기법을 제안한다. 제안하는 기법은 점진적 처리를 통해 변경된 영역만을 처리하여 연산량을 감소시키며 이전 결과 데이터를 재사용하여 계산되는 정점의 탐색 비용 및 디스크 I/O 비용을 감소시킨다. 점진적 처리 시 그래프 많은 변경으로 인해 탐색 비용 및 처리 비용이 증가할 수 있기 때문에 점진적 처리와 정적인 처리를 선택적으로 수행하기 위한 비용 모델을 제안한다. 제안하는 비용 모델은 실제 처리된 이력을 바탕으로 재계산 영역의 탐색 비용 및 처리 비용의 예측 값을 계산하여 점진적 처리가 정적인 처리보다 이득인 경우 점진적 처리를 수행한다. 제안하는 기법의 처리 구조는 캐시를 사용하여 읽어온 데이터와 인접 정점의 데이터를 저장하였다가 처리 시 메모리 매핑만을 수행하여 처리의 효율성을 높인다. 다양한 성능 평가를 통해 제안하는 기법이 기존 기법에 비해 성능이 우수함을 보인다.",
		"KEYWORD": "Cost Model,Data Reuse,Graph Processing,Incremental Processing,Stream Processing"
	},
	{
		"ID": 429,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "소셜 빅데이터를 이용한 전자파 인체 영향 인식도 조사 및 분석 =Analysis on perception level of the influence of electromagnetic wave to human body using social big data ",
		"AUTHOR": "박미진",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:나종화 참고문헌 : p.41-43",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Although the controversy over the effects of electromagnetic waves on the human body has been continuing up to now, there is a limit to the existing awareness of electromagnetic waves based on direct stakeholders. Therefore, in order to overcome the limitation of the traditional survey which are based on questionnaire, it is necessary to investigate SNS and social media especially for the general public as the indirect survey method. ?? The electromagnetic wave that the public thinks is RF electromagnetic wave, and it refers to the electromagnetic wave which comes out from household electric appliances used in daily life. In this study, using social big data such as news, blog, and twitter on RF electromagnetic waves, limitations on the population based on the existing general questionnaire and limitations due to the survey time point can be improved. Through the various analysis of social big data, we understand the perception of the influence of electromagnetic waves on the human body on SNS, and provide basic data on the countermeasures for public awareness and related policies. The data used in the analysis are social big data(news, blog, twitter) for the last three years(2014 ~ 2016). The keywords used for data collection are rf, base station, Bluetooth, THAAD, WiFi, and mobile phone. In other words, the texts in which the electromagnetic waves and the keywords are mentioned together are extracted as data. The extracted data were analyzed after cleaning and R was used as an analysis tool. Key analyses performed in this paper include word cloud, association rule, social network analysis, and positive/negative analysis.",
		"KEYWORD": null
	},
	{
		"ID": 430,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "수치속성 빅데이터에 대한 맵리듀스를 이용한 그리드 기반 k-근접 이웃 분류 =Grid-based k-nearest neighbor classification for numeric big data on the MapReduce paradigm ",
		"AUTHOR": "김영준",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:이건명 참고문헌 : p.54-57",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "The technological development and widespread information infrastructure have made vast volume of data accumulated and have open up new era of big data. Big data denotes a collection of data whose size is beyond the capability of commonly-used software tools to capture, store, curate, search, share, and analyze within a tolerable time. Almost every sector of business, science, engineering, government and so on seems to have interest in taking advantage of their big data. The issues in big data processing are involved in data volume, varieties in data types and tasks to take care of, and velocity to process data. This thesis is concerned with the classification problem for big numeric data. We have observed that the k-nearest neighbor classifier is very simple and intuitive, yet not amenable to big data classification because of cost for finding neighbors. Parametric models such as mixture of Gaussians can compactly express a collection of data. In addition, MapReduce is an excellent paradigm to big data handling. From these observations, we come up with a big data classification method in which it is assumed that the data are generated from a mixture of Gaussians on a multi-dimensional numerical space, under the assumption, it expresses the whole data set with a collection of Gaussian distributions in a compact manner, classifies data in a k-nearest neighbor fashion where neighbors are expressed in Gaussian components, partitions the entire data space in a grid structure for efficient training and inference, and employs the MapReduce paradigm to handle big data. The proposed algorithm has been implemented and tested on the Hadoop framework. The experiments have shown that the proposed algorithm could produce meaningful results for the intented problem domains.",
		"KEYWORD": null
	},
	{
		"ID": 431,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "기계학습을 활용한 데이터 기반 경찰신고건수 예측 =The data-based prediction of police calls using machine learning ",
		"AUTHOR": "최재훈",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.46-49",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "본 연구는 기계학습의 하나인 신경망 분석과 음이항 회귀분석을 활용하여 경찰신고건수를 예측하고자 2016년 6월부터 2017년 5월까지 충남지방경찰청에 접수된 112신고 데이터를 이용하여 예측모델을 개발하였다. 모델을 개발하기 위해 경찰신고건수에 영향을 줄 수 있는 시간, 휴일, 휴일 전날, 계절, 기온, 강수량, 풍속, 관할면적, 인구, 외국인 수, 단독주택비율, 기타주택비율 변수 등을 활용하였다. 변수의 종류에 따라 몇몇은 경찰신고건수와 양의 상관관계 또는 음의 상관관계가 확인되었다. 사용된 두 개의 방법론을 비교한바, 신경망분석의 예측 결과는 예측 값과 실제 값의 상관계수 0.7702, RMSE 2.557이고, 음이항 회귀분석은 상관계수 0.7158, RMSE 2.831으로 나타났다. 신경망분석은 해석가능성은 낮지만, 음이항 회귀분석에 비해 예측력이 뛰어나다는 것이 확인되었다. 향후 경찰관서에서 본 연구의 예측모델을 기초로 하여 최적의 경찰력 배치를 할 수 있을 것으로 기대된다.",
		"KEYWORD": "112신고,경찰신고,기계학습,신경망분석,신고예측,음이항 회귀분석"
	},
	{
		"ID": 432,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "센서 네트워크에서의 데이터 신뢰성 향상을 위한 협업적 보정 방법 =Collaborative calibration method for improving data reliability in sensor networks ",
		"AUTHOR": "채영훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정한민",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "4차 산업혁명의 시작으로 사람과 사물, 사물과 사물이 인터넷 통신망으로 연결되어 생활의 편의를 증진하기 위한 기술의 필요성이 증가하고 있다. 이와 같은 요구사항을 충족하기 위해서는 효율적인 센서 네트워크 구축과 지역 커버리지가 넓고 정확한 데이터를 수집하는 기술이 필요하다. 센서 네트워크에서 정확도를 확보하기 위한 기초적인 연구로 센서 자체의 특징 및 문제점을 파악하고, 보정하는 연구가 필요하다. 본 연구에서는 센서 데이터의 특징을 분석하고 고정 주기 보정, 동적 주기 보정, 드리프트 보정의 방법을 통해 보정하여 정확도를 비교하였고 방법론을 조합하여 정확도를 향상시켰다. 센서 데이터의 특징을 분석하기 위해 실내에서 데이터 수집하였고, 정확도에 대한 비교 실험을 수행하기 위해 기상청의 자동기상관측장비 근처에서 데이터를 수집하여 기상청 데이터와 정확도를 비교하였다. 센서 데이터의 특징을 반영을 통해 주기를 고정적으로 설정하여 보정하는 방법에 대비하여 효과적으로 센서를 보정할 수 있는 방안을 도출 하였다. 실험 결과를 바탕으로 향후 진행될 미세먼지 센서 데이터의 보정 및 이동형 센서 네트워크에서의 보정 전파 연구에서 적절한 시간 주기 설정, 센서의 특성 등을 가이드라인으로 활용할 수 있다.",
		"KEYWORD": "BigData,Calibration,IoT,Sensor Network"
	},
	{
		"ID": 433,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "국민대학교 대학원",
		"TITLE": "커널 밀도 추정치를 이용한 모형 기반 군집분석의 초기화 방법 :Initialization method of model-based clustering using kernel density estimation : using big data of corporate default ",
		"AUTHOR": "조현주",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 정여진 참고문헌 : p. 46-51",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "Expectation-Maximization 알고리즘은 가우시안 혼합 모형(gaussian mixture models)과 같이 숨겨진 구조의 모델의 파라미터를 추정하는데 널리 쓰인다. 하지만 EM 알고리즘은 초기 값(initial value)에 따라 극댓값(local maximum)으로 수렴할 가능성이 있고 알고리즘 수렴 속도의 시간이 오래 걸릴 수 있는 결점을 가지고 있다. 본 연구에서는 이러한 EM 알고리즘의 결점을 해결하고자 Modal-EM 알고리즘으로 커널 밀도 추정치(kernel density estimation)의 local mode를 찾고 커널 밀도 추정치의 local mode를 갖는 모수를 초기 값으로 지정하여 최대우도추정량(maximum likelihood estimation)을 추정하고자 한다. 또한 모의실험을 통해 기존 연구의 무작위 초기화(random initialization) 방법인 10EM, 10CEM-EM, 10em-EM, SEMmax-EM 방법과 비교하여 본 연구에서 제안하는 초기 값 선택 방법이 우도 함수(likelihood function)의 최댓값(global maximum)을 찾는데 더 좋은 성능을 가지는 것을 확인하고 실제 기업 부도 데이터에 적용하여 기존 방법론과 커널 기반 초기 값 선택 방법을 비교하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 434,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "교통 빅데이터의 실시간 분석 및 예측 서비스 프레임워크 =(A)real-time analysis and prediction service framework for road traffic big data ",
		"AUTHOR": "정덕원",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 민덕기",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "최근 빅데이터는 민간 및 공공부문의 새로운 가치를 창출하는 미래 국가경쟁력의 핵심으로 대두되며 창의적인 빅데이터의 활용으로 생산성 향상, 기업 경쟁력 제고, 국가 미래전략 지원 및 공공 서비스의 혁신을 도모하고 있다. 이처럼 주목받는 가장 주된 요인은 기존과 차별화된 대용량 데이터의 새로운 분석과 추론을 통하여 새로운 서비스를 개발할 수 있는 가능성이 무궁무진하기 때문이다. 대용량 데이터를 기반으로 각 분야의 새로운 트렌드를 분석하여 전망할 수 있으며, 자연언어 처리, 기계 학습, 인공지능 기술로 맥락 이해와 추론 서비스가 증가되고 있다. 그리고 이러한 추론의 영역은 교통, 금융, 의료 등의 공공분야를 혁신하는 신산업 분야를 개발하고, 맞춤형 개인화 서비스를 가능하게 한다. 이러한 빅데이터 처리 및 분석 기술로는 대용량의 비정형화된 데이터를 저장하는 HDFS(Hadoop Distributed File System)와 데이터 처리를 위한 MapRedce로 구성된 Hadoop이 대표적인 공개 소프트웨어로 빅데이터를 활용하는 전 세계 모든 기업에서 사용 중이다. 또한 HDFS기반 Nosql DB인 HBase를 사용하여 실시간으로 쏟아져 나오는 데이터를 확장하여 저장하거나 갱신할 수도 있다. 본 논문에서는 이러한 빅데이터 관련 기술을 교통 분야 예방에 활용하여 최적의 서비스를 할 수 있는 프레임워크를 제시한다. 교통 사고율을 기반으로 처리 및 분석 예방하는 서비스를 제공하기 위하여 샘플데이터로 미국 캘리포니아주의 고속도로 교통 데이터와 사고데이터를 사용 하였으며, 실시간 교통 사고율 서비스를 위한 슬라이딩 타임 윈도우 모델을 제시하였다. 또한, 기존의 저장되어 있는 교통정보 데이터나 사고 데이터를 사용하는 방식뿐만 아니라 실시간으로 GPS 정보나 날씨등의 교통관련 데이터가 들어왔을 때 이를 처리할 수 있는 실시간 이벤트 기반의 처리 구조와 비실시간 처리 구조를 기반으로 슬라이딩 타임 윈도우 모델을 처리할 수 있는 프레임워크를 제시하였다. 실시간 처리를 위한 CEP를 OSGi프레임워크 기반의 사용자 정의 구조의 미들웨어 타입으로 설계하고 구현함으로써 모든 서비스를 OSGi의 번들로서 동적으로 배치 및 수정, 삭제가 용이한 유연한 구조로 개발하였으며 비실시간 처리에서는 Hadoop의 MapReduce의 불필요한 전처리 과정을 줄여 성능향상을 하고자 HBase의 Block Cache 데이터를 수집하여 Job Tracker내의 Traffic MR Job Manager를 통하여 보다 빠른 처리를 할 수 있게 하였으며 같은 구간의 서로 다른 경로를 동시에 처리하는 경우를 생각하여 JobSet의 개념을 정의하여 처리하였다. 그리고 단순히 처리 및 저장하는 방법뿐만 아니라 교통 사고 원인의 상관 관계 분석을 하고 결과를 도출하기 위하여 기존 교통 사고율 분석의 방법과 본 논문에서 제시하는 인공 신경망(Artificial Neural Network)을 통하여 분석결과를 제공하는 방법을 비교하여 효율성을 강조한다. 이러한 분석을 위하여 사고 데이터를 수집하여 분석을 위한 데이터 셋을 만드는 전처리 과정을 거쳐야 하는데, 이때 측정하고자 하는 특정 구간의 교통정보데이터 및 사고 데이터의 양이 1년, 5년,10년 이상씩 늘어날 경우에 엄청나게 방대해져 컴퓨터 1대로 처리 할 경우에 하루 이상의 시간을 소요할 수도 있다. 이에 본 논문에서는 빠른 시간에 데이터를 처리하여 서비스 할 수 있도록 하둡의 HDFS와 맵리듀스를 사용하여 성능을 향상하였으며, 실시간으로 수집되는 교통 정보 및 사고 데이터를 반영하여 결과를 도출할 수 있도록 하였다.",
		"KEYWORD": "교통사고율,뉴럴네트워크,빅데이터,실시간처리,하둡"
	},
	{
		"ID": 435,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "의료 빅데이터를 활용한 연구지원시스템 모델 개발 =Development of research support system model for clinical big-data ",
		"AUTHOR": "장광수",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 이욱 권두 국문요지, 권말 Astract 수록 참고문헌 : p. 33-35",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "",
		"KEYWORD": "컴퓨터프로그램"
	},
	{
		"ID": 436,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "비정형 데이터를 활용한 Machine Learning기반의 금융소비자 유형화 및 금융상품 추천 방법 =Methods of financial consumer classification and financial instrument recommendation based on machine learning using unstructured dat ",
		"AUTHOR": "이재웅",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 권오병 참고문헌: p. 44-55",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "정보기술의 혁신과 함께 접근성과 편의성이 높은 비대면 채널의 로보어드바이저가 확산되고 있다. 현재의 로보어드바이저는 개인이 입력한 투자 성향을 정보를 토대로 투자상품을 추천하기 때문에 소비자가 질문을 잘못 이해하거나 투자상품의 조건 등을 제대로 이해하지 못한 경우에는 잘못된 추천을 하게 된다. 그러나 금융소비자가 자신의 주관적인 투자성향을 포함하는 금융정보를 직접 입력하게 하게 한다면 좀 더 정확한 투자상품 추천이 가능할 것이다. 따라서 본 연구에서는 고객이 온라인 상에 노출한 비정형자료에서 추출한 단어 특징을 통해서 투자성향을 파악한다. 문서를 기반으로 한 예측기법은 각 분야별 텍스트의 성격이 많은 차이를 보이고 있다. 이에 따라 예측 성능이 달라지기 때문에 다양한 학습판별 알고리즘의 예측 성능평가를 수행함으로써, 금융소비자 성향 평가에 최적의 판별 규칙을 가진 알고리즘을 선정하였다. 본 연구에서는 개인화된 추천 시스템과 같이 잠재적 혹은 불특정투자자가 공유한 온라인 상의 비정형 텍스트를 분석하여 자동적으로 그에 맞는 투자상품을 추천하여 주는 지능적 방법을 제안한다.",
		"KEYWORD": "Fintech,Robo-Advisor,Text Mining"
	},
	{
		"ID": 437,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 국악교육대학원",
		"TITLE": "빅데이터를 활용한 국가무형문화재 예능분야 동향 분석 ",
		"AUTHOR": "박기묘",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최상화 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 연구는 국가무형문화재 예능분야 실시간 키워드 검색데이터를 분석하여, 전통예술의 향후 방향성 예측이 가능할 것이라는 가설을 세우고 시도하였다. 2016년 현재 예능분야 국가무형문화재 69종을 15개 상위 키워드로 묶어 2013년 기준 국내 포털사이트 검색 점유율 79.83%를 차지하고 있는 네이버 데이터랩을 통해서 2007년부터 2016년 10월까지 검색된 관심도를 관찰하고 분석한 것이다. 국가무형문화재 예능분야 15종류를 상위키워드로 설정하고, 하위키워드는 국가무형문화재 예능분야 종목명으로 설정하여 15종류의 국가무형유산의 관심도를 파악할 수 있었으며, 상위키워드와 하위키워드가 동일한 항목을 제외하고, 나머지 국가무형유산의 상위키워드에 속하는 각 하위키워드가 전체에 얼마만큼의 영향을 미치는지 또한 파악할 수 있었다. 네이버 트렌드는 불특정 다수의 키워드 검색 값을 다년간 계량화하여 지표로 나타낸 것이며, 검색 값의 기준은 설정기간의 최대 검색량을 100으로 하여 상대 값을 나타낸 것이기에, 실제 키워드 검색량에 대한 절대값, 검색 횟수 등은 네이버 트렌드 서비스에서 제공하지 않는다. 따라서 데이터를 수치화하기 어렵기 때문에 전체적인 동향을 살피기엔 문제가 없으나, 보다 깊이 있는 분석을 하지 못한 것이 본 연구의 제한점이다.",
		"KEYWORD": null
	},
	{
		"ID": 438,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경상대학교 대학원",
		"TITLE": "클라우드 컴퓨팅 기반의 빅 데이터 보안 모델 설계 =Security model design for big data based on cloud computing ",
		"AUTHOR": "목연정",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 439,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "빅 데이터 분석을 통한 지역관광 활성화 방안 :전라북도를 중심으로 ",
		"AUTHOR": "박로운",
		"REGION": "전라북도",
		"PROFESSOR": "지도교수: 이기훈 참고문헌: p. 59-62",
		"STORE_LOCATION": "전주대학교 도서관",
		"ABSTRACT": "This study investigated main factors for activating local tourism of Jeollabuk-do with big data analysis. We gathered tourism big data from public open data sources and social network services(SNS) and used the analysis tools,‘Opinion Mining’,‘Text Mining’and ‘Social Network Analysis(SNA)’. The opinion mining and text mining analysis identified the key local contents of the 14 areas of Jeollabuk-do and the evaluations of customers on local tourism. The social network analysis detected the relations between their contents and figured the importance of contents. The results of this research showed that each locations in Jeollabuk-do had their specific contents attracting visitors and the number of the contents affected the scale of tourists. Also, when their tourism contents were highly correlated with the another contents, a number of visitors might be large. Hence strong connections among their contents are the point to activate local tourism. The social network analysis divided the contents into several clusters and derived the eigenvector centralities of the content nodes implying the role importance of them in the network. We found out that the tourism were active when the nodes at high value of the eigenvector centrality were evenly distributed in every clusters, however the results were contrary when the nodes were located in a few clusters. This study suggested an action plan to extend local tourism that develop valuable contents and connect the content clusters properly. Key Word: local tourism, big data, a plan for activation",
		"KEYWORD": "관광학"
	},
	{
		"ID": 440,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "수원대학교 대학원",
		"TITLE": "빅 데이터 처리를 위한 클라우드 컴퓨팅 기반 자원 할당 기법 ",
		"AUTHOR": "최영호",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 임유진",
		"STORE_LOCATION": "수원대학교 도서관",
		"ABSTRACT": "Cloud service is one of major challenges in IT industries. Cloud service has three steps. Firstly, VM provisioning is that service providers prepare physical resources to VM instances for requested resources by users in advance. Secondly, resource allocation is that service providers allocate VM instances to users. Lastly, service providers process requested jobs by users. In VM provisioning, service providers predict dynamic user demands and provision resources to guarantee the QoS to cloud users. The conventional prediction models guarantee the QoS to cloud user, but don’t guarantee profit of service providers. In this paper, we propose new VM provisioning techniques in fixed-price and auction model to provide the QoS to cloud user and guarantee profit of service providers. Therefor, we consider the cases of VM provisioning and SLA violation. To evaluate the performance of our techniques, we compare the total expense and profit of service providers with conventional techniques with real workload data.",
		"KEYWORD": null
	},
	{
		"ID": 441,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "수원대학교 대학원",
		"TITLE": "빅 데이터 처리를 위한 증분형 퍼지 클러스터링 기반 RBF 신경회로망에 관한 연구 =(A)study on incremental fuzzy clustering-based RBF neural networks for big data processing ",
		"AUTHOR": "이승철",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 오성권",
		"STORE_LOCATION": "수원대학교 도서관",
		"ABSTRACT": "In this thesis, radial basis function neural networks based on incremental fuzzy clustering are designed for big data processing. Radial basis function neural networks consist of condition, conclusion and inference phase. Gaussian function is generally used as the activation function of the condition phase, but in this study, incremental fuzzy clustering is considered as the activation function of radial basis function neural networks, which could effectively do big data processing. There are two incremental clustering techniques such as single data incremental type and group data incremental type. These techniques depend on the processing method of data. In the conclusion phase, the connection weights of networks are given as the coefficients of linear polynomial function which is the extended type of constant term. And then the connection weights are calculated by the least square estimation-based learning. There are two estimation methods such as recursive least square estimation and block least square estimation, which could effectively do big data processing. The recursive least square estimation and the block least square estimation depend on the processing method of data like as the incremental fuzzy clustering techniques indicated previously. In the inference phase, a final output is obtained by fuzzy inference method. Some machine learning datasets are considered to evaluate the performance of the proposed model as well as pattern classifier, and the experiments are carried out for two methods such as modeling and pattern classification. Root mean square error and pattern classification rate are used as the performance index of modeling as well as pattern classification. From the experiments results, the proposed model and pattern classifier are compared with other previous studies and also analyzed.",
		"KEYWORD": "Incremental Fuzzy Clustering,Modeling,Pattern Classification,Radial Basis Function Neural Networks"
	},
	{
		"ID": 442,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "대전대학교 대학원",
		"TITLE": "빅 데이터 분석 아키텍처를 사용한 DDoS 공격 탐지 ",
		"AUTHOR": "안광민",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 이봉환",
		"STORE_LOCATION": "대전대학교 도서관",
		"ABSTRACT": "In this dissertation, a hybrid machine learning algorithm which combines unsupervised K-Means and supervised Decision Tree machine learning algorithm is proposed in order to detect a high volume distributed denial of service (DDoS) attack. The proposed algorithm can be used to detect unknown attack pattern. In particular, the proposed machine learning algorithm mainly focus on the application level DDoS attack which is very weak in the current DDoS attack protection system. The KDD99 dataset from MIT Lincoln Lab is utilized to evaluate the performance of the proposed machine learning algorithm and compared the performance of the proposed algorithm with the previous research results. In particular, a SPARK-based Bigdata platform is used to collect, analyze, and process a high volume of dataset in a very fast fashion. Application of the algorithm to the IDS system will be very effective to protect an unexpected attack and provide an automated intrusion detection method for various new types of attacks. For the further study, since the adapted experimental dataset, KDD99 CUP dataset, is a little bit different from the current network application traffic, further experiments using the actual network traffic are need.",
		"KEYWORD": null
	},
	{
		"ID": 443,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "극동대학교 대학원",
		"TITLE": "에너지 사용량 빅 데이터 수집/분석에 따른 에너지 절감 방안 연구 =Study for saving energy by big data analysis and collection technique ",
		"AUTHOR": "김형주",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 444,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "보건복지 분야의 빅 데이터 활용 연구 ",
		"AUTHOR": "김지애",
		"REGION": "전라북도",
		"PROFESSOR": "지도교수: 이기훈 참고문헌: p.61-62",
		"STORE_LOCATION": "전주대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": "건강증진"
	},
	{
		"ID": 445,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "Dynamic resource allocation for throughput maximization in 5G HetNet architecture =5G 환경에서의 데이터 전송률의 최대화를 위한 동적 리소스 할당 기법 ",
		"AUTHOR": "장선민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조성래 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "In order to accommodate the rapidly increasing LTE data traffic, 3GPP has standardized LTE heterogeneous networks and carrier aggregation. Since standardization, many studies have continued to improve the performance of the two technologies and to solve the existing problems, which have resulted in the update of the LTE standard. In addition, ongoing research has suggested that derivative technologies such as eICIC (enhenced Intercell Interference Coordination), LAA (Licensed-Assisted Access using LTE) and LWA (LTE Wifi Link Aggre-gation). This derived technology has greatly improved the performance of existing LTE heterogeneous networks. However, it is predicted that these techniques alone will not efficiently control interference among small cells in a 5G ultra-dense small cell network. In addition, there are numerous papers on coordination of existing LTE heterogeneous networks, but most papers deal only with the interference problem between a macro cell and small cells and do not consider interference among small cells. In this thesis, we propose a centralized interference coordination method, which is called as queueing based resource allocation(QBRA), based on the status of pico BSs’ queues to target 5G ultra-dense small cell networks. In order to apply this method to various network topologies, we classified possible topology through analysis of existing LTE heterogeneous network. Then, the algorithm was applied to the classified topology, and the result of the simulation shows that the throughput of macro BS and pico BSs are improved with QBRA.",
		"KEYWORD": null
	},
	{
		"ID": 446,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "한신대학교 대학원",
		"TITLE": "빅 데이터 환경에서 프로세스 마이닝을 이용한 내부 감사 실시간 모니터링에 대한 연구 =A study on real-time monitoring of internal audit using process mining under the big data environment ",
		"AUTHOR": "유영석",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 홍성찬 참고문헌: p. 95-97",
		"STORE_LOCATION": "한신대학교 장공도서관,한신대학교 중앙도서관",
		"ABSTRACT": "최근 대내외적으로 많은 사건들이 발생하고 있고 특히 기업, 공공기관을 둘러싼 경영환경이 빠르게 변화됨에도 불구하고 선제적인 대응부족으로 다양한 리스크들이 발생하였거나 잠복상태에 있다. 이에 정형화된 데이터 뿐만 아니라 스마트폰, 소셜 미디어 등의 비정형 빅 데이터를 수집, 가공, 분석하여 숨겨져 있는 이상 징후들을 실시간 모니터링 하여 리스크 요인들을 제거함으로써 기업경영의 투명성을 높이고 가치를 창출하고자 하는 니즈가 증가하고 있다. 이러한 빅 데이터 시대가 도래함에 따라 데이터 분석의 중요성에 대한 인식이 증가하고 있으며 데이터를 기반으로 한 프로세스의 과학적이고 체계적인 분석에 대한 수요도 증가하고 있다. 최근 프로세스의 과학적이면서 체계적인 분석에 대한 수요를 바탕으로 프로세스 마이닝 연구의 중요성도 증가하고 있으며, 많은 곳에서 프로세스 마이닝에 대한 다양한 방법들이 적극적으로 활용되어 비즈니스 프로세스(Business Process)를 혁신해 나가고 있다. 이에 프로세스 마이닝의 강점을 최대한 활용함으로써, 기업 조직의 감사 업무에 적극적으로 활용하기 위한 다양한 연구 활동이 활발히 진행중에 있다. 한편, 기업 조직의 중요한 경영 활동인 영업, 구매, 생산 부문 등 내부 감사 시 빅 데이터 환경하에서 생성된 방대한 데이터를 프로세스 마이닝을 이용하여 체계적이고 효율적으로 분석하고 감사 측면에서 위험 관리 사전 모니터링하는 관련 연구는 미흡한 실정이다. 본 연구에서는 기업의 구매 부문에서 발생되는 대량의 데이터들을 단순하게 사후에 모니터링 하는 수준에서 벗어나 거래의 이상 징후들을 사전에 탐지하고 사고를 미리 방지하기 위하여 개발되어진 하둡 기반의 내부 감사 통합 실시간 모니터링 시스템을 구현하고자 한다. 이 결과로, 프로세스 마이닝을 이용하여 데이터를 효율적으로 분석하고 하둡 기반의 시스템을 구축함으로써 보다 강화된 구매 감사 통합 실시간 모니터링을 할 수 있게 되었고 즉각적으로 실행할 수 있는 정보 제공이 가능하게 되었다. 또한, 통합적인 관점에서 효율적이면서 입체적으로 구매 업무 진행관리를 할 수 있게 되었고, 상시 모니터링 보다 대량의 작업을 빠른 속도로 처리하게 됨으로써 구매 감사 품질개선, 구매 프로세스 혁신 및 경영의 투명성 제고 등의 효과가 나타났다. 이러한 구매 감사 통합 실시간 모니터링 시스템을 통해 공급 업체에 발주한 구매 자재의 납기 관리 강화, 구매 원가 절감, 경쟁력 있는 업체 관리, 사기발생 억제, 규정준수, 내부통제 회계제도 준수 및 강화를 기할 수 있었으며, P사의 경우 84%에서 97%까지의 감사 적중률이 나타남을 알 수 있었다. 향후, 실시간으로 데이터를 분석, 조회할 수 있는 사물 인터넷 기술들을 추가적으로 활용하여 기업 경영의 감사 측면에서의 위험 관리 사전 모니터링 기능을 강화할 수 있는 방안을 지속적으로 연구, 발전시켜 적중률 뿐만 아니라 처리율과 속도 측면에서도 효과적인 시스템을 개발하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 447,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "창원대학교 대학원",
		"TITLE": "한국프로야구에서 빅 데이터 분석 기법을 이용한 수비수 평가 모델 =An estimation model for defence ability using big data analysis in Korea baseball league ",
		"AUTHOR": "허규준",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 우용태",
		"STORE_LOCATION": "창원대학교 도서관",
		"ABSTRACT": "In this paper, we propose a new model for effectively evaluating the defenders in the KBO League using the big data analysis technique. Currently, the ratio of defence used to evaluate defenders in Korean professional baseball is a simple indicator value using the number of errors only. In this study, we proposed an effective defender evaluation model considering the game situation, difficulty of hit, and win contribution. In the proposed model, defenders were evaluated using various evaluation items such as out conversion score, win contribution score, double play score, and additional runs score. In order to prove the efficiency of the proposed model, we experimented with the Korean baseball game data in 2015. As a result of the experiment, the out conversion scores were higher when more defensive areas recorded out conversion rates than the average out of position conversions. The win contribution score was higher as the defensive success was achieved without defensive errors. The double play score was high when the double play was more than the average defender. In addition, the ranking of defender who allowed a minimum level of additional runs in each of the areas where the ball was dropped was high. The defender evaluation model proposed in this study can provide baseball fans with various evaluation results that are not provided by the KBO. It can also be used to set up a strategy for baseball experts to use defenders into the game situation appropriately. And we will be able to utilize the results of the defender`s evaluation effectively in the recruitment of players and salary negotiations. Further research is required to collect detailed data such as the speed and angle of the ball to create a new defensive area and to evaluate the ball field considering the size of a different baseball field.",
		"KEYWORD": "빅 데이터 분석,수비능력,야구 전략,야구기록 분석,한국프로야구"
	},
	{
		"ID": 448,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "군산대학교 대학원",
		"TITLE": "공간 빅 데이터 웨어하우스 시스템을 위한 질의 및 색인 ",
		"AUTHOR": "조현구",
		"REGION": "전라북도",
		"PROFESSOR": "",
		"STORE_LOCATION": "군산대학교 도서관",
		"ABSTRACT": "Recently many companies are attempting the business analysis for the effective decision making using the big data through the big data analytic or warehouse system, but existing big data-related systems do not support the spatial big data analysis. And, since the spatial big data analytic system only supports the specialized format for the spatial data and cannot execute queries in the format of ANSI SQL, non-specialists cannot easily use the system. In this thesis, for the processing queries with respect to the spatial big data in the big data warehouse system, we propose an extended Tajo system equipped with a spatial query processing module that supports the spatial query and index. The proposed extended Tajo system supports processing of spatial queries by combining Tajo, which is a big data warehouse system that provides ANSI SQL and dynamic scheduling, and ensures fault tolerance, with open source libraries that support spatial types, spatial operators, and spatial indexes suggested in the Simple Feature Specification of the OGC standards. The spatial query processing module for the extended Tajo system is composed of a spatial type module, a spatial operator module and a spatial index module, and detailed modules are combined and operated systematically with the module of the Tajo system. The spatial type module was implemented as the spatial data type matching one-to-one with the spatial object model of OGC standards, and was allowed to store spatial object data in the format of WKB (Well Known Bytes) or WKT (Well Known Text) using a spatial constructor function. For the spatial operator module, a spatial operator function was created using the user-defined function of Tajo and open source libraries in order to support 7 spatial relational operators and 6 spatial analytic operators suggested in the OGC standards, and its format was transformed into the existing operator format to execute the aforementioned function in queries. As for the spatial index module, the Two-level R-tree, a multi-level index in the format of global-local index, was created by referencing to the R-tree of SpatialHadoop and BST structure of Tajo, and the STR (Sort-Tile-Recursive) technique was used to predesignate the spatial area distributed uniformly in the spatial big data. The performance evaluation confirmed that it takes shorter time to execute a spatial query when spatial index was used, and the number of local indexes was an important factor among those affecting the execution time of a spatial query. It was also confirmed that the extended Tajo system equipped with a spatial query processing module was appropriate for the spatial query execution on the spatial big data. Further studies on the addition of various spatial operators, the performance improvement of the query processing module, and the comparison with commercial systems able to treat spatial big data are needed.",
		"KEYWORD": null
	},
	{
		"ID": 449,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "창원대학교 대학원",
		"TITLE": "빅 데이터 분석 기법을 이용한 한국프로야구 주자 평가 모델 =Efficient estimation model of runner using big data analysis in Korean baseball league ",
		"AUTHOR": "박가혜",
		"REGION": "경상남도",
		"PROFESSOR": "",
		"STORE_LOCATION": "창원대학교 도서관",
		"ABSTRACT": "In this paper, we proposed a new type of Runner Estimation Model that takes into account the batting position, the left/right characteristics of the pitcher, and the victory contribution according to the game situation using the big data analysis technique in the KBO League. The proposed model consists of a Winning Contribution Estimation Module and an Advance Estimation Module for left/right characteristics of the pitcher. The Winning Contribution Estimation Module consists of a Steal Victory Contribution Score and an Additional Victory Contribution Score. Steal Victory Contribution Score refers to the score that contributed to the victory of the team according to the situation before and after the runner`s stolen. The Additional Victory Contribution Score is the score that contributes to the victory of the team due to the additional runs by comparing the pre/post game situation of the runner. And the Advance Estimation Module is a module that calculates the advance score by using the difference between the average ability of all runners and the ability of each runner to advance runs according to the batting position. In order to verify the effectiveness of the proposed model, we compared the rankings of KBO League Records in Korea. As a result of the experiment, unlike the KBO League Records, which ranked in terms of the number of successful stolen bases, in this study, runners who have contributed significantly to team victory are in the top rank. In addition, the runners were ranked differently depending to the left/right characteristics of the pitcher. As a result, the proposed model is considered as a new Runner Estimation Model that can effectively evaluate the performances of the runners who have contributed greatly to the team win. The proposed model can analyze the competence of the runners according to the items and apply them to the individual training or the strategy development process according to the left/right characteristics of the pitcher. It can also be used for salary negotiation through rank evaluation of all runners. Further research is needed to develop a model that takes into consideration the ability of the defenders to stop the offense, which affects the runner`s ability to move forward.",
		"KEYWORD": null
	},
	{
		"ID": 450,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "계명대학교 대학원",
		"TITLE": "빅 데이터를 활용한 IT 트렌드 분석 :전문기관 예측과 트윗에서의 반응 비교 분석 ",
		"AUTHOR": "이진백",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 이충권",
		"STORE_LOCATION": "계명대학교 동산도서관",
		"ABSTRACT": "Predicting IT trends has a long history and has been an important subject for information systems research. IT trend prediction makes it possible to acknowledge emerging eras of innovation and allocate budgets to prepare for rapidly changing technological trends. Towards the end of each year, various domestic and global organizations predict and announce IT trends for the following year, but the accuracy of these reports are difficult to verify. This study investigates how frequently the prediction trends for the following year as announced by public organizations and global consulting firms are mentioned on social network services such as Twitter. IT trend predictions for 2013, announced near the end of 2012 from two domestic organizations, the National IT Industry Promotion Agency (NIPA) and the National Information Society Agency (NIA), and two foreign organizations, the Gartner Group and PWC, were used as a basis for this research. Twitter data generated from Seoul (Korea), Silicon Valley (USA), London (England), and Helsinki (Finland) was collected and compared with the predictions of the professional organizations to analyze the differences. Big Data tools were used to collect and analyze 622,245 tweets between May, 2013 to December, 2013 to review how frequently the IT trend topics announced by Gartner and PWC were mentioned by tweets in each country. It was found that the IT trend tweets from Korea acted as a predictive variable for the following year`s IT trends in Nara Market, Korea`s online e-Procurement system. Big Data and cloud computing was a common IT trend among all of the four domestic and international organizations, but showed a significant correlation only with England and the US. The analysis results for each IT trend`s correlations showed that most of the IT trends in the US and England showed significant results while Finland and other countries only showed significant correlations in enterprise social networking and gamification trends. These results imply that most of the IT trends closely resembled twitter activities in the US and England, but did not accurately reflect the trends in Finland.",
		"KEYWORD": "Big Data,IT트렌드,빅데이터"
	},
	{
		"ID": 451,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "맵리듀스와 대응분석을 활용한 비정형 빅 데이터의 정형화와 시각적 해석 ",
		"AUTHOR": "최요셉",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 최용석 참고문헌: 장 49-50",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "These days, massive and various type of the data are being recorded everywhere in our life. We can call this type of the data, big data. It has been very important to analyze big data and to find valuable information from it. Besides, to standardize unstructured big data is also very important for applying to statistical method. In this paper, we will show that how to standardize unstructured big data using MapReduce which is a distribution processing system. And, we will apply simple correspondence analysis and multiple correspondence analysis to finding the relationships and characteristics around Samsung Electronics and words of the newspaper named The Korea Economic Daily, and also apply for Apple Inc and the word of the newspaper.",
		"KEYWORD": "데이터가공,비정형 데이터,빅데이터개념,빅데이터요소,빅데이터정형화"
	},
	{
		"ID": 452,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "창원대학교 대학원",
		"TITLE": "빅 데이터 분석 기법을 이용한 한국 프로야구 타자 평가 지표 개발 =Efficient estimation model of hitter using big data analysis in Korea baseball league ",
		"AUTHOR": "정진상",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 우용태",
		"STORE_LOCATION": "창원대학교 도서관",
		"ABSTRACT": "When the size of data is very big so that we cannot collect, manage and process that data with usual software program, such data is called a Big data. Baseball is very appropriate area to analyze using Big data. Because there are lots of things to research and investigate such as the direction of the ball hit by player, the movement of a fielder and the course of the ball pitched by player. From now on, departing from using usual indicators like a batting average, analyzing non-standardized data is going to be significant issue in baseball. This thesis suggests Highballpoint to estimate hitter in Korea Baseball League using Big data. This consists of `Base score`, `Distribution score` and `Pitch waste score`. The `Base score` is a point of event for result of hitting calculated on `Run value` based on Run. The `Contribution score` is a point of context for result of hitting based on `Win expectancy` which calculates probability of winning. The `Pitch waste score` is a point for waiting a number of balls when pitcher pitches hitter. The Highballpoint considers all events calculated on Run and winning of team unlike the OPS and Casspoint which is another estimation of hitter. The OPS does not consider several events except single, double, triple, homerun to estimate hitter. The Casspoint highly estimates homerun score more than the others therefore hitter who hit homerun is ranked on high position. The Highballpoint calculates all events based on empirical data. It also estimates result of hitting considered team win or lose.",
		"KEYWORD": null
	},
	{
		"ID": 453,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경북대학교 경영대학원",
		"TITLE": "재난 예방활동 시스템 설계를 위한 재난 빅 데이터 활용 ",
		"AUTHOR": "허영태",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 서창교 참고문헌 (p. 59-62) 수록",
		"STORE_LOCATION": "경북대학교 중앙도서관",
		"ABSTRACT": "The information system of disaster management have developed to take care of the field situation after arriving the disaster spot of rescue and first-aids incidents afterwards and developed to improve the field response of emergency taking, dispatching and reporting in disaster incidents. This thesis is to the design of disaster prevention activities information system to support the disaster prevention activities of 119 regional safety center and communities using the big data of rescue and first-aid incidents. The data collection and data structure, data analysis and pattern search analysis was taken to follow the procedure of the big data analysis methodology to find the pattern of the rescue and first-aids incidents. the data collection and data structure used the structured data such as the rescue and first-aids activities data, Daegu city council`s statistics data, Minister of Public Safety and Security`s statistics data and used the unstructured data such as Minister of Public Safety and Security`s disaster status monthly reports, Daegu`s fire and safety department`s disaster daily reports, and its prevention activities guidelines, Daegu disaster`s twitter messages. the collected data was categorized and was streamed after the removal of the unnecessary blank and specific symbols to analyze those data. the data analysis identified the characteristics of the spacial, time-based and population-social factors by analyzing the region, place, month, day, hour, sex, and age of the disaster occurrences. the pattern analysis found the occurrence pattern of disaster based on the factors of the region, place, day, hour and age among the previous 7 factors. the pattern found was applicable to the prevention activities in rescue and first-aids incidents and used the design of prevention activities of 119 safety center and communities and the rescue and first-aids prevention activities information system.",
		"KEYWORD": "구급,구조,빅 데이터,예방활동,재난 예방활동 시스템"
	},
	{
		"ID": 454,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "배재대학교 대학원",
		"TITLE": "빅 데이터 기반 질병 키워드 추천 시스템 =Disease keyword recommendation system based on big data ",
		"AUTHOR": "강희범",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 정회경",
		"STORE_LOCATION": "배재대학교 도서관",
		"ABSTRACT": "As the world-improved quality of life has increased dramatically the population with chronic disease, anywhere for convenient and efficient for the management and prevention of disease management using a smart phone or computer to obtain the necessary information about the disease and the development of the system has emerged which can be managed. Existing U-Healthcare sector was mainly developing medical technology. However, the current technology that combines information technology and your blood pressure or blood sugar, diabetes, due to the increase in chronic diseases. But the problem was falling readability when you use the disease management. because it provided for the current management system along with unnecessary information, not just the information you need. In the case of blood pressure and blood sugar, the accuracy has dropped due to manage user has only a simple maximum and minimum values without using a weight or body information, and the like. In this paper, in order to solve such problems as above, after the web scraping and analyzed by R. And generates the keyword analyzed data is automatically check box, count keyword of interest is through the selection of the other users with the users of the same disease in the graph shows. And data represent the top of the table increased readability. In addition, by displaying with the user`s body information such as body weight or BMI it was for the user to manage in many ways. We Implemented Big data based disease keyword recommendation system.",
		"KEYWORD": "Bigdata,Desease Management,Healthcare,Recommendation,Scraping"
	},
	{
		"ID": 455,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "창원대학교 대학원",
		"TITLE": "빅 데이터 분석과 투수 기량을 반영한 한국프로야구 타자 평가 모델 =Korean professional baseball batter estimation model reflecting big data analysis and pitcher ability ",
		"AUTHOR": "정예린",
		"REGION": "경상남도",
		"PROFESSOR": "",
		"STORE_LOCATION": "창원대학교 도서관",
		"ABSTRACT": "In this paper, we proposed a new type of batter evaluation model which takes into account the degree of win contribution which can be changed according to the game condition even though the same batting result is obtained using the big data analysis technique in the KBO League. Pitcher weights are assigned differently according to the pitcher‘s grades, so that the batting results can be evaluated differently according to the skill of the opponent pitcher. The final score and rank of the batter were calculated by using the run value, contribution score, ball consumption score and pitcher weight. In order to verify the effectiveness of the proposed model, we conducted a comparative experiment between Cass point and Hiball point and the proposed model using the iSTAT data of Korean professional baseball game from 2007 to 2012. As a result of the experiment, the proposed model showed a high rank among others who contributed to team win in a crucial game situation compared to Cass point. In addition, the batter who contributed a lot to the team victory ranked higher than the Hiball point against a stronger pitcher in the proposal model. The proposed model can be applied to the competitive strategy that configure the batting order considering the skill of the opponent pitcher. The proposed model can be used for salary negotiation process by presenting the criteria that can effectively evaluate the objective value of the batter. In the future, we plan to research the proposed model to reflect the correlation between batter scores and salary.",
		"KEYWORD": null
	},
	{
		"ID": 456,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "항공 안전 분야 빅 데이터 분석 기법 활용 방안에 대한 연구 ",
		"AUTHOR": "채정기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신경식 참고문헌: p. 53-60",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "최근 빅 데이터의 중요성이 높아지고 관련 인프라가 발전함에 따라 과거 거래 처리 데이터 위주의 분석이 중심이 되던 때와는 비교할 수도 없이 많은 데이터들이 끊임없이 발생하고 있다. 특히 데이터의 형식 측면에서 기존 정형 데이터 위주의 분석 데이터가 문서, 사진, 음성 파일 등과 같은 비정형 데이터와 반 정형 데이터 위주로 변화하고 있으며, 데이터가 실시간으로 생성되고 있어 기존 데이터 분석 및 처리 기술의 범위를 넘어서는 경우가 발생한다. 과거에는 저장 용량의 한계 및 분석 기술의 부재로 인해 빅 데이터를 효과적으로 활용할 수 없었으나, 데이터 저장 매체가 발전하고 다양한 오픈소스 빅 데이터 관련 인프라가 등장하면서 빅 데이터의 활용 가능성이 높아지고 있다. 이처럼 빅 데이터 활용 가능성이 높아지고 분석기술 및 저장 매체가 발달함에 따라 사회 · 경제 · 정치 각 분야에서 빅 데이터 분석을 통한 분석 결과 활용에 대한 관심이 증가하고 있다. 민간 부문에서는 기업의 비즈니스 의사결정에 빅 데이터를 활발하게 적용하고 있으며, 공공 부문에서는 국가 미래전략 수립, 데이터 기반의 과학적 정책 수립, 재난 관리 등에 빅 데이터를 활용하고 있다. 우리나라에서는 1990년대 일어난 대형 사고들을 계기로 재난에 대한 체계적인 관리가 필요하다는 인식이 확산되었고, 국가 차원에서 재난 및 안전 관리에 관한 법률을 제정했다. 과거 재난은 자연 재해, 전쟁 등에 치중되어 있었으나, 최근에는 인적 요인에 의한 사고와 국가 기반 체계의 마비를 일으킬 수 있는 장애 요소들을 뜻하는 것으로 그 의미가 확장되고 있다. 빅 데이터 분석은 빅 데이터로부터 데이터간의 연관 관계 및 숨어있는 패턴을 찾아내어 미래를 예측할 수 있기 때문에 재난 관련 분야에 적용하려는 수요가 크다. 본 연구에서는 재난의 범위 중 교통사고, 그 중에서도 항공 안전과 관련된 비정형 데이터에 빅 데이터 분석 기법을 적용했다. 항공 사고는 한 번 발생하면 수많은 인명 피해와 더불어 물적 재산의 손해, 나아가 큰 사회적 문제가 될 수 있기 때문에 우리나라에서는 항공 사고를 교통 부문 재난으로 규정했다. 기존의 많은 연구들에서 항공 안전 분야 관련 데이터를 분석하려는 시도가 있었으나 항공 분야에는 아직 정형 데이터만을 분석 대상으로 한 연구들이 대부분이며, 비정형 데이터를 분석에 적용한 연구는 미비하다. 이에 본 연구에서는 항공 사고 및 준 사고 관리를 재난 관리 관점에서 바라보고, 항공 재난 관리를 위한 빅 데이터 분석 기법 활용에 관해 연구한다. 본 연구에서는 기존에 정형 데이터에만 치중 되었던 연구들의 한계를 극복하기 위해 빅 데이터 분석 기법인 텍스트 마이닝을 적용하여 항공 안전과 관련된 비정형 텍스트 데이터를 분석하였다. 항공 안전 장애 사례 텍스트 데이터의 토픽 분석을 통해 항공 안전과 관련된 중요 키워드들을 도출하고 키워드 간 관계를 시각화하며, 텍스트 클러스터링을 통해 항공 사고 및 준 사고를 일으킬 수 있는 장애 요인을 살펴봄으로써 잠재 원인 도출 및 향후 항공 사고로 인한 재난 발생을 예방하기 위한 항공 분야 빅 데이터 분석의 기반을 마련하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 457,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "Data-centric computing system design for emerging big data applications =빅 데이터 어플리케이션을 위한 데이터-중심 컴퓨팅 시스템 설계 ",
		"AUTHOR": "HongyeolLim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 458,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "디지털 인문학으로서의 철학 컴퓨팅 :Philosophy computing as digital humanities : applying unstructured data analytics to classifying thoughts ",
		"AUTHOR": "서한솔",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 권오병 참고문헌: p. 38-44",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "With the advent of digital human literature, which is mainly supported by big data analysis, it contributes to improvement of the efficiency of humanities science research. Especially in humanities research, it is important challenge to prasp what kind of thought is included in a specific person or document and analyze the connection with other thought in an intelligent and automatic way. The purpose of this research is to provide a method to understand assertions in books, papers and articles which included as unstructured data and analyze how they are related to other assertions and ideas. For this reason, we utilized classification algorithm method including deep learning method, and as a result, we were able to obtain very satisfied level of classification performance.",
		"KEYWORD": "Classification Algorithms,Data Mining,Philosophy,Text Analysis"
	},
	{
		"ID": 459,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "경상대학교 대학원",
		"TITLE": "유동인구 빅 데이터를 활용한 도시재생활성화지역 유형 분류 및 특성분석 =Classification and characteristics of urban regeneration activation region by floating population big data ",
		"AUTHOR": "조정훈",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 문태헌",
		"STORE_LOCATION": "경상대학교 도서관",
		"ABSTRACT": "A lot of urban problems, caused by urbanization and industrialization, have occurred around the world. In particular, the creation of satellite towns, which was attributed to the explicit expansion of the city, has led to the traffic problems and the hollowization of old towns, raising the necessity of urban regeneration in old towns along with the aging of existing urban infrastructure. To select urban regeneration activation region for the strategic execution of urban regeneration in Korea, the number of population, the number of businesses, and deterioration degree were chosen as standards. Existing standards had a limit in coping with solving urban problems fundamentally and rapidly changing reality. Therefore, it was necessary to add new indicators that can reflect the decline in relevant cities and conditions. In this regard, this study selected Busan-si, Korea as the target area as a leading city, where urban regeneration such as an international port city has been activated like Yokohama, Japan. Prior to setting the urban regeneration activation region, the conditions of reality should be reflected because uniform and uncharacterized projects have been implemented without a quantitative analysis about population behavior within the region. For this reason, this study conducted a characterization analysis and type classification, based on the user behaviors by using representative floating population of the big data, which is a hot issue all over the society in recent days. The target areas were analyzed in this study. While 23 regions were classified as three types in existing Busan urban regeneration activation region, 23 regions were classified as four types in existing Busan urban regeneration activation region in terms of the type classification on a basis of user behaviors. Four types were classified as follows; A type of young people - morning type, B Type, the old and middle aged- general type with sharp floating population, C type of the old and middle aged-24hour-type, and D type of the old and middle aged with less floating population. Characteristics were shown in each region of four types and the study results of user behaviors were different from those of existing urban regeneration activation region. According to the results, in A type young people were the majority around the existing old built-up area, where floating population at dawn is four times more than in other areas. In B Type, there were many old and middle aged people around the existing built-up area and general neighborhoods, where the average floating population was more than in other areas due to commuting, while in C type, there was no change in the floating population throughout 24 hours, although there were many old and middle aged people in population around the existing general neighborhoods. D Type includes existing economy-based type, central built-up area type, and general neighborhood type, where old and middle aged people were the majority as a general type of commuting with less floating population. In addition, D type was divided into D-1 type and D-2 type due to the difference of the floating population through the subdivision of D type. Unlike existing urban regeneration activation region, these types were sub-divided according to types, and in this study, approach methods and basic orientations of urban regeneration were set to reflect the reality to a certain degree including the indicators of effective floating population to identify the dynamic activity of urban areas and existing regeneration activation areas in connection with urban regeneration projects by regions. Therefore, it is possible to make effective urban plans through offering the substantial ground by utilizing scientific and quantitative data. To induce more realistic and effective regeneration projects, the regeneration projects tailored to the present local conditions should be developed by reflecting the present conditions on the formulation of urban regeneration strategic plans.",
		"KEYWORD": "Big Data,Floating Population,Type Classification,Urban Regeneration,Urban Regeneration Activation Region,도시재생활성화지역,유동인구"
	},
	{
		"ID": 460,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "빅 데이터를 활용한 지자체 교통정보 개선방안 연구 =A study on improvement of local traffic information providing using big data ",
		"AUTHOR": "이중건",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박재표 참고문헌: p. 24",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "한국은 지능형 교통정보 시스템을 2000년도부터 본격적으로 도입하여 시행하였다. 지능형 교통정보 시스템을 도입하면서 도로 운전자들에게 실시간 교통정보를 제공하였다. 운전자는 전반적인 교통상황을 출발 전 출발지점에서 인지하여 가장 적합한 출발시간과 교통수단, 그리고 운행경로 등을 선택하게 된다. 교통정보 이용자 중 65%는 출발 전후로 교통정보를 이용하고 있으며, 이 중 20% 정도의 이용자는 운전 중에도 교통정보를 이용하는 것으로 나타나 운전자들이 교통정보에 대한 의존도가 높은 것으로 나타났다. 그러나 운전자에게 제공되는 교통정보가 실제 교통상황과 다르고, 정확한 정보를 제공하지 못하면서 이용자들이 지자체 제공 교통정보 외에 민간업체에서 제공하는 교통정보를 사용하기 시작하였다. 본 논문에서는 현재 각 지자체에서 제공하는 교통정보의 문제점을 파악하고, 과거 빅 데이터를 이용해 현 교통정보 시스템을 개선하는 방안을 제안한다. 또한 빅 데이터를 활용한 교통정보 제공을 통해 운전자 개인의 통행 시간 및 비용의 절감과, 더 나아가 지자체 차원의 교통혼잡비용 감소 효과에 도움을 줄 수 있을 것이다.",
		"KEYWORD": "교통,교통정보,빅 데이터,알고리즘"
	},
	{
		"ID": 461,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "대구가톨릭대학교 대학원",
		"TITLE": "빅 데이터를 활용한 호텔 선택속성의 중요도-만족도에 관한 연구 :특급호텔과 중저가 호텔 비교 ",
		"AUTHOR": "김용범",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 윤세남",
		"STORE_LOCATION": "대구가톨릭대학교 중앙도서관",
		"ABSTRACT": "The purpose of this study is to examine segment and importance-performance analysis of hotel selection attributes by using big data in terms of business travelers for the first time. Also it may be referred to as difference from the previous research. Specifically, this study applies a text analytical approach to large quantity of business traveler reviews extracted from Trip Advisor. The empirical data consisted of 4,750 business traveler reviews from 82 hotels in Seoul of Korea. The results from this study are as follows: First, hotel facilities showed no significant differences by gender, age and region. second, the food and beverage showed that satisfaction were higher in deluxe hotel than mid-priced hotel most of asian men who were in 30s below. third, room division showed that satisfaction were higher in deluxe hotel than mid-priced hotel most of asian men who were in 30s below. fourth, environment showed that satisfaction were higher in deluxe hotel than mid-priced hotel most of asian men who were in 30s below. fifth, employee showed that satisfaction were higher in deluxe hotel than mid-priced hotel most of asian men who were in 30’s below. Compared with deluxe and mid-price hotel, the IPA grids showed the commonalities and the differences are as follows: in the keep up the good work quadrant(1 quadrant) the commonalities were location, cleanliness, access, wifi, amenities, breakfast, bed, foreign languages, friendly, shopping and the differences were room size, appearance, services, landscaping, fitness, sauna, views. in the concentrate here quadrant(2 quadrant) the commonalities were no attributes and the differences were room size, appearance. in the low priority quadrant(3 quadrant) the commonalities were air conditioning, heating, sound proofing, breakfast price and the differences were lounge, menu, bathroom, room service, politeness, size, grade. in the possible overkill quadrant(4 quadrant) the commonalities were bar, business center, fast, trust, convenience stores, professional, helpful, membership preferential, duty-free shops, dining, swimming pool, coin laundry, drinks and the differences were fame, room prices. Hopefully, the outcomes of this research will be available to the interested individuals or to the industry.",
		"KEYWORD": "Big Data,Hotel Selection Attributes,Importance-Performance Analysis,고객만족,비정형 호텔 선택속성,빅 데이터,인구통계학적 특성,중요도-만족도,중저가 호텔,추출된 호텔 선택속성,호텔 선택속성"
	},
	{
		"ID": 462,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "빅 데이터를 이용한 제품디자인의 감성반응 분석 :스마트폰을 대상으로 ",
		"AUTHOR": "김건아",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 김철기 참고문헌: 장 131-136",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "Recently, research has been performed in various areas such as public administration, marketing, medical area, IT industry, and manufacturing area to analyze and apply big data. This study uses big data to structurally analyze the sentimental response of consumers on product design. Engineered analysis system using N-gram analysis and TF-IDF algorithm was developed to identify the possibility with alternative method about limitation of survey method used in sentimental analysis of general design, and the non-cognitive situations were acquired and analyzed. Big data created from Twitter based on smart phones was collected to analyze by separating into preprocessing, processing, and postprocessing. Preprocessing is the stage of removing span and useless words in the collected data. Processing was classified into 14 categories including price, function, design, psychology, usability, advertisement, location, type comparison, prediction, period, brand, product name, purchase, and others to the consumer response about the products through pre- and post- investigation by applying the weighted value after extracting the key words in the text data by applying N-gram analysis and TF-IDF System. The classified categories were performed with sentimental analysis, active analysis, and design response analysis. For sentimental analysis, 71 words were extract by using the 5 categories including psychology, design, function, price, and purchase by applying the opinion mining method. A chart was composed according to the frequency of word appearance. polar analysis was performed into positive, negative, and neutral on the extracted words. For design response analysis, the response on the products were classified into function, usability, maintenance, economic, psychology, social, sensual, and environmental areas. Details were used to extract the factors with influence in the design response. The post-processing used wordcloud to effectively deliver the keyword, sentimental analysis, and result of polar analysis to the users. Then, these results were visualized, and factorial analysis, regression analysis, and statistical processing were executed on the 11 categories excluding the 3 categories including location, brand, and product name. As a result of the factor analysis, the main components including life photo function in comparison with iPhone 6S and 6S+ were extracted. In relations to the purchase opinion, significant influence was identified in the usability, purchase opinion, and psychological properties in relations to the new functions of iPhone. As time passes to the response on the product, data was regularly collected to check the change of the main contents through tracking analysis. When comparing October analysis result, the new products showed high factors related to new function, price, and purchase according to release of product. For November, psychological response and various public opinions related to the review, price, and new function were identified. Through the polar analysis, the accumulated data was collected to provide response comparison of before and after the product. Comparison analysis of sentimental value on leading to brand loyalty is also possible. Also, this thesis paper can be used for feedback data and consumer response prediction through the change of public opinion, and it can be used as data for market analysis.",
		"KEYWORD": "감성반응 분석,디자인 감성분석,빅데이터,제품디자인 감성분석"
	},
	{
		"ID": 463,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "소셜 빅데이터를 활용한 인플루엔자 일일 예측모형 =Daily-based prediction models for influenza disease using social big data ",
		"AUTHOR": "황은지",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 나종화 참고문헌: p.55-57",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "통계적인 예측은 과거의 정보를 이용하여 과학적인 방법으로 미래를 예측하는 기법으로, 사회 전반에 걸쳐 그 활용도가 매우 높다. 최근 국민의 건강을 위협하는 질병 대상이 점점 다양해지고 있으며, 사스, 조류인플루엔자 등 신종 감염 병이 발생 때 마다 국민적 불안감 증대하고 있다. 이로 인한 사회적 손실을 줄일 수 있는 질병의 조기 예보 서비스가 매우 필요한 실정이다. 질병에 대한 사전 예측을 위한 모형구축에는 기존의 여러 시계열 및 회귀 모형에 소셜 빅데이터 정보를 결합한 모형을 제시하였다. 또한 현재 국내 질병자료를 예측함에 있어 빠르게 급변하는 질병의 추이를 반영하지 못하는 경우가 흔히 발생하며, 중요한 질병의 경우 즉각적인 대응미비로 인해 매우 심각한 결과를 초래하게 된다. 그리하여 특정 질병에 영향을 미칠 수 있는 환경적 요인도 함께 고려하여 예측하였다. 또한 최근 빅데이터의 부상과 함께 크게 주목받고 있는 소셜미디어 정보를 결합하여 예측의 성능을 높이는데 활용하였다. 소셜미디어 정보의 강점은 자료의 예측에 있어 가장 최신의 정보를 이용한 실시간적인 예측을 가져다준다는 것이다. 본 논문에서는 질병에 대한 모형의 성능비교를 위해 적합력과 예측력을 제시하였다. 질병 예측에 사용될 모형으로 ARIMA 계열의 시계열 모형인 계절형 ARIMA 모형, 계절형 ARIMAX 모형과 이를 회귀적으로 간략하게 나타낼 수 있는 계절형 ARX 모형을 비롯하여 회귀 모형과 시계열 모형의 결합된 형태인 계절형 ARIMA 오차 회귀 모형이 있다. 그 결과 계절형 ARIMA 오차 회귀 모형의 예측력이 가장 뛰어난 것을 확인하였다.",
		"KEYWORD": "소셜 빅데이터,시계열,예측"
	},
	{
		"ID": 464,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "소셜 빅데이터를 이용한 재난 감정 분석 ",
		"AUTHOR": "심규승",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 송민",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "disaster,probability distribution analysis,sentiment mining,social big data,text mining,감정 분석,소셜 빅데이터,재난,텍스트마이닝,확률 기반 분석"
	},
	{
		"ID": 465,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "빅데이터의 연관성분석을 이용한 시각적 해석 ",
		"AUTHOR": "노윤환",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 조영석 참고문헌: 장 32-34",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "Abstract In this article, we propose a statistical method to find significant association patterns of Sinmumgo boards and free boards on the website of Pusan National University from January, 2011 to September, 2014. We employed on association rules with textmining in analysis of the big data. In our method, Support, Confidence and Lift were measured to test degrees of associations. We used R packages ‘KoNLP` and ’tm` in order to visualize unstructured big data. Also, new efficient algorithm for generating a network graph with the association rule was implemented. We demonstrated that the proposed method can visualize association patterns much more clearly than existing association rules.",
		"KEYWORD": null
	},
	{
		"ID": 466,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경북대학교 산업대학원",
		"TITLE": "공공부문 빅데이터를 이용한 민원편익 분석 ",
		"AUTHOR": "장병문",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 이상조",
		"STORE_LOCATION": "경북대학교 중앙도서관",
		"ABSTRACT": "The amount of data produced in the public sectors is expected to be enormous. Such data in public sector would abundantly incorporate useful information and provided that these data are shared among institutions or combined with technologies and data from the private sector, promoting benefits for community members and the national interests while decreasing the waste of administrative costs would be feasible. However, not only is external access to these data highly limited but also most data die out due to lack of communication between the departments and technological limitations in public institutions as they fail to overcome the internal barriers between departments. The Park Geun-hye Administration announced the ‘Big Data policy,’ which consists of disclosing and sharing public data by「government 3.0」. It advocates that the government must provide customized service to citizens with the Government Big Data and that the opportunities to utilize and commercialize the Government Big Data must be provided to private sectors. In order to extract useful information for adminstration by utilizing public data, this paper has analyzed the factors that influence the frequency in which the local residents visit the Dong community center by cross-correlating various data in Daegu Dong-gu Office. More specifically, the analysis cross-correlates the number of copy of resident registration issued by each Dong community center in Daegu Dong-gu Office with the population density, the rate of imposition of local tax, the number of households inhabited in apartments, and the number of business in each Dong. This will become the foundation of propositions to utilize the government’s public data in the future.",
		"KEYWORD": "공공부문,빅데이터"
	},
	{
		"ID": 467,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "베이지안 네트워크를 이용한 카셰어링 산업의 미사용 이탈요인 분석 :앱 내 행동 데이터를 중심으로 ",
		"AUTHOR": "민병철",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 468,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "대전대학교 대학원",
		"TITLE": "R을 이용한 빅 데이터 분석 ",
		"AUTHOR": "최유진",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 469,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "빅 데이터 분석을 통한 과학신학적 성경 해석의 가능성 탐색 ",
		"AUTHOR": "류우권",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김문조 참고문헌: 장 79-89",
		"STORE_LOCATION": "고려대학교 도서관",
		"ABSTRACT": "Abstract This paper is an Exploratory Study on the Scientific Theological Interpretation possibility of Bible by using Big Data Analysis. The purpose of it is to suggest the model which can study the Bible in the scientific theological way. To achieve this purpose, the K-Scientific theological Complementary Analysis Model (K-SCAM) is suggested. From the methodological standpoint, the limitation on the method of the conventional interpretation of the Bible is described and methods to overcome it are suggested in this paper. In addition, through a scientific theological interpretation, the methodological principles for the interpretation of Bible are proposed. This paper contributes to three aspects in the scientific theological interpretation of the Bible as follows. The first one is the contribution to the methodology. It is the approach to analyze the whole biblical texts by the analysis of big data and interpret the Bible based on the result of it. Since this has not been tried up to now in this field, this method can be a creative approach in terms of research methodology. The second one is interpretative contribution. When the research on the Bible is conducted, there are many theological problems, whereas theological tools are not sufficient to solve them. However, there is a case in which the long-term dispute on the divinity and humanity of Jesus Christ has been solved by the understanding of the scientific theological interpretation called quantum physics. Namely, this case is significant in that science can help to solve theological problems of the Bible. In this regard, there is one of the critical methodological principles which can contribute to analytics, which is `the complementary interpretation principle`. In the past, it seemed that science and theology had developed with different directions and goals and their goal and the subject of study were completely different. However, this study shows that science and theology fundamentally go toward the same direction as well as the problem in science is also that in theology and vice versa. The last one is the contribution to interdisciplinary study. These days, there have been interdisciplinary studies between science and humanities. It is also true that interdisciplinary study leads to various range of research performances and the academic results. The interdisciplinary study between science and theology, however, is still at an early stage. Nevertheless, if science and theology can be used not as a tool of war but a tool for co-existence, the most productive results would be produced by the meeting of them.",
		"KEYWORD": "과학 신학"
	},
	{
		"ID": 470,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "전북대학교 정보과학대학원",
		"TITLE": "빅 데이터 환경에서 개인의 정보인권 보호방안에 관한 연구 =A study on personal information right protection methods in the big data environment ",
		"AUTHOR": "최재봉",
		"REGION": "전라북도",
		"PROFESSOR": "전북대학교 논문은 저작권에 의해 보호받습니다. 지도교수:조기환 참고문헌 : p.44-45",
		"STORE_LOCATION": "전북대학교 중앙도서관",
		"ABSTRACT": "Recently, it has been paid attention on big data as a core ICT technology to solve various social problems. Meanwhile, with the indiscriminate use of data, big data environment brings about the infringement of human rights. However, the current statute has not been working as an effective means to protect personal privacy in this new era of big data. This thesis proposes some specific methods to protect personal information right in the this big data environment. Firstly, the global competition is discussed to secure data acquisition in order to be a big brother. Then, the infringement of personal information right is analysed with some examples of the illegal uses for business purpose along with the indiscriminating personal data acquisition. Finally, the advanced cases are also explored with other countries which move quickly to come up with the measures to protect personal information right. Based on these observations, we presents four methods; firstly it is need to separate personal information into identifiable one and not-identifiable one by the big data technology, and process them differently. Secondly the right of the information principal should be strengthened through the preparation institutional strategies. Thirdly, it is required to establish an independent and exclusive organization to protect personal information right which oversees both public and private sectors. Finally, the current resident registration number should be replaced with one which is not embedded personal information. Along with the technical aspect of proposed methods, it is strongly required to come up with some degree of social efforts to accept and embody the methods. Besides the wise use of the big data technology should be discussed together.",
		"KEYWORD": null
	},
	{
		"ID": 471,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "교통 빅 데이터 분석에 의한 교통정체 변화 판별 알고리즘 ",
		"AUTHOR": "정도성",
		"REGION": "부산",
		"PROFESSOR": "지도교수:홍봉희 참고문헌 : 장 51-52",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "이 논문에서는 과거 교통정체 패턴을 이용하여 현재의 교통정체가 풀리는 정체인지 아니면 악화되는 정체인지를 판별하는 알고리즘을 제안한다. 과거 교통정체 패턴은 다중 포인터를 이용하여 정체구간들을 연결한 인접 리스트(adjacency list)자료구조에 교통정체의 시간적 길이와 공간적 길이로 저장된다. 교통정체가 시작된 구간에 해당하는 헤드노드를 탐색하고 현재패턴과 가장 유사한 과거 교통정체 패턴을 선정한다. 과거 교통정체 패턴을 이용하여 장래의 교통정체변화정보를 제공한다. 제안하는 알고리즘의 검증을 위해 부산교통정보서비스센터에서 제공하는 2013년도 4월 30일부터 5월 9일까지 5분 단위로 수집된 링크속도 데이터를 사용하였다. 실험을 통해 검증한 결과, 1개의 링크의 정체 변화를 예측하였을 경우 실제값과 비교하였을 때 평균적으로 10~20분 오차를 보였으며, 연속된 다수의 링크들을 결합하여 비교적 긴 구간의 정체 변화를 예측하였을 경우 평균적으로 5분 이내의 오차를 보이며 실제값과 유사한 것을 보였다.",
		"KEYWORD": "교통 빅 데이터,교통정체 패턴,인접 리스트"
	},
	{
		"ID": 472,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충남대학교 특허법무대학원",
		"TITLE": "빅 데이터의 상업적 이용에 있어 지적재산권 문제의 고찰 ",
		"AUTHOR": "은창수",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 李鐵男 참고문헌 : p. 61-64",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "In this thesis we discuss the intellectual property issues that may arise when the ‘Big data’ and public data are used for commercial purposes. The issues can be categorized into two parts: patent rights and copyrights. The patent issue can be raised with the ‘idea’ of selecting an appropriate data set for the desired result among the mountains of data sets (for example, as presented in the thesis, in predicting the quality of vintage of the year, the idea that the climate is a crucial factor that determines the quality is of the utmost value). Since the idea itself is neither complex nor expensive to keep confidential, it hardly seems to be protected as a trade secrete. It does not seem appropriate to protect the idea as a business method either. However, it is asserted that idea should be protected by law in some way, since it is the idea that creates value in extracting valuable information from data. The importance of algorithm is also discussed. Since it is mainly the algorithm that adds competency in the data mining, it is stressed that a patent should be granted for a noble algorithm, should there be specific descriptions in the patent specifications on the roles of the hardware components in the algorithm, even when the algorithm is run in a single computer unit. Also the business method using data is considered. As the business methods based on data usually utilize the servers and clients, there would be no problem of being issued a patent if the patent specifications include the roles of the them (i.e., the servers and clients). The copyright issue can be also raised. The commercial use of the data includes data collection, storage, processing, mining, and visualization to name a few. The copyright issue can be addressed as to the collection, storage, and processing of the copyrighted data. It is not clear that the handling of the copyrighted material in the process of collecting, storing, and extracting information from data for commercial purposes can be regarded as a fair use, as the copyright law exemplifies fair use with reporting, criticism, education, and research which are usually considered non-commercial. Since the use of the copyrighted material for information extraction is not a normal way of use, for the maturity of the data industry, it is necessary to extend the concept of ‘fair use’ to incorporate the process for data handling. The visualization of data also raises the copyright issues. Data or information extracted from data are usually presented using visualization techniques. Since it is common to use commercial tools for data visualization, the copyright of the visualization results can be disputed. The issue is more evident when the data are from the public domain, which are open for everybody’s use. A legal regulation is needed to be devised to prevent such confusion. As the data are either free or available from market, there can be conflicts among parties who provide the same service with the same data. It is necessary to decide whether to allow the free competition or to protect the first provider. The terms and conditions for protection should be specified by law if the first service provider is to be protected. When the data are from the public domain, the copyright of the visualized material can be of concern. Since the public data are collected using tax, it seems inappropriate that the copyright is claimed by a private party. It seems appropriate that the copyright remains in the public, though some compensating measure is to be devised for the effort of the creation of value.",
		"KEYWORD": null
	},
	{
		"ID": 473,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "전남대학교 대학원",
		"TITLE": "빅 데이터의 군집분석을 위한 군집화 유효성 지수 개발과 응용 ",
		"AUTHOR": "이수현",
		"REGION": "광주",
		"PROFESSOR": "지도교수: 김재윤",
		"STORE_LOCATION": "전남대학교 중앙도서관",
		"ABSTRACT": "빅 데이터는 고객관리 및 마케팅 전략 수립, 그리고 품질개선 등의 경영학 분야와 패턴인식, 영상처리 등의 공학분야, 그리고 유전체 또는 단백체 분석 등의 의료분야 등 다양한 분야에 널리 활용할 수 있어 이에 대한 관심이 증대되고 있다. 군집분석은 빅 데이터를 분석하는 대표적인 방법 중의 하나로, 경영학 분야에서는 군집분석을 이용하여 동질적인 특성을 지닌 집단을 도출하고 이를 재무, 마케팅, 생산관리 분야 등에서 다양하게 활용하고 있다. 따라서 군집분석에 의한 군집화 결과는 기업의 가치를 극대화 시킬 수 있는 핵심자원의 역할을 하고 있다. 본 연구에서는 빅 데이터의 분석기술 중 군집분석에서 필요한 군집화 결과의 유효성을 검증하는 군집화 유효성 지수(CVI: clustering validity index)의 개발에 관한 이론적 연구와 그 결과의 실무적 활용을 다루고자 한다. 본 연구에서는 다양한 형태의 데이터에서 군집화의 유효성 검증 성능이 우수하다고 알려진 Dunn 지수, Calinski and Harabasz 지수, 그리고 Davies-Bouldin 지수들을 응집도와 분리도의 개념으로 분해하고, 각 CVI의 응집도 계산에 서포트 벡터 데이터 표현(SVDD: support vector data description) 개념을 반영하여 새로운 CVI들을 제안하였다. 다양한 실험문제를 이용한 성능비교 실험을 수행함으로써, 새로운 CVI들은 임의형상과 노이즈 데이터에서 성능이 크게 향상됨을 확인하였다. 뿐만 아니라 재무, 마케팅, 생산관리 분야의 경영학 사례문제를 이용하여 새로운 CVI의 적용성도 검증하였다. 본 연구를 통해 SVDD 개념을 CVI의 응집도에 반영할 수 있으며, 이를 반영한 새로운 CVI들은 군집화 유효성 검증에 효과적임을 확인할 수 있었다. 본 연구에서 제안한 CVI의 응집도 계산방법은 기존에 알려진 다양한 CVI의 응집도에 적용이 가능할 것으로 기대된다. 이는 빅 데이터의 군집분석 대상이 확대되고 연구가 다양해지고 있는 상황에서 군집분석 및 CVI의 이론 확장, 그리고 SVDD 적용범위 확장에 공헌할 것으로 기대된다.",
		"KEYWORD": "경영사례,군집화 유효성 지수,빅 데이터,서포트 벡터 데이터 표현,응집도"
	},
	{
		"ID": 474,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "아주대학교 IT융합대학원",
		"TITLE": "사용자 실적 빅 데이터에 기초한 지역난방 배관망 동적 시뮬레이션 모델 =Dynamic simulation model for district heating pipe network based on end-user big data ",
		"AUTHOR": "정준철",
		"REGION": "경기도",
		"PROFESSOR": "아주대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 정기현 참고문헌: p.45-46",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "현재까지 우리나라 지역난방사업자의 대부분은 최대 생산시설의 용량산정에 근거하는 배관망 해석방법에 주력해 왔으나, 최근 열, 전기 동시 생산시설의 확대와 경제운전을 목적으로 하는 생산계획 수립의 필요성이 점차 요구되고 있다. 지역난방 최종사용자의 안정적 공급과 열 생산 시설의 경제적 활용이라는 두 가지 목적을 달성하고, 배관망 설계의 기본 정보가 되는 열수요 분석을 위하여 열 생산 추정치를 사용하고 있다. 본 논문은 기존 최대 생산 시설 용량 산정을 위해서 시행되고 있는 설계방식의 개념을 벗어난 시설 최적 운영을 위한 동적 시뮬레이션 방법을 제안한다. 사용자의 실제 열사용 실적 데이터를 활용한 실험에서 기존 시뮬레이션 방법보다 제안하는 동적 시뮬레이션 방법이 효과적임을 보인다. “D”지역 상업지역과 주택지역의 열사용 부하율은 기존의 방법으로는 50:50 이었으나, 20:80으로 분석되었고 이는 실제 부하율과 매우 근접한다. 시뮬레이션을 통해 얻은 결과는 지역난방 공급 시스템에 대한 정보로 활용 가능하며, 외기온도와 사용자 사용량에 대한 상관관계 분석에도 활용되어 외기온도에 따른 열 공급 예측에로의 확장에도 활용 가능할 것이다. 시뮬레이션 결과는 동적 해석 시스템의 정확도가 기존 시스템에 비해 비약적으로 향상됨을 알 수 있다. 제안한 방법의 정확한 열수요 분석을 활용하면, 시설의 효율적 운용이 가능하여 열 생산 시설의 확충을 늦출 수 있을 것이다. 또한, 제안 방법은 지역난방 이외의 배관망 해석 분야에 적용되어 정확한 시설설계 및 투자에 대한 근거를 확보하는데 활용 할 수 있을 것이다.",
		"KEYWORD": "동적시뮬레이션모델,사용자실적빅데이터,지역난방배관망"
	},
	{
		"ID": 475,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "강원대학교 대학원",
		"TITLE": "비정형 빅데이터의 전세가격 예측 유용성 연구 =An empirical study on the availability of unstructured big data in Jeonse price prediction ",
		"AUTHOR": "이종민",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:정준호 참고문헌 : p.91-101",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "The development of big data technologies not only assists in deciding the efficient production of products and the direction of services through analysis of consumer`s purchase pattern and behavior but also presents the possibility of a shift in a new paradigm in the analytical method of having forecasting the market with limited data over the years such as providing useful data at the level of asset risk management. The purpose of this study was to make clear whether the topic weight of news articles and the search index of the Internet search portal were useful in improving the improvement of the predictive ability of Jeonse price index ARIMA model. For this purpose, the following three research hypotheses were set. First, the topic weight of news articles would have precedence and causality in the Jeonse price index. Second, the portal search index would have precedence and causality in the Jeonse price index. Third, both the topic weight and the portal search index would useful in improving the predictive ability of the Jeonse price index. This study intended to find out whether the psychological flow of the market and the issue of interest could be useful as the leading indicator of the Jeonse price through hypothesis testing. Analytic data included the search index of portal Naver, the apartment Jeonse price index published in weekly and monthly units by KB used in many previous studies and the news articles of 16 press companies collected through BIGKINDS, the big data analysis system of Korea Press Foundation. The period of analysis was between January 2011 and December 2016, a point in time when Naver, the search portal, provided information including the mobile search index and the number of smart phone users began to exceed 10 million persons. The method of analysis was to compare and analyze a difference in predictive ability of ARIMAX including the topic weight of news articles and the search index of portal in the Jeonse price index ARIMA as well as the Jeonse price index ARIMA. There is a difference between existing studies and this study. First, it is the first study to analyze the improvement in the predictive ability of the Jeonse price with the use of ARIMA model and portal search index and topic weight. The second difference is that most previous studies over real estate used monthly data but this study attempted to test the degree of improvement in the more diverse and precise predictive ability Jeonse prices by making use of weekly and monthly Jeonse price index, weekly portal search index data and monthly news articles over the period between January 2011 and December 2016. The third difference is that this study presented the degree of improvement in the predictive ability of unstructured data by point in time and by region for the purpose of practical use. This study results showed that the Seoul JPI(Jeonse Price Index) ARIMAX model including the topic weight of Jeonse showed an improvement in the predictive ability(MAE, Mean Absolute Error) of 6.39% compared to the Seoul JPI ARIMA model. And the ARIMAX model including the Jeonse search index of Naver showed an improvement in the predictive ability(RMSE, Root Mean Squared Error) of 26.34% compared to the nationwide JPI ARIMA model. A detailed investigation showed the following results. First, the results of study over the availability of the Jeonse price prediction of the topic weight of news articles showed that the Seoul JPI ARIMAX model including the Jeonse topic weight selected through cross correlation analysis between regional Jeonse price index and each topic and Granger causuality analysis showed a improvement in RMSE of 3.49% compared to the Seoul JPI ARIMA model. Second, the results of analysis on the availability of the Jeonse price of Naver search indexes showed that the ARIMAX model including the portal Jeonse search index in the Seoul JPI ARIMA selected through Granger casuality analysis and cross correlation analysis between Jeonse price indexes in nationwide, in Seoul, in Gyeonggi Provice, in Daejeon and the Jeonse search indexes of portal Naver had an improvement of the predictive ability in RMSE of 17.21% and MAE of 16.83% compared to the Seoul JPI ARIMA model. The recent housing market of Korea is that the difference in residential quality has become deepened due to the phenomenon of three low rates such low growth, low interest rates and low birth, and the high ratio of housing price to income, a reduction in Jeonse housing, the conversion of Jeonse into monthly rent which becomes a burden to common people`s housing expenses and so on, which have a negative effect on residential stability. The future more accurate prediction of the Jeonse housing market would not only enable national government to cope quickly with changes in the price of the Jeonse market but also to monitor the effects of the residential stabilization policy in advance. Previous studies over the prediction of the real estate market focused on structured data. But this study has its academic significance in that it attempted to predict the Jeonse housing market by making use of unstructured big data capable of collecting, analyzing, processing and storing the Psychological state of market participants in real time due to the recent supply and spread of mobile equipment, the development of large-scale data processing technologies and so on. The practical use of unstructured big data would enable people to make an advance grasp of changes in the Jeonse housing market rising as a social problem consequent on recent residential unstability. And it would assist in formulating quick and sophisticated policy and provide the results of accurate prediction over the Jeonse price for participants in the Jeonse housing market highly interested in future changes in Jeonse prices. This study has its implications in that the practical use of unstructured big data laid the foundation for making a more accurate quick prediction prices of the asset market occupying a great weight in the asset portfolios of individuals and asset operators such as real estate, stocks, financial commodities and so on as well as the prediction of Jeonse prices.",
		"KEYWORD": "ARIMA,비정형 빅데이터,예측,전세,토픽비중,포털 검색지수"
	},
	{
		"ID": 476,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "한국어 텍스트 마이닝의 특징 고찰 및 실제 빅데이터에의 적용 ",
		"AUTHOR": "구주나",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김경아 참고문헌: p. 36-38",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "텍스트 마이닝 기법들은 영어권 문서를 중심으로 활발히 개발되고 다양한 분야에서 활용되었으나, 한국어 텍스트 마이닝에 대한 연구는 상대적으로 제한적이었다. 최근 한국어 텍스트 자료를 포함하는 빅데이터가 증가함에 따라 한국어 텍스트 마이닝의 중요성이 부각되고 있으며, 이에 대한 집중적인 고찰과 빅데이터에의 적용이 요구되고 있는 시점이다. 본 연구에서는 한국어 텍스트 마이닝의 과정을 정리하고 단계별 특징을 고찰하며 텍스트 자료를 포함하는 실제 빅데이터인 2011 경제총조사의 한식 음식점업 사업체 자료에 적용하여 분석과정에서 발생하는 통계 및 기술적 문제점들을 정리하고 해결 방법을 제시하고자 하였다. 특히 설문조사의 주관식 문항에 대한 응답 형태로 기록된 텍스트 자료에 한국어 텍스트 마이닝을 적용할 경우 발생하는 문제점들을 해결하기 위해, 기존 범용 사전이 아닌 특정 자료에 맞는 피드백 기반 사용자 사전을 구축하는 것을 제안하였다. 피드백 기반 사용자 사전은 수작업으로 구축되며 기준에 따라 편의의 문제가 발생한다는 단점이 있으나 기존 범용 사전의 한계를 보완하고 분석 목적을 효과적으로 달성하는 장점이 있다. 또한 텍스트 자료에 대한 마이닝 결과를 수치 자료로 구성된 구조화된 데이터베이스와 통합하고 군집분석 및 시각화 분석 등의 데이터 마이닝 방법들을 적용하여 전국 한식 음식점업 사업체에서 취급하는 대표 메뉴의 현황과 특성을 다각도로 탐색하였다. 이 결과들은 취급 메뉴의 변경을 고려하고 있는 현 업주 및 한식 음식점 창업을 계획하는 예비 업주들에게 메뉴 선택의 가이드라인을 제시하는 데 기여할 것이라 예상된다. 또한 관련 정부 부처가 영세 사업체들의 적절한 메뉴 변경 유도를 통한 폐업 방지 및 성공하는 창업을 위한 메뉴 선정의 유도 등의 정책을 마련하는데 도움이 될 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 477,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "을지대학교 대학원",
		"TITLE": "행위기반의 빅데이터를 이용한 사이버 테러 차단기술의 분석과 평가방법에 관한 연구 =(A)study on the analysis and evaluation methods of cyber terrorism blocking technology using behavior-based big data ",
		"AUTHOR": "김장일",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 정용규",
		"STORE_LOCATION": "을지대학교 대전캠퍼스 도서관",
		"ABSTRACT": "",
		"KEYWORD": "사이버사기,사이버테러,샌드박스,스미싱,악성코드,안드로이드,차단기술,차단앱,평가방법,행위기반 빅데이터"
	},
	{
		"ID": 478,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "빅 데이터와 TRIZ기법을 이용한 기술간의 창의적 융합 방법론 =An approach for creative convergence among technologies with bigdata and TRIZ ",
		"AUTHOR": "심영주",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김진화",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": "Bigdata,TRIZ,융합"
	},
	{
		"ID": 479,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "경북대학교 대학원",
		"TITLE": "SNS상에서 빅 데이터를 활용한 인포그래픽스 연구 ",
		"AUTHOR": "이상훈",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 이경용 참고문헌: p. 99-101",
		"STORE_LOCATION": "경북대학교 중앙도서관",
		"ABSTRACT": "급변하는 현대사회를 살아가는 현대인들에게 정보는 가장 중요한 요소이자 자산이다. 정보가 귀하고 정보의 공유나 수집 자체가 어려웠던 시기도 있었으나, 지금은 넘쳐나는 정보의 홍수 속에서 유용하고 가치 있는 정보를 축출하고 보다 효과적으로 수용하고 활용하는 것이 최대의 관건이 되었다. 또한 방대한 데이터와 정보의 분석을 통한 빅 데이터형식의 콘텐츠는 진화를 거듭하며 사회와 문화를 넘어 현대인 개개인의 성향과 삶의 패턴까지도 찾아내고 있다. 본 논문의 가치는 이러한 시대적 양상에 맞추어 빅 데이터에 내재된 가치와 가능성의 인식, 데이터의 정보화를 통한 소통과 운용의 극대화 연구에 있다. 이를 위해서는 소셜 네트워크 서비스에서 끊임없이 생성되는 방대한 데이터들이 만드는 패턴을 볼 수 있어야 하며, 패턴의 분석과 이해를 통해 데이터 생성원의 실체를 파악하고, 파악된 실체의 관련 정보와 데이터에 내러티브를 부여하여 소통의 극대화를 추구하는 인포그래픽스를 제안한다. 대중과의 보다 효과적이고 효율적인 커뮤니케이션을 위해서 인포그래픽스는 필수적으로 연구되어야 한다. 본 논문은 SNS상에서 수많은 빅 데이터의 조각들 가운데, 대학생 집단을 타겟으로 하여 대상들의 온라인을 통한 여가활용과 관심사의 연구를 통해 그 실체를 파악하고 분석하였다. 빅 데이터 분석 방법으로는 국내최대 포털인 네이버 그룹별 인기 검색어를 SNS상에서 분석했다. 분석 도구로는 데이터 마이닝 기반 서비스인 소셜 매트릭스와 펄스K를 사용해서 단편적인 결과가 아닌 다중적이고 복합적인 연관 키워드까지 분석했다. 빅 데이터를 분석한 결과, 대학생 집단의 쇼핑의 패턴에선 주체적이고 실용적인 소비보다는 유행에 따른 특정 브랜드 선호가 높은 양상을 보였다. 또한 대학생 집단의 종합 관심사의 분석에 의하면 방송, 연예관련 가십 중심의 기사에 관심을 가지며 대부분의 여가시간을 웹툰과 게임으로 보내고 있는 양상을 나타내고 있다. 게임과 웹툰의 경우, 해당키워드는 일일 모든 시간대에 이슈가 되고 있는 것으로 보아 여가시간의 활용에 있어서는 미디어기기를 통한 온라인 여가활동에 집착하는 경향이 있음을 알 수 있다. 정보와 데이터를 활용하는 인포메이션 디자인을 위해서는 방대한 데이터로부터 조직화 및 정보화된 데이터에 네러티브를 가진 인포그래픽스 타입의 디자인을 제시함으로써 사용자와의 보다 효과적인 소통을 이루어 낼 수 있어야 한다. 효과적인 정보전달을 위한 인포그래픽스의 고려할 사항으로 데이터나 정보를 단순히 시각화하는데서 끝나는 것이 아니라, 각종 데이터가 연계성을 갖고 의미 있는 정보로 생성되어 효율적인 정보 전달이 이루어질 수 있도록 스토리텔링으로 차별화 시켜야한다. 데이터의 성격과 내용에 부합하는 시각요소의 선택과 표현은, 전달하고자 하는 정보를 정보 이용자가 명확히 지각하고 이해할 수 있도록 해야 한다. 소셜 미디어 분야에서 쏟아지는 방대한 콘텐츠를 다루는 정보전달 매체로서는 인포그래픽스가 가장 강력하고 효과적이라고 판단된다.",
		"KEYWORD": "SNS,빅 데이터,인포그래픽스"
	},
	{
		"ID": 480,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "교통 빅 데이터를 활용한 고속도로 성능평가 방법론 개발 =Development of performance evaluation methodology using traffic big data in expressway ",
		"AUTHOR": "오인섭",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이철기",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "고속도로의 확대와 더불어 고속도로 운영 및 유지관리 효율 저하, 교통정체 및 혼잡, 교통안전 문제, 대기오염 등 환경문제, 이용자 서비스 불만 등 고속도로 운영상의 다양한 문제들이 지속적으로 발생하고 있으며, 해당 도로관리기관에서는 다양한 개선방안을 수립하여 추진하고 있다. 전반적으로 고속도로 정책 수립 및 효율적 고속도로 운영 유지관리를 위해서는 현재의 고속도로 상태를 명확히 진단하는 것이 가장 중요하며, 이를 위해서는 고속도로의 교통운영, 안전, 유지관리 등 다양한 분야와 다양한 시?공간적 범위에 대하여 도로의 성능진단이 우선적으로 필요하다. 또한, 도로관리기관의 측면에서 관리 대상도로의 성능을 상시적으로 평가함으로써 대적으로 부족한 도로의 성능분야에 대한 진단 및 개선을 통하여 최고의 도로 성능수준을 유지하게 함으로써 도로이용자에게 최고의 서비스를 제공할 수 있는 도구로 활용할 수 있도록 한다. 고속도로의 종합적 성능평가 방안의 필요성을 충분히 실감하고 있으나, 현재까지 활용할 만한 종합적인 성능평가 방안이 없는 실정이다. 따라서, 본 연구에서 국내 고속도로의 교통혼잡성, 교통안전성, 도로 유지관리 효율성, 이용자만족도 4개 성능평가 분야를 선정하고 해당 분야별 성능 지표를 개발하여 종합적으로 고속도로의 성능을 모니터링하고 진단 평가할 수 있는 성능평가 모형과 평가 방법론을 개발 제시하였다. 이러한 성능 지표 및 종합적 성능 평가 방법론은 단기적으로는 현황 진단 및 운영효과 분석 등에 적용할 수 있을 것으로 예상되며, 중장기적으로는 중장기 고속도로 정책수립, 건설?확장?개선 사업계획 수립, 투자우선순위 선정 등 다양한 고속도로 정책에 대하여 데이터 기반의 과학적인 의사결정 지원도구로서 활용이 가능할 것으로 기대한다.",
		"KEYWORD": "교통,빅데이터,성능평가"
	},
	{
		"ID": 481,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서강대학교 언론대학원",
		"TITLE": "인터넷 포털 카페의 역동적 여론 형성에 관한 연구 :빅데이터를 활용한 사회 네트워크 분석, 의미 연결망 분석,감성 분석을 중심으로 ",
		"AUTHOR": "김시영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 장용호",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "본 연구는 빅데이터 기술을 활용하여 국정원 대선 개입 의혹 사건 발생부터 국회 본회의 국정원 개혁안 통과 시점까지 1년 1개월간 국내 대표적인 인터넷 포털 카페인 <다음 카페>, <네이버 카페>에 ‘국정원’ 키워드로 이용자들이 작성한 게시글을 수집하였고 이를 바탕으로 인터넷 포털 카페의 역동적 여론 형성 과정을 살펴보았다. 인터넷 카페 이용자의 역동적 여론 형성 과정을 크게 네트워크 측면, 의미 구조 측면, 감성 측면에서 빅데이터 분석을 실시하였다. 연구 결과, 인터넷 포털 사이트 및 카페 속성별 게시글의 차이점을 발견하였다. 전체 게시글 중 다음 카페 게시글이 네이버 카페 게시글보다 월등히 많은 버즈량이 발생한 것으로 조사되었다. 이를 통해 인터넷 카페 이용자들의 역사적 경로 의존성이 존재하는 것으로 생각된다. 그리고 네이버 카페의 경우, 여성 카페인 ‘레몬테라스’에서 가장 많은 게시글이 작성되었고, 패션?의류?육아 카페 등 일반 취미 공동체로 모인 카페가 상위 카페로 조사되었다. 따라서 여성의 정치 참여가 더욱 활발해지고 삶-정치(Biopolitics)시대가 도래한 것으로 고려된다. 인터넷 카페 게시글의 의미 연결망 분석을 실시한 결과, 정치 성향에 따라 게시글 속 사용되는 핵심 단어의 출현 빈도와 중심성 값에 차이점을 확인하였다. 그리고 친정부 성향 카페와 정부비판 성향 카페가 상반된 의미 구조를 형성하고 있는 것으로 분석되었다. 또한, 유사한 의미 그룹이라고 할지라도 핵심 단어에 따라 다르게 해석되는 것을 확인하였다. 시간에 흐름에 따라 역동적 여론 형성 과정을 살펴본 결과, 인터넷 카페 게시글의 경우에는 국정원 대선 개입 의혹 사건 이후로 발생한 다양한 하부 이벤트에 민감하게 반응하기보다는 자신이 정해놓은 정치적 신념에 부합하는 이벤트만을 선별적으로 수용하였다. 그리고 국정원과 직접적인 관련이 없지만, 정치적 신념을 대변하는 다른 이벤트를 대입하여 게시글을 작성하는 것으로 분석되었다. 인터넷 카페의 네트워크 분석을 통해 정보의 생산과 확산에 큰 영향력을 발휘하는 정치 성향별 유력 카페와 다중자(Multiful self)를 추출하였다. 인터넷 게시글의 감성 분석을 실시한 결과, 친정부 성향 카페 게시글에서는 ‘분노’가 가장 출현 빈도가 높은 감성 범주로 나타났다. 그다음 순으로는 ‘슬픔’ > ‘기쁨’ > ‘놀람’ > ‘혐오’ 등으로 조사되었다. 정부 비판 성향 카페 게시글의 감성 범주는 ‘슬픔’ > ‘분노’ > ‘기쁨’ > ‘놀람’ > ‘혐오’ 순으로 상위 감성 범주가 분석되었다. 그리고 게시글 유형에 따라 ‘직접 작성의 경우’와 ‘퍼온 글인 경우’로 분류하여 감성 분석을 실시한 결과, 게시글 유형 간 상관관계가 유의미하게 나타났다. ※ 키워드 : 빅데이터, 인터넷 포털 카페, 국정원, 사회 네트워크 분석, 의미 연결망 분석, 감성 분석, 유력 카페, 다중자",
		"KEYWORD": "감성 분석(Sentimental analysis),국정원(Nation intelligence service),다중자(Multiful self),빅데이터(Bigdata),사회 네트워크 분석(Social network analysis),유력 카페(Influential cafe),의미 연결망 분석(Semantic network analysis),인터넷 포털 카페(IInternet portal cafe)"
	},
	{
		"ID": 482,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "순환신경망 기법을 이용한 도심도로 차량 통행속도 예측 =The prediction of vehicle speed passing urban road using recurrent neural network technique ",
		"AUTHOR": "최연호",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 조완섭",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "교통 혼잡으로 인한 막대한 교통 혼잡비용이 발생하고 있다. 이러한 교통 혼잡비용을 해결하기 위해 각 지자체에서는 지능형교통 정보시스템(ITS)을 도입하였으며, 이를 통해 다양한 종류의 교통 빅데이터가 축적되고 있다. 최근에는 이 데이터를 기반으로 다양한 통계적 분석을 수행하고 있지만 기존의 통계적 분석은 비선형적인 변수와 입력변수가 고차원이 될수록 예측의 정확성이 낮아지는 문제점이 있다. 이러한 통계적 기법의 한계를 해결할 수 있는 딥러닝 기법이 각광 받고 있다. 본 논문에서는 딥러닝을 이용하여 통행속도를 예측하는 방법을 제안하고, 이를 청주시 교통현황 분석에 활용한다. 구체적으로 청주시 교통 빅데이터 분석 시스템의 DSRC 로그 데이터를 이용하여 데이터 셋을 구성하였고, 순환 신경망 기법을 적용하여 학습과 예측을 수행하였다. 제안된 예측기법의 정확도를 평가하기 위해 청주시내 5개 도로, 56개 구간에 대한 예측을 수행하였으며, 그 결과 예측치의 평균 절대오차 비율이 평균 7%미만으로 나타나 정확도가 높은 기법임을 확인하였다.",
		"KEYWORD": "DSRC,LSTM,RNN,교통 빅데이터,딥러닝,속도예측"
	},
	{
		"ID": 483,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "빅데이터를 활용한 이상 징후 탐지 및 관리 모델 연구 ",
		"AUTHOR": "권영백",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김인석",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "APT(Advanced Persistent Threat)공격은 기관, 기업의 정보통신 설비에 대한 중단 또는 핵심정보의 획득을 목적으로 장기간 IT인프라, 업무환경, 임직원 정보 등의 다양한 정보를 수집하고, 이를 바탕으로 제로데이 공격(Zero-day attack), 사회공학적기법 등을 이용하여 공격을 실행한다. 악성 시그니처 탐지 등의 단편적인 사이버 위협대응 방법으로는 APT 공격과 같이 고도화된 사이버 공격에 대응하기 어렵다. 본 논문에서는 APT 공격 대응 방안 중 하나로 이종 시스템 로그 (Heterogeneous System Log)를 빅데이터로 활용하고, 패턴기반 탐지 방법과 이상 징후 탐지 방법을 병합하여 사이버 침해시도를 탐지하는 모델을 제시하고자 한다.",
		"KEYWORD": "Anomaly Detection,APT"
	},
	{
		"ID": 484,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "반도체 생산에서 시계열 빅데이터를 사용한 기계학습 기반 실시간 이상징후 예측 알고리즘 개발 =Online fault prediction using machine learning with time-series big data in semiconductor wafer production ",
		"AUTHOR": "김대희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이기천",
		"STORE_LOCATION": "한양대학교 중앙도서관",
		"ABSTRACT": "대량 생산 체제인 현대 산업에서는 장비(설비)의 유지 보수 관리가 매우 중요하다. 그 이유로는 대량 생산체제의 지속적인 유지와 양질의 제품을 일정하게 생산하기 위함이다. 그 중에서도 특히 반도체 생산 공정은 더욱더 중요한 것이, nm 크기의 미세공정과 초 대량 생산이 이루어 지기 때문이다. 그러나 아직까지 많은 산업 현장에서는 대량 생산 장비의 유지 보수가 정기적인 유지 보수(계획 정비)와 문제 발생 이후의 유지보수(고장 정비)로 나누어져서 수행된다. 이는 경험적인 측면에 의지하는 유지보수의 형태로써, 설비의 고장 징후가 발생함을 예측하는 방법은 아니다. 따라서 대량 생산체제의 산업현장에서는 보다 많고 안정적인 생산량과 품질을 유지하기 위해서는 설비 장치의 이상징후를 사전에 파악하여 그 이상 징후에 맞는 조치를 취하게 된다면 현재의 유지 보수 방법에 부가되는 우수한 설비 관리 방법론이 될 여지가 크다. 본 연구는 설비의 변수 등에서 나타나는 대량의 변수를 이용하여 기계학습과 시계열 분석적인 방법에서 접근하여 설비가 고장정지를 발생하기 일정 시간 이전에 고장을 예측하여 생산관리/계획과 설비 보수에 도움이 되고자 한다.",
		"KEYWORD": "기계학습 시계열 분석,반도체 장비 이상 예측 알고리즘,실시간 장비 고장정지 예측"
	},
	{
		"ID": 485,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한세대학교 대학원",
		"TITLE": "빅데이터를 활용한 제조공정 결함 예측에 관한 연구 =(A)study on defects prediction of production process using big data ",
		"AUTHOR": "서정정",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 신승중",
		"STORE_LOCATION": "한세대학교 도서관",
		"ABSTRACT": "최근 경제의 패러다임은 정보화 시대를 넘어 ICT기술과 기존 산업 간의 창조적 결합으로 새로운 기술·시장 가치를 창출해 보고자 하는 동기에서 시작하였다. 웨어러블 디바이스, 3D프린터, 지능형 노봇, 자율주행자동차 등의 새로운 기술을 발달하면서 시장에 신속한 보급과 인터넷, 소셜미디어간의 연결은 데이터량이 기하급수적으로 증가하고 있다. 이처럼 증가된 데이터는 물류, 유통, 제조 산업에 큰 변화를 주면서 데이터는 경제적 자산이 될 수 있는 빅데이터(Big Data) 시대를 맞이하게 되었다. 본 연구는 PCB와 반도체의 제조 공정에 사용자 편의성이 극대화된 소프트웨어를 통해 공정 이상의 원인이 되는 설비변수를 즉시 감지하여 사용자 API에 피드백 하는 시스템을 구축하는데 빅데이터 도입 관련 방법론을 제시하였다. 또는 빅데이터를 활용한 기타 산업군의 특성을 조사해 빅데이터의 도입 과정, 활용 방안 및 거둔 성과에 대한 연구를 통해 빅데이터의 활용법을 검증한다. 비록 산업이 다르겠지만 분석 목적이 명확해지면 거둔 성과는 크겠다는 것을 입증하기 위해 이 논문의 연구 목적 이였다.",
		"KEYWORD": "ICT,IoT,결함,빅데이터,실시간 예측,제조공정"
	},
	{
		"ID": 486,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "빅데이터를 활용한 해외여행상품의 구성요소와 해외여행객의 지각된 가치 분석 :베트남 여행을 중심으로 ",
		"AUTHOR": "김동완",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 설훈구",
		"STORE_LOCATION": "부경대학교 도서관",
		"ABSTRACT": "As the economy grows and the desire for travel increases, the number of international travelers is renewing its peak every year. For this reason, the domestic travel industry enjoys a boom, but it lacks qualitative growth compared to quantitative growth. So, This study examined the components of travel products and the perceived values of travelers and the purpose of this study is to activate the tourism industry by increasing the qualitative value of travel products. Data in this study are collected from major portal sites in Korea, focusing on Vietnam which has the highest growth rate and the most number of Korean travelers in South - East Asia. This study analyzed the components of Vietnam travel products, the perceived values and the influence of these factors. The results are summarized as follow. First, the Vietnam travel showed a lot of family free travels around Da Nang. Second, the factors of `tourism activities` and `tourist attractions` were identified as the main factors of Vietnam travel products. Third, the perceived value formed in the travel to Vietnam showed positive parts and emotional value factors. Fourth, the clusters formed in Vietnam travel have a large cluster that considers before traveling to Vietnam and three small clusters that include `Package-related cluster`, `Food-related cluster` and `Experience-related cluster`. Fifth, comparing the two most influential values formed in Vietnam with the components of travel products, it was found that there are many positive parts overall. Sixth, this study was able to measure the factors measured in a survey of traditional travel products and perceived value using survey method through portal sites. The results of this study provide a way to create travel products and to use them as marketing tools by researching the Vietnam travel products and the perceived value of tourists. In addition, this study contributes to the presentation of new methodologies by analyzing the components of travel products and the perceived value of travelers based on the results of previous studies.",
		"KEYWORD": null
	},
	{
		"ID": 487,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "빅데이터를 활용한 시큐어 코딩 취약점 분석 시스템 아키텍처 설계 =Secure coding vulnerability analysis system architecture design using big data ",
		"AUTHOR": "민정현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조인휘 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 35",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "소프트웨어 활용의 중요성과 의존성은 지속적으로 증가하고 있다. 이로 인해 소프트웨어의 보안성 확보와 소프트웨어 개발보안 적용의 중요성도 증가하고 있다[1]. 여러 가지 보안 위협들 중에서 소프트웨어 취약점으로 인한 보안 사고의 비중이나 사고 발생이 증가하고 있다. 소프트웨어에 취약점들의 과반수 이상은 소프트웨어 개발 과정의 코딩 오류로 비롯하는 것으로 알려져 있다. 현행 보안 활동으로 구현 단계에서 소스코드를 정적 분석하여 취약점을 분석하고 운영 단계에서 보안교육, 보안계획, 보안설계 평가 등의 보안활동은 이루어 지고는 있지만 운영 단계에서의 소프트웨어 소스코드의 직접적인 보안 활동에는 미흡한 점이 있다. 이에 본 제안은 코딩오류를 최소화 하여 소프트웨어 취약점 예방을 위한 소프트웨어 개발보안을 적용하기 위해 물리적 Source Code를 Big Data Analysis를 활용 하여 실시간 수준으로 취약점을 분석하는 아키텍처 설계 절차를 설명 하고 있다. 또한 취약점 분석 목록을 바탕으로 하여 정보화 시스템의 개발 소소를 분석하여 적용 적합성, 침해 심각성, 침해 가능성, 신뢰성/품질향상, 수정비용 등의 평가 항목을 분석하여 개발된 시스템 특성에 최적화된 시큐어 코딩 룰를 적용할 수 있도록 제시하고 있다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 488,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "계명대학교 대학원",
		"TITLE": "소셜미디어 빅데이터로 분석한 항공사 이미지 변화 :K항공 램프리턴 사건 전·후를 중심으로 ",
		"AUTHOR": "홍지숙",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 오익근",
		"STORE_LOCATION": "계명대학교 동산도서관",
		"ABSTRACT": "To survive in a keen competition, it is necessary for corporations to build good corporate images to consumers. Many corporations have tried to enhance their images in the market places. The purpose of this study is to suggest some implications to improve and enhance corporate image after the scandal. This study is focused on the image difference of the airline before and after ramp return called nuts scandal of K airline through big data analysis. The big data were collected by text mining approach and co-occurrence frequency analysis and semantic network analysis were conducted to analyze the collected data. The result showed that most of the data about K airline were related to flight routes and schedules, cabin crews and recruiting before the scandal. Previous image of K airline was presented as the corporation that has been socially responsible and ethical and it has corporate competitiveness in the market place. But after the nuts scandal, the data about K airline were jumped rapidly than ever before and the scandal caused an increase of public’s interest in K airline. The data related to the executives and the incidents dramatically increased after the scandal and the data presented negative images about K airline. The recent scandal is creating a negative impact on K airline corporate image. K airline should make an effort to clean up its negative image and seek ways to boost competitiveness of the business. This study suggested the implication in crisis management by analysing public’s image difference of K airline before and after the scandal on social media channel through big data analysis.",
		"KEYWORD": "빅데이터,소셜미디어,항공사 이미지"
	},
	{
		"ID": 489,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "대구경북과학기술원",
		"TITLE": "(A) multilayer networks analysis for mining quantification rules from big proteomics data =빅 데이터에 기반하여 단백질체학 데이터에서의 수량화 규칙을 찾기 위한 다층 네트워크 구축과 분석 ",
		"AUTHOR": "SuhyoenJin",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 490,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 교육대학원",
		"TITLE": "빅데이터를 이용한 청소년의 통신언어 사용 양상 연구 :네이트판 10대 게시판을 대상으로 ",
		"AUTHOR": "조혜리",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정명교",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "This research aims at the aspects of usage of the internet communication language of adolescents. To overcome the quantitative limitation on existing research targets of the internet communication language, 20 millions posts and replies of Nate Pann, popular portal open board, are targeted in this research process. This research proposes environmental suitability involved with data collection and basic concept of program running process of Nate Pann service. Next, with result of data collection, we propose explanation about raw data, explanation about modification of collected raw data and the annual result. Through this result, we observe that there is no difference of word top ranking list from year 2013 to 2016. adolescents most frequently use word `진짜(Jin-ch`a)` and `걍(Gyang)` as a communication language is also highly frequently used. Targeting the communication languages which take highest percentage in collected data, we figure out the change of communication language by annual percentage changes comparison table and we overlapped and modified the data for the analysis of the changes of certain communication languages. With the result by tracking each communication languages` time of creation and analyzing it annually, we determine that communication languages are changing at the individually different speed, and that similar or opposite meaning and the same time creation don`t show the same aspect of usage of internet communication language of adolescents.",
		"KEYWORD": "adolescent,annual changes,big data,internet communication language,posts"
	},
	{
		"ID": 491,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "건국대학교 부동산대학원",
		"TITLE": "빅데이터를 활용한 백화점형 할인점의 특성 연구 :(A)study on characteristics of department store type discount store using big data :소비자 형태 및 입지특성 중심으로 =focused on the consumer behavior and location characteristics ",
		"AUTHOR": "김현동",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이상엽",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "본 연구는 우리나라 유통구조의 변화와 재편 과정에서 출현한 백화점형 할인점의 소비자 행태 특성을 분석하여 그 성격을 규명하고 그 입지특성을 파악하는 것이다. 또한 “21세기 원유”, “산업혁명기의 석탄”에 비유되는 빅데이터를 부동산 관련 연구에 활용해 보고자 하였다. 유통구조의 변화와 재편 과정에서 출현한 백화점형 할인점은 “할인백화점”, “도심형 아울렛”, “백화점형 아울렛”, “백화점형 할인점” 등 다양하게 분류되며 업태를 명확하게 분류하고 있지 못하다. 그러나 본 연구는 우리나라 실정에 맞게 백화점과 할인점 사이에서 전략적 소매업태 포지셔닝을 취하고 있는 백화점형 할인점을 유통의 신업태로 분류하였다. 백화점형 할인점의 소비자 행태는 성별, 연령별, 이용 빈도수, 구매상품의 종류, 소비금액, 주 구매 시간대 6가지 특성요인을 도출하여 기존 백화점과 할인점의 소비행태 특성요인을 상호 비교하여 분석하였다. 분석결과, 백화점과 할인점이 남자 35%, 여자 65%의 구성비인데 백화점형 할인점은 남자 9.7%, 여자 90.3%로 성별 구성비의 뚜렷한 차이가 있고, 연령별 구성비는 백화점과 백화점형 할인점이 40대가 가장 많은 반면 할인점은 30대가 가장 많은 연령대로 차이점이 있고, 이용 빈도수는 백화점과 할인점이 월2-3회와 2개월2-3회의 이용빈도 수가 50-70%를 차지한 반면 백화점형 할인점은 2개월 이상이 50-60%를 차지하여 백화점형 할인점이 백화점과 할인점 보다 이용빈도수가 낮다는 것을 분석하였다. 구매상품의 종류는 백화점은 의류상품이 70-85%이고 할인점은 음식료(식품)가 76.9%이며, 백화점형 할인점은 의류상품이 50.5%, 식품(음식료)이 20%를 차지하고 있어 백화점이 의류상품 중심이고 할인점은 음식료 중심인 반면 백화점형 할인점은 백화점과 할인점의 중간 형태의 소비행태를 보이고 있다. 소비금액은 연구대상 4개 점포의 평균 소비금액이 41,107원이며, 백화점 84,534원, 할인점 45,703원으로 백화점과 할인점보다 평균 소비금액이 낮은 것으로 분석되었다. 주 구매 시간대는 백화점, 할인점, 백화점형 할인점 모두 12시-5시 사이에 50% 이상의 비중을 차지하여 주 구매 시간대에 공통점을 발견할 수 있다. 그러나 12시 이전은 백화점이 5%, 할인점이 6.6%인 반면 백화점형 할인점은 17.61%의 비율을 보여 상대적으로 12시 이전 구매 비중이 높다. 이는 백화점형 할인점이 백화점 보다 영업개시 시간이 30분 빠른 오전 10시인 것이 주요 요인으로 분석된다. 백화점형 할인점의 입지특성을 분석하기 위하여 입지요인을 인구요인, 경제적요인, 접근성요인, 경쟁요인으로 분류하고 독립변수로 인구요인은 1차상권내 인구수, 1차상권내 세대수를, 경제적 요인에는 점포 입지 해당행정구역인 기초자치단체 시·군·구의 주택 자가소유율, 1인당 지방세납부액, 세대당 자동차보유율을, 접근성요인에는 도로의 유무, 지하철 유무, 버스노선 수, 영업면적, 주차대수를, 경쟁요인에는 1차상권내 경쟁업체의 수로 세분화하였다. 각 독립변수와 세이브존 4개점의 실제 매출액을 종속변수로 하여 다중회귀분석방법을 통해 상관관계를 분석하였다. 분석결과, 백화점형 할인점은 인구요인의 인구수, 세대수, 접근성요인의 지하철 유무, 버스노선 수, 경쟁요인의 경쟁업체수에서는 상당히 높은 유의관계를 나타냈으며, 경제적 요인의 주택자가소유율, 1인당 지방세납부액, 세대당 자동차보유율, 접근성요인의 도로의 유무, 영업면적, 주차대수는 무의한 관계로 분석되었다. 본 연구도 포인트 적립카드의 회원정보와 매출정보인 빅데이터를 활용함에 있어 기본 데이터라고 할 수 있는 포인트 카드 “회원가입신청서”에 입력 시키는 입력정보의 한계와 정보 입력 시 기입항목을 누락 시키거나 정확하게 입력하지 않을 경우 데이터가 정확하지 않을 수 있다는 점과 본 연구의 대상인 백화점형 할인점의 표본을 지방백화점과 중소백화점에서 업태를 변경한 세이브존의 4개점만으로 한정하여 연구함으로써 독립변수의 샘플 수에 한계가 있어 각 점포별 입지의 특성을 분석하지 못하였고, 세이브존의 4개점의 입지요인만으로 백화점형 할인점의 입지특성이라고 하는 대표성의 문제가 있을 수 있는 한계가 있으나 “21세기 원유”, “산업혁명기의 석탄”에 비유되는 빅데이터를 부동산 관련 연구에 활용하였다는 점과 유통의 틈새시장인 백화점형 할인점에 대한 유통의 새로운 한 업태로 분류하여 백화점형 할인점의 소비행태와 입지특성을 연구하였다는 점에서 의미 있는 연구라고 할 수 있겠다.",
		"KEYWORD": "백화점형 할인점,빅데이터,소비자 행태,입지특성"
	},
	{
		"ID": 492,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "주거환경 및 건축현황 관련 공간정보 빅데이터를 이용한 도시재생지역 선정평가법의 개발 :서울시 주거지역을 중심으로 ",
		"AUTHOR": "안상미",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 孔正植 참고문헌: 장 84-85",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 노후주택의 정비수요가 점점 증가하고 있으며 이를 해결하기 위해 다양한 도시재생사업이 진행되고 있다. 현재 시행중인 주거지재생 관련 사업들을 살펴본 결과, 크게 두 가지의 문제점이 발생하고 있었다. 도시계획적 측면으로는 기반시설의 부족이나 타 지역과의 연계가 부족한 문제가 발생하였고, 지역별현황 측면으로는 노후도에 대한 명확한 판단이 모호해지고 수익을 위한 난개발이 진행되는 문제가 있었다. 단지 물리적 기준 충족에 의해서 사업의 시행여부를 판단하는 것이 아니라, 도시여건과 지역적 현황을 정확하게 판단하여 재생지역을 선정하고, 정책의 방향을 설정할 필요가 있다. 도시재생지역 선정에는 도시계획적 측면과 지역별현황 측면을 모두 반영한 지역 분석이 필요하며, 이에 맞는 선정평가법이 요구되고 있다. 본 논문에서는 공간정보 빅데이터를 이용하여 도시계획적 측면으로는 주거환경등급을, 지역별현황 측면으로는 건축현황등급을 산출할 수 있도록 각 지표를 재선정하고 두 가지 모두를 반영한 선정평가법을 개발하였다. 서울시를 대상으로 새로운 선정평가법을 적용하여 도시재생 우선순위 지역을 선정하고 실제 진행중인 도시재생사업과의 비교를 수행하였다. 더불어 각 지표들과 최종 등급 결과와의 상관관계 분석을 통해 변수들 간의 관련성 정도를 판단하였다. 이를 활용하면 평가체계에 따른 도시재생지역의 선정 이후 실제 사업을 계획하는 단계에서도 재생의 목적 및 사업의 방향성을 결정하는데 용이할 것이며, 각 단계별 연계를 통해 불필요한 분석을 반복하는 일이 줄어들 것으로 예측이 된다.",
		"KEYWORD": "공간정보,도시재생"
	},
	{
		"ID": 493,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충남대학교 대학원",
		"TITLE": "빅데이터에서 모분포 형태에 따른 t통계량에 대한 영향함수의 성능에 관한 연구 ",
		"AUTHOR": "김소정",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김홍기 참고문헌 : p. 39-40.",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "In big data sets, we analyze how the individual observations are far from the center of the whole data and the data affect the analytical statistic, and how the effect varies according to the shape of the population distribution. The effect on the t statistic for the hypothesis test for the central parameter of the model distribution is derived. In this paper, we try to compare and analyze how each influence function of statistic is operated in big data which is repeatedly observed more than 300 times in each distribution, assuming that the distribution is in one of three different distributions. ??As a result of the analysis, it was confirmed that the equation that predicts the change of the t statistics in each distribution was satisfied and it could be used regardless of the underlying distribution. In addition, the change of the t statistic value through the influence function at the extreme values ??of the distribution is confirmed, and the performance of the influence function is very satisfactory.",
		"KEYWORD": null
	},
	{
		"ID": 494,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "순천대학교 대학원",
		"TITLE": "하둡에서 태그를 이용한 빅데이터의 동적 분류에 관한 연구 =(A)study on dynamic classification of big data on Hadoop using tag ",
		"AUTHOR": "김승현",
		"REGION": "전라남도",
		"PROFESSOR": "순천대학교 논문은 저작권에 의해 보호받습니다. 지도교수:김원중",
		"STORE_LOCATION": "순천대학교 도서관",
		"ABSTRACT": "In last years, Hadoop has become a basic data processing infrastructure in the field of Big data processing. Due to design limitations of Hadoop, it is difficult to efficiently classify for real-time processing and identify information of data. File in HDFS modification is not possible due to a feature of WORM-based. Also a very large block size is inefficient to process a small file. MapReduce to perform parallel analysis on a cluster is not suitable for real-time processing because the analysis proceeds around the batch processing. In this paper, we proposes a method of real-time processing and dynamic classification of Big data using tags. The tagged data can be used to the real-time processing. In addition, it can assist batch processing of MapReduce. The proposed method to lower memory usage of Hadoop name node, and when performed MapReduce, it was effective to reducing the number of mappers generated. In addition, it was confirmed that the tags that are useful for real-time processing and dynamic classification.",
		"KEYWORD": null
	},
	{
		"ID": 495,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "스마트카드 빅데이터를 이용한 대중교통 편의성 분석 =Analysis of public transportation convenience using smart card big data ",
		"AUTHOR": "문현구",
		"REGION": "경기도",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김상국 참고문헌 : p.54-56",
		"STORE_LOCATION": "경희대학교 국제캠퍼스 도서관,경희대학교 중앙도서관",
		"ABSTRACT": "Recently, many smart devices are used widely and these devices accumulate a large amount of data. Since ICT(Information & Communication Technology), which enables to analyze unstructured data. has been developed in transportation, there has been much effort to provide better service such as civil planning and personalized recommendation. A study on the change of transportation use in severe weather condition was conducted to understand it by the time and regional groups. Another example of the study is determining late-night bus route by utilizing the location data of passengers’ cellular phone. In this paper, the transportation convenience index based on the smart card big data is presented to understand current transportation systems according to regions. The objective is achieved by utilizing real-world big data. Previous studies presented the analysis of transportation convenience based on traffic facilities. These studies did not provide the measurement for transportation convenience considering passengers’ movement data. Therefore, a new index is presented in this study to reflect how passengers actually feel the convenience of transportation in real world. In this study, GeoHash technique is used to divide the regions in the zone since it maintains adjacency of space well. Also, passengers’ movement information such as moving distance, moving time and how many movements between zones is deducted by using data attributes as follows: initial boarding time, final getting off time, initial boarding location, and final getting off time. Based on the insights above, the realistic transportation convenience index is presented. A concrete example of transportation data from 12th of March to 18th of March is given to understand the index better. The contribution of this study is providing the transportation convenience index by the regional zones based on the factors that passengers actually experience. And furthermore, this index can be used in the area such as a traffic policy or local policy.",
		"KEYWORD": "대중교통,빅데이터,스마트카드,편의성"
	},
	{
		"ID": 496,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "성신여자대학교 대학원",
		"TITLE": "기업경영에서의 빅데이터의 인식요인과 활용 및 효과에 관한 연구 ",
		"AUTHOR": "윤희정",
		"REGION": "서울",
		"PROFESSOR": "성신여자대학교 논문은 저작권에 의해 보호받습니다. 지도교수:심현철 권말에 참고문헌 및 영문초록 수록",
		"STORE_LOCATION": "성신여자대학교 도서관",
		"ABSTRACT": "하루가 다르게 변화 발전하는 정보기술을 이해하고 적용하는 것은 기업에게 매우 중요하다. 조직의 리더는 빅데이터가 나타내는 전략적 위협뿐만 아니라 잠재적인 기회를 인식하고, 기업과 관련한 빅데이터의 활용과 효과를 평가할 필요가 있다. 본 연구는 기업경영에서 빅데이터를 도입하여 활용하는데 있어 조직적 측면, 기술적 측면, 환경적 측면에서의 주요요인이 기능별 활용성과 비즈니스 효과에 미치는 영향을 분석하였다. 본 연구모형은 조직적 측면(CEO 및 구성원의 인식, 교육 및 인재육성), 기술적 측면(시스템 도입, 데이터 유형), 환경적 측면(투자환경, 인프라환경), 기능별 활용성(공급망분야, 생산활동 분야), 비즈니스 효과(고객이해, 예측성, 생산성)로 구성되었다. 조직적 측면에서의 가설 검정 결과, ‘CEO 및 구성원의 인식’은 ‘기능별 활용성’에 영향을 미쳤고, ‘교육 및 인재육성’은 ‘기능별 활용성’과 ‘비즈니스 효과’에 영향을 미쳤다. 또한 빅데이터를 이용하여 공급망 분야나 생산활동 등에 활용하는데 있어 CEO 및 구성원의 인식보다 교육 및 인재육성에 대한 인식이 더 많은 영향을 미치는 것으로 나타났다. 기술적 측면에서의 가설 검정 결과, ‘시스템 도입’은 ‘기능별 활용성’과 ‘비즈니스 효과’ 모두에 영향을 미쳤다. 기업의 빅데이터에 대한 인식을 기술적 측면에서 살펴보면, 공급망 분야나 생산활동 기능에서 빅데이터를 활용하거나 비즈니스 효과를 기대하는데 있어 정형/비정형과 같은 데이터 유형보다는 분석사례가 풍부하고, 프로그램이 안정적이며, 처리속도 및 제품인지도가 좋은 기술, 개발형태에 영향을 받는 것으로 나타났다. 환경적 측면에서의 가설 검정 결과, ‘인프라 환경’이 ‘기능별 활용성’ 및 ‘비즈니스 효과’에 영향을 미쳤다. 이는 빅데이터 관련 투자나 실행 정도, 예산 규모보다는 지속적인 지원과 관리를 통해 기업 전반에 걸쳐 빅데이터 활용을 위한 인프라를 조성하는 것이 중요한 요인임을 나타낸다. 빅데이터를 활용한 ‘기능별 활용성’은 ‘비즈니스 효과’에 영향을 미치는 것으로 나타났다. 이는 공급망 분야(구매 및 조달, 유통 및 배송, 로지스틱스)와 생산활동(원가관리, 공정관리, 품질관리, 제품개발 및 설계)에 대한 활용성이 고객이해, 트렌드분석, 수요예측, 위기관리, 적시성, 매출증대, 생산성 향상과 같은 비즈니스 효과에 영향을 미친다는 것을 나타낸다. 업종별/규모별/직책별 조절효과 분석을 한 결과, ‘교육 및 인재육성’에서 업종별 조절효과가 나타났고, 제조업보다는 서비스업이, 대기업보다는 중소기업이, CEO 및 임원진보다는 일반관리자 및 실무자에서 영향을 미치는 요인들이 더 많이 나타났다. 기업경영에 있어 빅데이터는 새로운 기회와 도전이 될 것이다. 그러나, 빅데이터에 대한 사회적 관심에 비해 이를 제대로 활용하고 성과를 본 기업들에 대한 사례는 많이 알려져 있지 않다. 빅데이터는 기업에게 있어 또 다른 정보시스템의 도입이 아니라, 기업이 보유하고 있는 데이터, 세상에 존재하고 있는 방대하고 다양한 형태의 데이터들 속에서 기업에게 필요한 진정한 가치를 찾는 것이고, 그러한 능력을 갖춘 기업이 급변하는 경영환경 속에서 경쟁우위를 갖게 될 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 497,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "빅데이터를 통한 주가예측의 메타 분석적 연구 ",
		"AUTHOR": "이수현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "기계학습 알고리즘,빅데이터와 주가예측,오피니언마이닝,텍스트마이닝"
	},
	{
		"ID": 498,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "동의대학교 대학원",
		"TITLE": "빅데이터를 활용한 유치원 교사에 대한 사회적 인식 연구 ",
		"AUTHOR": "조효미",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 전윤숙 참고문헌: p. 124-142",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "본 연구의 목적은 신문과 블로그, 카페에 나타난 유치원교사와 관련된 빅데이터 분석을 통해 현재 우리사회가 인식하고 있는 유치원교사에 대해 알아보는데 있다. 이를 위한 구체적인 연구문제는 다음과 같다. 1. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드는 무엇인가? 1-1. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드의 빈도수는 어떠한가? 1-2. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드의 중요도는 어떠한가? 2. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드의 관계 구조와 특징은 어떠한가? 2-1. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드 두 단어간 관계 빈도수와 방향성은 어떠한가? 2-2. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드의 관계 중 심성은 어떠한가? 2-3. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드간의 군집은 어떻게 형성 되는가? 3. 신문, 블로그, 카페에 나타난 유치원교사 관련 주요 키워드의 내용은 어떠한가? 본 연구 목적을 달성하기 위한 연구절차는 다음과 같다. 2016년 한해 신문, 블로그, 카페에 나타난 유치원교사 관련 데이터 총 4,937건을 Textom 프로그램을 이용하여 수집하였다. 수집된 데이터는 키워드 빈도분석과 관계분석을 통해 키워드 관계 구조와 특징 및 키워드 형성 구조를 파악하였다. 또한 수집된 데이터의 내용을 분석하였다. 그 결과는 다음과 같다. 첫째, 유치원교사와 관련하여 수집된 자료에 대해 주요 키워드 빈도분석결과, 전체 데이터와 대중매체별 데이터 모두‘유치원’,‘교사’,‘교육’이 높은 빈도로 언급되었다. 그러나 상위 50개의 키워드 내에서는 전체 데이터와 대중매체별 데이터가 각각 다른 키워드가 나타났다. 이는 대중매체별 특성과 목적에 따라 유치원교사에 대해 언급 되어지는 내용에 차이가 있음이 밝혀졌다. 둘째, 유치원교사와 관련된 주요 키워드 관계 분석 결과, 전체 데이터와 대중매체별 데이터 모두 다른 형태의 네트워크가 형성되었다. 연결 중심성은 전체 데이터에서는 ‘교육’이 대중매체별 데이터에서는 ‘유치원’이 높은 중심성을 보였다. CONCOR분석 결과, 전체와 대중매체별 데이터 모두 4개의 군집이 형성되었지만 군집을 이루는 키워드는 다른 양상을 보였다. 전체 데이터와 신문, 카페 데이터에서는 환경요인에 대한 군집이 나타난 반면 블로그 데이터에서는 전문적 자질에 대한 군집이 많이 나타났다. 셋째, 데이터 분석을 통해 수집된 키워드의 내용 분석 결과 각 대중매체 모두 사회경제적 특성, 업무적 특성, 윤리적 특성의 내용으로 구성되어 있음이 밝혀졌다.",
		"KEYWORD": null
	},
	{
		"ID": 499,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "아주대학교 교통·ITS대학원",
		"TITLE": "유동인구 빅데이터를 활용한 고속도로 휴게소 혼잡지표 개발 =Development of a congestion index for expressway service areas using floating population big data ",
		"AUTHOR": "김해",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 윤일수",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "고속도로 휴게소는 고속도로의 교통 소통과 안전 측면에서 매우 중요한 시설로 휴게소에 대한 혼잡을 고속도로 이용객에게 사전에 알려주어 적절히 분산되도록 관리하는 교통운영 전략이 필요하나, 휴게소를 진출입하는 차량이나 이용인원을 측정할 수 있는 수집장치와 데이터의 부재로 인해 휴게소에 대한 혼잡도 측정과 관리가 적절하게 이루어지지 못하였다. 본 연구에서는 민간 빅데이터인 이동통신사의 유동인구 빅데이터를 활용하여 고속도로 휴게소 혼잡지표를 개발하였다. 휴게소 혼잡지표로 휴게소 유동인구를 휴게소 건물면적으로 나눈 ‘휴게소 밀도’와 휴게소 유동인구를 휴게소 수용인구로 나눈 ‘휴게소 유동인구 V/c’, 두 가지를 대안으로 개발하였으며, 이 중 이해가 용이하고 용량값과 비교할 수 있는 ‘휴게소 유동인구 V/c’를 휴게소 혼잡지표로 최종 선정하였다. 휴게소 혼잡도 등급은 이용자들이 직관적으로 이해하기 쉽도록 ‘여유’, ‘약간혼잡’, ‘혼잡’의 3단계로 설정하였으며, 휴게소 혼잡지표의 분포를 고려하여 지표값이 50% 이하인 경우에는 ‘여유’, 50~70%인 경우에는 ‘약간혼잡’, 70% 초과인 경우에는 ‘혼잡’으로 등급 기준값을 설정하였다. 더불어 본 연구에서 개발된 휴게소 혼잡지표를 고속도로 교통 관리와 휴게소 관리에 활용하는 방안을 제시하였으며, 지속적으로 휴게소 혼잡도 분석과 정보제공에 활용하기 위한 휴게소 혼잡지표 발전방안을 같이 제시하였다.",
		"KEYWORD": "고속도로,빅데이터,혼잡도,혼잡지표,휴게소"
	},
	{
		"ID": 500,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "동국대학교 경찰사법대학원",
		"TITLE": "빅데이터를 활용한 경찰의 범죄예측 활성화방안 ",
		"AUTHOR": "김경원",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최응렬",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "Police is in charge of various crime control activities such as crime prevention and investigation to save peoples’ lives and properties. Thanks to technology development, police forces are further developing various techniques in preventing and predicting crimes. Now we have witnessed an increasing global concern of big-data analysis for the effective crime control in many advanced states. Especially, South Korean police agency has adopted big data analysis program named Geographic Profiling System (Geopros) since April 2009 as a measure to effectively respond to various violent crimes. As a new technology, Geopros is a mixture of Geographic Information System (GIS) and crime information contributing to the various investigation activities such as crime area analysis, suspect analysis, and serial criminal residence expectation. This research is aiming at examining the current status of big-data analysis to prevent and expect crimes by reviewing the effectiveness of the current Geopros system in order to provide intuitions about the development measure of this new technology by applying the concept of big-data analysis. To serve this purpose, this paper provides various diagnosis on the current status of big-data application in crime control while examining foreign cases for the effective crime prevention activity. And I also verify the effectiveness of the Geopros development initiative which has been completed in January 2004. To analyze the current utilization status of Geopros, this paper carries out various literature researches of relevant foreign cases and a survey of police officers currently using Geopros. This paper identifies the latent problems of the current Geopros system divided by three categories: development initiative; utilization level; and information opening status. As a result, this research provides various suggestions for the enhancement of the current Geopros system for the effective crime control. It provides various prerequisites of the success such as organizing relevant laws and regulation as well as reinforcing global cooperation as a measure to develop current Geopros to the high-level crime prediction system.",
		"KEYWORD": "범죄예측,빅데이터"
	},
	{
		"ID": 501,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "경상대학교 대학원",
		"TITLE": "공간 빅데이터를 활용한 범죄 발생 위험지역 예측 모형 구축 =The prediction of crime risky area using spatial big data ",
		"AUTHOR": "김주영",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 문태헌",
		"STORE_LOCATION": "경상대학교 도서관",
		"ABSTRACT": "Society has been constantly changing due to the rapid growth of cities and the rise of economic levels. Along with this social change, crime which one of the threats to society, continues to increase. The crime has become more severe over time. As the crime diversified and the crime incidence increased, the need for a predictive crime prevention strategy attracted attention. In the case of foreign countries, most countries provide accurate information on crime data to predict Crime Risky Areas and minimize crime damage. However, the accurate information has not been provided to citizen in korea due to the leakage of personal information. Furthermore, it provides only crime occurrence area information of the global level. For this reason, Such information was less effective to korea citizen in predicting and preparing Crime Risky Areas. Therefore, in order to improve the efficiency of citizen`s own crime prevention in Korea, it is necessary to prepare a plan to minimize crime damage without actual crime data. This study explored to predict the Crime Risky Areas without crime data. As the first step, we analyzed the three factors affecting crime occurrence : demographic characteristics, building structure and housing types characteristics. In this study, a probability statistic model was used to quantitatively assess the probability of crime occurrence and to predict the Crime Risky Area. In addition, this study used GIS to make it easier for citizens to identify Crime Risky Areas. The most important purpose of this study is to identify the dangerous area of crime by citizens themselves. Therefore, this study use spatial big data provided by a public institutions free to citizens. First, multiple regression analysis was used to select variables that affect crime occurrence among the spatial big data of crime safety. The Bayesian model was constructed using the significant variables to predict the Crime Risky Areas. The most dangerous areas in the predicted area were college campuses, and many crimes actually occurred. Also, the floating population is higher than the average. In order to verify the predicted results, the study compared the actual crime spot and crime density analysis results. Also, the ROC(Receiver Operation Characteristic) curve was used to quantitatively verify the prediction accuracy, and the AUC(Area Under Curve) value showed a prediction accuracy of 86.1 percent. Based on the above results, the crime occurrence risk was higher in area where residential and commercial facilities are concentrated and floating population is high. Therefore, in this area, measures such as revising and adding police patrol routes and installing street security bells are necessary. In addition, there is a need to identify the causes of frequent crime even though it represents high level of floating population and to take appropriate measures against it. The results of this study can predict the Crime Risky Area by using the spatial big data without fear of leakage of personal information, and it is expected that the efficiency of citizen`s own crime prevention will be able to be improved by utilizing this. In addition, since the characteristics of the Crime Risky Area are analyzed, it can be used as a guideline for preparing countermeasures for crime prevention and expected to contribute to building safer cities.",
		"KEYWORD": "공간 빅데이터,범죄 예측,베이지안"
	},
	{
		"ID": 502,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "안양대학교 대학원",
		"TITLE": "공간 빅데이터를 활용한 소지역 상권매출에 영향을 미치는 요인분석에 관한 연구 ",
		"AUTHOR": "이명호",
		"REGION": "경기도",
		"PROFESSOR": "",
		"STORE_LOCATION": "안양대학교 도서관",
		"ABSTRACT": "정보통신기술의 발전으로 지역개발사업을 비롯한 다양한 분야에 서 공간 빅데이터가 축적되고 있다. 공간 빅데이터는 정형ㆍ반정형ㆍ비정형 공간빅데 이터를 효율적으로 수집ㆍ저장ㆍ관리하는 동시에 공간정보와 융합된 다양한 속성정보 에 대해 실시간ㆍ통합 분석을 수행하여 의미 있는 정보를 추출함으로써 미래에 대응할 수 있는 기술이라 할 수 있다. 이러한 공간 빅데이터는 지역상권의 분석에서도 유용하게 활용될 수 있다. 본 연구는 공간 빅데이터를 활용하여 소지역 상권매출에 미치는 영향요인을 분석하고자 공간 빅데이터 구축 및 처리, 그리고 분석 방법을 제시하였다. 이를 위해 먼저 선행연구 검토를 통해 분석방 법과 이론을 확립하였다. 분석을 위한 데이터는 카드매출 및 유동 인구 등 공간 빅데이터와 관련 데이터를 수집하여 소지역 단위로 데이터를 구축하였다. 이후 공간가중회귀모형을 적용한 소지역 및 읍면동 단위의 회귀분석을 실시하였다. 이를 통해 국지적 R Square를 활용하여 연구모형의 설명력을 평가하였으며 소지역 분 석결과와 읍면동 단위의 분석결과를 비교ㆍ검토하였다. 또한 주요 변수별 회귀계수를 시각화하여 지역별 영향력을 측정하였다. 마지 막으로 본 연구의 분석과정 및 결과, 연구의 한계 등 결론을 제시 하였다.",
		"KEYWORD": "공간;빅데이터;활용한;소지역;상권매출;영향;미치;요인분석;연구"
	},
	{
		"ID": 503,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 공학대학원",
		"TITLE": "특허분석을 통한 빅데이터의 공백기술 예측 및 기술개발 방향에 대한 연구 =A study on the development direction and forecasting vacant technology of the big data through patent analysis ",
		"AUTHOR": "한지혜",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이철웅 참고문헌: 장 57-58",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "빅데이터 기술의 공백기술을 도출하기 위해서는 먼저 빅데이터 관련 기술에 관한 특허동향을 분석하여야 한다. 최근 12년간의 빅데이터 관련 기술에 대한 특허를 분석하고자 2005년 1월부터 2016년 5월까지 한국, 미국, 일본, 유럽에 출원 공개된 특허를 대상으로 하였다. 이를 바탕으로 국가별, 연도별, 세부기술별 동향을 파악하여 정량적인 분석을 수행하였고, 주요출원인의 특허출원을 살펴보고, 국내 출원과 비교하여 어느정도 기술발전이 이루어졌는지, 어떠한 분야가 상대적으로 취악한 공백기술인지를 파악하여 미래 시장의 국내 빅데이터 관련 기술의 연구개발 방향을 제시하고자 한다. 또한, 빅데이터의 데이터를 분석하기 위해 2014년 4월 한국전자통신연구원에서 수행하였던 창조경제 시대의 기술 ·시장 전망 특집 “특허분석을 통한 빅데이터 기술개발 동향”에서 빅데이터 기술에 관한 기술 분류 체계를 인용하여, 이를 대상으로 세부기술별 특허 데이터를 수집하고자 한다.",
		"KEYWORD": "빅데이터 공백기술"
	},
	{
		"ID": 504,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "아주대학교 교육대학원",
		"TITLE": "빅데이터를 활용한 수학 기반 STEAM 프로그램이 중학생 영재의 창의적 문제해결력, 수학 진로지향도 및 STEAM 핵심역량에 미치는 영향 =The effect of mathematics-based STEAM program using big data on the creative problem-solving abilities, mathematics career orientation and STEAM core competence of gifted middle school students ",
		"AUTHOR": "양윤정",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 유미현",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "본 연구의 목적은 수학 기반 STEAM 프로그램이 중학생 영재 학생들의 창의적 문제해결력, 수학 진로지향도 및 STEAM 핵심역량에 미치는 영향을 알아봄으로써 성취는 높으나 그에 비해 수학과목에 대한 흥미나 동기가 취약한 중학생 영재들의 창의적 문제해결력, 수학 진로지향도 및 STEAM 핵심역량에 대한 태도를 높이고 앞으로 영재들에게 질 좋은 수학 기반 STEAM 프로그램을 내실 있게 만들어 실제 영재교육 현장에 많이 투입하고자 하는 데 있다. 연구 대상 집단은 경기도 소재 A교육지원청 부설 영재교육원 중학교 2학년 학생 21명이며, 본 연구의 모형은 단일집단 사전?사후검사 실험설계이다. 우선 영재반 학생들에게 창의적 문제해결력, 수학진로지향도, STEAM 핵심역량에 대한 사전검사를 실시하였다. 이후, 빅데이터를 활용한 수학 기반 STEAM 프로그램을 12차시 적용한 후, 그 효과를 알아보기 위하여 동일한 사후검사를 실시하였다. 본 연구의 결과를 요약하면 다음과 같다. 첫째, 수학 기반 STEAM 프로그램 적용 후, 중학생 영재의 창의적 문제해결력이 통계적으로 유의미하게 향상되었고, 하위영역 중에서는 특정영역의 지식/사고기능/기술의 이해 및 숙달여부와 확산적 사고 영역에서 유의미한 향상이 나타났다. 둘째, 수학 기반 STEAM 프로그램 적용 후, 중학생 영재의 수학 진로지향도가 통계적으로 유의미하게 향상되었고, 하위영역 중에서는 수학 진로에 대한 가치 인식 영역에서 유의미한 향상이 나타났다. 셋째, 수학 기반 STEAM 프로그램 적용 후, 중학생 영재의 STEAM 핵심 역량이 통계적으로 유의미하게 향상되었고, 하위영역 중에서는 내용적 융합 영역에서 통계적으로 유의미한 향상이 나타났다. 결론적으로, 수학 기반 STEAM 프로그램은 중학생 영재의 창의적 문제해결력, 수학 진로지향도, STEAM 핵심역량을 향상시키는데 효과가 있었다. 특히, 수학 기반 STEAM 프로그램을 통하여 중학생 영재학생들이 수학 진로에 대한 가치를 인식하였다는 점은 시사하는 바가 크다. 본 연구를 통해 중학생 영재들을 위해 각 분야의 전문가들이 수학 진로와 연계된 다양하고 창의적인 수학 기반 STEAM 프로그램을 개발하여 실제 영재교육 현장에 제공되기를 기대한다.",
		"KEYWORD": "STEAM 핵심역량,수학 기반 STEAM 프로그램,수학 진로지향도,중학생 영재,창의적 문제해결력"
	},
	{
		"ID": 505,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 정보통신대학원",
		"TITLE": "실시간 인기검색어를 이용한 빅데이터와 주가지수의 상관관계 =Using real-time popular searches big data and the correlation between stock index ",
		"AUTHOR": "허양민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김지인",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "현대사회는 정보통신기술의 발전으로 인터넷의 대중화시대를 열었고 스마트폰으로 대변되는 모바일 환경의 확산으로 디지털 혁명이 가속화 되고 있다. 불과 몇 년 전만 하더라도 영화에서나 상상할만한 일들이 디지털화 되어 현실이 되는 요즘, 쏟아지는 수많은 정보의 홍수 속에서 가치를 만들어 내는 빅데이터를 활용한 기술들은 페이스북, 트위터, 감성검색엔진 등과 같은 새로운 분야의 기술들을 배출해내고 있다. 하지만, 데이터를 축적하는 기술이 발전한데 비해 이를 활용하고 가공하여 더 나은 정보로 변환하는 기술은 대형포털과 일부 대기업에서만 간간히 활용하는 사례를 보여 지속적인 보완과 관심이 필요한 실정이다. 특히 최근에는 트위터, 페이스북, 인스타그램과 같은 SNS가 꼬리를 물듯 출시되면서 대중들의 관심은 소셜네트워크 빅데이터의 비정형 텍스트에 집중 되고 있으며, 포털사이트와 함께 이용하는 블로그나 카페에 게재되어 있는 비정형 텍스트를 포함해 다양한 분석을 시도하는 연구사례들이 증가하고 있다. 본 연구에서는 이러한 사회적 흐름에 따라 기존 연구방법과는 차별화를 두기 위하여 인터넷에서 가장 대중적으로 손꼽히는 실시간 인기검색어를 바탕으로 수집된 대량의 비정형 텍스트를 분석하여 KOSPI지수의 상승과 하락을 예측하는 연구를 시도하였다. 연구에서는 제작된 감정단어사전을 필두로 수집되는 비정형 텍스트의 감정을 읽어내어 시간대별, 감정지수별, 날씨의 변화에 따라 KOSPI지수가 어떤 변화가 있는지를 알아보며 그에 따른 상승과 하락을 증명하는 실험 모델을 제시하였다.",
		"KEYWORD": "비정형텍스트,빅데이터,소셜네트워크,오피니언 마이닝"
	},
	{
		"ID": 506,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "빅데이터에 기반한 어울리는 색채 추천 시스템 =Harmonious color recommendation system based on big data ",
		"AUTHOR": "최하얀",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 507,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "기업의 위기관리를 위한 빅데이터에 관한 연구 ",
		"AUTHOR": "손기동",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:백승국 참고문헌 : p.136-143",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": "감정분석,기호학,빅데이터,위기관리"
	},
	{
		"ID": 508,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "안동대학교 대학원",
		"TITLE": "빅데이터를 활용한 예측 서비스 모델링에 관한 연구 ",
		"AUTHOR": "정은미",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 김현기",
		"STORE_LOCATION": "안동대학교 도서관",
		"ABSTRACT": "Recently, with rapid development of Internet, mobile technology, and Internet of Things, digitalization of industries is going on swiftly. Such a change in industrial environment requires various and quick responses such as adoption of new business models or evolution to the digital age, etc. At the time when effective management and use of data collected and accumulated with enormously quick speed becomes core elements for business success, the capacity of a company to provide individualized real-time service is emphasized among others. Accordingly, with the increase of data, attention on the technology to visualize the results from big data treatment as well as the technology to analyze big data has also increased. Thus, this dissertation, to demonstrate how small-size companies and individuals can use, made prediction models, visualized them, and embodied them on web service, with methods such as decision tree, naive Bayesian, neuron network, and regression analysis, etc. used in classification and prediction of big data and public data among supervised learning methods. The value of big data lies in that it is possible for users to retrieve necessary data, using the information in making decisions anytime and anyplace. To experiment and test the model, this research used the sales data for two years from June 21, 2014 to June 20, 2016. It selected major variables affecting prediction. It suggested analytical method to predict the dependent variable based on time-series data, and measured reliability and accuracy depending on prediction methods. To improve accuracy, the research detected outliers using the IQR(Inter-Quartile Range) rule, and made the model by classifying them per season. In classification and prediction model, accuracy and reliability were measured using confusion matrix. In the case of regression analysis model, accuracy was measured using IQR to build the model. Using Shiny of R, it was visualized as dialogue-type web interface. The merits of this research is that it suggested an applied program which can give real-time service of web and web app. simultaneously. The prediction service modeling in this research could improve reliability of prediction models by using both stereotyped data and non-stereotyped data, and diversifying them. In this study, we can reduce the forecast error-rate and improve the forecast accuracy through seasonal classification. In addition, this research demonstrated that all the process can be analyzed, visualized, and made web service possible using R. The prediction model developed in this research was used to analyze the real data, and demonstrated that if non-stereotyped data and various explanatory variables are properly used for different uses, they can be used as meaningful information. By visualizing analytical results and prediction results, and providing web service, users, who are not specialists, can have perspectives, and get help in their decision-making. And, by analyzing real data, the model can be used in other prediction services.",
		"KEYWORD": "빅데이터,시각화,예측"
	},
	{
		"ID": 509,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "빅데이터를?활용한?대학구조개혁 평가의 키워드 및 토픽 분석 ",
		"AUTHOR": "김지은",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 510,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국해양대학교 해양금융·물류대학원",
		"TITLE": "빅데이터를 이용한 부산항신항 ITT 효율적인 운영방안에 관한 연구 =A feasibility study on effective operation of ITT(inter terminal transportation) utilizing big data ",
		"AUTHOR": "백용주",
		"REGION": "부산",
		"PROFESSOR": "한국해양대학교 논문은 저작권에 의해 보호받습니다. 지도교수:신영란 부록 - 주요업체 활용사례, 각국 빅데이터 활용사례 수록 ( 78 - 86 p.) 참고문헌: 76 - 77 p.",
		"STORE_LOCATION": "한국해양대학교 도서관",
		"ABSTRACT": "The global maritime crisis and the financial slowdown are accelerating a fierce competition to induce container cargo volumes against other global ports. In particular, this competition among them is more intensified by offering large-scale incentives or free port dues in order to attract global alliances of liners. First above all, shipping lines constantly request that Busan Port Authority introduce the ITT, so that the subsidy of extra operating costs caused by ITT can secure transshipment container cargoes. Despite that there are many container terminal operators which have been splitted for a long time and disintegrated terminals have caused unnecessarily extra operating costs, however, an ITT operative problem in Busan Port can be solved by integrating all terminal operators into a unified single terminal. In fact, due to our current difficulty of the terminal integration, therefore, only establishing an ITT platform can be the key to solve ITT issues in the first place. This paper shows that an ITT platform can adopt an ITT platform design and configuration algorithm which should be first simulated utilizing Big Data tool. Big Data is one of the latest IT technologies in the 4th Industrial Revolution. It is a way to re-create valuable data through correlation analysis. In order that the data are used for Big Data, I’d like to propose a scenario to optimize the ITT platform construction by confining the optimal design requiring actual data after data mining through analysis tool (R). Particularly, optimized in-and-out container cargoes can be calculated by analysis of loading and unloading rates of transshipment cargoes between nearby two terminals and the turnaround time. Besides, an ITT platform can be optimized to the establishment of an ITT platform via analysis of the best route of terminal-to-terminal TS on a basis of day and time and the transportation pattern of cargoes. Thus, it is possible to reduce the failure rate of the ITT platform by performing the simulation once using the big data before execution, and it could be reflected in the future ITT platform design.",
		"KEYWORD": null
	},
	{
		"ID": 511,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "충남대학교 대학원",
		"TITLE": "빅데이터를 활용한 비즈니스 모델 개발 :철도공사 사례를 중심으로 ",
		"AUTHOR": "심승식",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김기문 참고문헌: p. 59-67",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 512,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한국해양대학교 해양금융·물류대학원",
		"TITLE": "빅데이터를 활용한 부산항 환적화물 물동량 이상치 탐지 분석 =Detecting abnormal changes in transshipment cargo throughput in Busan Port using big-data ",
		"AUTHOR": "박미혜",
		"REGION": "부산",
		"PROFESSOR": "한국해양대학교 논문은 저작권에 의해 보호받습니다. 지도교수:신재영 참고문헌: p.66-67",
		"STORE_LOCATION": "한국해양대학교 도서관",
		"ABSTRACT": "부산항의 환적화물은 최근 5년 동안 연평균 8.27%의 증가율을 나타내고 있 다. 이는 국내 환적화물 물동량의95%를 차지하나, 2016년 9월 한진해운사태를 비롯해 미국 대통령 트럼프의 보호무역주의, 중국 환율 조작국 지정 등의 경제 기조와 세계 교역량의 감소와 선대의 축소 등으로 인한 물량 감소는 부산항에 좋지 않은 영향을 주고 있다. 그러나 현재 선사에서 마케팅을 위해 활용하고 있 는 자료로는 부산항에 신고된 수출입 환적 화물의 물량 통계뿐이다. 물론 원시 데이터는 있지만 공개되지 않고 있고, 월별 년별 집계된 데이터가 대부분이다. 그래서 부산항 전체 뿐만 아니라 다른 국가, 항만, 각 선사별로 부산항으로 환적 되는 물량의 변화가 어떤지, 특별히 나타나는 이상치는 없는지 분석하는 자료가 필요하다. 본 논문은 변화되고 있는 환적화물의 흐름을 빅데이터 기반으로 분석하고, 이를 통해 부산항이 데이터 기반 마케팅 관점에서 환적 화물의 부산항 글로벌 경쟁력 강화 전략을 수립하는데 도움을 주는 것을 목표로 한다. 분석을 위한 자 료는 부산항만공사의 Port-MIS 자료 중 부산항을 경유하는 환적화물 자료 및 를 활용한다. 또한 터미널에서 관리하고 있는 COARRI, CODECO 자료도 포함 했다. 부산항 전체는 시계열분석 방법의 하나인 ARIMA 분석 방법을 사용하였 고, 국가별, 포트별 선사별 분석에서는 이동평균법(MA)방법을 사용하여 신뢰수 준 95%하에서 벗어나는 것을 이상치로 간주하였다. 또한 해당 이상치를 감지한 국가 및 항만에 대해서 상세하게 분석하여 어떤 국가에서 어떤 항만, 어떤 선사 의 환적화물 물량이 이상이 있는지 그 원인은 무엇이며, 다른 경쟁 항만은 어떤 일이 있어나고 있는지 환적화물 물동량 패턴을 분석하여 항만공사, 항만청, 선 사, 터미널 운영사 등 부산항을 이용하는 항만 주체들의 의사 결정에 도움을 주 고자 한다.",
		"KEYWORD": "물동량,부산항,빅데이터,이상치,환적화물"
	},
	{
		"ID": 513,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "계명대학교 대학원",
		"TITLE": "빅데이터를 활용한 글로벌 체인 호텔 고객의 쾌락적 태도와 실용적 태도 분석 :텍스트마이닝과 소셜 네트워크 분석을 중심으로 ",
		"AUTHOR": "안명숙",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 오익근",
		"STORE_LOCATION": "계명대학교 동산도서관",
		"ABSTRACT": "Despite the fact that HED/UT has been treated importantly in not only utilitarian aspects but hedonic aspects in attitude studies, there are few studies on the HED/UT of customers of global chain hotels using big data. The purpose of this study is to analyze the Hedonic(HED) attitude and Utilitarian(UT) attitude of hotel customers. In addition, the difference between HED/UT towards general products and towards hotel usage will be compared and analyzed to identify new factors in attitudes towards the usage of global chain hotels that have not been previously analyzed in general questionnaires. This study used data from portal sites to conduct a text mining and social network analysis to determine the attitude towards global chain hotel usage. After establishing data from blogs and online communities of Naver and Daum, The program Textom was used for processing (text-mining) and refining to discover the major keywords used and analyze the frequency. The programs UCINET6 and NetDraw were used to conduct a meaning connection network analysis, centrality analysis and CONCOR analysis to visualize the network. The study revealed attitudes that had not been discovered in preceding studies. Four factors of new HED were found: luxurious (luxury, high-end, best services, good, best), resting (comfortable, leisurely, satisfying), appreciative (good atmosphere, appreciative, good view) and bragging (wanting to brag, wanting to recommend). UT was concluded to be beneficial (benefiting, free, included) and good price quality ratio (good price quality, discounted). Moreover, there were four factors for the hotel usage of customers (leisurely factors, cultural factors, derailing factors and health factors). These indicate that customers use hotels in the summer or for vacation, to take a break from daily life, for cultural experience, and for health management. Looking at the HED/UT of general products and tourist products as well as global chain hotel usage shows that tourist products, `HED have a high share of derailing attitude, while chain hotel products’ HED showed appreciative and leisurely attitude to be high. For general products, customers’ utilitarian attitude was prominent. Product development promotion and marketing can be done by taking this into account. The implications are as follows From a theoretical presepective, preceding studies on HED/UT regarding global chain hotel usage were lacking in Korea and abroad. As such, the creativity and importance of this study should be emphasized. Moreover, this is a leading case where big data was used to analyze the hedonic and utilitarian attitude towards chain hotel usage. By concluding the HED/UT theory on global chain hotel usage, this study contributes to academic studies in the field. The theory in this study can be used in tourism_related industries such as restaurant, traveling and tourism industries such as airlines. In utilitarian respects, specific products on marketing application based on HED/UT can be presented. Moreover, this is an important study in promoting hotels and the hotel industry and can help explore measures to promote demand for hotels and to develop detailed products fit for customers in the global chain hotel management.",
		"KEYWORD": "고객 태도,빅데이터,실용성,체인 호텔,쾌락성"
	},
	{
		"ID": 514,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 교육대학원",
		"TITLE": "빅데이터를 기반으로 하는 받아쓰기 학습에서의 음운인식과정 분석 및 이의 활용방안 ",
		"AUTHOR": "김정훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정순영 참고문헌: p. 56-57",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "정보화사회가 가속화되면서 기존에 볼 수 없는 많은 양의 데이터들이 인터넷에 쏟아져 나오고 있다. 이러한 빅데이터는 정치,경제,사회,문화에서 넓고 깊게 활용될 수 있는 정보가 되고 있다. 하지만 교육분야에서는 학령인구를 통한 빅데이터가 생성될 수 있는 가능성이 많음에도 불구하고 교육부나 유관기관에서는 엑셀파일 정도의 데이터를 공유하는 수준에 불구하고 자료 규모를 볼 때 진정한 교육분야 빅데이터는 찾아보기 힘들다. 이에 이 연구는 초등학교 저학년 교육과정에서 시행하는 받아쓰기 학습내용을 살펴보고 문제풀이과정에서 일어나는 정보를 빅데이터화 하는 방법에 대해 알아본다. 학습자의 받아쓰기 풀이과정 중 생성된 정보를 국립국어연구원의 표준발음법,한글맞춤법에 근거하여 음운인식의 문법적 변형과정을 체크하여 오답 빅데이터를 생성하는 방법을 고안한다. 나아가 이렇게 빅데이터화 된 받아쓰기 자료를 가지고 컴퓨터과학에 널리 통용되는 기술들을 적용하여 학교 수업 현장이나 학술 연구분야에서 실질적으로 활용될 수 있는 사례를 찾아보았다.",
		"KEYWORD": "받아쓰기,빅데이터"
	},
	{
		"ID": 515,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "빅데이터를 이용한 보안정책 개선에 관한 연구 ",
		"AUTHOR": "김송영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임종인 참고문헌: 장 61",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "현대 기업의 핵심가치는 기존의 유형자산에서 정보자산으로 빠르게 변화되고 있으며, 기업은 이러한 변화에 대응해서 내부 핵심 정보자산의 유출을 방지하기 위한 다양하고 전문화된 고기능성의 보안 시스템을 도입하고 있다. 그 결과, 기업이 보유한 보안 시스템들의 로그들은 예전보다 유용한 정보를 포함하게 되는 한편, 대용량화 되고 세분화되어 모든 내부 구성원들의 행위에 대한 모니터링이 현실적으로 불가능하게 되었다. 이로 인해 보안 시스템들은 보안사고 방지라는 본연의 기능을 잃고, 이미 발생된 보안 사고의 원인 규명 및 재발 방지를 위한 시스템으로 전락하게 되었다. 또한 기업의 핵심 정보자산을 관리하는 IT인프라의 통합 및 대용량화 흐름은 모든 내부 구성원들을 대상으로 동일하게 높은 보안 수준을 유지하는 것을 어렵게 만들고 있다. 모든 구성원들을 대상으로 한 보안강화 활동은 구성원들의 스트레스를 수반하게 되고, 이는 기업의 본래 목적인 업무 생산성 하락이라는 역기능으로 이어지게 된다. 이러한 역기능을 막기 위해서는 정보유출 위험이 높은 조직 및 개인을 선별하여 차별화된 보안 정책을 수립하는 것이 필연적이다. 이를 위해 기업에서는 정보유출 고위험자들을 선별하기 위해 SIEM등의 시나리오 기반 장비를 도입하여 운영하고 있으나, 오탐으로 인한 선의의 피해자 가 양산되거나 기존 시나리오를 파악한 구성원들이 해당 시나리오를 우회하는 경우에는 선별이 어려운 등의 문제가 있다. 본 연구는 기존 시나리오방식의 고위험자 선별방식에 빅데이터 분석 기술을 도입하여 최근에 발생한 사고자와 유사한 행동을 하는 정보 유출 징후 보유자를 사전에 탐지 할 수 있도록 하는 내부정보유출방지 프로세스를 제시하는 것을 목적으로 한다. 본 연구에서 제시된 내부정보 유출방지 프로세스를 검증하기 위해, 실제 기업에 적용해서 케이스 스터디를 진행한 결과, 기존 시나리오방식 대비 33.1%의 효율성을 얻을 수 있었다.",
		"KEYWORD": "데이터마이닝,보안,빅데이터,정책"
	},
	{
		"ID": 516,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "전북대학교 대학원",
		"TITLE": "빅데이터의 반복적인 연산 작업을 지원하기 위한 Hadoop 기반 순환처리 기법의 설계 및 구현 =Design and implementation of hadoop-based iterative processing scheme for pepetitive computations of big data ",
		"AUTHOR": "홍승태",
		"REGION": "전라북도",
		"PROFESSOR": "지도교수: 장재우",
		"STORE_LOCATION": "전북대학교 중앙도서관,한국학중앙연구원 도서관",
		"ABSTRACT": "Recently, researches on big data processing have been actively done with the evolution of information technology. Big data means a massive volume of complex data which cannot be dealt with the traditional data processing techniques. In order to analyze big data efficiently, MapReduce was proposed at Google in 2004. MapReduce is a software framework that allows developers to write programs for processing big data in a distributed computing environment. MapReduce processes the data by using map and reduce functions commonly used in functional programming. Currently, Hadoop, one of the most popular MapReduce framework, is widely used for various real world applications, such as Yahoo cloud computing testbed. Meanwhile, typical MapReduce applications for analyzing the big data can be classified into two categories; non-iterative application and iterative one. The non-iterative application derives a result by doing one phase of Map and Reduce function. On the other hand, iterative applications requires to do the same Map and Reduce function repeatedly. Recently, there are various iterative applications. For example, scientific applications, e.g., genome data analysis, require iterative processing because they draw a result by doing operations iteratively. Because Hadoop has a non-iterative processing structure, it cannot provide an optimal performance for iterative MapReduce jobs. The existing Hadoop is appropriate for non-iterative data processing because it derive a result by doing one phase of Map and Reduce functions. As a result, the existing Hadoop is inefficient for iterative data processing applications which require to perform Map and Reduce functions iteratively. For this, there have been many researches on the iterative MapReduce processing. However, the existing iterative processing schemes have the following drawbacks. First, because the existing schemes are implemented based on the old version of Hadoop, they do not support the efficient resource management of cluster. Secondly, the existing schemes do not consider the entire resources of cluster, the tasks for processing MapReduce job can be skewed towards particular nodes. Thirdly, because the existing schemes do not consider the characteristics of iterative applications, they do not provide an invariant data caching mechanism efficiently. Finally, the existing schemes do not provide stopping condition check mechanism for preventing unnecessary computations. To solve the problems, we, in this paper, propose a Hadoop-based iterative processing scheme for repetitive computations of big data. First, we propose a iterative job scheduling technique for managing the iterative MapReduce jobs. The iterative job scheduling technique provides the stand-alone iterative job statemachine which can minimize the internal changes due to the version update of Hadoop. It also provides an inter job scheduling which transfers the output of previous reduce phase into the input of the next map phase. Secondly, we propose an iterative resource scheduling technique for efficiently managing the resource of Hadoop cluster. The iterative resource scheduling allocates resource uniformly to each node by considering the entire resource of cluster. For this, it is essential to share both the resource status of each node and the total number of tasks for MapReduce job. Thus, we store an iteration information into a meta-data table in HDFS (Hadoop Distributed File System). Thirdly, we propose an invariant data caching mechanism for reducing the I/O costs. The invariant data caching mechanism provides two caching mechanisms according to the types of applications, i.e., Map Input cache and Map Output cache, so as to reduce the I/O cost of loading and shuffling invariant data in subsequent iterations. Fourthly, we propose a stopping condition check mechanism for preventing the unnecessary computation. The stopping condition check mechanism determines the termination of iterative processing by comparing the current iteration output with the previous iteration output. Finally, we show the performance analysis by comparing the proposed scheme with the existing Hadoop. In case of dijkstra algorithm application, the proposed scheme shows twice better performance on execution time than the existing Hadoop. In case of k-Means applications with Map Input cache, the proposed scheme shows twice to four times better performance. In case of PageRank and Descendant query applications with Reduce Input cache, the proposed scheme shows four to seven times better performance. As a result, our Hadoop-based iterative processing scheme is suitable for iterative applications because it can provide improved job and resource scheduling with both invariant data caching and stopping check mechanism.",
		"KEYWORD": "Hadoop,MapReduce,분산 처리,빅데이터,순환처리"
	},
	{
		"ID": 517,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "빅데이터를 활용한 비즈니스 애널리틱스 도입의 성공요소에 대한 연구 =Study of critical success factor of application for business analytics for big data ",
		"AUTHOR": "이용철",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 518,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "인플루엔자 바이러스의 시계열 유행 서열 예측을 위한 은닉 마르코프 모델 기법 연구 =A hidden Markov model for time series prediction of pandemic sequences in influenza virus ",
		"AUTHOR": "박주연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 안인성",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "과거 오래전부터 현재까지 인류와 함께 해온 A형 인플루엔자 바이러스는 잦은 유전적 변화를 통해 진화를 거듭해오고 있다. 그러나 표면 단백질 항원형의 지속적인 변이는 인플루엔자 백신 개발을 어렵게하며 전 세계적으로 큰 위협이 되고 있다. 이에 일부 선진국에서는 자국 분리주를 통한 자체 백신을 생산하고 있지만, 우리나라는 국내 분리주의 항원 분석과 분리주 변이에 대한 연구가 미비하여 대부분의 백신 원료를 수입에 의존하고 있는 실정이다. 이에 본 연구에서는 2002년부터 2013년의 12년 간 국내에서 발생한 H1N1과 H3N2 아형의 인플루엔자 바이러스 표면 단백질 서열을 이용하여 국내 실정에 알맞은 시기별 유행 서열을 예측하였다. 이를 위하여 순차 데이터의 추론에 많이 사용되는 기법인 은닉 마르코프 모델(HMM)을 이용한 서열 예측 모델이 제시되었다. 그 결과, 실제 발생한 바이러스 서열에 대하여 모델을 통해 예측한 서열과 기존 참조 서열과의 유사성을 살펴봄으로써 해당 시기에 적합한 백신주와 잠재적 위험이 있는 염기서열을 도출하였다. 또한, 당시의 진료 기록 데이터와 연계하여 시기별 인플루엔자 병증의 특성을 살펴보았다.",
		"KEYWORD": "A형 인플루엔자 바이러스,백신,은닉 마르코프 모델"
	},
	{
		"ID": 519,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "Big-data-based novel and advanced biomarker mining focused on specific detection and quantification of pathogenic bacteria =빅 데이터 기반 신규 바이오 마커를 활용한 병원성 세균의 특이적 진단 ",
		"AUTHOR": "MinSeokCho",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 520,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "날씨가 배달음식 매출에 미치는 영향 :체감 기상변수와 계절 간 차이를 중심으로 ",
		"AUTHOR": "정수미",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 송상영 참고문헌: p.54-60",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "The weather has influenced not only on daily life but on all over the industries very closely and the previous researches had tried to prove the relationship. Especially, food service industry is influenced by the weather directly or indirectly and reacted sensibly by the consumers so lot of researches has been going on. In our country, food delivery service is one of the special culture in the field of the food service industry. Since later of 1990’s, the food delivery service has been growing up and the sum of market reached on about 12trillion Korean currency in 2015. But the related researches are not quite enough. Accordingly, in this study, we tried to specify the relationship between the weather effect and food delivery service. For analysis, we used the research data provided by SKT Big Data Hub and additionally daily weather data from the Weather Center. There are temperature, humidity, rainfalls, wind velocity, cloud and daylight time, etc. for the examination of weather influence in the previous researches. But in this study, we try to add parameters that the consumers are feeling about the weather. Accordingly, we used the weather variation such as wind chill temperature, heat index and the temperature-humidity index, etc. Finally, we investigated that the explanation adding the above index is much better than not. Furthermore, we examined the detailed weather impact in each season and reached to the results. According to the previous researches, the season is defined with 3months duration such as Spring is from March to May, Summer from June to August, Autumn from September to November and Winter from December to February. Eventually, we examined the weather condition impacted on food delivery service are different and the variation to the food kinds. Also we find out not only statistical significance but economical significance for the fluctuation of food delivery order. Finally, in this research, we try to predict the number of the food delivery order based on the weather data in 2015. So we utilized data mining technique such as artificial neural network, boosting and random forest for building prediction model. Also for the proof of predictive ability of the model, we tested the evaluation process once more with the data in 2016. 12. 26. At the result, we can see that the boosting predictive ability is most excellent among data mining technique. Eventually, we proved the demand fluctuation of the food delivery order depend upon the weather condition by the seasons. Moreover there are lot of meaning that we are able to suggest reasonable marketing strategy to small sized food delivery industry by building up actual prediction model.",
		"KEYWORD": null
	},
	{
		"ID": 521,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "텍스트 마이닝을 이용한 비속어기반 불량 이용지수 개발에 관한 연구 :트위터를 중심으로 ",
		"AUTHOR": "정용재",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김희웅",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Today, the internet is seen by us like the air. And development of smartphone and social media helping us to communicate between people and people beyond the city area. But such a baseless slander exploit the features abusive, rumors, and has also increased cyber violence that occurred targets youth is currently taking place, regardless of age. In terms of the various measures it is provided for, but a study that measures the level of bad fundamental situation user is incomplete. The goal of this study is one of the most common social tweeter centered on the media and metadata of the user by using the measured frequencies for the slang of the defect index and the user to compare the results of the measurement method. Research results are bad indices appear differently depending on the measurement method index showed that the greater the number of followers is growing volatility of the index. Using these results to derive the characterization of restrictions on use or to identify the user associated with the possibility of precautionary measures in the event of cyber violence is expected and will ultimately contribute to the reduction of cyberbullying victims.",
		"KEYWORD": "cyberbullying,faulty index,social media,textmining,Twitter,불량이용지수,사이버불링,소셜미디어,텍스트 마이닝,트위터"
	},
	{
		"ID": 522,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "SNS 버즈량과 트렌드 민감 고객이 상권 성장에 미치는 영향에 관한 연구 :Rising 상권을 중심으로 ",
		"AUTHOR": "신사임",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김경규",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "correlation analysis,existing commercial area,hierarchical regression analysis,hot place,new commercial area,rising commercial area,rising 상권,SNS,social buzz,trend sensitive score,성숙상권,소셜버즈량,신규 상권,트렌드 민감 스코어,핫플레이스"
	},
	{
		"ID": 523,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "Optimization of text feature selection using genetic algorithm for sentiment classification ",
		"AUTHOR": "MijungJang",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 524,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "전자상거래 추천시스템에 있어서 상품가격과 협업필터링 성능과의 관계 ",
		"AUTHOR": "차경환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "전자상거래 추천시스템에 있어서 상품가격과 협업필터링 성능과의 관계 경쟁이 치열해지는 전자상거래에서 추천시스템은 쇼핑몰을 운영하는 입장에서 보면 작은 사이버 공간에 소비자들이 원하는 상품을 가장 효율적으로 전시하는 방법이고 소비자의 입장에서 보면 자신에게 필요한 상품을 특별한 노력 없이 얻는 방법이다. 이러한 추천시스템에서 가장 기본이 되고, 핵심적인 알고리즘이 협업필터링 기술이다. 그러나 협업필터링 추천시스템은 희박성(Sparsity)이나 신규고객의 문제(Cold Start Problem) 등 고유한 한계로 그동안 추천시스템에 대한 연구가 협업필터링 성능 개선을 중심으로 활발하게 연구되었다. 그러나 협업 필터링 성능에 영향을 미치는 요인에 대한 연구는 적었다. RFM를 통한 고객세분화를 통한 수익극대화 방법이 추천시스템과 결부한 연구가 있었지만, 마케팅학과 연계된 연구가 많지 않았다. 이에 본 연구는 협업필터링 성능에 영향을 미치는 요인으로 소비자행동론에서 사회적판단이론에 뿌리를 두고 있는 관여도의 개념을 이용하여 관여의 수준과 관여의 유형에 따라 협업필터링의 성능을 분석하였다. 이때 관여의 수준은 가격으로 측정하였으며, 관여의 유형은 미용제품과 전자제품으로 조사하였다. 가격과 협업필터링의 성능과의 관계는 미용제품은 매우 강한 상관관계(0.85) 전자제품 소품에서도 강한 상관관계(0.51)를 가졌으나 일반전자제품에서는 상관성이 낮았다. 미용제품의 협업필터링 추천의 성능이 전자제품의 추천의 성능에 평균 4~5배 높게 조사되었다. 가격과 협업필터링 추천의 성능이 강한 상관관계를 보인 것은 Petty and Cacioppo의 정교화가능성모델(Elaboration Likehood Model; ELM)에서 제시한 것처럼 고관여는 중심경로로 메시지의 주장을 중심으로 상당한 인지적 노력으로 협업필터링으로 추천된 상품에서 정보를 얻으려하는 반면, 저관여에서는 주변경로를 통하여 메시지 주장과 상관없는 주변단서를 중심으로 태도를 형성하여 추천된 상품에 대하여 정보를 수동적으로 반응한 것으로 판단된다. 감성적 상품이 이성적 상품보다 협업필터링 추천 성능이 높은 것은 직관적으로 협업필터링 추천 시스템은 이성적 상품보다 감성적 상품에서 성능이 높을 것이라는 그 동안의 연구자들의 주장을 데이터로 반증할 수 있었다.",
		"KEYWORD": null
	},
	{
		"ID": 525,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "경북대학교 대학원",
		"TITLE": "Fog computing architecture for IoT and big data environment =IoT 및 빅 데이터 환경을 위한 포그 (Fog) 컴퓨팅 아키텍처 ",
		"AUTHOR": "PinjariHameed",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 526,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "조정원",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 527,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "한호준",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 528,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "장윤호",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 529,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김효실",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 530,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "최희윤",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 531,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "이현정",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 532,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "이미진",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 533,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "박영훈",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 534,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김태연",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 535,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김양헌",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 536,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "경희대학교 경영대학원",
		"TITLE": "스마트워치 사용자 만족도와 재구매 의향 분석을 위한 탐색적 연구 ",
		"AUTHOR": "김형우",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박주석 참고문헌: p. 24",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "수년전 스마트워치를 필두로 웨어러블 기기가 대중적 관심과 주목을 받으며 시장이 형성되었으나 최근에는 시장 발전이 주춤한 상황이다. 현재 시장이 침체되고 있는 이유를 분석하고자 스마트워치의 특성들과 이에 대한 사용자의 경험을 분석해보고 기존 스마트워치 제품들이 개선해야 할 부분이 무엇인지, 어떤 경험을 더 할 수 있도록 해주어야 이용만족도의 상승과 신제품 재구매 의향이 발생하는지를 확인하여 최종적으로 시장의 활성화를 위한 방안을 제시하는데에 본 연구의 목적이 있다. 이러한 연구목적을 이루기 위하여 개인적 특성요인과 사용 경험 요인, 가격요인, 보안요인을 연구모형의 독립변수로 선정하였고 이들이 종속변수로서의 이용만족도, 신제품 재구매 의향에 미치는 영향을 분석하여 다음과 같은 결론을 도출하게 되었다. 첫째, 개인적 특성 요인 중 유용성 인식 정도는 이용만족도에 긍정적 영향을 미치지만 신제품 재구매 의향에는 영향이 없는 것으로 나타났다. 사용경험자는 유용성을 인식하고 사용하며 만족은 하지만 유용성 인식이 반드시 신제품 재구매 의향까지 이어지지는 않는다고 판단된다. 둘째, 사용 경험 요인 중 외적 품질 만족도는 이용만족도와 신제품 재구매 의향에 모두 긍정적인 영향을 주는 것으로 나타났다. 외적 품질인 디자인, 착용감, 내구성에 대한 만족도는 실제 이용만족도 상승으로 이어지며 신제품 재구매 의향에도 긍정적으로 반영된다고 보여진다. 셋째, 사용 경험 요인 중 기능의 참신성 선호도는 신제품 재구매 의향에 긍정적인 영향을 주는 것으로 나타났다. 이는 타 기기에는 없는 차별성 및 스마트폰을 제외한 타 기기와의 연계활용성에 대한 선호도가 높을수록 신제품에 재구매 의향이 높아진다고 볼 수 있다. 넷째, 보안 요인 중 프라이버시 침해 기피는 신제품 재구매 의향에 부정적 영향을 주는 것으로 나타났다. 분실이나 해킹으로 인한 개인정보 노출위험을 줄이는 제품이 출시되어야 재구매율이 높아질 것으로 판단된다. 다섯째, 종속변수가 아닌 독립변수로서의 이용만족도는 신제품 재구매 의향에 긍정적인 영향을 주는 것으로 나타났다. 스마트워치를 사용하면서 전반적인 이용만족도가 높아야 신제품 재구매 의향이 발생한다는 것을 알 수 있다. 본 연구에서 도출된 결과를 정리하면 다음과 같다. 스마트워치 분실이나 해킹으로 인한 개인정보 노출위험 등의 보안상 문제를 해결하고 디자인, 착용감, 활동성, 내구성 등의 외적 품질을 제고하여 이용만족도를 높이고 타 기기 기능과의 차별성 및 타 기기와의 연계활용성을 좀 더 제고해야 기존 사용자의 신제품 재구매율이 높아져서 침체되고 있는 시장이 다시 활성화 될 수 있을 것이라고 본다. 특히 신제품 재구매율 증가에 매우 부정적인 영향을 미치는 것으로 조사된 보안상 문제는 시급히 스마트워치 제조업체에서 풀어야할 선결과제라고 할 수 있으며, 이러한 보안상 문제 해결을 시장의 활성화 전제조건이자 가장 중요한 활성화 방안으로 제시하고자 한다.",
		"KEYWORD": "스마트워치"
	},
	{
		"ID": 537,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "프로젝트 ",
		"AUTHOR": "박진성",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 538,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 경제대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "강승현",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 539,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 경제대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "이기선",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 540,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "정광진",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 541,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김용석",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 542,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "박준용",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 543,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "졸업시험 ",
		"AUTHOR": "박영준",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 544,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "졸업시험 ",
		"AUTHOR": "이용하",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 545,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "다중목적 진화 알고리즘 휘쳐 선택기법을 이용한 소프트웨어 결함 예측 =Defect prediction using multi-objective evolutionary algorithm feature selection ",
		"AUTHOR": "김준석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이찬근 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 연구에서는 다중목적 진화적 알고리즘 휘쳐 선택기법을 이용한 기계학습을 통해 만들어진 소프트웨어 결함예측 모델의 성능을 비교하고자 한다. 소프트웨어 결함 예측은 기계학습이나 통계분석을 통해 소프트웨어 각 개체에 결함을 미리 예측하는 방법이다. 저장소로부터 추출된 각 개체는 소프트웨어 메트릭이라 불리는 다관점의 정량적인 정보를 가지고 있다. 소프트웨어 결함예측에서는 메트릭을 각 개체의 휘쳐로 정의한다. 예측모델 생성 사전작업과정 중에는 예측력 향상을 위한 휘쳐 선택기법이 포함된다. 최근 기계학습을 이용한 소프트웨어 결함예측분야에서는 휘쳐 선택과 기계학습 조합의 성능비교를 하는 연구가 있었다. 본 연구에서는 휘쳐 선택부분의 실험을 확장하여, 다중목적 진화적 알고리즘을 이용한 휘쳐 선택과 기존 연구에서 사용되었던 기법에 의해 선택된 휘쳐들을 사용해 동일한 기계학습 방법으로 만들어진 모델들의 예측력을 비교한다. 또한, 실험에 사용된 각각의 예측 데이터 셋에서 우수한 성능을 보인 휘쳐에 순위를 만든다. 이를 이용해 높은 성능으로 예측되는 범용적인 휘쳐 집합을 만들어 성능을 측정해 본다.",
		"KEYWORD": "결함 예측,기계학습,다중 목적 진화 알고리즘,휘쳐 선택"
	},
	{
		"ID": 546,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "해지 요청 고객의 해지 방어 모형 개발 :금융 서비스 산업 중심으로 ",
		"AUTHOR": "이수영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김경규",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "chrun,Logistic regression analysis,retention,text analytics,TF-IDF,Word2vec,가입 유지(retention),고객 이탈(churn),로지스틱 회귀분석,텍스트 분석"
	},
	{
		"ID": 547,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "가짜뉴스에 대한 포털과 SNS간 반응 차이 감성분석 ",
		"AUTHOR": "김동진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원,연세대학교 학술정보원 언더우드 기념도서관",
		"ABSTRACT": "최근 미디어 환경의 급변과 온라인 콘텐츠에 대한 접근성이 늘어나면서 가짜뉴스 유포사례가 늘어나고 있고 2017년 대선을 거치며 이에 대한 규제 및 관리감독에 대한 필요성 역시 덩달아 증가하는 추세다. 그러나 가짜뉴스에 대한 연구는 아직 미흡한 상태로 무엇이 가짜뉴스인지 그 정의나 범주도 명확하지 않은 상태다. 2017년 대선을 통해서 가짜뉴스가 본격적으로 사회적인 이슈가 된 만큼 사회적으로 크게 관심을 끈 것도 그리 오래 되지 않았다. 기존 연구에서는 가짜뉴스가 무엇인지 그 정의를 명확하게 하는 작업들이 많았고 혹은 가짜뉴스가 가진 특성을 파악해 이를 조기에 탐지해내는 기법 등에 대한 연구, 가짜뉴스가 가지고 있는 법률적 문제나 경제상황에 미치는 영향 등에 대한 분석이 행해졌다. 본 연구에서는 가짜뉴스에 대한 지금까지의 논의들을 전반적으로 알아보고 특히 2017년 대선을 중심으로 중앙선거관리위원회, 언론사 에서 말하는 ‘가짜뉴스’에 어떤것들이 있었는지 조사했다. 이를 바탕으로 몇가지 주요했떤 이슈들을 추려냈고 포털과 SNS 상에서 이러한 가짜뉴스들이 사람들에게 어떠한 감성반응을 불러일으키는지 분석했다. 이를 통해 포털과 SNS 이용자간, 가짜뉴스에 대해 어느정도의 입장 차이를 가지고 있는지를 알아봤다. 연구결과 사실검증이 된 가짜뉴스의 경우 포털사이트에서보다 SNS 상에서 중립의견이 많았고 사실검증이 되지 않은 가짜뉴스의 경우 포털사이트에 비해 SNS 상에서 긍정, 부정적 의견이 더 많았다는 것을 알 수 있었다. 이를 바탕으로 생각했을 때 향후 가짜뉴스 방지 및 제재 방안을 마련할 때 일반 포털사이트나 네이버 밴드, 카페 뿐만이 아닌 트위터 같은 SNS 사이트도 그 대상에 집어 넣는 것이 좋다는 것을 뜻한다. 이러한 결과가 향후 효과적인 가짜뉴스 제재 방안에 기여할 수 있기를 기대한다.",
		"KEYWORD": "fake news,portal site,sentiment analysis,SNS,text mining,Twitter,가짜뉴스,감성분석,텍스트마이닝,트위터,포털사이트"
	},
	{
		"ID": 548,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "사용자 맥락에 따른 온라인 광고 효과 비교연구 ",
		"AUTHOR": "박정은",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 송상영 참고문헌: p.56-64",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "온라인 쇼핑 산업이 다양하고 급속하게 성장함에 따라 온라인 광고 시장 역시 매년 10%대의 성장률을 보이고 있다. 특히 최근에는 디지털 기술의 발달로 사용자의 온라인 이용 기록을 활용하는 리마케팅이나 검색엔진 광고 등 온라인 광고의 종류가 점점 세분화되어 나타나고 있다. 소비자의 인터넷 의존도가 점점 높아지고 있는 가운데 기업이 보다 효과적인 온라인 광고 전략을 수립하기 위해서는 온라인 광고 효과에 영향을 미치는 요소를 밝히고, 이러한 요소들이 사용자들에게 영향을 미치는 매커니즘을 이해 할 수 있어야 한다. 본 연구에서는 광고에 영향을 미치는 비광고적 요소인 사용자 맥락에 주목하여, 온라인 환경에서의 사용자 맥락이 광고 효과 지표인 구매 전환율에 미치는 영향을 살펴보고자 한다. 사람들은 광고를 받아들일 때 광고의 메세지 뿐만 아니라 그 광고가 어떤 맥락 안에서 제시되는가에 의해 영향을 받기 때문에, 동일한 광고에 대해서도 사용자 맥락에 따라 상이한 효과가 발생할 수 있다. 본 연구에서는 사용자 맥락을 광고 노출 시점과 채널 선택 시점으로 나누어 살펴보았다. 따라서 본 연구에서는 사용자 맥락을 구매 단계 시점에 따라 나누어 살펴보며, 사용자 맥락이 광고 효과에 미치는 영향을 검증하고자 하였다. 광고 노출 시점에서의 사용자 맥락은 사용자의 동기적인 측면과 물리적인 측면으로 세분화 하였다. 동기적 맥락은 인터넷 이용 목적에 따라 목표 지향적 맥락과 경험적 맥락으로 구분하였으며, 물리적 맥락은 광고접속 기기에 따라 PC와 모바일로 구분하였다. 채널 선택 시점에서의 사용자 맥락은 소비자의 채널 이용 양상에 따라 멀티, 단일 PC, 단일 모바일로 구분하여 살펴보았다. 각 시점에서 발생하는 사용자 맥락에 따른 구매 전환율 검증하기 위해 본 연구에서는 온라인 숙소 예약 사이트 데이터를 활용하였다. 데이터에 포함된 온라인 광고 변수로는 검색 엔진 최적화, 스폰서 링크, 리마케팅, 콘텐츠 마케팅이 있다. 이를 로지스틱 회귀분석을 통해 실증적으로 분석하였으며, 그 결과는 다음과 같다. 첫째, 광고 노출 시점에서의 사용자 맥락은 구매 전환율에 유의미한 영향을 미치고 있었다. 동기적 맥락에서는 목표지향적 맥락의 소비자가 경험지향적 맥락의 소비자에 비해 높은 구매 전환율을 보였으며, 물리적 맥락에서는 PC 환경에서 광고에 노출된 소비자가 모바일 환경에서 광고에 노출된 소비자에 비해 높은 구매 전환율이 나타났다. 또한 광고 접속 기기에 따른 개별 광고 효과의 조절 효과를 살펴본 결과, PC에서 광고에 노출되는 경우, 개별 광고의 효과는 더욱 높게 나타났다. 둘째, 채널 선택 시점에서의 사용자 맥락은 구매 전환율에 유의미한 영향요인으로 작용한다. 멀티채널 이용자의 구매 전환율이 단일채널 이용자에 비해 높게 나타났다. 또한, 온라인 광고의 효과에 대한 채널 선택의 조절 효과를 살펴본 결과, 광고의 효과는 멀티채널 이용자일 수록 높게 나타나는 것으로 검증되었다. 본 연구에서는 사용자 맥락이 광고 효과에 미치는 매커니즘을 밝히는 데서 한걸음 더 나아가, 데이터 마이닝 기법을 활용하여 사용자 맥락에 따른 구매 예측 모델을 구축하고자 하였다. 그 결과 광고 노출 시점에서의 사용자 맥락에 따른 구매 예측 모델에서는 그래디언트 부스팅 모형이, 채널 선택 시점에서의 사용자 맥락에 따른 구매 예측 모델에서는 랜덤 포레스트 모형이 가장 높은 예측 정확도를 보였다. 이에 본 연구는 다음과 같은 시사점을 가진다. 첫째, 본 연구는 다양한 맥락과 매커니즘을 통해 발생하는 네가지 광고의 효과에 대한 비교 측정을 수행하였다. 또한 사용자 맥락의 구분을 통해 세부적인 사용자 맥락이 광고에 미치는 매커니즘을 밝히며, 광고 전략 수립 시, 맥락 이해에 대한 중요성을 제시하고 있다 둘째, 본 연구결과는 모바일을 통한 구매 유도가 항상 더 좋은 효과로 이어지지는 않는다는 점을 보이고 있다. 특히 숙소 예약과 같은 경험재의 경우, 소비자는 깊은 정보 탐색을 필요로 하고 있기 때문에, 모바일 고객에 대해서는 멀티 채널 이용을 유도하는 것이 오히려 나은 결과로 이어질 수 있다는 점을 시사하고 있다. 셋째, 본 연구에서는 단순히 사용자 맥락이 온라인 광고 효과에 미치는 매커니즘을 밝히는 데에서 나아가, 예측 모형을 구축하였다. 이를 통해 실제 구매 여부를 예측할 수 있으며, 실무자들의 주된 관심사를 충족시킬 수 있다는데 의의가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 549,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경희대학교 경영대학원",
		"TITLE": "디지털콘텐츠 발달에 따른 사용자 경험 변화 연구 :전자책을 중심으로 ",
		"AUTHOR": "김갑성",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박주석 참고문헌: p. 43-44",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "Despite the optimistic outlook of the domestic e-book market, the actual usage is present is some difference. Therefore, in this study,factors that affect the time of purchase usage satisfaction of domestic e-book users (use promotion factor, quality factor, price factor) is derived, and to verify the extent of its influence, domestic and electronic there is a purpose of the study to derive a suggestion for the activation of the book market.??Therefore, to understand the basic theory and characteristics of the e-book, we were new previous research that the e-book model was analyzed and the literature research and materials research. In addition, factors promote the use factor of e-books available, quality factors, the analysis was organized as the price factor was carried out. Based on this, we summarize the conclusions of the study ? ? First, promote the use factor of e-books, but has given a positive impact on utilization satisfaction, of the e-book platform development I was found to be not a somewhat positive. This is a development factor of e-book platform, at the time of e-books available, DRM applied to a variety of file formats and different levels, lack of compatibility with non-standardized, resulting in restrictions on the discomfort and content production of consumer, it is determined that the adverse effect on the final satisfaction. Meanwhile, also released devices recently to support various digital contents including an electronic book, the consumer is capable of experiencing the electronic book via the device that hold groups, recent users prefer in the case of general-purpose devices, such as mandatory offer e-books, it is tinged with the form that the device supports e-books. By this, it found that given the positive impact of the change and use satisfaction of recognition for the e-book. Secondly, the quality factor of the electronic book has been found to give a positive effect on the utilization satisfaction. This is, consumers, major publishers bestseller and awareness of preservation of, plays an important role in the selection of e-books, a large number of users, continuous, such as a particular genre or series of the same writer tend to use the content is it seen to be high.The electronic book, audio, video, fusion contents in a form such as multimedia elements are fused are manufactured continuously,recent new book, of course, form as it is published only in the electronic book is enabled ing.?A best-selling selection which is not biased towards order to improve the quality of the electronic book, it is determined that there is a need for further production of various new book content. Thirdly, the price factor for the electronic book was found to not give a positive effect on the utilization satisfaction. Less interest in new business models and a flat rate model, it is expected to use the electronic book experiential provided with some free.If there is no use needs of different contents, the flat rate model is needed a new model of another form.??To see the price factor of e-books in order to increase the utilization level of satisfaction of the user, it is necessary to develop new models, such as aggressive public relations and resale models and series of All Rights discount purchase of use the e-book of the flat-rate model It is.??Thus, the user that is to increase the satisfaction experience with electronic book has been found to be most important.??This domestic for the activation of the electronic book market, it is expected to become more active and the explosive growth in a new attempt and efforts of related industries.",
		"KEYWORD": "e-Book,독서행위,비즈니스모델,전자책,전자책 디바이스"
	},
	{
		"ID": 550,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "소셜 네트워크에서 사용자 행위 분석을 통한 전문가 추천 기법 =Expert recommendation scheme through user behavior analysis in social networks ",
		"AUTHOR": "송희섭",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 유재수",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "최근 인터넷과 스마트 폰의 발달로 사용자들 사이의 관계를 통해 다양한 정보를 생성하고 공유할 수 있는 소셜 미디어 서비스가 활발히 이용되고 있다. 특히 소셜 네트워크에서 정보의 양이 많아지고 신뢰할 수 없는 정보가 증가함에 따라 사용자에게 필요한 정보를 제공해 줄 수 있는 전문가 추천 기법에 대한 연구들이 진행되고 있다. 본 논문에서는 사용자의 관심 분야, 인적 관계, 응답 품질을 고려한 전문가 추천 기법을 제안한다. 프로필 기반의 전문가 추천 기법의 문제점을 해결하기 위해 사용자의 소셜 활동을 분석하여 최신의 사용자 관심 분야를 판별한다. 사용자의 관심 분야는 사용자의 소셜 활동을 분석하여 최근 사용자가 관심이 있는 분야에 대하여 추출하여 사용자 관심 분야를 판별한다. 사용자마다 인적 관계의 크기나 맺고 있는 사용자가 다르기 때문에 질의한 사용자 중심으로 전문가를 추천해준다면 정확한 전문가를 추천해줄 수 없다. 사용자의 인적 관계는 소셜 네트워크상 사용자들의 인적 관계를 이용하여 같은 관심 분야의 사용자들이 사용자와 관계를 얼마나 맺고 있는지 분석하여 사용자의 영향력을 판별한다. 사용자의 응답 품질을 고려하지 않은 전문가 추천 기법의 경우 전문가로 추천된 사용자의 응답 속도나 응답 품질을 보장할 수 없다. 사용자의 응답 품질은 사용자가 응답한 것을 고려하여 얼마나 빠르고 정확하게 다른 사용자의 질의를 답해 줄 수 있는지에 대하여 분석하여 사용자의 응답 품질을 판별한다. 또한, 사용자가 질의한 내용을 분석하여 단어의 계층적 구조를 이용하여 전문가 그룹을 매칭하는 방법을 사용하고 있다. 사용자 질의를 단어의 계층적 구조를 이용하여 질의의 내용뿐만 아니라 하위어에 대해 전문가를 포함해 전문가 추천의 정확도와 신뢰성을 높인다. 다양한 성능평가를 통해 제안하는 기법이 기존 기법보다 성능이 우수함을 보인다.",
		"KEYWORD": "소셜네트워크,전문가추천"
	},
	{
		"ID": 551,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "소셜 네트워크에서 연결 관계와 영향력을 고려한 사용자 간접 신뢰도 검출 기법 =User indirect reliability computation scheme considering connection relationship and influence in social networks ",
		"AUTHOR": "서인덕",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 유재수",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "최근 인터넷의 발전과 스마트폰의 출현으로 소셜 네트워크가 활발하게 사용되고 있다. 소셜 네트워크 사용자들은 다른 사용자의 게시물에 반응하거나 사용자간 의견 공유 및 표현을 통해 사용자간 상호 작용을 수행한다. 이러한 상호 작용을 수행한 과정에서 사용자간 잘못된 정보를 교환하거나 악의적인 정보가 유포됨에 따라 사용자의 신뢰도는 매우 중요하다. 또한 다양한 사용자가 있는 인적 네트워크에서 정보를 공유하거나 유포 할 때 사용자의 간접 신뢰도는 매우 중요하게 여겨지고 있다. 본 논문에서는 사용자의 정확한 신뢰도를 판별하고, 추천과 사용자 정보 공유에서 정확한 결과를 검출하기 위한 간접 신뢰도 검출 기법을 제안한다. 제안하는 기법은 사용자 행위, 사용자간 상호 작용을 분석을 통해 사용자의 관심 분야를 도출하고 도출된 분야와 연결 관계를 고려하여 네트워크를 재구축하고, 사용자 신뢰도를 검출한다. 또한, 사용자가 악의적인 정보를 퍼트리는지를 판단하기 위해 사용자의 영향력을 고려한다. 영향력은 사용자 행위에 따른 다른 사용자들의 반응을 통해 판단된다. 검출된 사용자의 평가점수와 영향력을 통해 사용자의 간접 신뢰도를 검출한다. 본 논문에서는 제안하는 기법의 우수함을 보이기 위해 성능평가를 진행하였으며 기존 유사 기법에 비해 우수한 성능을 보였다.",
		"KEYWORD": "간접신뢰도,소셜네트워크,신뢰도"
	},
	{
		"ID": 552,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "재건축사업 아파트 사업시행인가 이후 가격 추정과 주요 요인 분석 ",
		"AUTHOR": "김진배",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Recently, interest in reconstructed apartments and the real estate market has surged since the establishment of the reconstruction union of the Eunma Apartment located in Daechi-dong, Gangnam-gu. As a result, there is a growing interest in reconstructed apartments built at similar times. Social issues among various stakeholders have been highlighted around the development of these reconstructed apartments. This is a problem surrounding the price at the time of announcement of the subscription after The authorization for project implementation. In the previous study, unlike the case of cross section analysis based on Gangnam 3-gu or only a specific point of view, this study estimates the price of apartments in reconstruction in Seoul city and finds out the structural factors, reconstruction factors, positional factors, financial factors, comparative factors and policy factors. As a result of the analysis, the influences of the positional factors were significant, and the basement level and the constructor brand were significant factors for the change during the project. DTI was negatively correlated as policy factors. I hope that these results will help to resolve conflicts between constructors, unions, union members and financial companies.",
		"KEYWORD": "apartment,big data,brand stock index,DTI,general trading price,hedonic,KB real estate,KB부동산,LTV,real estate,reconstruction,부동산,브랜드스탁,빅데이터,아파트,일반거래가,재건축,헤도닉"
	},
	{
		"ID": 553,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "취업사교육 콘텐츠 시장에 효율적인 추천시스템 구축연구 =Establishment of an efficient recommendation system for career consulting market ",
		"AUTHOR": "이택승",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "ABSTRACT Establishment of an efficient recommendation system for career consulting market Lee, Taek Seung Strategic Management of Big Data Analytics The Graduate School of Information Yonsei University ??Due to the increment on unemployment, undergraduate students are facing difficulties on being hired. The number of participants in career consulting market reached 606,000, which is the highest number of people in the recent four years. In addition, according to a survey conducted by Saramin which is a human resource company, about eighty four percent of the respondents answered they would like to rely on career consulting regardless of the amount of the payment. ??In meantime, most research on career consulting market is based on investigating factors affecting participation on the market. However, the participants on career consulting market are looking for efficient solutions to get a job. Recommendation systems are expected to be useful for job candidates and career consulting market itself. The recommendation system presents appropriate products based on the customers’ tendency and interest; the market and the institution are developing the performance through various research. The purpose of this study is to build a successful recommendation system for career consulting market. Conducting research on establishing a recommendation system based on w company’s data, showed over ninety percent of accuracy. This is a positive result and encourages adoption a recommendation system into the career consulting market. key word: career consulting, recommendation system, collaborative filtering, random forest",
		"KEYWORD": "career consulting,collaborative filtering,random forest,recommendation system,랜덤포레스트,의사결정트리,추천시스템,취업사교육,협업필터링"
	},
	{
		"ID": 554,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "사용자 감성을 이용한 클러스터링 기반 하이브리드 추천 시스템 ",
		"AUTHOR": "김기령",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신경식",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "최근 스마트폰, 태블릿 등 개인화 서비스가 가능한 기기들이 활발히 보급됨에 따라, ‘개인화된 서비스’의 중요성이 날로 증대되고 있다. 특히, 기업 경쟁력 강화에 개인화된 추천 시스템의 구축은 필수적인 요소로 자리매김 하고 있는 추세이다. 추천 시스템(Recommendation System)은 목표고객에게 그가 좋아할 만한 서비스나 아이템을 추천해주는 서비스로서 사용자들이 선호하는 아이템을 일일이 검색하고 선택하는 시간과 노력의 낭비를 줄여준다. 실제로 추천시스템은 Amazon, Netflix, CDNOW, IMDB 등과 같이 많은 기업들에 도입되어 활용되고 있는데, 특히 Netflix의 자체 영화 추천 시스템인 ‘씨네매치(Cinematch)’의 추천 성공률은 80%에 육박한다. 추천을 위한 여러가지 기법들 중에서, 대표적으로 많이 사용되는 기법들로는 대표적인 콘텐츠 기반 필터링 기법(Content-based Filtering)과 협업 필터링 기법(Collaborative Filtering)이 있다. 콘텐츠 기반 필터링 기법이란 목표 사용자가 기존에 평가한 아이템들을 분석하고 그와 유사한 아이템들을 추천해 주는 기법이다. 이러한 콘텐츠 기반 필터링은 사용자 자신이 과거 평가했던 정보만으로 추천이 이루어지기 때문에 다양한 아이템에 대한 추천이 어려워지며, 텍스트 정보가 충분하지 않은 영화나 음악 아이템 등은 추천의 질이 떨어지는 문제점이 존재한다. 협업 필터링은 목표 사용자와 유사한 성향을 지닌 유사 사용자 그룹을 형성하고, 목표 사용자 자신의 평가치 정보와 유사 사용자들이 평가한 아이템들의 평가치 정보를 이용하여, 목표 사용자가 평가하지 않은 아이템의 평가치를 예측한다. 이렇게 예측된 평가치를 기반으로 목표 고객이 높게 평가할 것이라고 예상되는 서비스나 아이템을 추천한다. 이러한 협업 필터링 기반의 추천 시스템 구현을 위해서는 추천 대상이 되는 사용자와 유사한 사용자가 누구인지를 정확하게 식별해내는 것이 중요한데, 전통적인 협업 필터링에서는 고객 간 유사도 산출을 위해 상품 구매 여부 또는 평점과 같은 정량적인 정보들에 의존하여 왔다. 그러나 최근 SNS와 온라인 쇼핑몰 등의 발전으로 정보 공유가 활발해짐에 따라 고객들의 구매패턴이 변화하고 있다. 고객들은 상품에 대한 평가에 적극 적으로 참여하고 있으며, 이렇게 축적된 상품 평가정보는 소비자들의 구매행위에 적지않은 영향을 미치고 있다. 특히 상품에 대한 고객들의 의견을 공유할 수 있도록 하는 사용자 리뷰가 크게 활성화되고 있는데, 이와 같은 리뷰는 해당 상품에 대해 고객이 갖고 있는 선호에 대한 보다 상세한 정보를 담고 있어 추천 시스템에서 활용하기에 매우 유용하다. 이러한 배경에서 본 연구는 정성적 지표인 사용자의 리뷰 데이터를 사용하여 세부적인 사용자 선호를 파악한 후 이를 군집화 하여, 전통적인 협업 필터링의 추천 정확도를 개선하고자 한다. 사용자 선호를 더욱 정교하게 파악하기 위해 아이템 카테고리별 속성기반 감성분석을 수행한다. 이를 통해 만들어진 카테고리별 User profile을 통합하여 취향이 비슷한 사용자들을 군집화 한 후 군집별 추천을 진행하는 기법을 제시하고, 기존의 협업 필터링 기법과의 성과 비교를 통해 그 유효성을 입증하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 555,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "기업 페이스북 팬페이지 인게이지먼트 향상 연구 :하이마트 사례 ",
		"AUTHOR": "이수빈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김희웅",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "기업 페이스북 팬페이지의 팬의 광고 반응에 대해 ‘금전?물질적 보상’과 ‘페이스북 내 사회적 관계를 맺고 있는 친구들과의 공감대 형성의 장’을 마련해 주는 것 중 어느 것이 확산 효과를 높일 수 있을까? 본 연구는 기업 페이스북 팬페이지와 고객이 상호작용할 때 인게이지먼트를 극대화할 수 있는 요소들을 분석하여 광고특성 및 광고유형을 제안한다. 운영이 잘 되고 있는 기업의 우수 페이스북 팬페이지를 선정하여, 인게이지먼트 상위 10%와 하위 10%의 광고 비교를 통해 광고 요소를 분류하고, 인게이지먼트 향상 광고 전략을 분석한다. 연구 결과 페이스북 내 친구들과 공감할 수 있는 광고의 경우 인게이지먼트가 높았다. 또한 고객의 접근 단계를 단순화시키는 전략이 반응도가 높았다. 효과적 광고 소통을 위한 광고특성 별(친교, 정보, 이벤트 등), 행동유도방식(좋아요하기, 공유하기 등)과 광고 유형(동영상, 사진, 일러스트 등)은 상이했다. 본 연구는 마케팅 성과를 높이는 광고특성, 행동유도방식, 광고유형 전략을 제시했다. 기업 디지털 마케팅 담당자들이 현장에서 실질적으로 활용 가능하다는 점에서 실무적 기여를 한다.",
		"KEYWORD": "digital marketing,engagements,Facebook,Facebook fan pages,social media,디지털마케팅,소셜미디어,인게이지먼트,페이스북,페이스북 팬페이지"
	},
	{
		"ID": 556,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "오피니언 마이닝을 활용한 기업의 위기 전후 온라인 여론 변화에 대한 연구 ",
		"AUTHOR": "박진홍",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이정훈",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Crisis is an inescapable task for a company, and how it overcomes crises often leads to new growth of the company or to its survival. As new media such as SNS are activated, information and sharing of people are getting more and more. News and comments provided by Twitter and Internet portal also include the thoughts and opinions of the communicators who transmit information. If a company can objectively analyze consumer opinions generated online through big data and detect negative emotions in advance, the company will be able to cope with the crisis more appropriately when a crisis occurs. In this study, we analyzed the change of internet public opinion before and after the crisis of company by using Twitter and Naver News comments, not experiments or questionnaires, to find out how to recognize the crisis of the company in advance. I collected the relevant texts by selecting the domestic manufacturing companies `Samsung Electronics` and `Hyundai Motors` as keywords, and analyzed frequency analysis, LDA topic modeling analysis and emotional analysis using the crisis detection monitoring system and emotion algorithm presented in this study. As a result of analyzing the frequency of collected data related to the keyword, it is difficult to detect the potential crisis of the company as the number of news articles. However, when the frequency of comment of news articles increases rapidly or the amount of Twitter buzzword surges, and it was confirmed that there could be a potential risk factor. I analyzed topics extracted from the comments of news articles through topic modeling method, and we could more clearly identify the topics that constitute the topic of what issues people think about the company at the time of collection. In addition, emotional words are classified into five categories of `positive`, `anger`, `dissatisfaction`, `anxiety`, and `disappointed`, and different weights are assigned according to the emotional word classification to discriminate against the strength of the negative emotional word and emotional score that reflects the number of ‘like’ and ‘dis-like’ in the comment, and developed a new emotion analysis algorithm. When the negative emotion such as anger, dissatisfaction, and anxiety increases in the comment through this emotion analysis algorithm, it is possible to clearly identify the change in the intensity of negative opinions about the company. This suggests that the emotional intensity of people responding to negative corporate issues is higher when they are exposed to the media. This is because it is difficult to confirm the number of simple comments and news stories.",
		"KEYWORD": "corporate crisis,emotional analysis,frequency analysis,opinion mining,topic modeling,감성분석,기업 위기,빈도수,오피니언 마이닝,토픽모델링"
	},
	{
		"ID": 557,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경희대학교 경영대학원",
		"TITLE": "인터넷 쇼핑몰의 상품 추천서비스가 고객만족도에 미치는 영향 연구 ",
		"AUTHOR": "강준호",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김민용 참고문헌: p. 54-57",
		"STORE_LOCATION": "경희대학교 국제캠퍼스 도서관,경희대학교 중앙도서관",
		"ABSTRACT": "Changes in transaction methods, media environments and the way we engage in economic activities as a result of advancements in data communications technologies are transforming the lifestyles of consumers. More customers are using internet shopping sites as a result of these changes to their lifestyles and the internet e-commerce market continues to grow because shopping can be enjoyed without any time or location limitations while this industry makes efforts to deliver satisfaction to customers through various services. This research focused on examining the effects that product recommendation services on internet shopping sites had on customer service and verified these effects by deriving the main factors, which were internal characteristics (convenience of the shopping system provided, information search functionality, reputation and service) and product recommendation related characteristics (accuracy, quality of service, price fairness and appropriateness) to achieve the objectives of this research, which are to derive suggestions on how to further spur growth in the internet e-commerce market. To achieve the above, the theories on how to operate internet shopping sites and related product recommendation services were assessed and after conducting preceding research and examining related data and articles, the results of the research can be summarized as follows. First, it was confirmed that for the internal characteristics, while reputation and service had positive effects on customer satisfaction, convenience of the shopping system provided and information search functionality were shown to have a non-positive effect. This can be attributed to the fact that while the reputation of a service and brand are being strengthened through the adjustments in management that take a more customer oriented approach, any changes or advancements in the convenience of the shopping systems provided have become so commonplace that they are unable to influence customer satisfaction, and because there are many ways search can be conducted, the necessity and functionality of search within a site has significantly diminished. These results of this research were confirmed through literature research to be partially different from the findings of previous research. While previous research studies show that internal characteristics have a positive effect on customer satisfaction, because this research has confirmed that internal characteristics only have a partially positive effect, it is concluded that there is a need for a change in the implementation of the services and functions of e-commerce shopping site. From the perspective of strengthening the reputation of a brand and increasing the convenience of a site, customer satisfaction must be achieved through improving the site using visual and design elements that are unique and easy for the consumer to use, and by search functionality that is compatibility with other search services, a positive effect on customer satisfaction from an information search point of view must also be achieved. Second, this research confirmed that accuracy, price fairness and appropriateness were the product recommendation related characteristics that had a positive effect on customer satisfaction. It is concluded that because the product recommendation services were mostly able to recommend products that accurately and appropriately provided recommendations according to the preferences and tastes of the customers and because the prices of the products were maintained at appropriate levels, these services were able to have a positive influence on the customer satisfaction of customers that used the provided recommendations services. Through the results of this research, while it was confirmed that product recommendation services have been able to establish accurate and appropriate prices from the perspective of recommending products based on customer purchase history, because these products recommendation are populated by products that are related to products that the customer has already purchased, this can pose as a barrier to entry for recommending new and unrelated products in the future. Therefore it is considered that there is a need to develop a product recommendation system that can recommend new and unrelated products to customers based upon consumption predictions.",
		"KEYWORD": "상품추천,서비스,쇼핑몰,인터넷 쇼핑몰,전자상거래,추천시스템"
	},
	{
		"ID": 558,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "법률적 관점에서 살펴본 개인정보 침해 유형과 판결의 상호관계에 대한 연구 :미국 판례를 중심으로 ",
		"AUTHOR": "박민정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 채상미 참고문헌: p. 50-59",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "This study was inspired by the importance of protecting personal information which was increased to the advent of ‘Big data environment’. Personal information protection is still an important concern for both users and enterprises. This research focuses on the online environment where almost personal data is created and stored. In this research, 853 US judical cases(2000.01~2016.05) related on data privacy are extracted from Westlaw and analyzed by next following steps. All of collected text data are firstly preprocessed through tagging part of speech and processing stemming and stopwords. To identify the relationship between the factors of invasion of personal information and adjudications, the main objectivity of this study, it conducts Network Text Analysis(NTA). This method is appropriate for understanding social phenomena because it is based on the assumption that language and knowledge can be modeled as networks of words and the relations. Finally, this research suggests the probability of judgements and specific punishments depended on the types of personal information infringement. This paper will be applied to improve existed legal retrieval systems which are operated only keyword-based searching platforms. They are now performed unsatisfactorily because of poor semantic identifications that consequently lead to reduce the effectiveness and accuracy. Furthermore, this paper offers foundations of reforming established practical framework of personal information. It also emphasizes businesses should recognize the importance of personal information and reflect it when they make strategies.",
		"KEYWORD": null
	},
	{
		"ID": 559,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "최유희",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 560,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김대준",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 561,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "최수빈",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 562,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "변성원",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 563,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "안동현",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 564,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "전명수",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 565,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "최인업",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 566,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "이연희",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 567,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "박정훈",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 568,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "노민욱",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 569,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김영준",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 570,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "권우찬",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 571,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "온라인 리뷰와 머신러닝을 활용한 드라마 시청률 예측 모델 연구 =Drama viewer rating predictive model study using online review and machine learning ",
		"AUTHOR": "박승수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김희웅",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "광고수입의 대부분을 차지하는 방송프로그램은 예능과 드라마 장르에 집중되어 있고, 이에 따라 시청률 경쟁도 광고단가가 상대적으로 높은 시간에 편성된 드라마와 예능 프로그램에서 치열해 지고 있다. 이 중 드라마의 흥행여부는 방송사업자 경영에 큰 영향을 줄 수 있어, 흥행의 성과를 측정하는 주요 기준이 되는 시청률은 방송사업자의 중요한 관심사이다. 이런 상황에서 사전에 시청률을 예측할 수 있다면 방송사업자의 광고시장 경쟁력 확보에 큰 도움이 될 것이다. 실제로 그동안 시청률 예측과 관련된 많은 선행연구가 있었는데, 연구분야는 크게 세가지 였다. 첫 번째는 드라마 시청률에 영향을 미치는 요인을 분석하는 분야 였고, 두 번째는 이렇게 밝혀진 요인을 변수로 하여 예측모델을 개발하는 것이었으며, 세 번째는 소셜 온라인 리뷰와 시청률간의 상관관계를 연구하는 분야 였다. 하지만, 선행연구에서는 온라인 리뷰와 드라마 시청률간 상관관계가 존재한다는 사실만 일부 확인하였을 뿐, 이를 적용한 예측모델은 부족하였다. 본 연구에서는 이런 문제의식을 바탕으로 드라마 시청률에 영향을 미치는 온라인리뷰 관련 요인을 파악하고, 이를 이용하여 기존 예측모델 보다 성능이 향상된 모델을 개발하고자 하였다. 본 연구에서는 예측모델 개발을 위해서 2015년 이후 방송 종료된 드라마 중 30편을 임의로 선정하여, 훈련에 필요한 데이터 (시청률, 드라마제작정보, 온라인리뷰) 를 수집하였다. 수집한 데이터는 모델링에 적합하도록 독립변수와 종속변수로 변환한 후 머신러닝의 3가지 기법 (다중선형회귀, 인공신경망, SVM) 에 각각 적용하여 다양한 유형의 드라마 시청률 예측모델을 개발하였다. 그 다음, 모델의 설명력과 예측 정확도를 계산하여 모델을 최종 확정하였고, 실제 방송중인 드라마에 적용하여 모델을 검증하였다. 연구 결과, 온라인리뷰는 40~50대 시청률 보다 20~30대 시청률에 더 많은 영향을 주는 것으로 나타나 선행연구 결과와 일치하였고, 수치예측에 사용되는 머신러닝 3가지 기법의 예측모델 성능은 서로간에 차이가 없어, 설명력이 뛰어난 선형회귀분석이 좀 더 적합한 것으로 나타났다. 최종적으로 확정된 평균시청률 예측모델을 실제 방송중인 드라마 8편에 대입하여 검증한 결과 평균 오류율 25%로 나와 기존 연구대비 약5~10%의 성능 향상을 확인하였다. 본 연구에서는 드라마 장르만을 대상으로 하였으나, 방송사업자 입장에서는 드라마 장르 못지 않게 예능 장르 또한 중요하다. 다매체 다채널 시대에 그 중요성이 점점 더 증가하고 있는 것이 예능 장르이나 이에 대한 연구는 부족한 실정이다. 지금까지 진행된 드라마 시청률 예측 연구를 토대로 향후에는 예능 장르에 대한 더 많은 연구가 필요할 것으로 보인다.",
		"KEYWORD": "big data,machine learning,numerical forecasting,online review,rating forecasting,regression analysis,머신러닝,빅데이터,수치예측,시청률예측,온라인리뷰,회귀분석"
	},
	{
		"ID": 572,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "프로젝트 ",
		"AUTHOR": "엄유빈",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 573,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 경제대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "최미연",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 574,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "류청렬",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 575,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "양지헌",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 576,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "강봉일",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 577,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "한광희",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 578,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "졸업시험 ",
		"AUTHOR": "박종민",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 579,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "졸업시험 ",
		"AUTHOR": "이형기",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 580,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "크라우드펀딩 프로젝트 소개 글 분석을 통한 펀딩 성공 예측 방법 =Predicting crowdfunding success by analyzing documents for introducing crowdfunding project ",
		"AUTHOR": "남수현",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 권오병 참고문헌: p. 30-36",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "크라우드 펀딩은 벤처 기업의 자금 조달에 있어서 엔젤투자자로부터의 펀딩보다 더 중요한 비중을 차지하고 있어, 관심도 같이 증가하고 있다. 따라서 크라우드펀딩 프로젝트의 성공 요인을 밝히고 성공 가능성을 사전에 예측하는 것은 자금 모집자와 투자자 양측에게 모두 중요하다. 특히 프로젝트 목표액, SNS 팔로워 수 등의 수치적인 정보들이 크라우드 펀딩의 성공에 미치는 영향을 분석한 연구들은 진행되어 왔다. 그러나 투자자로 하여금 크라우드펀딩에 참여하고자 하는데 크게 기여하는 정보인 펀딩 소개글의 내용적 특성과 구조적 특성을 활용하여 성공 가능성을 예측하는 연구는 그 비용 효율성에도 불구하고 아직 거의 존재하지 않는다. 따라서 본 연구의 목적은 텍스트 분석 및 판별 알고리즘을 활용하여 비정형 문서인 크라우드편딩을 소개하는 소개글을 분석하고 이를 근거로 편딩의 성공 여부를 사전에 예측하는 방법을 제안하는 것이다. 이를 위해, 1,980 개의 프로젝트를 수집하고 실증적으로 연구하였다. 이들로부터 확보된 Text data set 으로부터 맞춤법, 가독성, 감성분석, 지역정보, 토픽, 명사 수, DTM, 그 외 가용한 수치 정보 등을 자동 확보하여 이를 input feature 로 하는 판별 알고리즘으로 추론하였다. 성능 분석 결과 텍스트 분석 기법을 활용하지 않았을 기존 방법에 비해 더욱 우수한 판별 성능을 얻을 수 있었다.",
		"KEYWORD": "Classification,Crowdfunding,Online Data,Text Analysis"
	},
	{
		"ID": 581,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "Load scheduling scheme using game theory =게임이론을 이용한 에너지 스케줄링 기법 ",
		"AUTHOR": "엄재현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조성래 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "최근 전통적인 전기 그리드는 증가하는 에너지 수요, 노후화된 장비 그리고 증가하는 그린 가스와 같은 문제에 직면하고 있다. 우리는 이러한 문제를 해결하기 위하여 새로운 전력시스템인 지능형 전력망을 도입하여야 한다. 지능형 전력망은 IT 기술과 전력 기술이 합쳐진 융복합 기술이다. 지능형 전력망에서 는 에너지를 무조건적으로 공급하는 것이 아니라 수요 반응 기술을 이용하여 각 고객들의 수요를 조절할 것이다. 우리는 새로운 전력망에 대비하여 전기 요금과 소비자의 가전제품 사용 패턴을 고려하여 사용자 불편도가 최소화하는 에너지 스케줄링 기법을 제안하였 다. 본 문제에서는 두 가지 방법을 통하여 문제를 해결한다. 첫 번째 방법은 하나의 중앙 장치에서 각 가전제품을 스케줄링 하는 중앙 집중 방식이다. 하지만 중앙 집중 방식은 소비자가 많은 가전제품을 가지고 있다면 중앙 유닛은 스케줄링을 처리하기 위해 많은 연산을 하여야 하며, 이때 서버에 부하가 발생하여 많은 문제가 발생할 수 있다. 따라서, 우리는 이러한 문제를 해결하기 위해서 게임이론을 활용한 분산형 방식을 제안하였다.",
		"KEYWORD": null
	},
	{
		"ID": 582,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "Distributed cooperative directional spectrum sensing for cognitive radio networks =지향성 안테나를 활용한 분산 인지 무선 네트워크의 협동 스펙트럼 센싱 기법 ",
		"AUTHOR": "윤종하",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조성래 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "최근 무선 트래픽의 수요가 급격히 증가하고 있으나 스펙트럼 할당은 빈익빈 부익부의 특성을 보이며 비효율적으로 이루어 지고 있다. 이러한 문제는 지향성 안테나와 인지 무선 네트워크를 통하여 해결이 가능하다. 지향성 안테나는 방향성을 갖는 빔을 통해 통신하는 안테나로 공간 분할을 통한 네트워크 용량 증대가 가능하다. 또한 인지 무선 네트워크은 본래 사용자가 사용하지 않아 시간적, 주파수적으로 스펙트럼의 빈 곳을 사용하는 네트워크이다. 따라서 스펙트럼을 센싱하여 본래 유저가 나타나는지, 혹은 어디 채널이 비어있는지를 확인해야한다. 기존 기법에서는 이러한 센싱 기간에 휴지 기간이 필요하기 때문에 네트워크의 성능을 감소시키는 주요 원인이 되어왔다. 본 논문에서는 최신기술인 엑티브 센싱 기법과 전이중 통신 방식을 도입하여 이러한 성능 감소를 상쇄시켰다. 스펙트럼 센싱의 정확도는 에러가 발생할 확률이 존재한다. 따라서 본 논문에서는 협동 스펙트럼 센싱 기법에 기반하여 에러에 대응할 수 있도록하였다. 또한 지향성 안테나를 사용함으로 지리적 정보를 활용하여 보다 더 효율적인 센싱이 가능하다. 본 논문에서는 게임이론에 기반하여 ”얼마나 정확하게 센싱하는가”와 ”얼마나 효율적으로 협력하는가”라는 2가지 사항에 입각하여 협동 스펙트럼 센싱 기법을 설계하였다. 특히 엑티브 센싱, 전이중 통신, 지향성 안테나를 사용한 인지 무선 네트워크는 첫번째 시도이다. 시뮬레이션 결과 제안된 스킴은 우수한 전 분야에서 우수한 성능을 보였다.",
		"KEYWORD": null
	},
	{
		"ID": 583,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "Clustering scheme to minimize charging power for mobile charger with wireless charging in wireless sensor networks =무선네트워크에서 무선 충전 이동기기의 충전 소모 에너지 최소화를 위한 클러스터링 기법 연구 ",
		"AUTHOR": "박준호",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조성래 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "현재 무선 센서 네트워크는 많은 분야에서 적용되어지고 있다. 그러나 센서베터리의 제한은 센서네트워크의 수명을 연장하는데 장애물이 된다. 본 논문에서는, 현재 유망있게 다루어지는 기술인 자기 공명 무선 충전 기술과 이를 결합한 이동형 충전기기를 이용해 무선 센서 네트워크의 수명 연장을 위한 솔루션으로 사용한다. 하지만 MC 자체가 가진 제한된 에너지 베터리는 자신의 운행시간의 제한을 초래하게 된다. 따라서 본논문에서 MC의 충전에너지를 최소화 하는 문제를 공식화 하며, 해당 문제의 NP-hardness를 증명하였다. 또한, 빠르고 효율적인 휴리스틱 알고리즘들을 개발하였으며 그중 greedy 알고리즘에서 선형 계획법의 Duality를 이용해 최저 경계를 도출하여 해당 알고리즘의 성능을 보증하였다. 그리고 greedy algorithm의 성능저하의 원인을 분석하여 이를 해결한 BSBG 알고리즘을 구현하였다. 마지막으로 제안 알고리즘의 해와 최적해의 성능을 비교하였으며, 제안된 알고리즘은 최적값과 1%이내의 성능 차이를 갖음을 검증하였다.",
		"KEYWORD": null
	},
	{
		"ID": 584,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "노인 고혈압 외래환자 의료비 영향 요인 분석 :Analysis of influencing factors of medical expenditure on elderly hypertension outpatients : focused on region and medical use ",
		"AUTHOR": "김슬람",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 조완섭",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "In 2000, the proportion of elderly people aged 65 or older in Korea exceeded 7% of the total population and entered the aging society. By 2019, this ratio is expected to be 14.4%, making it an aging society. The government encourages patients to receive chronic disease management in the clinics by implementing various policies to build a healthcare delivery system for chronic diseases. Although the role of medical institutions is important for managing chronic diseases, there are not many studies on the medical expenditures of treatment and differences in the contents of medical care according to the type of medical institutions for chronic diseases. This study finds the factors affecting the medical expenses after constructing the scenario in Healthcare Bigdata Link Platform through the medical use variables by choosing two provinces, Chungcheongnam-do and Gyeongsangbuk-do, which have the largest expenditure difference for hypertension. Also, this study will compare and analyze the medical use patterns by region and medical use through clustering. Various analysis algorithms random forests, self-organizing maps, and hierarchical clustering, are used to investigate patterns of medical use. There were differences in medical use between Chungcheongnam-do and Gyeongsangbuk-do. According to the policy of the government, hypertension was well managed in the ‘Clinic’. Although the number of patients was small, the cost of medical care was overwhelmingly high, and the incidence of complications and Charlson Comorbidity Index(CCI) was high in these patients. In addition, patients who spent a lot of money changed the type of medical institution and provided many medical services in the hospital. This suggests that systematic management of hypertension is necessary by establishing a medical delivery system according to the severity of the patient and the influencing factors of the region.",
		"KEYWORD": null
	},
	{
		"ID": 585,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "위치 기반 소셜 네트워크에서 개인화된 POI 추천 시스템 설계 =Design of a personalized POI recommendation system in location based social networks ",
		"AUTHOR": "이규남",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 유재수",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "위치 인식 기술의 발전 및 스마트 디바이스 사용의 활성화로 인해 위치 기반 서비스와 소셜 네트워크를 결합하여 사용자에게 정보를 공유하는 위치 기반 소셜 네트워크(LBSN: Location Based Social Network)가 활성화되고 있다. 위치 기반 소셜 네트워크에서 사용자의 체크인 기능을 이용하여 사용자가 흥미 있어 할 만한 장소인 POI를 추천하는 연구가 활발히 이루어지기 시작했다. 제안하는 기법은 기존 논문에서 고려하지 못한 시간에 따른 지역의 전문가, 희귀한 선호도를 고려한다. 지역의 전문가를 고려함으로써 지역의 정보가 많은 사용자들을 활용하게 된다. 그럼으로써 보다 정확한 사용자의 선호도가 반영된 POI를 추천 후보 목록에 구성할 수 있다. 또 희귀한 선호도를 고려함으로써 사용자 개인의 선호도를 보다 면밀하게 예측하고 추천에 활용할 수 있다. 이를 통해 사용자의 선호도가 반영된 카테고리의 POI들을 추천 후보 목록에 구성할 수 있다. 제안하는 기법과 기존 기법의 성능평가를 통해 성능의 우수함을 보인다.",
		"KEYWORD": "POI,개인화추천,추천시스템"
	},
	{
		"ID": 586,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "클러스터 앙상블을 통한 소프트웨어 아키텍처 모듈-뷰 복원 ",
		"AUTHOR": "조충기",
		"REGION": "서울",
		"PROFESSOR": "중앙대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 이찬근 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "소프트웨어 시스템의 아키텍처 문서는 효율적인 유지보수작업을 지원해줄 수 있는 중요한 재산이다. 그러나 불행하게도 많은 경우에서 아키텍처 문서가 존재하지 않거나, 존재하더라도 현재 시점의 시스템의 상태를 반영하지 못하고 누락된 경우가 많다. 이에 관련 학계에서는 자동으로 소프트웨어 아키텍처를 복원하는 연구가 시작되어 지금까지 활발히 진행되고 있다. 지금까지 다양한 클러스터링 알고리즘을 통한 복원기법들이 제안되었다. 그러나 기존에 제안된 대부분의 연구는 단일한 클러스터링 알고리즘만을 사용하고 있다. 본 논문에서는 단일 클러스터링 기법의 약점을 보완하여 좋은 복원 품질과 견고한 성능을 달성하기 위해 클러스터 앙상블 기법을 적용한 소프트웨어 아키텍처 모듈-뷰 복원기법을 제안한다. 5개의 오픈소스 프로젝트를 사용한 실험 결과 클러스터 앙상블을 적용한 경우 그렇지 않았을 때와 비교해 높은 복원 성능과 일관된 성능을 보인다는 것을 확인할 수 있었다.",
		"KEYWORD": "소프트웨어 아키텍처 복원,클러스터 앙상블,클러스터링"
	},
	{
		"ID": 587,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "Recurrent neural network based recommendation system with sequence pattern mining ",
		"AUTHOR": "SoheeKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 588,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "CyberBullyWordNet: 오피니언 마이닝에서의 비난 댓글 파악을 위한 방법 개발 =CyberBullyWordNet: a method of identifying blame for refining negative opinions in opinion mining ",
		"AUTHOR": "이중원",
		"REGION": "서울",
		"PROFESSOR": "경희대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 권오병 참고문헌: p. 41-44",
		"STORE_LOCATION": "경희대학교 중앙도서관",
		"ABSTRACT": "비정형적 문장에서 작성자의 견해나 감성, 그리고 태도를 판별하는 오피니언 마이닝(Opinion Mining)을 위해서는 문장 내 특정 키워드의 감성값을 추정해야 하는데 이를 위해 감성어휘사전을 활용하는 방식이 일반적이다. 기존에 감성어휘사전을 구축한 여러 사례들이 있었지만, 사이버 상에서 욕설이나 위협 등과 같이 대상에 대한 비난(Cyberbullying)을 건설적인 비판과 구분하기 위해 감성어휘사전 구축 방법으로 접근한 사례는 거의 없다. 따라서 비난과 비판을 자동으로 분류하는 연구도 거의 존재하지 않는다. 따라서 본 연구의 목적은 부정적 의견이 실린 문장에서 비난의 글을 자동으로 판별하기 위해 비난 관련 감성 사전을 구축하는 것이다.",
		"KEYWORD": "Cyber Bullying,Opinion Mining,Sentiment Analysis,WordNet"
	},
	{
		"ID": 589,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "박문호",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 590,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "한지연",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 591,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "양건필",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 592,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "강한",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 593,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "윤기성",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 594,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "(A) distributed IoT query engine based on oneM2M architecture ",
		"AUTHOR": "PutuWiramaswaraWidya",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 595,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김정미",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 596,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "류재혁",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 597,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김동민",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 598,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "윤여원",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 599,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "이재현",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 600,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "한국어 특성 기반의 어절 수 변화에 따른 n-gram 성과 비교 ",
		"AUTHOR": "송재연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신경식 참고문헌: p.60-67",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "Recently, text mining begins to make a mark because of understanding people’s mind and sentiment to specific target. In this field, feature selection is most important on text mining due to varying the performance depending on feature that the researcher choose. A few previous oversea studies have been focused on how to raise the performance of classifier depending on the number of words using n-gram in sentiment analysis. However, a few previous domestic researches have not been focused on n-gram because a large number of researchers have developed the studies that is based on the domain specific lexicon. It is unsatisfactory condition to use n-gram for sentiment analysis in Korean language though n-gram is common and outstanding methodology for feature selection in sentiment analysis. The purpose of the study is the proof of the effectiveness of n-gram and the consideration of the causes of the performance difference by the number of words using n-gram in sentiment analysis. Most noticeable is finding the optimum number of words using n-gram. In this study, the performance is defined accuracy rate in sentiment classification-positive and negative-. The results according to the proposed experiment proved the effectiveness of the number of words using n-gram. The optimum number is two when we use the single n-gram and the most optimum number is the combination of one, two and three when we use the combination of the number of words. The main reason that show the performance difference is sequence of particular words. The strong point of n-gram is extracting the consecutive words. We can get the reliable variable when we used more than two words using n-gram as feature. It means three benefit and effectiveness when we use more than two using n-gram as feature. First, some variable is used to emphasize the sentiment. For example, “very good” is more positive than “good”. Second, some negative words change the sentiment when it combines with the particular word. For instance, “not good” is negative. However, unigram recognize the sentence as neutral because unigram set the two variable are “not” and “good”. Though bigram appreciates the sentence as negative because bigram set the one variable is “not good”. Third, some words make new sentiment. For example, “waste time” is negative. However, unigram is failed to realize the sentence as negative. Because unigram set the two variable are “waste” and “time”. Moreover, the list of effective variable consists of words showed the characteristic of Korean language. It means n-gram is valuable methodology in sentiment analysis for Korean language. The contribution of this research is to prove the effectiveness of n-gram, offer the optimum number using n-gram, and find the reason of the performance difference based on the characteristic of Korean language. In hereafter research, it is expected to use briskly n-gram in sentiment analysis and other fields based on characteristic of Korean language.",
		"KEYWORD": null
	},
	{
		"ID": 601,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "프로젝트 ",
		"AUTHOR": "정도영",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 602,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "프로젝트 ",
		"AUTHOR": "김정식",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 603,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "키워드 기반 특허 관계 유형 정의 및 분석 연구 =Definition of patent relation type based on keyword, and research of analysis ",
		"AUTHOR": "장윤지",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정한민",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "빅데이터 환경에서 우리 사회는 그 어느 때보다 급속한 변화를 하고 있다. 지식 기반 사회로 접어들며 세계 각 국에서는 지식을 창출하기 위한 노력을 하고 있다. 지식 활동이 중요해지면서 지식 활동의 결과물에 대한 연구 또한 증가하는 추세이다. 본 논문에서는 지식 활동의 결과물 중 특허 데이터를 수집, 분석하였다. 또한, 특허를 출원하기 위한 선행 단계에서 특허의 공백 기술을 찾거나, 선행 기술 조사를 하여 전략적이고 내실 있는 특허를 내는 것이 중요하다. 본 논문에서는 특정 키워드로 특허 검색을 하며, 검색된 특허 데이터 중 초록, 제목에서 의미 있는 키워드를 찾아 재검색한다. 특허 제목에서 방법론을 나타내는 키워드 Approach, 연구 대상을 나타내는 Goal Object, 연구 목적이 되는 Goal Predicate 키워드를 추출한다. 추출된 키워드로 특허 관계 유형을 정의한다. 또한, 특허 제목 간 관계 유형에 시계열 데이터를 적용하여 특정 키워드와 관련된 특허 내에서의 현상을 파악한다. 또한, Approach, Goal Object, Goal Predicate 키워드에도 시계열 데이터를 적용하여 특정 키워드 관련 특허들에서의 키워드 흐름을 살필 수 있다. 이로써 본 논문은 기존에 출원된 특허들에서 공백 기술을 찾거나 선행연구조사 등에 기여를 할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 604,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 경제대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김형석",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 605,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 경제대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "강수진",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 606,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "김미혜",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 607,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "장영완",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 608,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "학점이수 ",
		"AUTHOR": "명진",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 609,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 경영대학원",
		"TITLE": "졸업시험 ",
		"AUTHOR": "우덕채",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 610,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "Efficient parallel processing of skyline queries for big data =빅데이터의 효율적인 스카이라인 질의 처리를 위한 병렬처리 알고리즘 ",
		"AUTHOR": "Park,Yoonjae",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 611,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "(A) study on the method for the estimation of energy efficiency operational indicator of a ship based on technologies of big data and deep learning =빅데이터와 딥러닝 기술을 기반으로 한 선박 에너지 효율 운항 지표 예측 방법에 대한 연구 ",
		"AUTHOR": "김성훈",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "In shipyards, EEOI estimation is required to compare the efficiency of ships and to check the time-varying efficiency of the ships. However, since it is difficult to obtain operating data required for EEOI estimation, it is necessary to estimate EEOI using public data such as Automatic Identification System (AIS) data, ship and engine data, and weather data. In this study, a method for EEOI estimation using public data was proposed. In the proposed method, total resistance and propeller efficiencies are estimated using the Holtrop-Mennen method, additional resistance is estimated following the International Organization for Standardization (ISO)15016:2015, and engine power is estimated using the modified Direct Power Method (DPM) and Holtrop-Mennen method. Since the public data have a large capacity, big data technologies such as Hadoop and Spark were applied. The public data was stored to Hadoop, and the data was processed using Spark. Moreover, to reduce the computation time for EEOI estimation, a surrogate model constructed using deep learning was also applied. To evaluate the effectiveness of the proposed method, it is applied to estimate EEOI of the example ship. The result shows that the method can estimate EEOI effectively and accurately.",
		"KEYWORD": "Automatic Identification System (AIS),Big data,Deep learning,Energy Efficiency Operational Indicator (EEOI),Hadoop,Spark,Surrogate model"
	},
	{
		"ID": 612,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "Non-compliance with recommended duration of zolpidem treatment and its predictors :건강보험공단 빅데이터를 활용한 졸피뎀의 투여기간의 처방양상 및 관련요인, 2002-2013 ",
		"AUTHOR": "YunJeungJang",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 613,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "Bloom Filter를 이용한 Outbound Traffic 모니터링 방안 연구 ",
		"AUTHOR": "강성중",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 21-22",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "인터넷과 네트워크를 이용한 각종 서비스가 개발되고 이로 인한 이용자의 편의가 증대되어 인터넷 사용이 기하급수적으로 증대되었고, PC보급율 역시 향상되었다. 또한, 기업은 이제 PC와 네트워크가 없이는 사업을 유지할 수 없는 상황에 이르렀다. 이에 따라 서비스를 방해할 목적이나 회사에 금전적인 정보를 취득하기 위해서 등 다양한 목적에 의해 해커들의 공격이 증대되고 있고 간단한 툴을 이용하면 누구나 악성코드를 손쉽게 만들어 배포할 수 있는 시대가 되었다. 기업은 지금까지 회사의 네트워크와 전산 자산을 보호하기 위하여 각종 정보보호 시스템을 구축하여 운영하고 있으며, 보안관제 서비스 등 추가적인 비용을 투입하며 외부로부터의 공격에 대응 다각도로 대응하고 있다. 그러나 대부분의 보안시스템은 대부분 Inbound Traffic에 대한 모니터링 및 접근통제를 실시한다. 또한 악성코드 탐지 역시 백신 제조업체에서 시그니처를 만들어 배포하기 전까지는 탐지가 불가능하다. 기업의 업무를 수행하는 과정에 있어 메일의 송수신 등 외부와의 완전한 단절은 불가능 하고, 어떤 경로를 통하든 악성코드는 유입 될 수 있으며, 악성코드가 감염되면 가장먼저 통신대상과 구동 프로세스가 달라진다. 이에 따라, 본 논문에서는 악성코드가 외부로부터 유입되는 것은 어쩔 수 없음을 가정하고 이미 감염된 PC를 신속하게 찾기 위한 방법으로 악성코드의 확산단계에서 이상행위를 감지하기 위하여 PC에서 발생하는 Outbound Traffic을 분석하여 C&C(Command & Control)서버와 통신하는 PC를 찾아내어 후속조치를 취할 수 있도록 함으로써 악성코드 확산 방지에 도움이 될 수 있는 방안을 연구한다.",
		"KEYWORD": "내부관제,블룸필터,패킷모니터링"
	},
	{
		"ID": 614,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "암 본인부담률 인하정책이 의료이용과 의료비 부담에 미친 영향 :건강보험 빅데이터를 이용하여 ",
		"AUTHOR": "장수목",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정형선",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "Impact of co-payment reduction policy for cancer patients on healthcare utilization and financial burden: employing big data from the Korean National Health Insurance Jang, Soomok Dept. of Health Administration The Graduate School Yonsei University Cancer is a serious disease with the number one cause of death during the last 34 years in South Korea, generating costly health care expenditures. For the purpose of alleviating financial burden of cancer patients, the Korean government lowered co-payment rates in the National Health Insurance (NHI) from between 20 to 60% to 10% in 2005, which was followed by the second reduction to 5% in December 2009. Up till now, there have been a considerable number of studies on influences of the first policy, whereas research on the second one has been rare. Moreover, a few studies on the second policy showed different results and raised questions about the representativeness of samples and study methods. This study aimed to grasp the impacts of the second policy on cancer patients` health care utilization and burden of medical costs in terms of influence level and equity between the income brackets. In order to determine pure causal effects of the policy, I used difference-in-difference (DID) analysis, comparing cancer patients (treatment group) with patients with liver diseases (control group). The study subjects were divided into two sub-groups: group 1, newly registered patients with doctor’s definite diagnosis, and group 2, patients already under continuous treatment in intermediate periods, considering the -shaped curve of cancer treatment costs presented by Yabroff et al.(2007). The dependent variables were quantity indicators of healthcare use (i.e., length of stay and the number of outpatient visits), cost indicators (i.e., total, inpatient, and outpatient medical expenses), tertiary-care hospital use as a share of total use, and financial burden due to out-of-pocket (OOP) payments (i.e., OOP payments as a share of annual income, incidence of catastrophic health expenditures (CHE), and incidence of impoverishment). I defined ‘pre-policy’ period as January to November 2009 and ‘post-policy’ one as January to November 2010, employing big data from the NHI on the basis of personal unit. I suggested the effects of co-payment ceilings and non-covered service spending on the financial burden by classifying OOP payments as amounts by 3 stages: (1) amount at the point of medical treatment, (2) amount after reflecting co-payment ceiling system, and (3) amount including uninsured medical services. In addition, I analysed the impact of the second policy on equity between low- and high-income brackets within cancer patients. My results showed that after implementing the policy, health care utilization and expenses for cancer patients increased (especially in outpatient care) compared to those of patients with liver diseases. It implies that the second policy contributed to improving access to health care services with patient-perceived price-cutting effect working. The policy, however, seemed to fail to improve the equity in service use between income strata within cancer patients. With regard to big hospital utilization, the rate of utilization at tertiary-care hospitals by new cancer patients in group 1 decreased in terms of inpatient days, outpatient visits, and total medical expenses compared to those of the control group. On the other hand, in the case of group 2, the rate of use at ‘Big 5’ hospitals and tertiary-care hospitals excluding Big 5 by cancer patients under ongoing treatment increased in length of stay but decreased in outpatient visits and total medical expenses compared to those of the control group, which can be translated as ‘a transition effect’ from outpatient to inpatient care. The different results between two groups may derive from the gaps in perception of information and level of experiences for the new policy. The transition effect may result from a combined work of moral hazard from patients and supplier-induced demand. When taking income level into account, I found that the utilization rate at big 5 hospitals by low-income cancer patients decreased significantly in inpatient days and total medical expenses compared to those of the high-incomers only in group 2. As for the financial burden of patients due to OOP payments, this study revealed overall improvement in co-payment ratio to annual income, incidence of CHE, and incidence of impoverishment after the policy intervention regardless of group types. The higher the values of CHE thresholds were, however, the lower became the degrees of improvement effects, which suggests we need another countermeasure to protect people from CHE. Regarding equity between income groups within cancer patients, the policy was confirmed not to have enhanced the equity, with showing different results between the two groups after adjusting co-payments for uncovered services. In group 1, the poor seemed still to suffer financial difficulties in utilizing uninsured services even after lessening coinsurance from 10% to 5% with the incidence of CHE and impoverishment decreasing, while the rich used more uncovered services than before, with the incidence of those increasing. Meanwhile, since cancer patients under continuous treatment, group 2, were likely to acquire information on new policy more quickly through their providers and to respond more sensitively to it than group 1, the poor showed increased use of non-covered services but tended to be easily exposed to incidence of CHE and impoverishment due to their low incomes. Those results suggest that OOP payments for uninsured services are not only a major factor for the financial burden of the low-incomers but a cause of incidence of CHE and impoverishment even for the high-incomers. Besides, it was observed that the co-payment ceiling system favored the rich rather than the poor in reducing the financial burden although it reduced inequity between beneficiary and non-beneficiary groups. This study suggests that since only lowering the rate of patients` co-payment does not work well in attaining the policy goal, fair financial protection, more efforts need to be made in the future to expand benefits package by converting uncovered services into covered ones, to reform the current regressive ceiling system in co-payment, and to take a countermeasure against CHE.",
		"KEYWORD": "catastrophic health expenditure,difference-in-difference,health insurance coverage,healthcare utilization,impoverishment,건강보험 보장성,과부담 의료비,빈곤화,의료이용,이중차이분석,형평성"
	},
	{
		"ID": 615,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "Epidemiologic characteristics and antibiotics usage pattern of acute pyelonephritis in Korea, 2010-2014 =건강보험 빅데이터를 이용한 국내 급성 신우신염의 특성과 이에 대한 항생제 사용 양상 분석 :population-based study ",
		"AUTHOR": "BongyoungKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 616,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "계명대학교 대학원",
		"TITLE": "사회연결망 분석을 활용한 대구의 관광지 이미지 분석 :온라인 빅데이터를 중심으로 ",
		"AUTHOR": "서정아",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 오익근",
		"STORE_LOCATION": "계명대학교 동산도서관",
		"ABSTRACT": "광산업은 지역 사회의 수입과 고용 창출에 기여할 뿐만 아니라 다양한 관련 산업의 발전에 기여한다. 따라서 많은 국가와 지역들은 경제 활성화와 경쟁력 확보를 위해서 관광산업의 활성화를 도모하고 있다. 그러나 관광목적지로서 타지역과 차별화된 경쟁력을 확보하기 위해서는 관광지 이미지의 정확한 파악이 필수적이다. 다양한 온라인 채널을 통해 생산되고 공유되는 온라인 관광정보는 관광소비자들에게 관광지의 특색을 전달하고, 관광소비자들이 인식하는 관광지 이미지에 영향을 미칠 수 있다. 온라인 데이터를 활용한 관광지 이미지 분석은 관광소비자들의 관광목적지에 대한 인식과 이미지를 설명할 수 있는 유의미한 정보를 도출할 수 있으며, 관광소비자 관점에서 관광지 이미지를 더욱 심층적으로 이해할 수 있는 토대가 될 수 있다. 따라서, 본 연구는 대구광역시를 대상으로 온라인 빅데이터를 활용한 관광지 이미지 실례연구를 실시하여 대구의 관광지 이미지를 분석하고 관광목적지로서 차별화된 경쟁력을 갖추기 위한 이미지 제고방안에 대한 시사점을 도출하고자 하였다. 본 연구의 목적을 위하여 국내 주요 포털 사이트를 대상으로 텍스트 마이닝과 사회연결망 분석을 실시하여, 대구의 관광지 이미지를 형성하는 관광지 이미지 요소들을 조사하고 이러한 이미지 요소들의 대구 관광지 이미지에 미치는 영향 정도를 분석하고자 하였다. 본 연구의 주요 연구결과는 다음과 같다. 첫째, 지역의 대표적인 관광프로그램들과 코스에 포함되는 장소들이 포함되는 관광객 인프라시설과 문화와 예술, 역사 요소가 대구의 관광 이미지를 형성하는 주요한 관광지 이미지 요소로 파악되었다. 둘째, 사회연결망 분석을 통해 관광지 이미지 요소들의 관광지 이미지 형성에 미치는 영향 정도를 확인한 결과 ‘대구중구골목투어’가 대구의 관광지 이미지 형성에 핵심적인 역할을 하는 것으로 파악되었다. 셋째, 데이터 수집기간 동안 발생하는 사회적인 이슈나 정부의 정책과 홍보 주제가 지역의 관광지 이미지에 영향을 미치는 될 수 있음을 파악하였다. 넷째, 관광목적지의 입지적 조건이나 특색에 따라서 지역의 관광지 이미지에 영향을 미치는 요소들이 달라진다는 것을 확인할 수 있었다. 다섯째, 전통적인 관광지 이미지 연구에서 측정 가능한 관광지 이미지 요소들은 온라인 관광지 이미지 연구에서도 대부분 측정이 가능하였다. 본 연구결과를 통해서 대구의 이미지를 제고하여 관광목적지로서 경쟁력을 고양시킬 수 있는 관광마케팅의 전략적인 방안을 제시할 수 있을 것이다. 또한, 텍스트 마이닝과 사회연결망 분석의 결합을 통한 온라인 관광지 이미지 연구의 새로운 방법론 제시에 기여할 수 있을 것이다.",
		"KEYWORD": "Big data,SNA,관광지이미지,빅데이터,사회연결망분석,소셜네트워크분석"
	},
	{
		"ID": 617,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국교통대학교 경영행정대학원",
		"TITLE": "Big Data의 活用과 對應戰略 硏究 =(A)study for business strategies using big data ",
		"AUTHOR": "곽종철",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수: 김경일",
		"STORE_LOCATION": "한국교통대학교 중앙도서관",
		"ABSTRACT": "오늘날 우리가 살고 있는 정보화 사회는 정보기술의 비약적 발전과 시간과 공간에 제약이 없는 스마트기기의 폭발적인 증가에 의해 일상생활 전반에서 다양한 형태의 데이터가 생산되고 있다. 정부와 기업은 빅데이터의 활용을 통해 의사결정의 적시성과 효과성을 높이고 나아가 선제적인 의사결정의 기반을 마련할 수 있으며, 내부역량 강화, 업무자동화 및 중복 제거, 프로세스 안정화 등으로 경영효율성 증대를 기대할 수 있다. 본 논문에서는 빅데이터를 이용하여 새로운 정보와 지식을 창출하는 것이 창조경제를 위한 중요한 가치창출 전략임을 인식하여, 다양한 문헌조사를 통해 빅데이터의 등장 배경과 요구사항을 이해하고, 국내?외 활용 사례와 그에 대한 시사점을 살펴본 후, 빅데이터의 적극적인 활용을 위한 분석기술을 고찰하여, 비즈니스 측면에서의 대응전략을 모색하는데 의의가 있다.",
		"KEYWORD": "Analysis,Big Data,Convergence"
	},
	{
		"ID": 618,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "헬스 케어 분야 전문의약품의 사용자 인식 현황 실태 분석 :(The)analysis of user perception and usage patterns about ethical drug :온라인 텍스트 데이터를 활용하여 =using online text data ",
		"AUTHOR": "김재화",
		"REGION": "",
		"PROFESSOR": "지도교수 : 정승렬 참고문헌: p. 38-41",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "소셜 미디어가 보편화되며 매시간 누적되는 데이터의 양이 기하급수적으로 증가하였다. 이는 기존의 데이터 처리 체계 및 인식에 변화를 몰고 왔다. 데이터가 곧 경제적 자산이 되는 빅데이터 시대가 도래한 것이다. 이에 따라 빅데이터 관련 연구가 활발히 진행되고 있지만 빅데이터에 대한 개념 및 기술 동향 등으로 연구 범위가 국한되어 있다. 본 연구에서는 헬스 케어 분야에서 빅데이터를 활용하여 사용자 인식 현황을 분석함으로써 빅데이터 관련 연구 범위를 확대하고자 하였다. 전문의약품으로 분류된 사후피임제를 일반의약품으로 전환하고자 하는 계획안이 2012년 6월 식품의약품안전청에 의해 추진되었으나 2015년 7월 현재까지 구체적 방향 모색을 이유로 보류되어 있는 상태이다. 본 연구는 이에 대한 정책적 방향성을 제시하고자 사후피임약에 대한 사용자의 인식 현황 실태 조사를 실시하였다. 한국은 전통적으로 엄격한 성 문화권을 가지고 있으며, 이러한 문화에서 설문 조사 등의 방법으로 ‘피임’이라는 다소 노골적인 주제에 대한 정확한 실태 조사 결과를 얻기란 쉽지 않을 것으로 예상하였다. 따라서 이를 보완하기 위한 방법으로 온라인 텍스트 데이터 기반 빅데이터 분석 방법을 도입하였다. 익명성이 보장된 사이버 문화에서는 보다 솔직한 개인의 의견이 반영되어 있으므로, 이를 실증적으로 분석하면 사후피임약에 대해 보다 실제적인 인식 및 이용 현황을 파악할 수 있으리라 예상하였다. 본 연구에 사용된 데이터의 범위는 피임 키워드가 포함된 텍스트 데이터로 2009년부터 2014년까지 총 7,921건의 데이터를 웹 크롤링 통해 수집하였다. 이를 자연어처리와 형태소분석을 통해 명사를 추출하였으며, 추출된 명사를 토대로 현황 분석, 시계열 분석, 소셜 네트워크 분석, 군집 분석을 수행하였다. 분석 결과 사용자들은 주로 사후피임약에 대한 전반적인 정보(효능, 복용방법)를 필요로 했으며, 특히 남성과 미성년을 대상으로 하는 교육이 부족하다는 것을 발견하였다.",
		"KEYWORD": null
	},
	{
		"ID": 619,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "관계형 데이터베이스를 활용한 하이브 질의 처리 성능 향상 기법 =Performance acceleration techniques for Hive query processing using relational databases ",
		"AUTHOR": "김윤호",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 나연묵",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "최근 소셜 네트워크 서비스(SNS)로 대표되는 소셜 미디어의 급격한 성장, 스마트 폰을 필두로 하는 다양한 모바일 장치의 대중화, 그리고 다양한 정보를 생산하는 센서 장비의 이용 확대 등으로 인하여 빅 데이터의 시대가 도래하고 있다. 이에 발맞추어 빅 데이터의 효율적인 분석 및 처리를 위한 솔루션으로 하둡(Hadoop) 그리고 이와 연계된 다양한 관련 프로젝트들이 등장하였다. 관련 프로젝트들 중 하나인 하이브(Hive)는 페이스북(Facebook)에서 개발된 것으로 빅 데이터를 분석하기 위해 사용자들이 맵 리듀스(MapReduce) 프로그램을 직접 개발해야 한다는 단점을 해결하였다. 즉 기존 사용자들이 사용하던 SQL문을 그대로 사용하여 빅 데이터를 분석할 수 있는 인터페이스를 제공하고 있다. 하지만 하이브는 대용량 데이터를 분석 및 처리하기 위해서는 결국 하둡의 맵 리듀스를 수행하는 이전과 동일한 수행 방법을 적용하고 있기 때문에 성능 상의 이점이 전혀 존재하지 않는다. 이러한 수행 구조로 인해 하이브는 대용량 데이터의 실시간 처리 작업보다 일괄 처리 위주 작업에 주로 사용되고 있다. 본 논문에서는 하이브가 기존 사용자들에게 친숙한 SQL 인터페이스를 제공하지만 성능상으로 얻을 수 있는 이점이 없다는 점에 착안하여 이를 개선하기 위한 기법을 제안한다. 먼저 성능 개선을 위한 핵심 아이디어로 기존의 스토리지 계층 구조의 개념을 적용하였다. 인덱스와 같은 기법들이 적용되어 빠른 속도로 데이터 질의 처리를 수행하는 관계형 데이터베이스를 하이브 질의 처리 결과를 저장하는 캐시 저장소로 이용함으로써, 성능 향상을 이끌어냈다. 즉 사용자들은 빅 데이터 처리 결과를 하이브가 아닌 관계형 데이터베이스를 통해 빠르게 얻을 수 있는 것이다. 이러한 성능 향상과 더불어 관계형 데이터베이스에 저장되어 있는 데이터들이 최신 정보를 유지할 수 있는 방법과 자주 사용되지 않는 데이터들은 캐시에서 제거하는 등 다양한 기법들에 대해 기술한다. 본 논문에서 제안하는 하이브에서 수행된 빅 데이터 처리 결과를 관계형 데이터베이스에 저장하는 기법을 HoneyBee라는 이름의 소프트웨어로 구현하였다. HoneyBee는 관계형 데이터베이스를 캐시 저장소로 사용하기 때문에 하둡과 달리 확장성이 떨어진다. 그렇기 때문에 하이브 처리 결과가 방대할 경우 데이터를 관계형 데이터베이스에 캐시하지 못하는 경우가 있다. 이러한 제약 사항 때문에 HoneyBee는 처리 결과가 매우 적은 SQL문이나 COUNT, AVERAGE와 같은 집계 함수 처리에 보다 유용하게 사용될 수 있을 것이다. 더불어 현재 HoneyBee는 사용자 질의에 대해 간단한 WHERE 절 분석을 통해 캐시 데이터를 처리하고 있다. 추후 보다 완벽한 사용자 질의 분석을 통해 HoneyBee에 캐시된 데이터를 효율적으로 활용할 수 있는 기법에 대한 연구가 진행되어야 할 것이다.",
		"KEYWORD": "Hadoop,Hive,RDBMS"
	},
	{
		"ID": 620,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "신규 ICT 환경에 따른 개인정보보호 법규 정비에 관한 연구 ",
		"AUTHOR": "박미사",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김광수 참고문헌: p. 129-136",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "우리는 사물인터넷(IoT), 빅데이터(Big Data) 시대라고 불리는 ‘개인정보 기반’의 시대에 살고 있다. 세계적인 IT분야 리서치 기업인 가트너(Gartner)는 2020년까지 절반 이상의 신규 비즈니스에 IoT가 적용될 것이라고 발표하였다. 또한 가트너는 빅데이터를 ‘21세기의 원유’라고 하며 “기업들은 다가오는 데이터 경제시대를 이해하고 이에 대비해야 한다.”라고 강조하였다. 과거에는 영화나 TV 속의 상상 속에서만 존재했던 웨어러블 디바이스, 스마트 홈, 스마트 카, 드론 등의 기기들이 지금은 실생활에서 활용되는 현실이 되었다. 이처럼 새롭게 떠오르는 산업인 IoT와 빅데이터 등 신규 ICT 서비스들은 모두 개인정보의 기반으로 이루어진다고 해도 과언이 아니다. 빅데이터, IoT 산업의 발달은 많은 양의 데이터 축적과 활용이 이루어진다는 측면에서 개인정보 활용에 대한 요구를 증가시키고 있다. 빅데이터, IoT 활용 과정에서 수많은 개인정보가 수집·이용되며, 그 과정에서 새로운 개인정보가 생성될 수 있기 때문이다. 빅데이터, IoT 시대에서 데이터의 가치는 단순한 하나의 정보가 아니다. 축적된 데이터들을 통해 통계자료, 마케팅 자료 등으로 활용하며, 하나의 경제적 가치를 가진다는 점에서 그 중요성이 커지고 있다. 세계 주요국들은 빅데이터, IoT 산업에서의 활용성을 인지하여 육성 계획을 발표하고 있을 뿐 만 아니라, 필연적으로 논의될 수밖에 없는 개인정보보호의 문제와 관련하여 정책을 발표하고 법·제도 개선을 위해 노력 중이다. 최근 우리나라 역시 빅데이터와 IoT 산업에 대한 관심과 수요의 증가로 인해 입법적, 정책적 노력을 펼치고 있다. 우리나라 개인정보보호 법제는 정보의 이용이 증가하는 시대 상황을 반영하고 국민의 개인정보를 보호한다는 입법취지로 2011. 3. 29. 제정(2011.9.30. 시행)되었다. 이 후 대규모 개인정보 유출사고의 발생 등 지속적인 개인정보 유출로 우리나라 개인정보보호법제는 징벌적 손해배상 도입, 법정손해배상, 과징금 상향 등 보다 강화된 내용으로 개정되어 왔다. 그러나 이러한 강화에도 불구하고 실질적으로 국민의 개인정보를 보호해주지 못하고 있다는 비판을 받고 있으며, 다른 한편으로 개인정보 활용이 기반이 되는 신규 산업의 발전에도 장애물이 되고 있는 실정이다. 특히 최근에는 현행 우리나라 개인정보보호 법체계가 개인정보 ‘보호’의 관점에만 치우쳐져 있어서 신규 ICT 산업 활성화를 저해하고 있다는 비판을 받고 있다. 이에 IoT, 빅데이터 등 신규 ICT 산업의 활성화에도 기여하면서 실질적인 이용자 보호를 위한 개인정보 보호 법제도 개선방안이 필요하다. 따라서 본 논문에서는 모든 것이 연결되는 초연결사회가 도래함에 따라 개인정보보호 법제가 ICT 환경 변화의 속도에 맞추어 대응할 수 있는 개선방안에 대하여 논하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 621,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "텍스트 마이닝(Text Mining)을 이용한 관광지 이미지 결정요인에 관한 연구 =(A)study on the determinants of destination image using text mining ",
		"AUTHOR": "심영석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김홍범",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "최근 정보기술의 발전과 더불어 인터넷 환경의 급격한 변화는 관광객들의 관광정보 탐색, 여행 계획, 소비에 이르기까지 관광생태계에 다양한 방면으로 변화를 가져왔으며 온라인상에서 생성되는 대용량의 데이터들은 관광객들의 인식에 근거한 관광목적지의 이미지와 관광목적지 선택에 커다란 영향을 미치고 있다. 그러므로 관광생태계의 변화 속에서 관광목적지의 전략적인 이미지 마케팅을 위해서는 오프라인뿐만 아니라 온라인상에서 관광객들이 지각하는 관광목적지의 인식에 대한 파악이 반드시 필요하다. 이러한 온라인상의 데이터는 정량적, 정성적 연구가 동시에 가능한 관광정보 수집의 새로운 원천으로써 실시간 축적되는 대량의 데이터를 활용하여 관광지 이미지 파악에 새로운 시각을 제공할 수 있으며, 관광객들을 더욱 폭넓게 이해할 수 있는 기반이 될 수 있다. 따라서 본 연구는 Web 2.0 환경에서 대표적인 커뮤니케이션 수단인 SNS와 빅데이터를 분석하기에 적합한 방법인 텍스트 마이닝 기법을 활용하여 온라인 여행 커뮤니티인 Tripadvisor에서 리뷰 데이터를 수집하고 분석하여 관광지 이미지에 대한 유의미한 정보를 추출하고 관광지 이미지와 경쟁력에 대한 시사점을 제시하는데 목적이 있다. 또한, 이러한 온라인 데이터의 분석절차를 관광분야에 적용 가능하도록 체계화시키고자 한다. 먼저, 온라인 리뷰 데이터 수집을 위하여 전용 웹 크롤러를 개발하였으며 관광지 평가 사이트인 Tripadvisor로부터 분석에 필요한 표본을 수집하였다. 연구에 사용된 유효 표본은 2013년 1월부터 2015년 7월 31일까지 서울의 관광지 17곳(명동, 동대문, 남대문, 남산/N서울타워, 인사동, 신촌, 홍대, 이태원, 롯데월드, 한국전쟁기념관, 국립중앙박물관, 국립민속박물관, 경복궁, 창덕궁, 덕수궁, 창녕궁)을 대상으로 작성된 7,188건의 온라인 리뷰이며 R Programming을 이용하여 텍스트 마이닝 분석을 하였으며 SPSS 21.0을 이용하여 탐색적 요인분석, 신뢰도 분석, 일원분산분석(One-Way ANOVA), 판별분석, 다중회귀분석을 실시하였다. 연구결과, 관광지의 인지적 이미지에 해당하는 8개의 요인과 정서적 이미지에 해당하는 8개의 요인이 도출되었으며, 도출된 관광지 이미지는 관광지 유형별(쇼핑 관광지, 자연 관광지, 문화 관광지, 위락 관광지, 박물관/전시관, 역사 관광지)로 유의한 차이가 있는 것으로 나타났다. 뿐만 아니라 관광지 이미지로 관광지 유형을 구분할 수 있는 특징적인 요인을 밝혔으며 관광지 이미지와 만족도간의 유의한 영향관계를 검증하였다. 본 연구는 정성적 데이터인 온라인 리뷰에서 데이터를 추출하고 가공하여 정량적 분석을 체계화 시키는데 의의가 있으며 이를 바탕으로 인터넷과 모바일을 통하여 기하급수적으로 증가하고 있는 빅데이터를 관광분야에 적용하기 위한 이론적 기반을 제공한 점에서 시사점을 가진다.",
		"KEYWORD": "관광정보,관광지 이미지,빅데이터,온라인 리뷰,텍스트 마이닝,트립어드바이저"
	},
	{
		"ID": 622,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "노선버스 재차인원 예측모형 개발 :Development of prediction model for route bus passenger occupancies : focused on red bus Gyeonggi province ",
		"AUTHOR": "임승국",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김영찬",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "The purpose of this study is to develop a prediction model for the route bus passenger occupancies. The requirement of the route bus passenger occupancies prediction model is that ① historical data should be used, ② multiple interval prediction should be possible, ③ prediction power should be good, and ④ portability should be. In this study, It used k-Nearest Neighborhood(k-NN) algorithm which is estimated to be the best predictor in the big data environment. In order to develop a prediction model for the route bus passenger occupancies, we first generate the pattern data for the route bus passenger occupancies and presented the k-NN Basic Model (BM) that use riding, getting off, passenger occupancies for input data. Euclidean Distance (ED) was used to measure the similarity of the k-NN Basic Model and the number of neighbors (k) was default 3. Passenger occupancies pattern data was constructed for each route and day of the week by using the historical data from May 1, 2015 to April 30, 2016 for 8 red bus in Gyeonggi province. The pattern data time interval was set to 10 minutes in consideration of the bus interval. To reflect characteristics of each route we constructed pattern data by each route, day of the week and time of day. The passenger occupancies pattern data for each route shows that is appropriate data apply to the k-NN model, Because the pattern is fixed according to the time and the day. In order to improve the predictive power of k-NN basic model, we evaluated the applicability of four areas such as ① consideration of operating time, ② whether weather information is used, ③ change of bus location, ④ change of input range and forecast range. As a result of the applicability evaluation, the predicted results were excellent when the operating time was limited to ± 1 hour based on the departure time of the starting bus stop. Although there was no significant difference in the prediction results according to the use of weather information, the results were somewhat better when using weather information. As a result of change of bus location, the relationship between bus location and prediction accuracy is low. As a result of evaluation based on the change of the input range and the predicted range, the best results were obtained when predicting 10 bus stop in the future using only the data of latest 10 bus stop. Based on the results of the applicability evaluation, the k-NN Advanced Model (AM) and the k-NN Fusion Model (FM), which improved the k-NN Basic Model, were presented. The k-NN Advanced Model (AM) is a model that additionally considers the operating time and weather conditions when searching for historical data in the Basic Model (BM). The k-NN Fusion Model (FM) is consisted a total 7 steps adding a data fusion step between the predicted data and the pattern data. For the prediction performance and portability evaluation of the two proposed prediction models, three routes (9003, 1007, 500-1) with different passenger occupancies patterns were evaluated. As a result of the evaluation, the predictive power of the k-NN Advanced Model and the k-NN Fusion Model showed different results depending on the route. As a result, the k-NN Fusion Model showed good results and the error variance was low. The k-NN Fusion Model was more stable and predictive than the k-NN Advanced Model. The most excellent model was the k-NN Fusion model and the best results were obtained by predicting in the future 10 bus stop occupancies using the latest 10 bus stops data. The passenger occupancies prediction model of the using the k-NN algorithm showed a difference in the predictive power according to the historical data pattern of the route. The k-NN Advanced Model (AM) is more suitable in case of having a fixed patterns and the k-NN Fusion models (FM) is more suitable in the case of having a uneven patterns.",
		"KEYWORD": "k-NN 모형,교통카드시스템,데이터퓨전,버스정보시스템,빅데이터,승차인원,예측모형,재차인원,패턴데이터,하차인원,혼잡도"
	},
	{
		"ID": 623,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "Memcached를 활용한 데이터 처리 성능 향상 =Performance improvement of data processing using memcached ",
		"AUTHOR": "전창식",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최용락",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 들어 빅데이터(Big Data)라는 용어와 함께 NoSQL(Not Only SQL)이 주목 받고 있다. NoSQL은 관계형 데이터베이스에 적합하지 않으면 무리하게 관계형 데이터베이스에 얽매이지 말고 용도에 맞는 데이터 저장소를 사용자는 것이다. NoSQL은 관계형 데이터베이스가 다루기 어려운 대용량 데이터 쓰기에 사용되며, Memcached는 NoSQL의 한 종류로서 데이터가 Hash형식으로 관리되는 휘발성 Key-Value형으로 분류되며 저장되는 데이터들은 모두 메모리에 보관된다.[1] Memcached의 장점은 데이터 조회에 대하여 매우 빠른 처리속도에 있다. 데이터가 모두 메모리에 있기 때문에 디스크 I/O를 발생시키지 않으므로 관계형 데이터베이스에 비해 상당히 빠르게 작동한다. 본 논문에서는 관계형 데이터베이스의 한계를 극복하기 위해서 Memcached와의 결합으로 관계형 데이터베이스 단독으로 사용 될 때보다 데이터 조회에 있어 높은 성능을 보장한다는 점을 증명하고자 한다.",
		"KEYWORD": "memcached,nosql"
	},
	{
		"ID": 624,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 과학기술대학원",
		"TITLE": "하둡 맵리듀스와 GPGPU를 이용한 K-Means 알고리즘의 가속 =Acceleration of K-means algorithm using hadoop MapReduce and GPGPU ",
		"AUTHOR": "신은섭",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이영민",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "최근 수집된 대량의 데이터를 분석하여 사용자의 패턴을 파악하거나 의사 결정하는데 빅데이터 활용에 관심과 수요가 높아지면서, 이를 처리하는 시스템에 대한 고가용성, 고성능이 요구 되고 있다. 빅데이터를 처리하는 프레임워크로 하둡 맵리듀스가 많이 사용 된다. 맵리듀스는 JAVA 함수형 프로그래밍 기법을 이용하여, 빅데이터를 여러대의 노드로 분산시켜 저장 및 연산 처리를 한다. 하지만 CPU의 순차적인 코드 실행 배치방식의 제약과 메모리 대역폭의 구조적인 한계 때문에 대용량의 데이터를 동일한 처리과정으로 반복하여 수행하는 분석 작업이나 실시간 처리 시 지연이 발생한다. 이에 GPGPU 범용프로세서를 사용할 수 있는 GPGPU CUDA 프로그래밍을 사용하여 CPU에서 반복 연산 처리하는 소스 코드를 GPGPU에서 가속 연산 처리하여 분산처리 환경에서 연산 처리 성능을 향상 시키는 것에 목적이 있다. 본 논문은 빅데이터의 데이터 분석에 적합한 K-Means 군집화 알고리즘을 사용하여 Single CPU 환경과 하둡 분산처리 환경에서 성능을 측정하고, GPGPU를 이용한 성능 가속화 방법을 제안 한다. 주요어 : 빅데이터, 하둡, 맵리듀스, GPGPU, CUDA, K-Means",
		"KEYWORD": "CUDA,GPGPU,K-Means,맵리듀스,빅데이터,하둡"
	},
	{
		"ID": 625,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "공공데이터 제공 및 활용의 생태계 조성을 위한 공공데이터 분석 플랫폼 연구 =ODAP :an architecture of open data analysis platform for open data eco-system ",
		"AUTHOR": "손석현",
		"REGION": "서울",
		"PROFESSOR": "건국대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 신효섭 부록: `1. ` 외 수록 참고문헌: p. 76-78",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "최근 정부의 공공데이터 개방율이 증가하고 있으며, 이를 활용한 서비스 역시 급증하고 있는 추세이다. 공공데이터는 정부가 수집한 정보를 기계판독이 가능한 형태로 처리된 자료 또는 정보를 의미하며, 국민 (개발자) 은 국가로부터 공공데이터를 취득하여 IoT (Internet of Things), 빅데이터 (Big data) 등 다양한 기술과 접목 (융합) 한 어플리케이션의 개발이 가능하다. 공공데이터의 대표적인 활용 사례로는, 실시간 교통정보와 공간정보를 이용한 각종 내비게이션 (Navigation) 서비스, 부동산정보를 이용한 전세, 매물정보 제공 서비스 등을 들 수 있다. 공공데이터의 활용을 위해서는 먼저, 데이터의 분석 (데이터간의 상관관계 및 정규분포, 데이터의 추세 등 수학적 분석) 이 필요하나 일반적인 통계 분석 프로그램 (R, SAS, Matlab 등) 은 고가이며, 복잡한 코드작성과 라이브러리 다운로드 등의 노력 또는 수고가 필요로 하여 비전공자는 데이터 분석의 한계를 나타내고 있다. 또한, 공공데이터 비즈니스 모델 발굴 시 기존 공공데이터의 활용사례 통계 및 수요도의 측정이 필요한데, 그 이유로는 현재 수요가 높은 데이터 또는 어플리케이션을 확인하여 미래의 수요 데이터 또는 어플리케이션의 분석 및 예측이 가능하기 때문이다. 본 논문에서는 공공데이터 표준을 준수하고, 별다른 코드 작성이 없으며, 공공데이터간의 수학적 분석이 가능한 공공데이터 분석 모듈과 공공데이터 활용사례를 통한 공공데이터 수요 및 공급의 실시간 현황을 분석하여 시각화하는 공공데이터 시각화 모듈이 포함된 웹 기반의 공공데이터 분석 플랫폼을 소개하고 구현 결과 및 파급효과를 제시한다. 또한, 본 연구의 결과물인 공공데이터 분석 플랫폼을 기존 통계 분석 시스템과 비교평가 하여 결과를 제시한다.",
		"KEYWORD": null
	},
	{
		"ID": 626,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "학습분석 도메인에서의 RDF기반 데이터 수집 및 전송 모델 =(A)RDF-based model for data collection and exchange in learning analytics ",
		"AUTHOR": "배재형",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이재호",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "예로부터 교육은 인간사회에 가장 중요한 부분으로써 많은 발전을 거듭해 왔으며, IT산업이 발전함에 따라 교육의 디지털화 역시 빠르게 이루어져왔다. 이러한 추세에 힘입어 방대한 양의 디지털 학습 정보로부터 새로운 정보와 지식을 도출하여 교육의 질을 높이고 새로운 서비스를 제공하기 위한 학습분석이라는 분야가 대두 되었고, 이에 대한 연구가 현재 세계적으로 활발히 이루어지고 있다. 현재 학습분석 분야에서는 다양한 센서로부터 수집되는 정보를 이용하기 위해 수집 데이터의 일관성을 유지하고, 대량의 데이터를 저장소에 전송하기 위해 전송 효율이 높은 데이터 모델이 요구되고 있다. 학습분석에 대표적으로 사용되는 데이터 모델인 IMS Caliper의 경우에는 JSON 데이터를 수집하여 분석하는 방법이 사용되고 있는데, 분석에 용이한 형태로 JSON데이터를 변환해주어야 하는 전처리 소요가 발생하고 전송 시에 중복되는 데이터가 필연적으로 발생하여 전송 효율이 떨어지는 단점도 존재하기 때문에 개선이 필요한 실정이다. 이에 본 논문에서는 IMS Caliper에서 발생하는 분석의 불편함과 전송의 비효율을 개선한 새로운 데이터 수집 및 전송 모델을 제안한다. JSON 데이터로부터 원하는 정보를 수집하고 객체화한 정보 모델(Information Model)과 전송하려는 데이터를 RDF 형태로 변환하여 데이터의 중복을 줄인 전송 모델(Exchange Model)을 이용함으로써 전송효율을 높일 수 있을 뿐만 아니라 분석에 용이한 형태로 데이터를 전송 할 수 있음을 실험을 통해 검증해 보았다.",
		"KEYWORD": "Exchange Model,Information Model,RDF,빅데이터,학습분석"
	},
	{
		"ID": 627,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "인천대학교 경영대학원",
		"TITLE": "사물인터넷(IoT) 기반 헬스케어 스마트 시스템 연구 =(A)study on health care smart system based on IoT ",
		"AUTHOR": "김준호",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 김준우",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "IT 분야의 리서치 및 자문회사인 가트너(Gartner)는 2012년부터 “가트너 선정 10대 IT 전략기술”에 사물인터넷을 꾸준히 선정했다. 매년 발표되는 가트너의 이러한 전략기술은 향후 3년간 기업의 혁신, 투자, 위험요소 등에 중대한 영향을 미칠 수 있기 때문에 기업의 전략수립 시 필히 반영되어야 하는 기술을 의미한다. 사물인터넷 기술을 활용한 헬스케어 스마트 시스템은 고령층 홈케어나 만성질환 치료 및 관리 등 의료서비스 부문에 접목되어 의료비 절감 및 서비스 품질 향상에 기여 및 건강에 대한 관심 증대를 배경으로 일반 소비자 대상으로 사물인터넷 기반 건강증진 제품 및 서비스를 개발, 보급함으로써 기존에 존재하지 않았던 새로운 시장과 부가가치를 창출할 수 있다. 하지만 생체정보를 측정하여 수집하고 가공하여 정보화 시키는 과정에서 개인정보에 대한 문제점들이 나타나고 있다. 이에 본 논문은 사물인터넷 기반 헬스케어 서비스가 필요한 기술적 요소를 이해하고 국내 소비자들이 건강의 증대와 개인정보 취약성 부분에서 어느 부분을 선호하는지 설문을 통하여 결과를 도출하고 향후 개선점을 연구하고자 한다.",
		"KEYWORD": "IoT,사물인터넷,헬스케어"
	},
	{
		"ID": 628,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "시·공간적 연계성을 고려한 공로망에서의 링크 통행속도 통합 추정 방법론 :Forecasting short-term travel speed in a dense highway network considering both temporal and spatial relationship :딥러닝 기법을 이용하여 =using a deep-learning architecture ",
		"AUTHOR": "이민서",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 손기민 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "Predicting the accurate travel speed is vital, since the travel speed is the basis of traffic information and is necessary for controlling or managing the dense highway network. However, the methodologies developed so far were not sufficient to ensure a satisfactory level of accuracy. Recently, with the increased utilization of big-data and the development of deep-learning technology, deep-learning based on big-data is widely used in the field of speech/image recognition and natural language processing. Also, deep learning is continuously applied in the field of transportation engineering, and has shown good applicability. Thus, this paper used the deep-learning technology to predict the accurate travel speed of the dense highway network. The existing models, such as Time-series model and Kalman filter method, are limited for their spatial and temporal range; thus, the researcher himself/herself should define the range of analysis. However, this paper used the RNN model, one of deep learning technologies, and expanded the limitation of spatial and temporal range. The test-bed of the analysis was set to the upward section of Youngdongdae-ro and the hyper parameters were optimized to boost the performance. To verify the performance of the developed model, the result derived by Kalman filter, the naive forecasting method, the RNN model for a single link, and the RNN model for multi links were compared according to the %RMSE value and pattern of the scatter diagram It is concluded that the accuracy of the travel speed prediction was placed in the following order: the RNN model for multi links, Kalman filter, the RNN model for a single link, and the naive forecasting method. In the future, the removement of abnormal links or upper limit of the travel speed is required to improve the performance of the developed model.",
		"KEYWORD": null
	},
	{
		"ID": 629,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "엔터프라이즈환경 게시판(Board)에서 관계형DB 데이터모델과 NoSQL 데이터모델 적용시 성능을 고려한 선택방법에 관한 연구 =(A)research on how to select a performance consideration when applying the RDB datamodel and NoSQL datamodel in enterprise board ",
		"AUTHOR": "이춘식",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박석 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "In 1970, it has managed to establish a stable database based on normalization in large database environment by E.F Codd. Accordingly, it was a trend to establish a database of companies by using a relational database for a long time. Recently, the factors causing the data are becoming diverse into a bulletin board that people express their opinions actively, social network that everyone participates and exchanges their ideas and so on. So, in order to process very large data rapidly, examples applying a NoSQL database based on Bigdata are increasing. In particular, many companies that have business characteristics such as e-commerce based on the Internet are actively applying a NoSQL database. But, in an enterprise environment with normal business characteristics, other companies are still applying a RDB that was used traditionally because the criteria that must be introduced to NoSQL about some business on what basis is ambiguous. Many people express their opinion and check it a lot in a short time, if you handle the large data by the NoSQL-based environment rather than the conventional method processing relational database, the cost can be much cheaper and it is possible to break the processing of data consistency(ACID; Atomicity, Consistency, Isolation, Durability) that gives much load to a relational database. For these reasons, the performance is expected to be further improved and to be able to handle better. Consequently, depending on the results of this study, in case of bulletin board in an enterprise environment, if you select a NoSQL database and apply it, it is possible to process business with much faster performance (approximately 2times to 58times) and efficient business processing.",
		"KEYWORD": null
	},
	{
		"ID": 630,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "확장적, 상호운용적 학습 분석 시스템을 위한 메시지 기반 플러그인 아키텍처 =(A)message-based plugin architecture for scalable and interoperable learning analytics systems ",
		"AUTHOR": "강진만",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이재호",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "정보통신기술이 발전함에 따라 교육 환경 역시 전통적인 교육에서 인터넷을 활용한 e-러닝으로, 더 나아가 최근에는 다양한 스마트 기기를 활용하는 스마트 러닝으로 변화하고 있다. 이러한 교육 환경의 변화로 교육 환경에서 다양한 데이터의 수집이 가능해졌고, 수집한 데이터를 빅 데이터 기술을 통해 분석 및 활용하는 학습 분석 분야가 대두되었다. 현재 국내에서는 학습 분석 관련하여 KERIS가 주관하는 ‘교육용 콘텐츠 및 비정형 데이터를 활용한 학습분석 기술 참조모델 표준 개발’과제가 진행 중이다. 진행 중인 학습 분석 과제에서는 국내외 학습 분석 표준을 수립하기 위한 노력으로 학습 분석 참조모델을 제안하고, 이를 검증하기 위해 데모시스템을 구축하였다. 제안한 참조모델 중 데이터 분석 단계의 경우 현재 미리 설계된 분석 프로세스를 기반으로 저장된 데이터를 분석하도록 이루어져 있다. 하지만 학습 분야의 특성상 교육 과정이나 학습 환경의 변화가 빈번하게 이루어 질 수 있고, 그에 따라 새로운 분석 방법이 추가되거나 기존의 분석 방법이 수정될 수 있다. 또한 다양한 분석 도구의 활용 역시 요구 될 수 있는데, 현재의 참조모델에서는 이러한 수정을 위해서는 전체 시스템의 수정이 불가피하다. 본 논문에서는 이러한 문제점을 해결하기 위해 메시지 기반 플러그인 아키텍처를 제안한다. 현재의 분석 프로세스를 기본 단위별로 컴포넌트로 나누고, 각 컴포넌트는 분산된 객체로서 별도의 프로세스로 돌아갈 수 있도록 한다. 또한 컴포넌트 간 직접적인 인터페이스를 통한 연결이 아니라 컴포넌트들을 관리하는 매니저를 통해 분석 워크플로우를 구성함으로써 실시간적인 컴포넌트의 추가 및 제거가 가능하도록 하였다.",
		"KEYWORD": "빅 데이터,학습 분석 플러그인 아키텍처"
	},
	{
		"ID": 631,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "(A)study of building energy control system with intelligent object energy chain mechanism based on energy-IoT infrastructure =에너지 IoT 기반의 지능적 에너지 체인 메커니즘을 통한 빌딩 에너지 제어 시스템 연구 ",
		"AUTHOR": "SangminPark",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 632,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "스타트업 기업 맞춤형 스마트프로덕트 기획·개발 프로세스의 제안 및 사례 연구 =(A)case study on the optimized smart product planning and development process for start-up firms ",
		"AUTHOR": "오경식",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최재붕 참고문헌 : p.103-107",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "개인용 모바일 기기인 스마트디바이스의 보급화와 함께 도래한 초연결사회와 만물통신의 시대에서 스타트업 기업은 자원부족 등의 요인으로 인해 포스트 스마트 시대를 선도할 스마트프로덕트 시장 진입에 큰 어려움을 겪고 있는 상황이다. 본 연구에서는 일반적 스마트프로덕트 디자인 프로세스에 효과적 사용자 니즈 도출을 위한 트렌드 서치에 기반 빅데이터 분석, 지속가능한 비즈니스 모델 확보를 위한 제품-브랜드전략, 투여자원 절감을 위한 3D프린터를 활용 시제품개발 등을 적용한 스타트업 기업 맞춤형 스마트프로덕트를 제안하였다. 그리고 맞춤형 프로세스를 실제 스타트업 기업의 스마트프로덕트 기획·개발에 적용하고 결과물의 핵심성과지표 분석을 통해 맞춤형 프로세스의 유효성을 검증하였다. 본 연구는 새롭게 열릴 포스트 스마트 시대에서 스타트업 기업이 성공적으로 진입하고 지속가능한 비즈니스모델을 확보하는데 기여할 것으로 기대된다.",
		"KEYWORD": "빅데이터(Big Data),스마트 디바이스(Smart Device),스마트 프로덕트(Smart Product),스타트업(Start-up),초연결사회(Hyper Connected Society)"
	},
	{
		"ID": 633,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "인터넷과 이중 관리권력 그리고 관리사회 ",
		"AUTHOR": "박승일",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 원용진 참고문헌 수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "The media environment has permeated through our life and become a natural background of everyday life as much as we normally cannot even recognize, since it was formulated in 1980s as the computer-based environment and gradually changed into the WiFi-based, the smartphone-based, and the Big Data. Information and communication technology, which emerged in the form of artificial intervention, has become part of our life and invisible just as Cloud and Big Data. Now all of our information is collected and stored somewhere beyond the clouds or Cloud. The information is used again to produce new surplus value and even to predict the future. Meanwhile, things are exchanging information with each other, and centralized in the automatic control system of objects. As a result of the changes, we are living in the Internet world of freedom and in the environment in which everything is mediated. The issue is that the environment surrounding the Internet itself is at the center of neoliberal governance strategies, so that the automation of governance through the optimization of the mediating environment has gained everyday power. It can be said that the contemporary media environment operates more effective power than the existing subjectification process such as internalization of power by individual subjects in that it drove the thoughts and behaviors of general people toward a certain direction. On the other hand, the Internet is generating another trend that can not be reduced to environmental management. The individualization mechanism of the Internet Web service collects, analyzes, and utilizes the past history of the Internet search by the user, and affects the thoughts and identity constructions of users by displaying the history as new information. Moreover, this enormous and large-scaled database provides the sources for sophisticated strategies and tactics of governance by visualizing the patterns of collective and unconscious will and desire of the user population through statistics and numbers. To activate this process, the Internet not only induces and promotes the active production, participation, and cooperation of users, but also leads their attitudes and emotions in a certain direction to do so willingly. All of these results tell that the mental ability of anyone including knowledge, communication, pleasure, participation, creativity, cooperation, passion, and expression, is a resource that can be collected and transformed into profitable sources and data which enable effective governance. In other words, directing individuals` thoughts, managing collective unconsciousness, and leading individuals` attitudes and emotions in a specific direction are not only the driving force of the neoliberalism`s valorization mechanism and subsumption strategy, but also the optimal governance strategy and technology that allows them to (freely) enter the circuit of governance. In this dissertation, I try to understand the operation of power by the Internet by dividing them into two aspects: the environment management and the management of mind. Each of them can be called the Environmental Power and the Psycho Power according to their principles. If the former refers to the vector of the power (strength and direction) that constitutes and manages the everyday environment as a constant, potential, automatic mediator of the Internet, the latter refers to a vector of power that leads the mind to a certain direction and form. In both cases, it is important to keep in mind that dialectics of freedom and governance function as key concepts. These dual powers of control can be distinguished in terms of its principles and mechanisms, but as a whole it is combined into a dual mechanism of social organization. Thus, the powers can not be separated into separate disconnective actions. This dissertation seeks to understand the social configuration that these two different vectors, interacting with each other, create as a synonym of The Society of Control. The Society of Control exists only as its result and effect, not as a priori reality that objectively exists without the functions of its forces. It cannot be understood that a particular social fabric exists first and the society mobilizes a variety of power mechanisms according to its purpose and needs. The Society of Control exists only by operating a variety of power mechanisms. Accordingly, the dual power mechanism, process, technique, and the combination of all these systems, which intersect and overlap with the machine (or dispositif) of the Internet, is the main topic of this dissertation. The purpose and main contents of this study are as follows. First, this dissertation aims to propose the concept of the Control Power, and to examine the plausibility of the notion. The Control Power, derived from Foucault`s notion of Governmentality, is but also to the notion to read the problematics of the current period, the post-Internet age, and to mark its own inseparability with neoliberalism in terms of the dimension of `management/control`. Secondly, this dissertation examines the actual operation mechanism of control power in terms of environmental management. Looking back at the development of information and communication technology, this dissertation examines how the technology has reconfigured the space of daily life into an environment of `in-mediation`, and how it has reorganized the experience and awareness of the subject to fit the environment configurations, and further extracts the concept of Environmental Power from through discussions on how the principle of the technology has led to the current mediating environment. Third, this dissertation aims to present the Psycho Power as the other aspect of the Control Power and to discuss the justification and necessity of this concept. It further discusses the rationality and power mechanism of the Internet technology, which leads users` thoughts in a specific direction, makes the collective unconsciousness of the population conform to the regular pattern of the algorithm, and drives users to consider the capability of the technology convenient, efficient, and even unnecessary. Fourth, I aim to conceptualize the social configuration, created by the process that the Dual Control Powers, the Environmental Power and the Psycho Power exchange and overlap with each other, as the Society of Control. In conclusion, this dissertation argues that the power of the Internet, on the one hand, intervenes in the Internet environment to manage and control users` thinking and behaviors, and on the other hand maximizes the freedom of internet users and monopolizes their capabilities. Through the dual controls of the environment management and psycho management, the technology has constituted the most efficient and effective governance system.",
		"KEYWORD": "관리권력,관리사회,노동의 사회화,매개 안에 있음,빅데이터,사물인터넷,생각의 인도,웹 2.0,이중 관리권력,인터넷,일반지성,정신관리권력,정신의 기계화,집합적 무의식,코드가 권력이다,클라우드,통치성,환경관리권력"
	},
	{
		"ID": 634,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "시스템 요구사항 분석을 위한 순환적-점진적 복합 분석방법 =Integrating iterative and incremental methodology for system requirement analysis ",
		"AUTHOR": "박지성",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이재호",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "현대 IT기술의 발전으로 데이터의 생성량과 속도, 그 다양성 또한 폭발적으로 증가하는 빅 데이터 시대에서 다양한 데이터의 분석을 위해 개발되는 서비스의 수가 증가하면서 이를 통합하는 과정에서 상충되는 요구사항의 수 또한 증가하고 있으며, 이 때문에 효과적인 시스템 요구사항 분석의 중요성 또한 점차 부각되고 있다. 효과적인 요구사항 분석을 위해서는 상충하는 요구사항들을 초기에 확인하고 이를 점진적으로 개선하며 요구사항을 구체화할 수 있어야 하지만, 기존의 순차적 요구사항 분석 방법은 이를 해결하기에 여러 제약사항이 존재한다. 따라서 본 논문에서는 기존의 순차적 방법과 순환적-점진적 방법을 결합하여 대규모 시스템에서의 효과적인 요구사항 분석을 가능하게 하는 복합 요구사항 분석 방법을 제안한다.",
		"KEYWORD": "대규모 시스템,빅 데이터,요구사항 분석 방법론"
	},
	{
		"ID": 635,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한림대학교 대학원",
		"TITLE": "구조방정식 모형과 기계학습을 이용한 데이터 분석 연구 =A study of analyzing panel data and user profile data through structural equation modeling and machine learning ",
		"AUTHOR": "용혜련",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 황현석",
		"STORE_LOCATION": "한림대학교 도서관",
		"ABSTRACT": "Study1 정보통신기술의 발달로 빅데이터 분석을 통해 사람들 일상의 기록과 잠재적 요구까지 통찰할 수 있게 되었으며, 우리의 일상 속에서 방대한 정보를 실시간으로 도출하고 있다. 여러 산업이나 기업에서 이미 빅데이터와 결합시켜 비즈니스 등 다양한 분야에 활용하고 있지만 게임 산업에서의 빅데이터 활용은 아직까지 미흡한 실정이다. 이에 본 연구에서는 데이터 마이닝을 기법을 적용하여 전략시뮬이션 게임 데이터를 분석하였다. 전략시뮬레이션 게임 데이터를 Decision Tree, Random Forest, Multi-class SVM, Linear Regression 분석 기법을 적용하여 게임 유저의 게임수준에 영향을 미치는 요인을 분석하였다. 게임수준을 예측하는데 있어 가장 우수한 성능을 보인 기법과 변수들을 도출하여 게임 디자인과 사용성을 증대시키기 위한 제안을 하고자 한다. Study2 청소년기는 아동에서 성인으로 넘어가는 과도기의 중간 기점으로서, 자신이 앞으로 어떠한 방향으로 살아갈지에 대한 고민과 자아를 정립하는 매우 중요한 시기이다. 이처럼 중요한 청소년기에 대한민국 청소년들의 삶의 만족을 조절하는 요인들에는 어떠한 것이 있는지 연구하고자 하였다. 본 연구에서는 청소년의 학습태도 및 삶의 만족에 영향을 미치는 요인들을 분석하기 위해 먼저 학습태도 및 삶의 만족에 영향을 미치는 요인으로서 부모, 또래, 교사와의 관계가 중요하다고 보았다. 탐색적 요인분석을 통해 설문에 사용된 변수들 간 관계를 찾아내었고, 이들 요인간의 구조적인 관계를 규명하고자 구조방정식 모형을 이용하여 분석을 실시하였다. 실증분석 결과, 청소년 시기의 부모양육방식, 또래애착, 교사관계는 학습태도 및 삶의 만족에 상당한 영향을 미치는 것으로 나타났으며, 분석된 결과를 통해 추후 대한민국 청소년들의 건강한 삶에 대한 결론 및 제언을 시사해보고자 하였다.",
		"KEYWORD": null
	},
	{
		"ID": 636,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한국교통대학교 대학원",
		"TITLE": "SNS 이미지 의미정보 분석 및 분류에 관한 연구 =(A)study on the semantic information analysis and classification for SNS images ",
		"AUTHOR": "이성재",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수:조수선",
		"STORE_LOCATION": "한국교통대학교 중앙도서관",
		"ABSTRACT": "최근 인터넷을 대표하는 서비스로는 사용자의 일상을 기록하는 SNS(Social Networking Service)가 화제가 되고 있다. 이러한 SNS서비스는 사용자의 일상과 정보를 적은 글뿐만 아니라 사진이나 동영상과 같은 멀티미디어 자료도 같이 업로드된다. 하지만 하루에도 엄청난 양의 데이터가 수억 명의 사용자로부터 업로드되는데 이러한 양의 데이터를 빅데이터(Big-Data)라고 불리며 이를 활용한 연구가 활발하기 이루어지고 있다. 예를 들어 사용자의 태깅된 이미지의 위치를 통한 다양한 광고 및 추천서비스를 제공하고 있고, 인터넷에서 가장 활발한 이슈거리를 파악하여 해당 사용자에게 추천 단어를 완성시켜주고 있기도 한다. 본 연구는 이러한 빅데이터 활용방안에서 착안한 사용자 이미지를 활용하여 해당이미지의 의미정보를 분석하고 자동으로 분류하는 기술을 연구하였다. 효과적인 분류를 위해 전 세계에서 가장 많이 사용하는 위키피디아를 이용하여 사용자 이미지의 의미정보를 파악하고, 기존 방식의 의미정보 순위 조정을 좀 더 효과적으로 재조정하여 이미지의 시각단어 추출을 통한 이미지의 실제 의미정보를 파악하는 적용 방안을 제안한다.",
		"KEYWORD": "SNS,검색,분류,시각단어,위키피디아,이미지,플리커"
	},
	{
		"ID": 637,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "트위터 마이닝을 위한 트위터 사용자의 거주지역 유추에 관한 연구 =(A)study on Twitter user`s residential location inference for Twitter mining ",
		"AUTHOR": "김문기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 고준환",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Tweets are created at the speed of thought, propagated in real time, produce social interchange on an international scale and are multifaceted. Twitter mining based on location that can identify topics of discussion in different regions on political controversy, sensitivity, disease, and social and trending issues becomes possible with the residential information of its users. Real difficulties, however, exist in analyzing data based on residential location due to the sparsity of spatial indicators. This study aims to develop an automated algorithm that allows twitter mining based on estimated residential location of twitter users through which massive twitter data can be processed by overcoming the sparsity of location information and inferring residential location up to the district level. As preliminary research, the study examined the problems in estimating twitter users’ residential information, the necessity of an algorithm, relation between population and number of twitter users, and previous cases of residential inference. Additionally, a literature review was conducted on the topic and the study’s contribution to the discussion assessed. The study conducted two main experiments to infer residential location of twitter users. The first experiment was conducted among users of Type I. This experiment calculated the accuracy of residential location inference based on the calibrated distance model for Seoul that showed strong correlation between the number of twitter users and population density. Additional spatial indicators B(location information on the SNS linked with tweet) and D(polygon shape geotag) were introduced to overcome the sparsity of location information. The inference success rate and accuracy were calculated and verified using a Convex hull with Onion Peeling(COP), K-Center Clustering(KCC) and Density-Based Spatial Clustering of Applications with Noise(DBSCAN) clustering algorithms. For the second experiment, the study conducted twitter mining on all twitter users in Korea and categorized users who included the frequent keywords “Chuseok(Major harvest festival and holiday of Korea)” and “exam” into types I, II, III and IV based on spatial indicators and the presence of location information on the profile. This study used the fire hose level, the massive 100 percent of twitter data to run twitter mining on all users in Korea. Spatial indicators B and D were additionally applied to overcome the sparsity of location information. As a result, the first experiment showed higher accuracy in inferring residential location when spatial indicators A, B, C and D were all applied compared to the conventional method of only using indicators A and C. COP clustering showed the highest inference accuracy for clustering. The accuracy of residential location inference was 50.2 percent within the tolerance radius of 3km(district), 71.03 percent within 14km(downtown Seoul) and 91.45 percent within 48km(outskirts of Seoul). The conventional method of using spritzer level data and the supervised method resulted in 44 times more positions inferred on tweets than the method using geotag, whereas the second experiment method used in this study saw inferences rise 680 fold. As for the clustering algorithm, that of KCC inferred the most number of user residential locations. The methods employed in this study allowed inferring residential locations of twitter users with higher accuracy than other existing studies. Yet limits appeared in inferring location within the tolerance radius of 3km. Nevertheless, the study offers a methodology for mass twitter data processing and introduced the use of new spatial indicators B and D to overcome the sparsity of location information and attempted inferring location information up to the tolerance radius of 3km.",
		"KEYWORD": null
	},
	{
		"ID": 638,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "SNS데이터의 도시정책지표로서의 활용 가능성 연구 :트윗 데이터의 주거환경 만족에 대한 공간적 특성 ",
		"AUTHOR": "박재희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 강영옥 참고문헌: p. 67-70",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "규모를 가늠할 수 없을 정도로 많은 정보와 데이터가 생산되는 가운데, 기존의 데이터로부터 가치 있는 정보를 찾는 것이 화두가 되었다. 다양하고 방대한 규모의 데이터로부터 의미를 읽어내고, 새로운 가치를 창출하는 것이 미래 경쟁력을 좌우하는 중요한 ‘자원’으로 활용될 수 있다는 점에서 주목받고 있기 때문이다. 많은 사람들이 자신의 현재를 기록하고 관심사를 공유하는 트위터와 같은 SNS는 하루에도 몇 억건씩 발생할 정도로 데이터 양이 방대하다는 점과 이용자들이 자발적으로 참여하여 의견을 올린다는 점에서 사람들의 관심사나 이슈사항에 대한 반응을 살피는 데에 활용이 되고 있다. 한편, 도시정책지표는 도시의 현재 상태를 진단하고 효율적인 정책을 수립하는 데에 참고하고자 그 필요성이 제기되어 왔고, 서울시에서는 2003년부터 서울서베이를 통해 서울시의 상태를 다양한 측면에서 평가해 왔다. 그러나, 서울서베이와 같은 구조적인 설문의 경우, 1-5점 척도 등을 제시하여 응답하도록 함으로써 전반적인 경향을 파악하기에는 용이하나, 구체적인 이유나 적극적인 의견을 얻기에는 한계가 있다. 이러한 배경을 바탕으로 본 연구는 트위터에 이용자들이 올리는 ‘현재’에 대한 정보가 있다는 점에 주목하여 트위터 데이터 중 주거환경에 대한 평가를 담은 트윗을 추출하여 공간적 분석을 수행하고, 도시정책지표를 보완하는 데에 트윗 분석이 활용될 수 있는지 그 가능성을 보는 것을 목적으로 한다. 이를 위하여 주거환경에 대한 평가를 나타낼 수 있는 주제어들을 관련 연구들을 조사하여, 안전성, 쾌적성, 편리성의 3가지 항목으로 선정하였다. 2012년 11월 30일~ 2013년 1월 10일까지 수집 된 데이터 중 선정한 주제어들을 포함하는 트윗을 추출하였으며, 총 516개의 트윗이 추출되었다. 트위터 데이터가 가진 시간 정보, 내용, 좌표값을 파싱한 후 ArcGIS Desktop 10.1을 이용하여 트윗을 지도화 하고 시도별·구별 공간적 분포를 보았으며, 분포 패턴을 찾고자 시간대별, 요일별 분석을 하였다. 이후 서울시 내 구별 주제어별 트윗의 상대적 분포와 서울서베이의 ‘도시 안전도’, ‘주거환경만족도’를 비교·분석하고, 트윗의 내용을 분석하였다. 연구 결과는 다음과 같이 요약할 수 있다. 첫째, 본 연구는 트위터 데이터로부터 주거환경에 대한 평가를 담은 트윗을 추출하고, 데이터 수집기간 동안 수집한 모든 트윗의 공간적 분포와 주제어를 포함한 트윗의 공간적 분포를 확인하였다. 주거환경에 대한 안전성, 쾌적성, 편리성 3가지 항목의 주제어를 관련 문헌을 참고하여 선정하고, 트윗을 지도에 나타내어 그 공간적 분포를 확인하였다. 전체 트윗은 서울과 부산 등의 대도시에서 주로 발생하였으며, 서울시 내에서 트윗은 강남구, 마포구, 중구 일대에서 주로 많이 올라오는 것으로 나타났다. 주제어를 포함하는 트윗 역시 강남구 일대에서 데이터가 공간적으로 편향되어 집중적으로 발생하고 있었다. 둘째, 시간대별, 요일별로 각 주제어를 포함한 트윗의 분포 패턴을 분석하였는데 ‘쾌적성’을 나타내는 주제어를 포함한 트윗의 경우 ‘주차’에 대한 불편은 이동이 많은 오후 시간대에, ‘소음’에 대한 불편은 밤 시간대에 더 많이 나타나는 등 대체로 주제어별로 그에 맞는 일반적인 생활패턴에 따라 맞는 시간대에 분포하고 있음을 확인하였다. 요일별로는 유의미한 패턴이 나타나지 않았다. 셋째, 서울시 내 각 구별 전체 트윗의 비율과 ‘주거지 불안전’, ‘주거지불만족’에 대해 언급하는 트윗의 비율을 비교하여, 상대적으로 다른 지역보다 더 불안하게 느끼고, 불만족하는 지역을 확인하고, 서울서베이의 결과와 비교하였다. 트윗 데이터의 ‘주거지 불안전’ 민감도가 높게 나타난 상위 3개 지역은 은평구, 강동구, 도봉구였으며, 서울서베이의 ‘도시안전도’ 결과와 별 상관이 없었다. ‘주거지 불만족’의 민감도가 높게 나타난 지역은 종로구, 광진구, 성북구, 금천구였으며, 서울서베이의 ‘주거환경만족도’가 낮게 나타난 지역이 도심권역 일대임을 볼 때 도심권 일대에서 주거지역에 대해 불만족을 보다 더 느끼는 것을 알 수 있었다. 넷째, ‘주거지 불안’과 ‘주거지 불만족’에 대한 내용을 포함하는 트윗이 가장 많이 올라온 지역의 트윗 내용을 분석한 결과, 특정 지역에서 반복적으로 같은 문제에 대해 불안을 느끼거나 불만을 나타내는 것을 확인할 수 있었다. 이는 트위터 데이터로부터 구 안에서의 지역별 차이를 읽을 수 있음과 방대한 양의 데이터를 분석할 시, 트위터 데이터에서 얻을 수 있는 한 지역에 대한 평가가 한 개인의 주관적 의견에 그치지 않고 다수의 의견으로 보다 객관성을 가질 수 있음을 의미한다. 또한, 데이터 수집기간이 겨울이었기 때문에 ‘안전성’ 측면에서 주로 겨울철 빙판길의 사고와 관련된 내용이 많았는데, 트위터가 ‘현재’를 담고 있으므로 장기간 동안 데이터를 수집하여 분석할 시 계절에 따른 차이도 확인할 수 있을 것으로 기대되었다. 본 연구는 국내의 기존 연구들과 달리 트위터 데이터를 통해 공간적 분석을 처음으로 시도하였다는 데에 의의가 있으며, 트위터가 ‘현재’에 대한 정보를 포함하는 것에 주목하여 트위터로부터 주거환경에 대한 평가를 담은 정보를 추출하고, 도시정책지표를 보완하는 데에 활용될 수 있는지 보고자 하였다. 향후 주제어 선정 및 주제어를 포함한 트윗을 추출하는 데에 객관성 및 정확성을 높이기 위한 추가적인 연구가 필요하며, 주거환경 뿐 아니라 현재의 도시정책지표가 포함하고 있는 다양한 분야의 주제어들을 선정하고 분석 할 때에 실제로 기존의 도시정책지표를 보완하는 데에 활용될 수 있을 것으로 기대된다.",
		"KEYWORD": null
	},
	{
		"ID": 639,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숙명여자대학교 교육대학원",
		"TITLE": "국내 대표 포털사이트 식품 안전사고 관련 검색어 빈도 및 연관성 분석 연구 =Frequency and correlation analysis of food safety related keyword from domestic portal site ",
		"AUTHOR": "조희경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤요한 참고문헌: p. 42-44",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "인터넷과 스마트폰의 보급과 함께 사람들은 관심 있는 정보를 실시간으로 검색할 수 있게 되었다. 그에 따라 빅데이터(Big Data)가 형성되고 있고 이를 이용한 예측 연구가 발전하고 있기 때문에 빅데이터를 획득하기 위한 연구가 여러 분야에서 이루어지고 있다. 본 연구는 국내 최대 규모의 포털 사이트인 네이버의 검색 통계를 활용하여, 사람들의 연관 검색어 빈도에 따른 식품안전 사고 원인 식품과 식중독 원인균들의 관계를 분석하였다. 특히 식중독과 관련된 식품과 식중독 원인 세균의 발생 시기에 따른 빈도를 통계분석 하여, 식중독 원인 식품의 예방에 활용하였다. 또한 뉴스검색 결과와 해당 원인 식품의 검색 빈도를 분석하여 그 수치를 비교하였다. 2012년부터 2014년까지 이슈가 된 일반 사례에서 밝혀진 해당 식품과 원인 세균을 네이버트렌드 검색으로 비교한 결과, 검색기간이 일치하는 것을 확인할 수 있었다. 단체급식사례와 일반사례의 식중독 발생기간과 해당 기간의 원인세균 및 원인식품 검색 결과를 비교한 결과, 대부분의 사건이 발생 직후에 검색이 증가함을 알 수 있었다. 그러나 일부 단체급식 사례의 경우, 여러 원인 경로로 인하여 식중독이 발생할 수 있기 때문에 원인규명이 늦어질 수 있으며, 이에 발생기간보다 한참 뒤에 검색건수가 증가함을 볼 수 있었다. 본 연구는 포털 사이트를 활용한 검색 시기와 검색 빈도의 정보를 활용하여, 식중독이 대부분이 가정이나 일반음식점에서 발생하며, 그 사건들이 뉴스를 통해 이슈화 되어 나타나고, 이를 통해 유통된 식품이 소비자의 비위생적 취급이나 행위에 의해 식중독 발생의 주요 원인으로 작용할 수 있다는 점을 파악하였다. 단체급식에서 식중독 원인으로 지목된 식품은 해당 기간 영양사가 식단을 구성할 때 주간 메뉴표를 구성해야 한다면 향후 식중독 예방과 확산의 차단에 대한 기초 자료로 활용될 수 있을 것으로 생각된다.",
		"KEYWORD": null
	},
	{
		"ID": 640,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "TV드라마의 속성에 따른 TV화제성지수와 시청률의 상관관계 연구 =Study on TV dramas attributions that correlates to TV ratings and online TV audience ratings ",
		"AUTHOR": "박명진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박천일 참고문헌: p. 120-124",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "‘기존의 시청률 측정방식이 오늘날 변화된 TV시청행태를 포괄할 수 있을까?’. 본 연구는 전통적인 TV프로그램 시청 성과 지표인 시청률과 새롭게 필요성이 대두되고 있는 TV화제성 지수의 상관관계를 드라마 속성을 통해 탐색하고자 했다. 드라마 속성은 편성요일, 방송사유형, 장르로 세분화하였다. 기존 선행 연구에서는 시청률과 SNS 빅데이터 간 상관관계 분석 결과가 상이하게 도출되었다. 이를 보완하여 분석기간, 분석대상, 분석채널을 확대하였다. 최근 13개월 동안 방송된 지상파, 종편, 케이블 방송사 드라마 44편을 선정하고, 여러 빅데이터 채널을 통해 산출한 TV화제성 지수를 연구에 활용하였다. 각 변인 간의 관계를 고려하여 선정한 연구문제 2가지를 피어슨 상관관계 분석과 다변량 분산분석을 통해 검증하였다. 연구결과, 드라마의 속성(편성요일/방송사유형/장르)에 따라 상관관계 정도의 차이는 있으나 주간TV화제성지수, 주간개인시청률, 연령별시청률에서 통계적으로 유의미한 상관관계가 나타났다. 다변량분석 결과 모든 변인에서 다변량 통계치(Wilks` rambda) 값이 유의확률보다 작아 집단 간 유의미한 차이가 발생했다. 또한 집단 간 사후 검증을 통해 집단별 평균 비교가 가능했다. 분석대상 드라마 44편의 주간화제성지수와 주간개인시청률의 평균값으로 4개의 그룹으로 분류했다. 고시청률-고화제성 집단은 스타파워, 흥미로운 스토리, 작가의 인지도가 드라마의 인기를 지속시켰다. 고시청률-저화제성 그룹은 안정적인 시청률 확보가 용이한 주말 편성이 많지만 화젯거리 형성이 잘 되지 않은 드라마가 포진되어 있었다. 저시청률-저화제성 집단에서는 금토드라마의 비중이 높았고, 실험적인 장르가 많았다는 특징을 보였다. 저시청률-고화제성 그룹은 로맨스 장르의 비중이 높으며, 작품성을 인정받는 웰메이드 드라마가 다수 속해있었다. 본 연구는 상관관계 정도에 따라 프로그램의 화제성지수를 토대로 시청률을 예측할 수 있음을 검증하였다. 또한 드라마 군(群) 분류를 통해 드라마 속성에 깊이 있게 접근했다는데 의의가 있다. 이를 통해 TV화제성지수가 시청률을 보완할 수 있는 TV프로그램 성과지표로서 기능할 수 있는 가능성을 제시하였다. 나아가 TV화제성지수가 시청률과 함께 편성 및 광고비 산정 등 다양한 영역에서 활용될 수 있는 점도 시사하고 있다.",
		"KEYWORD": null
	},
	{
		"ID": 641,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "경희대학교 대학원",
		"TITLE": "데이터 유통 서비스 모델 =A data distribution service model ",
		"AUTHOR": "이정학",
		"REGION": "경기도",
		"PROFESSOR": "경희대학교 논문은 저작권법에 의하여 보호받습니다. 지도교수: 이영구 참고문헌: p. 61",
		"STORE_LOCATION": "경희대학교 국제캠퍼스 도서관,경희대학교 중앙도서관",
		"ABSTRACT": "빅데이터는 최근 딥러닝, AI와 제4차산업혁명에서도 가장 중요한 요소 기술이자, 기술 혁신의 원재료로써 각광받고 있으며, 이에 따라 데이터의 유통은 모든 산업과 기술, 사회에 걸쳐 영향을 미치며, 향후 중요한 IT 서비스의 하나가 될 것으로 전망된다. 데이터를 보유한 개인 또는 기업은 자신의 데이터를 제공하려 하지 않고, 데이터 분석 및 올바른 해석을 위해서는 비즈니스별 전문가와 전문 시스템의 개발이 요구됨과 동시에 데이터 수요자는 원하는 데이터의 보유자 파악이 어렵다. 동시에 데이터 가격결정체계가 데이터 공급자 중심의 자의적 기준으로 공정한 시장가격으로 인정 받지 못했고, 결국 거래 전반의 신뢰 부족으로 직결되어 관련 생태계 형성 및 확대가 어려웠다. 이를 극복하기 위해서는 보다 신뢰 있고, 현재 시장의 요구를 수용 가능한 새로운 데이터 유통 서비스 모델과 합리적 데이터 가격결정체계가 필요하며, 이를 통해 데이터공급자들은 지속적인 거래와 매출 신장, 판매 부대비용의 최소화 등의 효과를 가져 올 수 있어야 하며, 데이터수요자에게는 필요 데이터의 원활한 공급, 데이터 가격의 절감, 데이터 가공 및 분석비용 및 전문인력 확보의 어려움을 해소할 수 있어야 한다. 전반적으로 데이터 유통의 생태계 활성화로 빅데이터를 활용한 제4차산업혁명의 성공적 진입을 모색하기 위한 기존의 데이터 유통 서비스를 대체할 새로운 서비스 모델에 대한 논의가 필요하며, 이와 같이, 데이터 거래의 활성화를 위해서는, 기존 공급자 및 공공기관 위주의 시장환경과 생태계에서 탈피하고, 데이터 확보와 다양한 데이터수요자의 시장 참여를 위한 데이터 사전 공급 후 수익 배분 방식의 데이터 유통 서비스 모델과 용량, 속도, 다양성, 품질을 기준으로 한 가격결정체계를 제안한다.",
		"KEYWORD": "데이터 가격결정,데이터 유통,빅데이터"
	},
	{
		"ID": 642,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "DSRC 기반 청주시 교통 네트워크 구조 분석 =DSRC based analysis of traffic network structure in Cheongju ",
		"AUTHOR": "김용연",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 조완섭 참고문헌 : p.43-44",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "교통은 사람과 물자를 도로, 철도, 해로, 항로 등을 활용하여 나르는 일로써, 빠르고 편리하고 안전하게 재화와 서비스를 이동시키는 방향으로 발전해 왔다. 교통기술의 발전은 우리 생활에 큰 영향을 미쳤고, 정보통신기술의 발전과 함께 각국에서는 효율적인 교통시스템을 꾸준히 연구하고 있다. 우리나라의 경우, 이용자의 안전과 편의를 도모하여 운영 및 이용 효율을 극대화하기 위해 지능형 교통 시스템(ITS)이 도입되었다. ITS가 전국적으로 확대되면서 도로소통상황, 교통량, 대중교통운영현황 및 관리상황, 대중교통이용현황 등 다양한 교통정보가 기하급수적으로 증가하고 있으며, 이를 각 기관과 민간에서 서비스를 제공하고 있다. 본 논문에서는 네트워크 분석을 통해 복잡한 교통을 단순화시키고, 차량 흐름에 따른 도시 교통의 구조적 특징을 도출하는 방법을 제시한다. 특히, 청주시 교통 빅데이터 분석 시스템의 DSRC 데이터를 가공하여 교통 네트워크를 구축하고, 거시적·관계·미시적 관점으로 나누어 다각적으로 교통을 분석한다. 분석 결과는 교통을 좀 더 쉽게 이해할 수 있도록 도와주고, 향후에 청주시 교통 발전을 위한 혼잡 해소방안, 도로 확장 계획 등의 청주시 교통계획의 기초연구 자료로써 기여할 수 있다.",
		"KEYWORD": "교통,네트워크 분석,빅데이터"
	},
	{
		"ID": 643,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 도시과학대학원",
		"TITLE": "노인보호구역 제도개선 방안 연구 :(A)study for silver zone policy enhancement :서울시 노인교통사고 분석을 중심으로 =focusing on analysis of elderly traffic accident in Seoul ",
		"AUTHOR": "김세교",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이동민",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "우리나라는 전국적으로 세계적으로도 유래를 찾아보기 어려운 속도로 고령화가 급속하게 이루어지고 있고, 전체 교통사고 피해의 감소 추세에도 불구하고 고령화에 따라 노인 관련 교통사고가 증가하는 추세임에도 지금까지의 교통안전 정책은 노인보다는 어린이 교통사고 예방사업에 집중되는 경향이 있었다. 본 연구에서 노인 교통안전을 위해 도입된 노인보호구역의 효과를 서울시 사례를 중심으로 검토한 결과 매년 노인보호구역이 신규 설치하고 있음에도 불구하고 노인 보행자 교통사고가 매년 증가하고 있으며, 노인보호구역이 보호구역 이외의 지점과 비교하여 평균적으로도 안전하지 못한 점이 확인되었으며, 거의 대부분의 노인교통사고 피해가 노인보호구역 이외의 지역에서 발생하고 있어 노인보호구역이 노인교통사고 예방이라는 제도 취지를 구현하는 데 한계가 있는 것으로 나타났다. 본 연구에서는 현재 도로교통법상 노인보호구역 지정기준인 노인관련시설이 노인밀집지역을 반영하지 못하고 있는 점을 감안하여 노인밀집지역을 노인보호구역으로 지정하는 방안의 유효성에 대해 검토하였다. 노인 밀집지역에 대한 직접 조사는 비용 등 현실적 제약 요건이 많은 점을 감안 본 연구에서는 서울시에 구축되어 있는 연령대별 휴대전화 위치정보 통계정보를 이용하여 타당성을 검토하였다. 빅데이터인 노인계층의 휴대전화 위치정보를 이용하여 노인 유동인구 밀집지역을 노인보호구역 대상으로 지정하는 방안에 대해 타당성을 검토한 결과 현재 도로교통법상의 노인관련시설 기준보다는 노인밀집지역을 노인보호구역을 지정하는 방안이 교통사고 예방에 더 효과적일 것으로 분석되었다. 본 연구에서 제시한 방안의 경우 빅데이터를 활용하여 노인 계층의 활동지역을 파악할 수 있는 장점이 있어 이를 이용한 노인보호구역 사업 추진시 보다 실제 노인유동인구를 고려할 수 있다는 특징이 있으며, 이러한 점은 향후 장애인 보호구역 지정에도 적용가능할 것이다. 또한, 노인 보호구역 제도의 실효성을 제고하기 위해 교통약자 보호구역에 대한 국비 지원 제도의 개선과 교통사고처리특례법의 개정방안을 제시하였다. 마지막으로 노인보호구역을 비롯하여 현재 운영중인 교통약자(어린이·노인·장애인) 보호구역 등 각종 유사한 보호구역 제도간 혼란이 발생되고 제도 정착에 장애가 되고 있음을 감안하여 유니버설 가로 디자인을 기반으로 하는 교통약자 보호구역으로의 제도 통합 방안을 제안하였다. 한편 본 연구에서는 도로교통공단의 교통사고통계와 연령대별 휴대전화 위치정보, 서울시 통계정보 등을 이용하여 노인보호구역 제도 개선방안에 한정하여 검토하였으나, 국가기관, 경찰, 지자체 등 관련기관에서 관리하고 있는 교통관련 데이터베이스를 기반으로 각종 통계를 공유하여 각종 빅데이터를 복합적으로 활용한다면 더 많은 교통안전 분야에 많은 변화와 발전이 있을 것으로 예상된다.",
		"KEYWORD": "고령자,교통안전,노인,노인보호구역,빅데이터,위치정보"
	},
	{
		"ID": 644,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울시립대학교 국제도시과학대학원",
		"TITLE": "Artificial Intelligence를 활용한 양수발전소 신뢰성 향상 방법론 연구 =A study of methodology for reliability improvement of pumped storage power plant by utilizing artificial intelligence ",
		"AUTHOR": "김경인",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현주",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "The power plant is a place to produce various kinds of energy by converting various energy sources from nature into electric energy and contributes to the development of national industry and is an indispensable part of our life. There are various kinds of power plants such as pumped-turbine, thermal, nuclear, solar, hydro, wind, geothermal, and tidal power depending on the energy source and power generation method. Among those plants, pumped storage power plant is similar to a hydroelectric power plant, and in a time when power demand is low, it is used to pump water to the upper reservoir as a pump mode and turn the turbine connected to the generator using the potential energy of the water and is a power plant that operates in turbine mode when electricity demand is needed. Therefore, it is a power plant that needs to increase the reliability of national power grid in response to peak load quickly. In this study, it tries to improve the reliability of operation and maintenance in the operation and maintenance stage by judging the signs of malfunctioning in advance and establish the basic conditions of an optimized pumping power generator to be reflected in initial design and construction stage through fault analysis based on operational data of a pumping power plant which requires reliability. In this study, an artificial intelligence tool on the process of database analysis and the reliability of the results was verified. In other words, we tried to obtain useful information by making a database of existing fault analysis results. The major contents of this study are summarized as follows. This study reviewed the existing literature and examined the cases where artificial intelligence was applied at each stage of the construction industry field, and examined the tools and algorithms of the artificial intelligence used, and conducted theoretical studies for methodology and case studies. Based on these reviews, it suggests a methodology based on case - based reasoning after conducting a methodology and case study.The methodology of the study adjusts attributes with examining the reliability of the data by examining the tree structure for 17 major faults by using the tool See.5 which is one of the decision tree and defines the weight factors by using Weka 3.6. The modeling of case - based reasoning is done with the influence factors having the weight defined in this way. In addition, the verification process was performed on three representative fault values built by the model. As a result of the verification, high similarities have been shown, and as the database accumulates further in the future, it shows that it will be a powerful tool for decision making by improving reliability with higher similarity. In this study, EPRI((Electric Power Research Institute) conducted a survey, which were databased on, about reviewing faults of 36 pumping station problems in the US and abroad, in the future, case-based reasoning can be done in the same way at other power plants. In addition, although this study provided decision tools in large frameworks, it needs to conduct in-depth study because accumulating the data values of the detailed sensors of the device can determine the diagnosis and timing of the failure of the machine, which can reduce the operation and maintenance cost and contribute to the improvement of the reliability of the machine.",
		"KEYWORD": "AI(Artificial Intelligence),Data mining,빅데이터,양수발전,인공지능"
	},
	{
		"ID": 645,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "서울과학기술대학교 IT정책전문대학원",
		"TITLE": "유전자 알고리즘 기반 ETL 배치작업 스케줄링 최적화 연구 =A study on the optimization of ETL batch job scheduling using genetic algorithm ",
		"AUTHOR": "최기선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김우제",
		"STORE_LOCATION": "서울과학기술대학교 도서관",
		"ABSTRACT": "With the development of the Social Network and the Internet of Things (IOT), the big data era has come, in which large amounts of data that could not otherwise be imagined are generated. Data analysis is essential to discover and use value from large amounts of data. In order to do this, an ETL (Extract Transformation Loading) task to load the data to be analyzed into DW or Big Data System should be preceded. ETL schedules hundreds or thousands of jobs on the limited system resource into a sequential relationship and keeps the pre and post-relationships of the tasks at a right time. In addition, it is difficult to optimize the overall performance of the ETL, because the scheduled ETL is performed by a complex number of operations. Therefore, it is necessary to increase or decrease the data capacity due to the business change. The performance may be delayed due to the complex load. For these reasons, professional engineer is needed to optimize and operate it, but it is a realistic difficulty. Because it requires not only a lack of experienced engineers but also a high cost. In order to optimize the performance of the ETL task and maintain the optimized performance on the various changing situation, this study has developed the optimization method by the genetic algorithm which is a kind of meta - heuristic technique and artificial intelligence. Optimizing ETL performance means you can deliver data at the right time in your business, without delay. To do this, optimizing the performance of the ETL unit job is also important, but it is important to optimize the performance of batch jobs that contain the whole unit job. It is also important to minimize the number of failures due to abnormal performance loads. To do this, we used minimization of ETL batch execution time and load minimization of server CPU resources as a fitness function of genetic algorithm. ETL batch end time and number of concurrent execution tasks were used as constraints. The data of this study were used to simplify the 3 - month average CPU usage and execution time of the 260 ETL units that are being performed in the business. Also, a mathematical model is defined for genetic algorithm implementation and implemented using Java program and Maria DB. Experiments were repeated to change the parameters of the implemented program in order to obtain optimal results. This study is expected to be an important foundation for constructing and maintaining a stable big data system by loading the explosive data of the Big Data era. It is a meaningful attempt to automatically optimize the loading of ETL data of the information system.",
		"KEYWORD": "AI,DW,ETL,GA,Gentiec Algorithm,데이터서비스,메타휴리스틱,빅데이터,유전자 알고리즘"
	},
	{
		"ID": 646,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "한국 스마트 카드 데이터를 이용한 대중교통 이용자의 이동 패턴 규칙성 연구 =Study on the regularity of mobility patterns of public transportation users using Korean smart card data ",
		"AUTHOR": "유수정",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 647,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "서울대학교 보건대학원",
		"TITLE": "Development of influenza surveillance model based on Internet search query and social media data =인터넷검색쿼리와 소셜미디어 데이터를 활용한 사회인구학적 독감 감시모형개발 ",
		"AUTHOR": "우혜경",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "Seasonal influenza epidemics present a significant public health challenge, and early detection is crucial for disease control. In the last few years, the availability of big data from novel sources has contributed substantially to influenza surveillance. The purpose of this study is to investigate, with an application to seasonal influenza epidemic, whether Internet-based online surveillance could be helpful to complement and intensify the traditional surveillance system in South Korea. In addition, I propose a pragmatic method for detecting the influenza epidemic in Korea using Internet based big data, especially social media data and web search engine query data. The concerns and specific approach of this study are summarized as follows: (1) The first study is to identify keywords as a predictor for detecting influenza epidemic using social media data, especially twitter and web blog. (2) The second study is to construct a forecast model for detecting influenza epidemic using search engine query data based on the keywords identified from social media data. In the 1st study, I identified keywords predicting influenza epidemics from social media data. I included data from Twitter and online blog posts to obtain a sufficient number of candidate predictors and to represent a larger proportion of the Korean population. The methods used this study include (a) initial keyword selection, (b) generation of the keyword time series, and (c) selection of optimal features for model building. I built the candidate models using the least absolute shrinkage and selection operator (Lasso), support vector machine for regression (SVR), and random forest regression (RFR) using the training set based on the features we selected. To find the model having the best performance, I evaluated the root mean square error (RMSE) of the predicted values and ILI incidence using the validation set. A total of 15 keywords optimally predicted influenza epidemic, evenly distributed across Twitter and blog data source. Predictions generated from using SVR model were highly correlated with the recent influenza incidence data (SVR model correlation: r=0.92, p<.001; RMSE=0.55). In the 2nd study, I described a methodological extension for detecting influenza outbreaks using Internet search query; I provided a new approach for query selection through the exploration of contextual information gleaned from social media data. Additionally, I evaluated whether it is possible to use these queries for monitoring and predicting influenza epidemics in South Korea. My study was based on freely available weekly influenza incidence data and query data originating from the search engine on the Korean web site Daum between April 3, 2011, and April 5, 2014. In order to select queries related to influenza epidemics, several approaches were applied: (a) exploring influenza-related words in social media data (b) identifying the chief complaints related to influenza, and (c) using web query recommendations. Optimal feature selection by Lasso and SVR were used to construct a model for predicting influenza epidemics. A considerable proportion of optimal features for final models were derived from queries with reference to the social media data. The SVR model performed well: the prediction values were highly correlated with the recent observed ILI (SVR model의 correlation: r= 0.956, p<.001; RMSE=0.39) and the virological incidence rate (SVR model의 correlation: r= 0.963, p<.001; RMSE=7.24). My models for detecting national influenza incidence have the power to predict. These results demonstrate the feasibility of search queries and social media data in enhancing influenza surveillance in South Korea. The current study provides further evidence, based on a new approach, for linkages between the use of Internet-based data and the surveillance of emerging influenza incidence in South Korea. I found that internet-based influenza surveillance that combines search engine query data with social media data has the power to predict influenza outbreaks, exhibiting strong congruence with traditional surveillance data. Furthermore, in an attempt to exploit the complementary nature of the two types of data sources in this study, I fused information drawn from social media with the methodology for query-based influenza surveillance. As seen through my results, these new data sources may be compatible and complementary in predicting influenza incidence. In addition, the basic principles underpinning my approach could be applied to other countries, languages, infectious diseases and data sources.",
		"KEYWORD": "big data,early response,epidemiology,forecasting,influenza,infodemiology,infoveillance,Internet search query,population surveillance,social media,surveillance"
	},
	{
		"ID": 648,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "단순 베이즈 분류에서의 범주형 변수의 선택 =Categorical variable selection in naive bayes classification ",
		"AUTHOR": "김민선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박창이",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Naive Bayes Classification is based on the assumption that input variables are conditionally independent given output variable. The Naive Bayes assumption is unrealistic but simplifies a problem of high dimensional joint robability estimation into a series of univariate probability probability estimations. Thus Naive Bayes classifier is often adopted in the analysis of a massive data set such as in spam e-mail filtering and recommendation systems. In this paper, we propose a variable selection method for based on chi^2 statistic on input and output variables. While the proposed method retains the simplicity of Naive Bayes classifier in terms of data processing and computation,it can select relevant variables. It is expected that our method can be useful in classification problems for ultra high dimensional or big data such as the classification of diseases based on SNPs(single nucleotide polymorphisms).",
		"KEYWORD": "SNP,단순베이즈가정,빅 데이터,카이제곱통계량"
	},
	{
		"ID": 649,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 예술대학원",
		"TITLE": "초연결사회 O2O 커머스플랫폼의 초연결성(Hyper-connectivity) 고찰 =(An)study of hyper-connectivity in hyper-connected society and O2O commerce-platform ",
		"AUTHOR": "최영규",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 권병웅 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 논문의 주제는 모바일기술의 발달로 인해 빠른 성장을 보인 O2O 커머스플랫폼의 초연결성에 대한 연구이다. 연구방법은 Fredette의 초연결성 6가지 요소와 O2O 커머스플랫폼과의 인과관계를 고찰하고, 사례연구와 문헌고찰을 통해 O2O 커머스플랫폼의 초연결성을 분석하여, 향후 발전방안을 예상하고 초연결사회와의 접점을 찾는 것이다. 연구의 기본개념은 동서양의 관계론, 마샬 맥루한의 신체확장의 원리, 초연결사회, 양면시장, 플랫폼, 커머스플랫폼, 온디맨드, 사물인터넷, 빅데이터, 초연결성 등의 개념을 적용하였다. 이러한 개념들과 Fredette의 초연결성을 바탕으로 O2O 커머스플랫폼의 사례를 분석하였다. O2O가 초연결사회와 밀접한 관계성을 지니고 있음에도 불구하고, 초연결사회와 연관되어서 연구된 논문은 전무하다. 가장 큰 이유는 초연결성을 제대로 분류한 학자가 없기 때문인데, Fredette은 초연결성의 분류는 총 6가지로 나누었다. Always on(상시연결성), Readily accessible(접근가능성), Information rich(정보파악성), Interactive(상호작용성), Not just about people(사물상호성), Always recording(상시기록성)이 그것이다. 각 분류에 맞게 대상을 선정하였고, 분석결과를 통하여 O2O 커머스플랫폼의 분석요소를 도출하였다. 분석요소는 총 6가지(4E2C)로, 확장성(Extendness), 간이성(Easiness), 장소교차성(Cross-spot), 교류성(Exchange), 간편성(Effortlessness), 문맥성(Context) 이 바로 그것이다. 이러한 분석요소를 도출한 것은 O2O 커머스플랫폼 연구 내에서 시도되지 않았던 것으로 그 의미가 깊으며, 앞으로 O2O가 나아가야할 전망과 향방을 추정할 수 있는 바이다. 또한, 이 분석요소를 통하여 향후 O2O 커머스플랫폼을 분석하거나 연구할 때, 좋은 틀이 될 것이며 이에 대한 연구도 증가시키는 모멘텀을 마련할 수 있을 것이다.",
		"KEYWORD": "O2O 커머스플랫폼,마샬 맥루한,빅데이터,사물인터넷,양면시장,온디맨드,초연결사회,초연결성,커머스플랫폼,플랫폼"
	},
	{
		"ID": 650,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "잠재 학습 모델링, 워드 임베딩 및 LDA에 기반한 비정형 어휘 데이터의 분석 및 적용 =Analysis and application of unstructured lexical data based on latent learning modeling, word embedding and LDA ",
		"AUTHOR": "서지완",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한상용 중앙대학교 논문은 저작권에 의해 보호받습니다 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "컴퓨터 기술의 발전과 스마트 기기의 보급으로 데이터가 폭발적으로 증가하는 빅데이터의 시대가 도래하였다. 과거에는 기록되지 않던 데이터가 전자적인 형태로 기록되고 분석할 수 없던 데이터를 처리할 수 있게 되면서, 빅데이터의 가치가 전면 재고되고 있다. 빅데이터는 ICT 분야뿐만 아니라 대부분 분야에서 빠지지 않는 중요한 주제로 자리 잡았다. 일반적으로 빅데이터는 규모, 증가량, 다양성의 세 가지 특징을 가지는데, 빅데이터를 분석하고 활용하기 위해서 무엇보다 다양성에 기반한 분석 및 활용 방법을 연구해야 한다. 이를 위해서 관련 연구에 대한 넓은 지식이 필요하며, 또 다양한 관점에서 빅데이터를 분석할 수 있는 새로운 방법이 필요하다. 이종 정보 네트워크는 다양한 관점에서 빅데이터를 분석하고 활용하기에 적합한 개념이다. 정보 네트워크를 구성하는 정보객체가 이종의 구성을 갖는 이종 정보 네트워크는 동일한 데이터를 사용해도 분석하는 관점이나 활용하는 목적에 따라 최종적인 모형을 다르게 모델링할 수 있다. 본 논문에서는 빅데이터의 주요 데이터 유형인 비정형 어휘 데이터를 다양한 관점에서 분석하고 활용하기 위한 연구를 수행했다. 우선, 빅데이터 및 이종 정보 네트워크의 관련 연구를 선정하고 관련 연구에 대한 고찰 연구를 수행하였다. 관련 연구의 고찰을 통해 빅데이터와 이종 정보 네트워크에 대한 정보를 제공하며 결과적으로 빅데이터와 이종 정보 네트워크를 분석하기 위한 기반 지식을 제공하고 있다. 또, 비정형 어휘 데이터를 분석/모델링/활용할 수 있는 새로운 프레임워크를 제안하였다. 제안하는 프레임워크는 이종 정보 네트워크 관점에서 단어 표상법을 기반으로 비정형 어휘 데이터를 분석하고 활용하는 새로운 방법이다. 이는 다양성에 기반한 빅데이터 연구에 공헌하고 있다. 제안 프레임워크의 세 가지 주요기능은 다음과 같다. 빅데이터 대부분을 차지하는 비정형 어휘 데이터를 자세히 분석하여 단어 관계망을 구축하는 방법을 제안하였다. 비정형 텍스트 데이터에 내재되어 있는 의미는 개인화, 마케팅 등 여러 분야에서 활용 가능한 높은 가치의 데이터이지만, 컴퓨터 시스템이 이를 찾아내기 어렵다. 잠재 학습은 주어진 문서를 분석하여 의미계급 기반의 관계망을 구축하고, 이를 기반으로 유용한 의미점수를 계산한다. 논문에서 제안한 수식 이외에도 다른 휴리스틱 알고리즘을 활용하여 목적에 적합한 다양한 의미점수를 만들어 낼 수 있다. 논문에서는 의미점수를 활용하여 사용자가 작성한 리뷰 데이터로부터 평점을 예측하는 방법을 설명하였다. 또, 다양한 관점에서 이종 정보 네트워크를 모델링할 수 있는 워드 임베딩 기반의 방법을 설명하였다. 제안방법은 샘플 테이블, 샘플 시퀀스, 관점 데이터를 만드는 일련의 과정을 수행하여 이종 정보 네트워크를 구성하는 정보객체 간 관계를 모델링한다. 제안방법은 분석관점, 활용목적에 따라 이종 정보 네트워크의 다양한 관계를 모델링할 수 있으며, 복수의 관계를 쉽게 합성하여 활용할 수 있다. 마지막으로 문서의 군집을 분석하여 사용자에게 리딩 리스트를 제공할 수 있는 방법을 제안하였다. 제안방법은 LDA 방법과 행렬분해 방법을 활용하여 일반적인 LDA에서 나타나는 응집력 문제를 완화하고, 특별한 도메인 지식 없이 대표어를 추출한다. 분류된 문서 군집과 대표어를 활용하여 리딩 리스트를 제작할 수 있으며, 이는 문서자료를 구조화하고 가공된 정보를 사용자에게 제공할 수 있다. 결과적으로 논문에서 제안하는 프레임워크는 빅데이터를 다양한 관점에서 분석하고 활용하기 적합하며, 빅데이터 분야의 연구에 공헌할 수 있다.",
		"KEYWORD": "비정형 어휘 데이터,빅데이터,워드 임베딩,잠재 학습"
	},
	{
		"ID": 651,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "비정형데이터에서 개인정보 제공에 대한 사용자 행동 의도에 관한 연구 ",
		"AUTHOR": "김우현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이봉규",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "빅 데이터 시대의 도래와 함께 비정형데이터에서의 프라이버시 침해 가능성이 제기되고 있다. 프라이버시 문제는 온라인 사용자들의 개인정보 제공을 예민하게하고 폐쇄적인 태도를 유발하기도 한다. 본 연구는 비정형데이터 사용에 있어서 발생될 수 있는 프라이버시 침해에 대한 우려가 소비자들의 정보제공을 결정하는데 있어 어떤 문제가 있는지, 정보제공을 결정하는 사용자들의 행동의도를 알아보기 위해, 개인정보의 유형(예민함 정도)에 따른 정보제공 요인으로 기업과 사용자 모두에게 이익이 되는 공통 요인을 찾는 데 목적이 있다. 본 연구에서는 이론적 기반인 프라이버시 계산 모델에서 독립변수를 위험(정보프라이버시 염려 수집, 통제, 인지)과 혜택(프라이버시 준수조항, 인증, 금전적 보상)의 2그룹으로 구분하고, 종속변수를 2개의 그룹(게임정보(PPI_A), 금융정보(PPI_B))으로 분석하였다. 연구 결과에 따르면, 먼저 정보가 게임정보(PPI_A) 일 때는 ‘프라이버시 인증’이 소비자가 개인정보를 제공하는데 정(+)의 영향을 미치는 것으로 나타났고, 금융정보(PPI_B)일 때는 충분하지 못한 ‘인지’와 ‘수집’으로 인한 정보프라이버시 염려가 개인정보를 제공하는데 부(-)의 영향을 미치며, ‘금전적 보상’이 개인정보를 제공하는데 정(+)의 영향을 미치는 것으로 나타났다. 따라서 6개의 독립변수는 정보의 유형마다 사용자가 정보를 제공하는데 영향을 미쳤으나, 공통적인 요인은 없는 것으로 분석되었다.",
		"KEYWORD": "big-data,privacy,provision of personal information,unstructured-data,개인정보 제공,비정형데이터,빅 데이터,프라이버시"
	},
	{
		"ID": 652,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "토픽 모델링을 활용한 한국 ODA 관련 보도 분석 :ODA articles analysis using topic modelling : based on newspapers from 1993 to 2016 ",
		"AUTHOR": "조성권",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 구정우 참고문헌: p. 42-43",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "극심한 빈곤과 국가 경제 개발을 위한 공적개발원조(ODA)가 수십 년간 사람들의 주목을 받으면서, 이와 관련된 사회과학적 연구가 꾸준하게 진행되어 왔다. 이러한 움직임 속에서 개발사회학 또한 다양한 방법으로 발전했다. 그러나 해외 원조 정책의 문화적, 제도적 환경에 대한 연구는 여전히 부족하다. 특히 언론은 독자적으로 움직이는 존재라는 점에서 언론이 해외 원조에 영향을 준다는 점은 ODA 연구에서 중요한 문제라고 할 수 있다. 해외에서는 언론과 ODA의 관계에 대한 다양한 연구가 진행 중이지만, 국내 연구는 매우 미진한 상태다. 한국 ODA 언론 보도를 조사하기 위해서 6개 신문사의 10,000개 이상의 기사를 수집했다. 본문에서는 신문 기사의 특성을 밝히기 위해 텍스트 마이닝과 토픽 모델링 기법을 활용하였다. 텍스트 마이닝을 통해 기사를 구성하는 키워드들을 가시화하여 추출한 뒤, 토픽 모델링을 통해 추출된 키워드들을 일정 주제로 범주화, 조직화했다. 본 작업을 R 프로그램을 기반으로 수행되었다. 정권 시기로 구분하여 신문 기사들을 분석한 결과 일정한 공통점을 발견할 수 있었다. 1) 한국 언론은 북한에 대한 지원과 ODA를 구분하지 못했다(국내법과의 충돌로 북한 원조는 ODA로 분류되지 않는다), 2) 한국 ODA는 한국의 경제적 이득을 위해 활용되었다, 3) 다자간 해외 원조가 선호되는 상황에서 한국 ODA는 대통령의 활동을 보여주고 국민의 호응을 얻기 위해 양자간 교류를 선호했다. 언론은 한 사회에서 매우 독특한 위치를 점한 하나의 제도라는 측면에서 ODA와 언론의 관계를 조명하는 것은 유의미하다. 언론은 의제 설정, 여론 형성 등을 가능하게 하는 자율적이고 독자적인 존재이다. 한국 사회에서 언론은 강한 권력을 지녔다는 점에서, 한국 ODA와 언론의 상호작용에 관한 연구는 여론의 지지를 얻고, 새로운 제도나 법률을 제정하는 등 ODA 역량 강화를 위한 길을 제공할 수 있다.",
		"KEYWORD": "ODA,국제개발협력,빅 데이터,언론 보도,토픽 모델링"
	},
	{
		"ID": 653,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양사이버대학교 디자인대학원",
		"TITLE": "한국 디자인 논문의 연구 경향 =(The)research paper tendency analysis of design related academic society in Korea :디자인 관련 학술단체 연구논문 주제어를 중심으로 ",
		"AUTHOR": "임성우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김학민",
		"STORE_LOCATION": "한양사이버대학교",
		"ABSTRACT": "한국 디자인은 매우 짧은 역사에도 불구하고 많은 연구와 발전을 거듭하고 있으며 , 최근에는 많은 연구자료들이 디지털 형식으로 공개되어 있다.공개된 디자인 학술지 논문연구들의 주제어를 기반으로 한국디자인의 연구경향을 분석하여 보았다. 공개된 디지털 형식 자료들을 수집하여 연구논문을 분야별로 분류하고 주제어를 추출한 다음, 이를 기준으로 디자인의 분야별 관심 주제어와 주제어 별 연구추이를 분석하여 한국 디자인의 경향을 연구하였다. 한국 디자인은 분야별로 중심 주제어가 상이할 뿐 아니라 주제어 내에서도 분야별 추이가 상이하여 디자인이 분야별로 어떻게 발전해 가고 있는지디자인 분야간에 서로 어떻게 영향을 주고 있는 지를 가늠할 수 있었다. 날로 발전하는 컴퓨터의 기술을 응용하여 한국디자인의 연구경향을 분석한 본논문이 향후 디자인 학의 다른 연구에 도움이 되길 바란다.",
		"KEYWORD": "디자인사,디자인사조,디자인학,빅데이터,텍스트마이닝,학술지,학회,한국디 자인"
	},
	{
		"ID": 654,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "효율적인 빌딩 에너지 운용을 위한 태양광 발전량 및 소비전력 예측 연구 =Study on prediction of photovoltaic power generation and power consumption for efficient building energy management ",
		"AUTHOR": "양동헌",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 마평수",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "The energy consumption of the building part accounts for more than 30% of the total energy consumption in Korea, and research on the energy saving of buildings such as renewable energy, ESS(Energy Storage System) and BEMS(Building Energy Management System) is important. Therefore, we conducted a study on prediction of photovoltaic power generation and building power consumption based on big data processing technology and machine learning technology for efficient building energy management. In addition, we conducted a study on the prediction of solar radiation, which is not included in the weather forecast of Meteorological Agency but has the greatest influence on solar power generation and building power consumption. The proposed models are as follows. First, dynamic piecewise solar radiation prediction model that predicts solar radiation using historical data of similar sun altitude and weather, Second, photovoltaic power generation prediction model 1 that can be used in the new photovoltaic power generation system without the past power generation data, and the photovoltaic power generation prediction model 2 that can be used after sufficient amount of power generation data is accumulated, Third, building power consumption prediction model trained by RNN-LSTM(Recurrent Neural Networks with Long Short-Term Memory) algorithm considering user consumption characteristics. We propose three models as above. And the performance of each model is verified by comparing with the previous studies. In addition, we present a fault diagnosis method of photovoltaic module and calculation of the energy to be stored in the ESS as the application of proposed prediction model. This can enable effective photovoltaic power system management, reduction of the building electricity charge and efficient building energy management.",
		"KEYWORD": "BEMS,ESS 축전량 계산,고장 진단,머신러닝,빅 데이터,소비전력 예측,일사량 예측,태양광 발전량 예측"
	},
	{
		"ID": 655,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "민간소비 이상징후에 대한 속보성 탐지모형 구축 :국가재난(세월호 참사와 메르스 사태)사례를 중심으로 ",
		"AUTHOR": "안성희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Nowadays, Big Data enables future prediction; it may provide answers to future issues such as president election and flu trends. However, there are many cases that still remain questionable despite the fact that it seems obvious that they have answers. This is not difficult in methodology, in many cases there is no data. One example is related to our topic; it is difficult to apprehend the scale, areas, dispersing speed of damage when Private Consumption Symptom such as disaster occurs. According to precedent research of disaster economics, most of the studies are either based on belated macroeconomic indicators or are limited to specific industries. It is certain that preventing disaster is important, but immediate analysis and reconstruction policy are crucial as well. This research analyzed the ripple effect of consumer spending followed by April 16 ferry disaster and MERS outbreak; it was done by applying credit card company’s real-time big data with Marketing Mix Modeling (MMM). The result indicated that April 16 ferry disaster had a long-term (three months) effect, causing a decrease of nearly KRW 2 trillion in Consumer Spending. In contrast, MERS outbreak resulted in temporary (one month) loss which soon recovered. The main focus of this research is to see if it is possible to predict the scale of damage during ongoing disasters. It is found that setting up weekly MMM and moving the timeline draws similar conclusion of precedent analysis. Thus, it can be said that it has significance as a quick indicator. When similar disasters or unknown events occur in future, this research may be the basis of building quick and intuitive indicator to monitor possible effects.",
		"KEYWORD": "April 16th ferry disaster,big data,check card,credit card,market mix modeling,MERS,MMM,national disaster,private consumption,quick detection,SEWOL ferry,국가재난,메르스,민간소비,빅데이터,세월호,속보성,신용카드,이상징후,체크카드"
	},
	{
		"ID": 656,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "인제대학교 대학원",
		"TITLE": "재난안전관리의 과학화를 위한 사용자 중심의 손상감시체계 개발 ",
		"AUTHOR": "배창효",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 정상태 부록 : 1. 손상감시지표 정의 및 산출 방법, 2. 시 단위의 재난안전사업 도출을 위한 손상감시체제, 외 수록 참고문헌: p. 127-130",
		"STORE_LOCATION": "인제대학교 백인제기념도서관",
		"ABSTRACT": "Background: To be prepared for the upcoming fourth industrial revolution, the Korean government emphasized the importance of establishing and implementing the practical and effective safety policies and programs by local governments through scientization of the disaster management. To suffice this need, we developed the injury surveillance system for local governments to effectively implement their safety polices and programs using accessible big data provided by public organizations and government agencies. Disaster and safety officers can utilize the developed user-centered injury surveillance system to understand comprehensively the current status of injuries within their municipality and to establish the safety policies and implement the programs based on relevant statistics in a scientific manner. Methods: Based on WHO’s guideline on the development of injury surveillance system, we developed the user-centered injury surveillance system through the process of 1) identification of the major injury data available in Korea, 2) determination of the goals and scopes of the surveillance system, 3) development of the definition and classification system of injuries, 4) assessment of the inury data resources, 5) determination of the injury surveillance indices, 6) development of the user-centered injury surveillance system, 7) evaluation of the validity of the developed surveillance system, and 8) application of the developed surveillance system and evaluation of the effectiveness. Results: The research results are summarized as: 1. We established the injury surveillance system which deals with all relevant injury data resources from Korean administrative agencies. We characterized the eight relevant data resources to identify their strengths and limitations, which includes the Statistics Korea, the statistics on traffic accidents from the Road Traffic Authority, the statistics on 119 emergency rescues form the National Fire Agency, the statistics on the workplace accidents from the Ministry of Employment and Labor, the statistics on the unnatural deaths from the National Police Agency, some statistics from the community health survey, and the community safety indices from the Ministry of Interior and Safety. 2. We classified core indices, essential indices, and supplementary indices from each injury data to come up with the surveillance indices which help continuous monitoring of the injury status in a community. We identified total 166 indices including 55 essential indices, 111 optional indices from the eight resources. 3. To maximize the utility of the developed surveillance system by local officers, we set the injury surveillance indices in six areas for the program development. We identified 51 traffic accident related indices, 22 suicide related indices, 9 fall related indices, 20 crime related indices, 33 fire related indices, and 26 disaster related indices. 4. We developed the user-centered injury surveillance system with which disaster and safety management officers can readily monitor the injury status using the surveillance indices of any interested area without handling and analyzing vast number of the unclassified injury data to plan and develop the safety programs. 5. The developed injury surveillance system was evaluated in its validity using the questionnaire survey from professional evaluation specialists based on the WHO’s seven evaluation criteria; simplicity, flexibility, reliability, utility, substantiality, timeliness, security. And its validity score was rated as 4.18 out of 5. 6. The developed surveillance system was applied to several metroplitan cities such as Busan, Gumi, and Ulsan Nam-gu, and successfully utilized in developing the tailored safety policies and injury prevention program, and prioritizing the developed programs by analyzing the strengths and weaknesses of their existing safety programs. 7. We surveyed the degree of satisfaction on the developed surveillance system by 28 disaster and safety officers who examined it in their works, having the rating results of the highest score of the utility 4.54(0.53) followed by the convenience 4.52(0.29), the reliability 4.50(0.45), and the applicability 4.03(0.58), which depicts the effectiveness of the developed system. Conclusion: The developed user-centered injury surveillance system could effectively accomodate all relevant injury data from public sectors and generate representing surveillance indices of the interested areas by overcoming the difficulties of using the vast data system during hands-on practices of the safety programs due to the fragmental information from disintegrated injury data. The developed system can help safety program planners letting them easily identify the injury status and develop their safety programs in a scientific manner. This is attributed to the effective data collection system of the developed system which helps the user to readily retrieve the relevant injury data, and provide the officers the scientific evidences in developing the tailored programs by gender and age based on the injury big data, eventually contributing to the scientizing the disaster and safety management of public sectors. Keywords: Injury, Big Data, Injury Surveillance System, Injury Prevention, Safety Promotion, Disaster preparation",
		"KEYWORD": "빅 데이터,손상,손상감시체계,손상예방,안전증진,재난안전"
	},
	{
		"ID": 657,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "학위",
		"YEAR": "2012",
		"UNIVERSITY": "대학",
		"TITLE": "Developing high performance gis simulation models on geospatial cyberinfrastructure :a case study of population change models with grid computing and cloud computing technologies ",
		"AUTHOR": "IckHoiKim.",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 658,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "서울대학교 환경대학원",
		"TITLE": "주거·공업 혼재지역의 성격 변화에 따른 성수동 유동인구 특성 분석 =Analysis of the characteristics of Seongsu-dong floating population according to character alteration of the mixed residential and industry area ",
		"AUTHOR": "박성경",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "서울시 준공업지역은 도시의 경제 성장에 큰 역할을 해왔다. 그러나 산업이 변화하고 도시화 과정을 거치면서 준공업지역에 위치하던 대규모 공장 부지들이 여타 지역으로 이전하기 시작하였고, 정부의 수도권 억제정책으로 다른 용도지역에 비해 용적률, 용도 등에 대한 행위 제한이 적은 준공업지역 이전 적지에 고급 아파트, 대형할인매장 등의 시설이 대거 몰려들게 되었다. 쇠퇴한 준공업지역에 지속적인 개발 수요로 인해 서울시는 준공업지역에 대한 산업 특화 공간육성, 주거·산업 분리 개발, 복합개발 등 여러 도시재생사업들을 시도해 왔다. 하지만 서울시 준공업지역의 공업용도지역 대부분이 직접적으로 주거 및 상업용도로 전환한 것에 대한 분석이 이루어지지 않아 토지이용 용도혼재로부터 일어나는 많은 문제점들이 해결되지 않고 있다. 서울시 준공업지역은 토지이용 변화를 중심으로 토지이용의 물리적·기능적인 변화 및 실태를 파악하고, 토지이용전환의 구조적 특성을 분석하여 준공업지역의 정비방향과 토지이용정책 제시에 필요한 기초자료를 제공하거나 나아가 도시재생에 기여할 수 있는 정책방향을 제안하는 연구들이 진행되고 있다. 하지만 기존의 연구 및 관련 사업에서는 지역 내 인구행태 분석 없이 대부분 물리적이고 경제적인 부분에만 치중하고 있어 그 지역을 이용하는 사람에 대한 사회적인 분석도 필요한 실정이다. 이에 본 연구에서는 2016년 길 단위 추정 유동인구 데이터를 이용하여 변화하고 있는 성수동 준공업지역의 유동인구 분포 특성을 파악하고자 하였다. 성수동의 토지이용 유형별로 각 시간대, 연령대별 유동인구를 분석하여 용도혼재에 따른 준공업지역의 유동인구 특성을 분석해 보고자 하였다. 대상지는 공간적 특성에 따른 유동인구 분포 특성을 분석하기 위해 토지이용 기능이 혼재된 서울 도심으로 선정하였다. 본 연구에서는 대규모 준공업지역을 포함하는 동시에 녹지지역인 서울 숲, 그리고 입지 분포가 높아지고 있는 주거지역과 상업지역 등 여러 토지 이용이 혼재되어 있는 서울시 성동구 성수동을 연구의 공간적 범위로 하였다. 성수동 지역을 간선도로와 보조간선도로를 기준으로 9개의 구역으로 나누어 각 구역별 성수동의 토지이용현황을 A구역은 고밀주거위주 상업지역, B구역은 상업위주 주·공 혼재지역, C구역은 공업위주 상업 혼재지역, D구역은 중·저밀주거위주 상업지역, E구역은 상업위주 주거혼재지역, F구역은 공업·상업 혼재지역, G구역은 공업중심지역과 기타혼재지역, H구역과 I구역은 고밀주거상업위주 주거·상업 혼재지역으로 정의하였다. 다음 각 구역별 단위 유동인구 밀도 및 분포 특성을 분석하여 성수동의 유동인구 특성을 몇 가지로 기술 할 수 있었다. 구역별 성수동 유동인구 분석 결과 첫째, 주로 주거지와 상업지 위주의 토지유형으로 구성된 구역에서 유동인구 밀도가 높게 나타났다. 따라서 E구역: 상업위주 주거 혼재지역, H구역과 I구역: 고밀주거상업위주 주거·상업 혼재지역에서 일평균 유동인구 밀도가 높게 나타났다. 둘째, 토지이용유형에 따라 공업위주지역의 특성이 나타난 구역에서는 유동인구 밀도는 현저히 낮게 나타났다. 특히 C구역: 공업위주 상업 혼재지역은 전 구역 중 공업지역의 면적이 가장 높은 구역으로 가장 낮은 유동인구 밀도를 가졌다. 셋째, 연령대별, 시간대별 성수동 유동인구 밀도 또한 모든 연령대와 모든 시간대에서 주거·상업의 토지이용 유형의 면적이 높은 E구역, H구역, I구역에서 높았으며, 공업지역이 포함된 구역에서 가장 낮은 유동인구 밀도로 나타났다. 따라서 특정 시간대나 특정 연령대가 특정 구역에서 인구의 집중도가 확연히 변화하는 구역은 찾을 수 없었다. 하지만 30대와 40대가 성수동의 유동인구 중 약 50% 이상을 차지하는 것을 알 수 있었으며, 시간대별 유동인구의 경우 오후시간에 집중적으로 분포했다. 또한 심야시간대에 유동인구 밀도가 오후시간대와 큰 차이를 가지고 있어 주간 인구의 비율이 상당히 높은 것으로 예측 할 수 있었다. 본 연구는 향후 도시를 계획하거나 도시 정비 등 다양한 도시 분야 관련 연구에서 유동인구 빅데이터가 도시의 활성 인구분포를 예측할 수 있는 지표임을 제시하며, 특히, 새로운 데이터의 접근을 도시계획 및 설계에 접목시킬 수 있는 기회임을 시사한다. 하지만 길 단위 추정 유동인구의 경우 SKT 통신데이터에서 추정된 점 단위 유동인구를 재가공하면서 시간대를 임의로 합쳐 한 시간 단위의 유동인구 데이터가 아닌 점, 그리고 월 단위 유동인구로 평일과 주말의 일평균 데이터로 한정된 점으로 인해 다소 부족한 부분이 있다. 향후 길 단위 유동인구의 데이터 보완과 함께 빅데이터의 활용이 보편화 될 수 있길 바라며, 본 연구에서는 성수동 준공업지역의 토지이용유형에 따라 유동인구 특성을 기술하는데 그쳤다면 향후 유동인구 분포 특성을 바탕으로 도시계획 및 설계에 적용까지 가능 할 것으로 예상한다.",
		"KEYWORD": "빅데이터,성수동,유동인구,준공업지역"
	},
	{
		"ID": 659,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "한국해양대학교 대학원",
		"TITLE": "조선 생산 리드타임 예측을 위한 기계학습 방법론에 관한 연구 =A study on machine learning for prediction of the shipbuilding lead time ",
		"AUTHOR": "김지혜",
		"REGION": "부산",
		"PROFESSOR": "한국해양대학교 논문은 저작권에 의해 보호받습니다. 지도교수:우종훈 참고문헌: p.75-76",
		"STORE_LOCATION": "한국해양대학교 도서관",
		"ABSTRACT": "In recent years, big data technology, which is one of the biggest issues in IT field, has been applied in various fields as data has increased exponentially compared to the past, however, in the shipbuilding and offshore industries, the use of big data related technology is relatively rare compared to other manufacturing industries such as automobile and electronics industries. But, shipbuilding and offshore industry is one-piece manufacturing industry, and statistics-based analysis such as the Big Data methodology can be very effective because vast amounts of data are generated throughout the entire life cycle and are highly variable in the manufacturing environment. As a result, the big data-based machine learning research is progressing slowly in the shipbuilding industry. However, this is limited to the design field that manages the fixed variables and it is difficult to apply it in terms of production management such as lead time which is the basis of construction activity. In particular, the standard data such as production lead time is highly variable due to various process variables so, it is necessary to study changing from causation viewpoint to correlation to solve it. Therefore, in this paper, I has constructed a prediction model applying machine learning and deep learning algorithm to improve the standard data for the time factor of production lead time. In order to predict the variable lead time considering the various properties of the product in comparison with the standard lead time, I collect data from several shipyards and apply various machine learning and deep learning algorithms to predict the production lead time according to the process. Respectively. To analyze the data, open source such as R and Python language was used and a lead time prediction model based on the algorithm was created. Various evaluation indices were used to evaluate the prediction model generated by the analysis algorithm. In addition, I compared the results of machine learning and deep learning algorithms with those of previous studies, and the decision support for the establishment of standard information according to various process variables is made possible.",
		"KEYWORD": "기계학습,기준정보,딥러닝,빅데이터,생산관리,통계분석"
	},
	{
		"ID": 660,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "강릉원주대학교 대학원",
		"TITLE": "중국 상업은행 중개업무의 발전에 영향을 미치는 요인들에 대한 연구 =The analysis of factors on intermediary business development among Chinese commercial banks ",
		"AUTHOR": "샤화",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 최준환",
		"STORE_LOCATION": "강릉원주대학교 중앙도서관",
		"ABSTRACT": "빅 데이터와 정보화 시대가 도래함에 따라 최근 중국의 전통적인 은행업무가 갈수록 심각한 타격을 받게 되었다. 금리시장화의 추진에 따라 동종업의 경쟁이 점차 심해지고 인터넷 금융 산업이 급격히 성장하여 전통적인 은행경영모델이 거센 도전을 맞게 되었다. 이로 인하여 예대금리차만 의존하는 경영방식에 대한 반성이 발생하고 있다. 상업은행 중개업무는 원가가 낮고 리스크가 적고 수익이 높다는 특징을 갖고 있다. 따라서 상업은행이 중개업무를 발전시키는 것은 상업은행 수익성을 높이는 중요한 방법이 되었다. 또한 중개업무는 전통적인 예대업무의 발전을 촉진할 수 있을 뿐만 아니라 상업은행의 사회적 이미지를 드높이고 경제적 효과를 높이는 역할도 할 수 있다. 또한 서방 선진국에서의 상업은행이 발전해 온 길을 더듬어 보면 중개업무는 상업은행 미래 발전의 성공 여부를 결정할 수 있다는 것을 알 수 있다. 따라서 금융 세계화와 자유화의 배경하에 중국의 상업은행의 발전에 대하여 연구하는 것은 이론적·실제적으로 중요하다.　최근 수년 동안 학계에서도 중국 상업은행 중개업무의 발전에 대하여 중국의 발전 현상을 바탕으로 연구하였다. 특히 중국 상업은행 중개업무의 발전에 어떤 요인들이 영향을 미치는지 어느 정도 영향을 미치는지에 대하여 깊이 연구해 왔다． 본 논문은 상업은행 중개업무에 대한 문헌연구를 기초로　하여 중국 상업은행　중개업무의 발전에 영향을　미치는　요인을　실증분석하였다.　우선 중국　상업은행　중개업무에　대한　이론적　고찰을　한 후 거시적·미시적　차원에서　분석하였으며 연구방법으로는 비교분석법,　정성분석법과 정량분석법을 이용하였다. 거시적 관점에서 보면 거시적 경제 환경이 상업은행 중개업무의 발전에 상당한 영향을 미칠 것으로 예상된다. 본 논문에서 국가경제상황, 화폐공급, 국민소득수준, 기업융자구조, 금융 감독 등 다섯 거시적인 요인들을 독립변수로 삼고 중개업무수익을 종속변수로 삼게 되었다. 회귀분석을 통하여 거시적인 요인들이 중국 상업은행 중개업무의 발전에 미치는 영향을 전면적으로 분석하였다. 미시적 관점에서 보면 본 논문에서 상업은행의 안전성, 유동성과 영리성을 고려하는 차원에서 대표적인 유동성비율, 자기자본비율, 부실대출비율, 자기자본수익률 4개를 독립변수로 선정하여 분석하였다. 그리고 중국 상업은행 중개업무의 발전 추세를 세밀하게 관찰하기 위하여 중개업무수익이 총수익에서 차지하는 비율을 종속변수로 선정하여 분석하였다. 또한 본 논문은 고정효과모형을 통하여 미시적인 요인들이 중국 상업은행 중개업무의 발전에 미치는 영향을 분석하였다. 마지막으로 실증분석의 결과를 근거로 거시적·미시적 측면에서 중국 상업은행 중개업무의 발전에 대한 시사점을 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 661,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "스포츠방송콘텐츠의 경쟁구조 분석 :텔레비전 방송시장을 중심으로 ",
		"AUTHOR": "오태연",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "본 연구는 미디어시장 내 스포츠방송콘텐츠의 경쟁구조를 다양한 관점에서 분석하는 것을 목적으로 하며 특히 텔레비전 방송시장 내에서의 경재에 대해 주로 살펴보고자 한다. 스포츠미디어는 스포츠시장과 미디어시장의 접점으로서 양 시장 모두에서 중요한 역할을 하고 있으며 따라서 본 연구에서는 스포츠시장 관점과 미디어 시장 관점을 모두 고려하였다. 미디어 시장에서의 소비자행동패턴은 크게 니즈를 파악하고 이를 충족하려는 능동적 소비자 관점과 방송사의 방영전략 및 편성에 의해 시청하는 수동적 소비자 관점으로 구분된다. 두 관점 모두 소비자 행동을 분석하는데 있어서 제한점이 존재하며 이에 대한 통합적 관점으로 시청자들은 취향에 따른 시청 레퍼토리를 형성하고 이 중 상황에 맞게 시청한다는 레퍼토리 관점이 있다. 본 연구에서는 이러한 레퍼토리 관점을 바탕으로 스포츠방송콘텐츠의 경쟁구조에 대해서 분석하였다. 스포츠방송콘텐츠의 경쟁구조를 분석하기 위하여 본 연구는 시청자들의 프로그램 레퍼토리를 통해 시청자세분화를 실시하고 이를 바탕으로 스포츠 프로그램의 경쟁관계를 분석한 연구1과 시청자세분화를 바탕으로 시청자들의 시청선택행위를 분석하여 스포츠 프로그램의 경쟁력과 시청자들의 시청결정요인을 분석한 연구2로 구성되어 있다. 연구1에서는 시청자들의 시청로그를 통해 연구를 진행하였다. ABC닐슨에서 제공한 시청로그자료를 토대로 각 시청자들이 각각의 프로그램을 몇 회 시청하였는지에 대한 시청자-프로그램 행렬을 구축한 후 tf-idf방식으로 정리하였다. 구축한 시청자-프로그램 행렬을 바탕으로 시청자들에 대해 K-평균 군집분석을 실시하였다. 총 16개의 군집이 도출되었으며 이 중 스포츠와 관계가 있는 군집은 5개가 나타났다. 각 군집내 속한 프로그램 및 시청자를 분석한 결과 스포츠방송콘텐츠는 40대 남성이 가장 확고한 시청자 층을 형성하고 있으며 전체적으로 30대 후반에서 50대 초반에서 높은 시청선호를 기록하였다. 각 시청자 집단에 따라 4~50대 시청자 집단에서는 주로 뉴스 등 보도프로그램이 스포츠와 경쟁관계가 있으며 2~30대 시청자에서는 드라마 및 예능이 주요 경쟁 프로그램임을 확인할 수 있었다. 연구2에서는 선택모형을 바탕으로 시청자 행동 및 프로그램간의 경쟁구조를 분석하였다. 선택모형을 분석하기 위해서 다항로짓모형을 사용하였으며 기존 연구에서 제시한 모형에 연구1의 결과로 도출한 시청자 집단을 새로운 독립변인으로 추가하여 추정하였다. 추정결과 시청자 특성에 따라 남자, 미혼자일 경우 스포츠를 선택할 확률이 높은 것을 확인하였다. 또한 각 시청자 집단 별로 프로그램간 상대적 시청확률을 분석한 결과 스포츠중심군에서 스포츠 프로그램의 선택확률은 다른 프로그램들을 압도하는 것으로 나타난 반면 기타 시청군에서는 경쟁 프로그램인 드라마 및 예능 프로그램에 비해 현저하게 낮은 선택확률을 기록하여 충성스런 시청자를 제외하고는 선호도가 낮음을 확인할 수 있었다. 또한 시청 중 채널 변경여부를 의미하는 계속시청확률에 있어서 스포츠는 다른 대안 프로그램들에 비해 매우 낮은 확률을 보였으며 특히 인접효과에 있어서도 드라마나 예능에 비해서 낮은 것을 확인하였다. 본 연구는 기존 연구에서 시청자 분석을 위해 사용하던 능동적 시청자 관점과 수동적 시청자 관점을 아우르는 프로그램 레퍼토리 관점을 통해 스포츠 프로그램의 경쟁에 대해 분석하였다. 이를 통해 기존 연구에서 관점에 따라 간과한 부분에 대해서 종합적으로 분석하여 입체적인 연구 결과를 수립할 수 있었다. 첫 번째 연구에서는 미시적 단계인 프로그램 수준에서 시청자세분화를 실시하여 프로그램 간의 경쟁관계에 대해서 분석할 수 있었으며 두 번째 연구에서는 프로그램 레퍼토리 관점을 선택모형에 포함함으로써 기존의 구조주의적인 시각에서 시청자들의 선호라는 능동적 관점을 포괄하는 모형을 추정할 수 있었다. 본 연구는 스포츠미디어시장 분석을 하는데 있어 기존의 관점들을 통합하여 제시하면서 동시에 다양한 분야의 연구방법을 도입하여 대안적인 연구결과를 제시하였다. 이를 바탕으로 향후 스포츠 사업자 혹은 미디어 사업자들이 시장을 명확하게 분석할 수 있는 방법을 제안하고 이를 토대로 향후 실무적으로 적용할 수 있는 전략적인 방향성을 도출할 수 있었다.",
		"KEYWORD": "K-평균군집분석,경쟁구조,다항로짓,빅데이터,선택모형,스포츠미디어,스포츠시장가치망,융합"
	},
	{
		"ID": 662,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "미디어 3.0 시대 방송 프로그램 발전방안 연구 =(A)study on future development of TV programs in the era of media 3.0 :IT 방송 프로그램을 중심으로 ",
		"AUTHOR": "차정인",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 663,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 언론대학원",
		"TITLE": "넷플릭스(Netflix)의 신기술 활용 혁신전략에 관한 연구 :빅뱅파괴 패러다임을 중심으로 ",
		"AUTHOR": "문성길",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김성태 참고문헌: p. 140-149",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "대표적 OTT 사업자인 넷플릭스(Netflix)는 최근 미국 미디어 산업의 돌풍의 핵이다. 미디어 산업의 중심에 서있다. 동영상 소비형태의 혁신을 통해 미국 미디어 산업에서 유료방송의 가입해지를 야기할 가장 위협적인 존재이다. 이미 2011년에 미국 최대 케이블TV 사업자인 컴캐스트의 가입자수를 추월했다. 유료방송의 부진과는 대조적으로 2014년에도 여전히 성장세가 가파르다. 본 연구는 이처럼 OTT와 넷플릭스의 혁신을 가능하게 하는 동인은 무엇인가? 넷플릭스의 구체적 혁신전략은 무엇인가? 그리고 넷플릭스의 혁신전략이 국내 미디어 산업에 주는 시사점은 무엇인가를 알아보고자 했다. 본 연구는 OTT와 넷플릭스의 혁신의 동인을 파악하기 위해 빅뱅파괴(Big Bang Disruption) 패러다임의 관점에서 살펴보았다. 최근의 미디어 산업에 나타나는 급격한 변화는 기존의 파괴적 혁신론(Disruptive Innovation)으로 설명하는데 어려움을 겪고 있기 때문이다. 빅뱅파괴는 제품이 즉각적으로 나타나 빠른 시간내에 새로운 시장을 생성하고, 기존 시장을 완전히 대체해 버리는 새로운 형태의 제품 확산현상이다. 이를 가능하게 하는 것은 바로 무어의 법칙에 기반한 기하급수적 기술이다. 유비쿼터스 컴퓨팅, 클라우드 컴퓨팅, 광대역 네트워크, 인터넷, 스마트폰을 포함한 모바일 서비스 등과 같은 기술이다. 연구결과 넷플릭스의 혁신을 가능하게 한 것은 바로 이러한 기하급수적 기술을 활용한 4가지 혁신전략임을 검토했다. 개방형 혁신전략, N스크린 혁신전략, 빅데이터 혁신전략 그리고 롱테일 혁신전략이다. 넷플릭스의 4대 혁신전략이 역동적인 미국의 미디어 산업과 달리 혁신이 지체되고 있다고 평가되는 국내 미디어 산업에 주는 시사점을 도출해 보았다. 개방과 공유의 혁신이 필요하다. TV중심에서 N스크린 전략으로의 전환이 필요하다. 미디어 산업에서 빅데이터 활용은 필수적이다. 동영상의 데이터화가 반드시 필요하다. 블록버스터와 롱테일의 병행전략이 요구된다. 마지막으로 최근 미디어 산업의 혁신을 추동하는 핵심 요소인 기하급수적 기술의 활용을 통한 미디어 산업의 경쟁력 제고가 필요하다라는 점이다.",
		"KEYWORD": "OTT,넷플릭스 혁신전략,넷플릭스(Netflix),빅뱅파괴(Big Bang Disruption)"
	},
	{
		"ID": 664,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "고객의 개인적 경험, 취향과 관련된 상품을 추천하라 :지각된 가치 기반 추천 시스템 특성이 웹사이트 충성도에 미치는 영향 연구 ",
		"AUTHOR": "박지은",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최준호",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Personalized Experience, Preference Based Recommender System -User Perceived Value-based Recommender System Properties and Website Loyalty- Website recommender system is widely provided by many companies including Netflix and Amazon. Netflix, which has launched its online video streaming service in Korea in Feb 2016, along with Amazon is well known for its long-term investment for its accurate big-data driven recommender system. To explain the background of recommender system and website personlization, as people exposed to more scalable amount of information online, more time and effort they have to pay for exact service that they want. In a sense, companies can make profits by providing customers exact content before they even try to search the content. This paper verifies whether user benefitable recommender system properties have positive impact on company benefit. For this, first of all, recommender system properties are selected and re-categorized based on user perceived value. Website loyalty indicates company benefit following previous studies. The result proved 4 given recommender system properties all have positive relations with website loyalty. Among them, self reflectiveness showed the most impact towards website loyalty. From this, companies should consider self reflective content as their core recommending content. This paper has meaningful lessons learned both for theoretical and business perspectives. If the weak points improved with further studies, more significant insight may attribute. Keyword: Recommender system, Perceived Value, Loyalty, Web personalization, Preference, Big data, Content recommendation",
		"KEYWORD": "big data,content recommendation,loyalty,perceived value,preference,recommender system,web personalization,빅데이터,상품 추천,웹사이트 충성도,자기 참조,지각된가치,추천 시스템 알고리즘,추천시스템,컨텐츠 추천"
	},
	{
		"ID": 665,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "평가기준 별 이슈 식별 방법론 =Methodology of identifying issues by perspective of evaluation criteria ",
		"AUTHOR": "변성호",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김남규 참고문헌 : p. 36-42",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "Due to the growth of internet data and the rapid development of internet technology, “big data” analysis is actively conducted to analyze enormous data for various purposes. Especially in recent years, people trends to share their experience over leisure and also review other`s thoughts as well. This trends over majority of leisure life such as movie, travel, and dining. As these sharing activities trends, a lot of website like “Metacritic”, “Rotten Tomato” and “Tripadvisior” were formed among the users. Most of these website provides a forum to users to review, discuss and also help the user decide by combining overall reviews with reasonable facts. But there is one thing to consider; the depth of the review. For example, if a review was written over a certain hotel, people tend to only write reviews for accessibility, rooms, services, or food. These might be the reviews for most frequently asked questions, but still lacks information such as distance between the nearest subway station or condition of the bathroom. To ensure fulfilling variety point of interests, this research will provide standards written by major website`s reviews and also restructure the reviews to suggest and improve various ways how information is provided to the readers.",
		"KEYWORD": null
	},
	{
		"ID": 666,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "행동 및 감정 추론 중심 펫케어를 위한 Node.js 기반 실시간 스트림 프로세싱 시스템 =Node.js based realtime stream processing system for action and emotion inference driven pet care ",
		"AUTHOR": "김현준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정갑주",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "사물인터넷 환경에서는 상당한 양의 센서 데이터가 생성된다. 이러한 센서 데이터의 적절한 프로세싱은 반드시 필요하지만 프로세싱 과정의 안정성과 효율성을 보장하기는 매우 어렵다. 본 논문에서는 사물인터넷 펫케어 시스템을 제안한다. 펫케어 시스템은 반려견의 웨어러블 디바이스로부터 나오는 센서 데이터를 분석하여 반려견의 행동/감정을 추론하고 사용자에게 서비스하는 종합 애완동물 관리 시스템을 말한다. 본 시스템은 Event-Driven, Non-Blocking I/O, Single Thread로 작동되는 Node.js를 기반으로 구현하였으며, 가속도 센서와 자이로 센서 데이터를 분석하여 반려견의 행동을 추론하고 도출된 행동 추론 결괏값들의 연속성과 가중치 계산을 통한 애완동물의 감정 추론을 목적으로 한다.",
		"KEYWORD": "노드제이에스,빅데이터,사물인터넷,스트리밍 프로세싱,아파치 스파크,웨어러블"
	},
	{
		"ID": 667,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "그레이딩 시스템을 이용한 관계형 DBMS와 File 분산처리 시스템 성능 비교 평가 ",
		"AUTHOR": "김상진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김경섭",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "",
		"KEYWORD": "bigdata,file distribution system,grading system,hadoop,oracle,RDBMS,response time,server performance,관계형 데이터베이스,그레이딩 시스템,빅데이터,성능평가,응답속도,파일 분산처리 시스템,하둡"
	},
	{
		"ID": 668,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 수자원전문대학원",
		"TITLE": "(The) development of integrated management system for water information based on ICT :ICT기반의 물정보 통합관리시스템 개발 : 지능형 물관리의 구현 ",
		"AUTHOR": "홍석민",
		"REGION": "서울",
		"PROFESSOR": "Adviser: 장암 Includes bibliographical references (p. 48)",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "Recently, natural disasters such as floods, droughts, and water disputes between countries and regions are emerging as social issues not only in Korea but globally. This water problem is characterized by the spreading and widening of the whole watershed when it occurs at one point, so there is a need to find a solution for an integrated viewpoint. In Korea, there have been discussions on integration of related ministries to solve various problems related to water in the past, however, due to the nature of water information produced, managed and serviced individually according to the relevant role and the law, it has been frequently disrupted by the relevant ministries’s different opinions. In response to the development of ICT technology, in order to solve the problem of scattered water information’s availability, WINS(Water management Information Networking System) by the Ministry of Land, Infrastructure and Transport was established and has been operated since 2004. However, there has been a disadvantage of providing specialized and limited information to the water resources sector mainly and a lack of active sharing of information because of no compulsory provision of information sharing between participants. In order to solve these problems, this paper carried out system development study and reached to actual construction. To do this, the status of domestic water information was surveyed and domestic and overseas related systems were compared and analyzed. In addition, a needs survey for government, institutions, academia, industry and general public to make basic concepts of contents, target and methods and so on for service was conducted. The latest ICT technology was used to realize the contents as screen, and the user interface definition was created to present a role model of integrated water management through maximizing visualization by combining GIS and realtime data and providing space-time integrated information. The water information used in the system were the water information of K-water itself and water information of the government, local governments, and water agencies, which accounted for about 63% of the producted information of domestic water facilities. The JAVA, JSP, e-government framework for the development tool were used, and the web service using K-water`s MSPP network was constructed. The system was configured the DB server storing water information, the GIS server storing and processing geographic information, WAS with programs that run the system and the external network web server. The construction results and expected effects can be summarized as follows. First, an information based integrated water management model is proposed to view the location, realtime operating information of water resources, water supply and groundwater facilities at a glance by using water information of the government, water agencies already had, but scattered. Second, countermeasures against disasters such as floods and droughts will be possible. It is possible to integrate hydrological observation information and life, agriculture and industrial water supply information of all public agencies and to use it for flood and drought analysis. So, it will be possible to improve accuracy of warning, and to make decisions on post-recovery and support direction. Third, it will be possible to respond to river water quality accidents. If the informations on the discharge of the dam, the water level of each water level monitoring station, the operation status of each local intake and water treatment plant, the water supply zone and the spot pollution source such as the industrial complex are integrated, it will be possible to respond promptly and make decisions when pollution sources enter the water source. The system to be studied in the future should be focused on differentiated, customized UI enhancements aimed at tiered users of the integrated system. In addition, it will be necessary to gather more water information and to promote continuous functional enhancement for additional content’s discovery and development, and for providing high quality information services.",
		"KEYWORD": "big data,integrated water management,IWRM,SWG,water information"
	},
	{
		"ID": 669,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울대학교 융합과학기술대학원",
		"TITLE": "Breadth-first search 벤치마크의 성능비교 및 구현개선에 관한 연구 =(A)study on performance comparison and improvement of breadth-first search benchmarks ",
		"AUTHOR": "이상민",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "최근 들어 빅데이터, 그 중에서 소셜네트워크가 폭발적으로 성장함에 따라 소셜네트워크 데이터의 중요성이 높아지고 있다. 이런 방대한 양의 데이터들은 그래프 데이터구조를 이용하여 저장되고 분석된다. 그래프는 선으로 연결된 객체들을 나타낼 때 사용하는 표현법으로 소셜네트워크에서는 사용자를 노드, 사용자간의 관계를 엣지로 표현한다. 이런 소셜네트워크 데이터에서 의미 있는 정보를 얻기 위해서는 데이터를 분석하는 과정이 필요하며, 분석은 모든 노드를 순회하며 노드의 상태들을 확인하며 진행된다. 따라서 소셜네트워크 데이터분석에 그래프순회는 중요한 부분이다. 대표적인 그래프순회 알고리즘인 Breadth-first search(BFS)는 순회시작 노드와 인접해있는 모든 노드들을 우선적으로 방문한 후, 방문한 노드와 인접한 노드들을 순차적으로 순회한다. 이런 순회방식은 그 특성상 같은 레벨에 위치하는 노드들을 병렬적으로 처리할 수 있다. BFS는 전체적인 틀은 동일하지만 다양한 구현의 벤치마크들이 있다. 구현에 따라서 확인해야 할 엣지의 수를 줄이거나, 노드를 접근하는 순서 등을 바꿔서 성능 향상을 도모한다. 또한 각 벤치마크의 특성이 다르므로 워크로드에 따라 성능이 다르다. 본 논문에서는 최근 발표된 주요 BFS 벤치마크 5종을 선택하고 각종 워크로드를 사용하여 수행시간과 메모리 측면에서 성능을 비교 및 분석하고, 워크로드 특성을 고려하여 적합한 벤치마크를 제시한다. 또한 일부 벤치마크에 대해서는 구현개선을 통하여 성능을 개선하였다. 마지막으로 메모리와 벤치마크 성능간의 상관관계를 파악하여, 차후 벤치마크의 구현을 개선하거나 메모리접근 방식의 최적화를 통해 전체적인 성능 향상이 가능할 수 있음을 보였다.",
		"KEYWORD": "Breadth-first search,그래프,벤치마크,빅데이터"
	},
	{
		"ID": 670,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "고객 추천 시스템(CRM)에서 선험적 알고리즘과 LASSO의 비교 =(A)study on comparative of apriori algorithm and LASSO in customer relationship management(CRM) ",
		"AUTHOR": "김종대",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "유통분야, 마케팅 또는 웹 마이닝 분야에서 상품 추천이나 고객들의 구매패턴의 연관성을 발견하기 위하여 연관규칙분석(association rule analysis) 알고리즘을 사용한다. 연관규칙분석은 대용량 데이터베이스에서 변수들 간의 흥미로운 관계를 찾도록 고안된 방법으로 자료에 존재하는 항목(item)들 간의 if-then 형식의 연관규칙을 찾는 방법으로서 비지도학습의 일종이다. 본 논문에서는 고객 상품 추천 시에 기존의 연관성 분석보다 효과가 좋은 모델을 탐구해보고 기존의 알고리즘과 비교·분석한다. 고객의 구매여부는 Binary형태이므로 로지스틱 회귀 분석을 도입하고, 구체적으로 Zou와 Hastie(2005)에 의해 제안된 elastic net 모델을 비교·평가한다. Elastic net 모델은 능형회귀와 Lasso회귀의 절충으로서, 상관관계가 있는 변수들 중에서 하나의 변수만을 흔히 선택하는 Lasso의 단점을 보완하는 형태이다. Elastic net모델을 구성하는 능형회귀와 Lasso의 가중치인 와 의 조정과, 기존의 알고리즘보다 효과가 좋은 모델의 지속적인 탐구를 통하여, 향후 CRM의 여러 분야에서 분석 및 예측을 실시하는데 다양한 전략을 구상할 수 있도록 큰 도움이 될 수 있게 한다.",
		"KEYWORD": "CRM,Elastic net,Lasso,빅데이터,연관성 분석"
	},
	{
		"ID": 671,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "공개된 바이오 데이터베이스를 이용한 연구자 맞춤형 데이터 제공 서비스 설계 =Design of customized reasearch data services using the public bio database ",
		"AUTHOR": "우창우",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 류근호 참고문헌: p.27-29",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "The emergence of post-genomic era; which refers to the researches that exploit genes for an analysis of personal properties or prevention and therapy of disease by revealing gene functions via discovered RNA sequence, was accompanied by the activation of research in gene analysis. The biological experiments are producing big data of huge volume at a massive scale. However, the extraction of useable data for research purposes from the publicly available biological repositories is challenging and requires sophisticated tools and a solid background in both computers science and biology. This capstone project addresses the above mentioned challenges by proposing a service that can provide research-usable data formats from the publicly available biological databases. The project used Exome Sequencing, and the Cancer Genome Atlas data as case a study. We analysed the proposed service exploiting Porter five forces analysis, SWOT, and four P Models. As a result, Five Forces models show that bargaining power of suppliers and barriers of market entry represented weakness, whereas bargaining power of customers and Threat of substitute products or services revealed robust. In the result of SWOT, the opportunities are developing bio-industries and increasing researches utilizing related databases, while threats are the market entrance of conglomerates and the lack of original technologies for the service. Our strength is that comprehension of computer science and biology are higher than other companies and has social network with other researchers thus, collaboration is easy. However, our weakness is lack of experiences about processing public database and marketing. Based on these results, we decided that the proposed service, which is variable data processing and analysis, is sold by on-line and offline channels; in order to activate the service, is promoted to customers such as society of biology and medical, physicians and researchers. Furthermore, we employed trial version, which can use this service freely when the data volume is not over pre-decided criteria, in proposed service for sales promotion, therefore we have a competitive price comparing with others. Consequently, in this capstone project, providing fitting data created by proposed service to researchers can contribute in improving data accessibility. As a foreseeable future work, to implement proposed service, we will consider cooperating with biologist and computer scientist.",
		"KEYWORD": "Big data,Customized Research Data,Data Processing,Public Bio Database"
	},
	{
		"ID": 672,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "동아대학교 대학원",
		"TITLE": "H-CNN 알고리즘을 이용한 이미지 데이터 학습과 정확도 측정 및 학습 속도 비교 ",
		"AUTHOR": "여강국",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 강대성 참고문헌: p.67-69",
		"STORE_LOCATION": "동아대학교 도서관",
		"ABSTRACT": "현 시기에 대두되고 있는 제4차 산업혁명은 지난 2016년 세계 경제 포럼(WEF)에서 언급되었고 새로운 산업시대를 대표하게 되었다. 첨단 정보통신기술이 경제, 사회적으로 적용되어 혁신적인 변화가 나타나고 있고 기존 산업혁명에 비해 더욱 빠른 속도로 영향을 미치고 있다. 산업혁명은 새로운 기술의 등장으로 산업 생태계를 만들고 그것이 인간의 삶의 방식을 변화시킬 때 사용되는 단어이다. 정치, 사회 문화의 분야에서도 획기적인 변화를 나타낸다. 그런 의미에서 제4차 산업혁명은 우리의 삶을 지금보다 나은 삶으로 바꾸어 준다. 인공지능의 발전으로 딥러닝을 이용해 빅테이터를 정교하게 분석할 수 있는 기법도 함께 발전하였다. 인공지능, 빅데이터 기술의 활용 여부에 따라 미래에 더욱 발전할 수 있는 발판이 될 것으로 보인다. Google, Microsoft, IBM, AWS는 각자의 Cloud platform을 제공함으로 데이터 과학자들이 높은 수준에서 사용할 수 있는 딥러닝 framework가 점차 늘어나는 추세이다. 딥러닝은 컴퓨터가 사람과 같이 스스로 학습할 수 있는 인공지능 기술을 의미한다. 최근에 딥러닝은 음성인식, 자연어처리, 이미지 분석 등에서 획기적인 발전을 하여 급성장 하고 있고 빅데이터를 분석해 차이점을 가려내고 유사한 것들을 분류하는 데 탁월한 효과를 보이고 있다. 인공지능의 한 분야인 인공신경망은 생물학의 뇌 구조를 모방한 것인데 주어진 환경에 대한 학습 능력을 가지고 있다. 딥러닝을 이용하여 컴퓨터가 수 천만장의 이미지를 학습하여 객체를 인식하게 하는 데는 다수의 고성능 컴퓨터가 필요하다. 따라서 딥러닝에는 다수의 컴퓨터를 효율적으로 이용하기 위한 분산처리 기술이 필요하며 관련 연구가 활발히 진행되고 있다. 이미지를 데이터화 시켜서 컴퓨터에 인식 시킨 다음 특징을 추출하여 학습을 시키게 된다. 이미지 데이터에는 다수의 데이터 정보가 있다. 그 데이터 정보는 수치로 표현이 가능하다. 수치에 대해서 특징을 추출하는 다수의 계층을 갖춘 신경망을 통해 컴퓨터가 학습할 수 있는 Feature map으로 정보를 체계화하여 스스로 학습패턴을 찾아 낼 수 있게 한다. 본 논문은 H-CNN 알고리즘을 이용하여 이미지 데이터를 학습시키고 정확도 및 학습속도를 비교 분석한다. H-CNN 알고리즘은 이미지 분석으로 많이 알려진 CNN 알고리즘에 Hippocampal 알고리즘의 개념을 추가하였다. CNN 알고리즘에서 Convolution연산과 Max Pooling기법을 통해 추출된 최대값 Feature map에서 Hippocampal 알고리즘을 통해 장기기억과 단기기억의 형태로 나누어 Simple Feature map을 생성하고 학습시킨다. Simple Feature map은 특징이 단순화 되어있지만 필요한 특징들만의 집합이기 때문에 정확도에 영향을 주지 않으며 학습속도를 향상시킬 수 있다. 연구에는 Python언어를 사용하였고 Tensorflow라이브러리를 이용하여 해당 프로그램을 구현하였다. 연구에서 사용하는 데이터는 MNIST, Cifar10, 임상 영상 데이터이다. 다양한 이미지를 학습시켜 정확도를 측정하고 학습속도를 비교분석 하여 성능 향상을 확인 할 수 있다.",
		"KEYWORD": "CNN,H-CNN,HNN,MNIST,딥러닝"
	},
	{
		"ID": 673,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "GPGPU를 활용한 스파크 기반 공간 연산 =Spatial computation on spark using GPGPU ",
		"AUTHOR": "손찬승",
		"REGION": "서울",
		"PROFESSOR": "건국대학교 논문은 저작권에 의해 보호받습니다. Spatial Computation on Spark using GPGPU 지도교수:박능수 참고문헌: p. 27-29",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "최근 IoT와 위치 기반 서비스 등을 위하여 공간 정보를 사용하는 연구에 관심이 증대되고 있다. 그러나 기존 관계형 데이터베이스 시스템을 확장한 공간 데이터베이스 시스템은 공간 데이터 타입, 공간 함수, 공간 연산자 등을 지원하지만 대용량 데이터를 처리하기에는 확장성에 대한 문제가 있다. 분산 처리 플랫폼인 하둡을 확장한 SpatialHadoop은 중간 연산 결과를 디스크에 작성하기 때문에 파일 입출력의 오버헤드로 성능이 저하되는 문제가 있다. 따라서 본 논문에서는 대용량 공간 데이터에 대한 공간 연산을 효율적으로 수행하기 위하여 인-메모리 기반 분산 처리 프레임워크인 스파크를 확장한 공간 연산 스파크를 제안하였다. 또한 공간 연산 스파크의 성능을 향상시키기 위하여 GPGPU를 결합한 공간 연산 스파크를 개발하였다. 스파크 기반 플랫폼은 중간 연산 결과를 메모리에 유지시키는 스파크의 장점을 그대로 사용하고 있으며, GPGPU 기반 공간 연산 스파크의 경우 대량의 프로세서 유닛을 이용하여 공간 연산을 병렬처리하기 때문에 효율적으로 공간 연산을 수행할 수 있다. 마지막으로 본 논문은 단일 AMD 시스템에서 공간 연산 스파크와 GPGPU 기반 공간 연산 스파크를 이용하여 Point-in-Polygon 연산과 Spatial Join 연산을 수행하였으며, SpatialHadoop과 비교 성능 평가를 수행하여 본 논문에서 개발한 공간 연산 스파크와 GPGPU 기반 공간 연산 스파크의 성능 향상을 입증하였다. 실험 결과 GPGPU를 사용한 모델은 Point-in-Polygon 연산에서 SpatialHadoop에 비해 최대 5배의 성능 향상을 보였으며, Spatial Join 연산에서는 최대 8배의 성능 향상을 확인할 수 있었다.",
		"KEYWORD": null
	},
	{
		"ID": 674,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "딥러닝 알고리즘을 이용한 저널추천 방법론 ",
		"AUTHOR": "유영선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김창욱",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Owing to the development of such IT devices as internet and smart phone, it is possible to access the vast databases; in order to extract and use the significant information from the databases, diverse methods including the analysis of big data are being used. Nevertheless, due to the explosive increase of the data, it has become difficult for users to get their desired information promptly. In such circumstances, this study was aimed at discussing and recommending the methods using the Deep Learning Algorithm to help the users get their desired information. In particular, this study reviewed the methods of searching for the English abstracts carried on the industrial engineering journals and thereby, recommending a desirable one to users. To this end, the English abstracts carried on Computers & Operations Research and Ergonomics and International Journal of Production Economics were sampled, and thereby, the frequencies of the key words used were calculated and then, the traditional method of recommendation or the Recommendation via the neural network was used together with the Deep Learning Algorithm method to repeat the entire processing of the key words, and thereupon, the precision of recommendation via neural network was analyzed to verify the effectiveness of the Deep Learning Algorithm method. As a result of the verification with 9,776 abstracts, it was confirmed that the Deep Learning Algorithm method would be more effective than the recommendation via neural network. It is hoped that this study will be followed up by the future studies to extract the text data from the diverse domestic business documents for an auto-encoding and recommendation.",
		"KEYWORD": "artificial neural network,auto-encoders,big data,data mining,deep learning,recommendation of documents,데이터마이닝,딥러닝,문서추천,빅데이터,인공신경망"
	},
	{
		"ID": 675,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "버스정보시스템과 사회경제지표 기반의 다차원 대중교통 네트워크 분석 =Multi-dimensional network analysis of mass transit based on bus information system and socio-economic data ",
		"AUTHOR": "박한솔",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수: 조완섭 참고문헌: p.53-54",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "통합청주시 출범 이후, 주민 생활의 편리함과 지역 발전 추구를 통해 중부권 핵심도시로 성장할 기틀을 마련하였지만, 이에 따라 발생하는 지역 간 불균형 문제에 대한 우려가 대두되었다. 조사 결과, 도로 등 기반시설의 부족 및 불리한 지리적 여건이 지역별 불균형 격차의 원인으로 나타났다. 대중교통의 변화는 각 지역의 이동 및 거주민들의 통행을 편리하게 함으로써 공간적 마찰을 극복하고 지역적 격차를 좁히는데 기여할 수 있다. 따라서 새롭게 변화된 통합청주시 대중교통의 구조와 특징을 파악하여 새로운 수요에 맞추어 변화시켜야 할 필요성이 있다. 본 논문에서는 청주시 대중교통인 시내버스 운행 데이터를 활용하여 다차원의 대중교통 네트워크를 구축한 뒤, 네트워크 중심성 분석을 통해 대중교통의 구조적 특징을 파악하고, 사회경제적 지표와 연계 분석하여 대중교통 취약지를 도출한다. 분석 결과는 시내버스 노선 개편, 대중교통 취약지 개발 등의 청주시 교통계획의 기초연구 자료로써 기여할 수 있다.",
		"KEYWORD": "네트워크분석,대중교통,빅데이터"
	},
	{
		"ID": 676,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "스마트 카드 데이터를 통한 버스 수요 예측에 관한 연구 :Bus demand prediction with smart card data :딥러닝을 활용하여 =a deep learning approach ",
		"AUTHOR": "백정한",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 손기민 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "In order to create environment-friendly transportation system, modal shift from automobile to transit is encouraged. In this case, predicting the demand of transit is the key-factor, which can not be obtained by traditional 4-Step Models because of the excessive concentration of bus stops in Seoul Metropolitan Area. However, the rapid development in Deep Learning Technology with Large-scale data has been continuously gaining expectations in image and acoustic recognition fields. In this paper, `Station Level (Model A)` and `Station-to-station level (Model B)` analyses of Bus-stop demand in Seoul have been organized by Deep Learning Model and the results are validated. In each model, sensitivity analysis has been conducted according to the amount of hidden nodes, hidden layer size, and regularization factor(). Then, cross-validation has been achieved to determine suitability of the developed models. Since there were difference in the level of analysis, the developed models were designed to have different sample size and number of input variables. Model A has been calibrated with large number of input variables, while Model B has been calibrated with large sample size. Model A, with numerous input variables, has achieved about 94% of accuracy in the training set, while Model B, with large sample size, has showed about 73% accuracy. In the sensitivity analysis of the number of hidden nodes and layer size, it has been found that the suitable size of DNN model exists in certain type and amount of required data. Also, the accuracy of the model was insensitive to the regularization factor when the size of DNN model has decreased below certain level. In the cross-validation process, increase in the accuracy for both models would be expected, when more data and input variables are obtained.",
		"KEYWORD": "딥러닝,버스 수요,빅데이터,스마트카드 데이터,자료기반방법론,통행배정"
	},
	{
		"ID": 677,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "급성 방광염에서의 항생제 처방현황 :Antibiotics prescribing pattern for acute cystitis in Korea :건강보험데이터베이스를 대상으로 한 데이터마이닝 연구 =data-mining study using health insurance review & assessment service (HIRA) claims database ",
		"AUTHOR": "서유미",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이길호",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "연구배경 : 단순방광염은 임상에서 흔히 접하게 되는 요로감염의 하나로 지정된 기간 동안의 건강보험심사평가원 청구 데이터베이스를 사용하여 우리나라에서 급성방광염 진단으로 항생제를 사용하는 양상을 분석하고자 한다. 대상 및 방법 : 2011년 1월 1일부터 2011년 12월 31일 까지 심사평가원에 보험 청구된 자료를 대상으로 하여 명세서(table-20)에서 청구 주진단명이 급성 방광염인 환자 71.052을 추출하였고, 이의 명세서 연결코드를 이용하여 원외처방내역(table-53)과 병합하였다. 결과 : 급성방광염 환자에서 56.5% (40,112명/71,052명)가 다양한 종류의 항생제를 처방 받았다. 항생제를 처방한 40,112명 중에서 2종 이상의 항생제를 사용한 군은 16.4% (6,599명/40,112명)인데 비해, 항생제 단독 요법을 사용한 경우는 83.6% (33,513명/40,112명)였다. 이 중 가장 대중적으로 사용되는 처방은 aminoglycoside계 약물의 1회 단독 주사 요법으로 확인되었다. 흥미롭게도, 우리나라에서는 몇몇 종류의 질정 형태의 항생제도 급성방광염 환자에서 빈번한 횟수로 처방되었다. 경구항생제에서 trimexoprime/sulfamethoxalzole (Bactrim), fosfomycin trometamol, nitrofurantoin, 그리고 pivmecillinam의 처방건수는 매우 낮았고, 그 외로 ciprofloxacin, levofloxacin, ofloxacin과 lomefloxacin등 의 fluoroquinolone계 약물과 cefaclor와 cefpodoxime proxetil같은 cephalosporin계 약물의 경구처방도 높은 비중을 차지하지 않았다. 결론 : 우리나라에서 급성방광염 환자들에게 사용되는 약물치료는 원칙 없이 다양하게 사용되고 있다. 이러한 항생제치료는 과학적 근거와 요로감염의 임상진료지침에 맞춰서 시행되어야 한다.",
		"KEYWORD": "급성방광염,빅데이터,우리나라,항생제"
	},
	{
		"ID": 678,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "스트림 데이터의 부하 개선을 위한 분산처리방식에 관한 연구 =A study on the distributed processing method for improving work load of the stream data ",
		"AUTHOR": "조성근",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 민홍기",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "최근 사물인터넷(IoT : Internet of Things) 기술의 발달과 모바일 단말기를 이용한 소셜 미디어의 활용이 증가함에 따라 방대한 양의 데이터가 실시간으로 생성된다. 이러한 실시간 스트림 데이터를 처리하기 위해서 대표적인 분산처리 프레임 워크인 하둡에 파이프 라인 기능을 추가한 맵리듀스 온라인(MapReduce Online)을 이용 한다. 맵리듀스 온라인은 기존 맵리듀스의 일괄 처리에서 맵 단계의 처리 결과 데이터를 리듀스 단계로 전달하는 과정에 파이프라인 기능을 적용한다. 파이프라인 기능은 맵의 결과가 일정량 이상 처리되면 리듀스로 보내어 처리할 수 있다. 파이프라인 기능을 이용하면 리듀스가 일찍 작업을 수행할 수 있으므로 기존의 맵리듀스 보다 처리완료 시간이 빠르다. 이와 같은 파이프라인 기능을 이용하여 맵리듀스 온라인은 스트림 데이터와 같이 실시간으로 계속 발생하는 환경에서 활용이 가능하다. 스트림 데이터 처리는 기존의 하둡에서 적합하지 않기 때문에 맵리듀스 온라인의 파이프 기능을 적용한 입력 모듈을 추가하였다. 모듈의 동작은 맵단계에서 입력으로 들어오는 스트림 데이터를 큐에 저장한다. 그리고 맵태스크는 해당 큐에 접근하여 데이터를 처리한다. 하둡은 이미 저장된 고정 크기의 적당한 크기로 쪼개어 맵태스크들에게 균등하게 데이터가 나누어 진다. 그러나 스트림 데이터는 가변적이기 때문에 특정 맵태스크에 처리할 데이터가 몰리는 부하 문제가 발생한다. 이러한 부하 문제를 개선하기 위해서 부하 노드의 태스크 크기 동적 재설정 방법을 제안하였다. 스트림 데이터 처리 노드의 부하검출을 위해서 입력 모듈로부터 네 가지 요소를 얻는다. 큐에 쌓인 스트림 데이터 누적 량, 큐에 쌓인 스트림 데이터 누적속도, 스트림 데이터 수신 속도, 스트림 데이터 처리속도의 정보로 부하노드를 검출한다. 그리고 부하 노드의 태스크 재설정 계산 방법으로 맵태스크의 크기를 부하 노드의 코어수의 두배로 재설정하였다. 본 논문에서는 하둡에서 제공하는 wordcount 어플리케이션과 같은 <key/value> 형식의 데이터를 생성하는 프로그램을 이용하였다. 제안하는 방법의 실험을 위하여 각 각의 크기가 100byte인 7개의 스트림 데이터를 초당 100개, 500개를 입력으로 실험을 진행하였다. 입력 모듈의 성능은 700개의 스트림 데이터를 처리하는데 문제가 없음을 알 수 있었다. 그러나 초당 3500개의 스트림 데이터 처리 시에는 부하가 발생하였다. 실험 결과 부하 노드의 스트림 데이터 누적량이 6240개에서 태스크 크기 동적 재설정을 적용했을 때 누적량이 4409개로 감소하였다. 부하 감소량을 백분율로 계산했을 때, 부하 노드가 약 30% 개선되는 것을 확인 할 수 있었다.",
		"KEYWORD": "분산 처리,빅데이터,스트림,하둡"
	},
	{
		"ID": 679,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "(An)analysis of regional characteristics according to city safety related key words shown in Twitter data :트위터 데이터에 나타난 도시안전관련 주제어에 따른 지역별 특성 분석 :focusing on Seoul 10 districts =서울시 10개 구를 중심으로 ",
		"AUTHOR": "JungKabWang",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 680,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 생활환경대학원",
		"TITLE": "통계 데이터 시각화의 모바일 웹 인터페이스에 관한 연구 ",
		"AUTHOR": "최은정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이현수",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "현재는 다양한 모바일 기기와 소셜 미디어의 확산으로 가늠할 수 없을 정도의 많은 정보와 데이터가 생산되고 있는 빅데이터의 시대로, 다양한 데이터의 분석을 통해 트렌드를 분석하고 미래를 예측하는 것이 중요하다. 복잡한 데이터의 효율적인 분석을 위해 분석 결과를 쉽게 이해 할 수 있도록 직관적인 시각화 방법에 대한 다양한 연구가 진행 중이며, PC 환경 외에 빠르게 정보를 확인 할 수 있는 모바일 디바이스 내에서 다양한 정보를 포함한 데이터 시각화의 효율적인 인터페이스 방법에 대한 연구가 필요하다. 제한된 화면 크기의 모바일 디바이스 내에서 다량의 데이터를 쉽고 빠르게 분석 할 수 있다면, 기업과 개인에게 신속하고 이해하기 쉽게 정보를 제공하는 것 뿐 아니라, 데이터의 트렌드와 패턴을 빠르게 분석 할 수 있어 미래를 예측, 대비 할 수 있을 것이다.본 연구자는 화면 크기의 제약이 있는 모바일 디바이스 내에서 다량의 통계 데이터를 효율적으로 제공하는 인터페이스 방법을 제안하였다. 이를 위해 데이터 시각화와 모바일 웹 인터페이스에 대해 알아보고, 모바일 웹 환경에서 통계 데이터 시각화의 인터페이스 사례들의 분석을 통해 추출한 4가지 프로토타입을 바탕으로 전문가 심층 인터뷰를 진행하였다. 전문가 심층 인터뷰의 결과에서 도출된 7가지의 인터페이스 요소로 최종 설계안을 제안한다. 인터페이스 설계 시 고려되어야할 7가지 요소는 통계 데이터의 패턴을 파악 할 수 있는 데이터 시각화의 방법 및 제한된 화면 크기 내에서 복잡한 데이터 시각화의 정확한 정보 전달을 위한 정보 구성 방법과 인터렉션 방법이다.본 연구에서는 데이터 시각화와 모바일 웹 인터페이스에 대해 알아보고, 효과적인 정보 구성 및 인터랙션 방법을 모색하였다. 본 연구의 결과로 제안된 인터페이스 설계 시 고려되어야할 요소들은 모바일 웹 서비스 뿐만 아니라 제한된 화면 안에서 다량의 정보를 제공 할 경우 활용 할 수 있을 것이라 여겨진다.",
		"KEYWORD": "big data,data visualization,mobile web interface,데이터 시각화,모바일 웹 인터페이스,빅데이터"
	},
	{
		"ID": 681,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "신사업개발전략으로서의 사내벤처에 대한 연구 :생태계적 진화와 정보비대칭을 중심으로 ",
		"AUTHOR": "박다인",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박찬희 중앙대학교 논문은 저작권에 의해 보호받습니다 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "기술의 발전 및 시대 흐름의 변화는 비즈니스 생태계 변화를 이끌고, 기업은 이러한 변화에 대비한 전략을 구성한다. 지난 수십년 간 비즈니스 생태계에서는 예측하지 못한 위기와 변화가 있었고 이에 대비하지 못한 수많은 기업들이 도태되는 일은 빈번하게 일어났다. 이처럼 급변하는 경영 환경을 따라가지 못하거나 위기를 관리하지 못하는 기업은 비즈니스 생태계 내에서 생존을 보장받을 수 없는 현실이다. 대규모 자본력과 인력을 가진 기업마저도 기업 수명이 점차 단축되고, 단시간 내에 산업에서 퇴출되는 현실 속에서 초우량 기업이라도 지속적인 혁신 역량을 갖추지 못하면 도태되는 것이 현실임을 확인할 수 있다. 특히 규모가 크고 오래 된 기업일수록 경영이 방만해지고 수직화된 조직 구조 속에서 계열사 수를 늘리다보니 유연성이 떨어지는 문제가 발생한다. 이처럼 루틴과 유연성을 극복하기 위해서는 새로운 사업을 통해 기업의 변화를 주도하고, 새로운 비즈니스 생태계를 재편하고, 조직 구성 내 분위기를 바꾸는 것이 매우 중요하지만 다수의 기업들이 제대로 된 변화 및 혁신을 추구하지 못하고 있는 현실이다. 불확실성의 일상화 속에 놓인 기업 역시 현실에 안주하는 경우 단숨에 도태되기 때문에 혁신을 위한 기업 내부의 기업가정신이 중요하다고 본다. 즉, 기술 및 경제 환경 변화로 인해 복잡성이 증가하고, 안정적인 비즈니스 모델에 대한 의지가 어려운 비즈니스 생태계에서는 빠른 사업 변화와 조직 변화가 필요할 수 밖에 없다. 최근 기업의 유연성 및 새로운 투자처 확보, 새로운 사업군 발굴 등을 목적으로 사내벤처 전략이 다시 급부상하고 있으며, 사내벤처를 통해 탄생한 기업들의 성공사례가 이어지고 있다. 사내벤처는 1980년대 후반, 미국을 중심으로 다양한 틈새시장 개척을 기반으로 한 글로벌적인 벤처붐이 일게 되면서 사내에서 혁신적 창업 기회를 얻으려는 목적에서 시작했다. 사내벤처란 기업 내 구성원들이 포착한 기회를 중심으로 아이디어를 발현해 비즈니스 모델을 발굴한 후, 자본을 투자해 사업화 시키는 벤처 전략의 일종이다. 해당 전략은 사내 구성원들에게 혁신적인 자극제가 될뿐만 아니라 모기업의 새로운 투자처로 작용할 수 있다는 점에서 매우 빠르게 퍼져나갔다. 구글, 시스코 등 거대 IT 기업들은 사내벤처제도를 통해 수많은 사업화에 성공해 해당 조직을 분사시키고 투자 수익을 얻거나 인수합병을 통해 사업부로 편입시키는 등의 일련의 성과를 거두었다. 첫째, 국내 사내벤처는 1991년부터 기술을 중심으로 진화하고 있으며, 현재는 3번의 시대적 흐름을 지나 사내벤처 4.0시대에 위치함을 확인하였다. 사내벤처 1.0 시대의 경우 인터넷, 전자상거래, 소프트웨어 등의 키워드, 사내벤처 2.0 시대의 경우 인터넷, 서비스, 온라인, 네트워크 등의 키워드, 사내벤처 3.0 시대의 경우 서비스, 게임, 모바일, SNS 키워드 등이 주요 관련 키워드로 도출되었다. 현재 진행중이라고 볼 수 있는 사내벤처 4.0 시대의 경우 4차산업혁명의 영향을 받아 VR, AR, 클라우드 등의 주요 관련 키워드들이 확인되었다. 또한 사내벤처 성과인 독립(분사)와 연관 된 주요 개념들의 조합을 확인한 결과 시대별로 연관성이 높은 조합이 다르게 나타났으며, 특히 사내벤처 4.0 시대는 기술과 기업의 지원(투자 및 육성), 자율성이 모두 결합 된 유형이 성과와 가장 높은 연관성을 보이는 것으로 나타났다. 둘째, SK Encar 사례를 통해 Burgelman(1983)의 상호작용모델에서 회사와 구성원이 각각 외부의 기회를 찾는 가능성을 포함해 사내벤처가 검토되고 실행되는 과정을 확인하였다. 즉, 회사와 구성원이 외부의 기회가 아닌 사내벤처를 택하는 이유를 밝히게 된 사례라고 볼 수 있다. 사내벤처를 실시한 SK는 기존의 대기업 체제처럼 완벽한 기획을 추구하는 디자인 전략이 아니라, 현실 속에서 답을 만들어나가는 우발적 전략의 접근을 시도해 사내벤처 구성원들과의 정보비대칭 문제를 완화시켰다는 점에 의미가 있다. 셋째, 사내벤처를 통해 시작 된 기업은 다양한 벤처 진화 형태를 보이며 기업 생태계를 구성해나갈 수 있음을 확인하였다. SK Encar의 경우 SK C&C와의 합병을 통해 독립기업에서 모기업으로 회귀하는 전략을 선택했는데, 해당 과정을 이익 상충 가설과 효율적 거래 가설이라는 두 가지 시각으로 분석하였다. 이익 상충 가설 시각의 경우 사내벤처를 통해 독립한 기업이 독자적 성장을 통해 발전하고, 비즈니스 생태계 내 입지를 넓히는 것도 중요하지만 일정 단계에 이른 경우 투자자금 회수 및 사업 모델을 진화시키기 위해 인수합병 되는 전략 역시 효과적인 대안임을 확인하였다. 효율적 거래 가설 시각의 경우 사내벤처라는 이름 인수합병 혹은 터널링 수단으로 악용될 수 있는 과정이 충분히 존재함을 확인하였다. 즉, 인수합병 전개 과정 살펴봄으로서 양날의 검으로 작용할 수 있는 사내벤처 이후 진화 형태를 중립적인 시각으로 분석함으로써 추후 사내벤처를 통해 독립한 기업들이 재 진화과정을 거치는 경우 처할 수 있는 상황들을 확인하였다. 이처럼 본 연구는 사내벤처를 통해 탄생한 기업들에 대한 전반적인 분석을 통해 사내벤처를 추진하는 전반적인 거버넌스 체계를 살펴보았다는 점에 큰 의미를 갖는다. 첫째, 정보비대칭 문제 완화 관점에서 사내벤처 전략 실행 과정을 분석했다는 점에 큰 의미가 있다. Burgelman(1983a, 1983b)이 제시한 일련의 모델들을 기반으로 사내벤처 사내벤처를 기업 관점과 구성원 관점으로 구분하여 정보비대칭으로 인한 문제를 최소화시키기 위한 전략적 방법들을 확인하였다. 단순히 새로운 기회를 창출하거나, 기업가 정신을 고취시키기 위해 사내벤처 전략을 시도하는 것이 아니라 외부 시장에 대한 정보비대칭 문제 완화를 위한 전략적 방법으로서 사내벤처를 제시했다는 점에 의미가 있다고 볼 수 있다. 둘째, 약 21년 간 발행된 사내벤처 관련 뉴스 키워드라는 대규모 데이터에 기반한 분석을 통해 사내벤처의 변화과정을 설명하였다. 사내벤처 관련 연구는 대부분 정성적인 사례연구로 진행되고 있는데 새로운 관점에의 접근이라는 차별점을 갖는다. 셋째, 사내벤처 기업이 독립한 이후 상황을 모기업으로의 회귀와 또 다른 사내벤처 기업 창출로 분석해 비즈니스 생태계 내 선순환구조가 구축될 수 있음을 확인하였다. 사내벤처 기업의 성과는 모기업으로부터의 독립, 즉 분사라고 볼 수 있다. 그러나 분사라는 성과를 이룬 기업이 어떠한 모습으로 진화할 수 있는가에 대해 살펴본 연구는 존재하지 않는다. 본 연구는 사적 이득을 취득하려는 목적에서 인수합병을 시도하는 관점과 비즈니스 및 네트워크 기반을 확대하려는 목적에서 인수합병을 시도하는 관점을 동시에 고려해 균형을 가져야 함을 확인하였다.",
		"KEYWORD": "기업진화,데이터마이닝,빅데이터,사내벤처,상호작용모델,생태계적 진화,신사업전략,정보비대칭"
	},
	{
		"ID": 682,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "동국대학교 법무대학원",
		"TITLE": "신용정보와 개인정보보호에 관한 법적 연구 =(A)legal study on credit information and personal information protection ",
		"AUTHOR": "정영심",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김상겸",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "고도의 정보사회가 도래하면서 개인정보보호의 문제는 점차 기본적 권리의 차원에서 다루어지고 있다. 특히 포털이나 인터넷 쇼핑몰 내지 대기업에서 관리하는 개인정보가 해커나 관리자의 실수 또는 고의로 대량 유출되면서 온라인에서 뿐만 아니라 오프라인에서 개인정보보호의 문제는 중요한 핵심 사안이 되고 있다. 더구나 2014년 초 신용카드사에서 개인정보의 대량유출사고가 발생하면서 우리 사회에 충격을 주고 있다. 개인정보는 개인의 인격이나 건강, 교육과 신용 등 개인의 중요하고 민감한 정보를 포함하고 있다. 개인정보의 유출은 해당 개인의 인격을 침해할 뿐만 아니라, 경우에 따라서는 재산을 침해함으로써 개인의 기본권을 심각하게 침해하는 문제를 야기한다. 이와 함께 사회적 혼란뿐만 아니라, 경제적 손해를 발생시킴으로써 국가경제에도 피해를 가져오면서 발전을 저해하게 된다. 특히 개인의 인격이나 명예를 훼손시킴으로 인하여 개인의 사회생활에 타격을 입히고 심지어 파탄에 이르게 한다. 국제사회에서는 이미 개인정보보호의 문제는 심각한 사회적 이슈로 보고 이에 대한 대책을 수립하여 추진·시행하고 있다. 이미 20세기 말에 OECD는 개인정보보호를 위한 8대 원칙과 가이드라인을 정하여 시행하고 있으며, 유럽연합은 2000년대에 오면서 연합헌법에 개인정보보호권을 규정함으로써 개인정보보호가 하나의 기본권임을 선언하고 있다. 유럽연합은 개인정보보호를 위한 통일법전을 제정하여 공동 대응함으로써 다른 국가들보다도 보다 구체적으로 개인정보보호에 힘쓰고 있다. 개인정보와 관련하여 최근의 상황은 주로 개인의 신용정보를 이용한 금융사고에 초점이 맞춰지고 있다. 개인의 금융정보와 관련해서는 신용정보보호를 위한 특별법이 제정되어 시행되고 있는데, 이는 개인정보보호를 위한 통합법이며 일종의 기본법인 개인정보보호법과 함께 개인의 신용정보에 관하여 규율하고 있다. 2014년 초 신용카드사 고객의 신용정보 유출사고가 발생하면서 국회는 이에 대한 대책으로 신용정보 유출 방지법 제정을 추진하고 있다. 그렇지만 이에 앞서서 현행 신용정보에 관한 법률을 현실에 맞게 개정하고 관련법을 정비하는 것이 더 필요하다.",
		"KEYWORD": "개인정보보호법제,신용정보"
	},
	{
		"ID": 683,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "동아대학교 교육대학원",
		"TITLE": "스마트 교육을 위한 ICT 기술 현황 및 개선에 관한 연구 :음악 교육 중심으로 ",
		"AUTHOR": "박해민",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 김명규 참고문헌: p. 57-61",
		"STORE_LOCATION": "동아대학교 도서관",
		"ABSTRACT": "21세기 교육의 키워드는 스마트 교육으로 볼 수 있다. 스마트 교육은 지능형 맞춤학습체제로써 학습자의 역량 강화를 위한 교육을 의미한다. 정보 기술의 활용은 사회적, 경제적 변화와 정보기술의 발전에 따라 일상화 되었다. 교육 분야에서도 ICT 기술의 출현이 가속화됨으로써 시간과 장소의 제약 없이 학습이 가능하게 되었다. 최근 학계에서는 스마트 교육을 과제로 한 다양한 연구 성과물들이 축적되고 있다. 스마트 교육에 대한 연구의 저변은 확대되고 있는 실정이나 스마트 교육에 활용되고 있는 ICT 기술에 대한 연구는 아직 미흡한 편이다. 본고에서는 학계의 연구 성과를 토대로 ICT 기술현황과 ICT 기술들이 음악교육에서 활용되는 양상과 그에 따른 문제점 및 개선 방향에 대한 연구를 개진하고자 한다. 이를 위해 먼저 스마트 교육에 대한 정의와 함께 관련 요소들을 분석하고 현재 음악교육에 활용되는 ICT 기술들을 조사하였다. 수많은 ICT 기술 중에서 디지털교과서, 스마트 디바이스와 앱, 빅 데이터, 서비스 로봇을 선별하여 연구를 진행하였다. 본 연구의 결론은 다음과 같다. 첫째, 디지털교과서 분야에서는 다른 여느 나라보다 선진적으로 기술적 구성을 완성하였다고 볼 수 있다. 반면 디지털 교과서는 디지털 콘텐츠의 혼합, 디지털 교과서 저작도구 표준화 및 콘텐츠의 부재 등으로 인한 문제점도 누적되어 있는 상황이다. 이러한 문제점을 개선하기 위해서 디스플레이 기술의 발전과 디지털교과서를 제작할 수 있는 제작도구, 교육용 콘텐츠의 개발에 힘써야할 것이다. 둘째, 스마트 디바이스와 앱은 전문 교육용 앱의 양산과 발전을 필요로 하고 있으며 이를 제작하기 위한 기술은 이미 갖추어진 상태이다. 그럼에도 불구하고 효과가 검증되지 않았다는 이유로 교육용 앱의 효율성에 대한 의문은 여전히 제시되고 있는 실정이다. 이를 개선하기 위한 방안으로 교육용 앱의 인증 제도를 도입하고 교육용 어플리케이션 시장의 새로운 생태계 조성이 필요하다고 생각한다. 셋째, 빅 데이터는 여러 분야에서 많은 관심을 보이고 있는 장르이다. 교육 분야에서는 아직 연구 초기 단계의 수준이지만 현재 세계적인 협회 및 대학에서 빅 데이터를 통한 연구가 활발하게 진행되고 있다. 빅 데이터의 보편화와 일상화는 그에 따른 저작권을 요구할 것이며 적절한 관리절차를 필요로 하게 될 것이다. 이를 위한 법이나 제도의 도입은 필수불가결이다. 넷째, 서비스 로봇은 이미 전 세계적으로 다양한 교육용 매체로 활성화되고 있다. 교육용 로봇은 자율형 로봇보다 텔레 프레즌스 로봇이 교육적 효과가 더 높았고 경제적 측면과 기술적 완성도가 더욱 우수하다. 교육용 로봇은 학습자에게 학습의 필수적 기능뿐만 아니라 경제성을 포함한 다양한 방면에서의 발달도 요구될 거라 예상된다. 본 연구가 향후 스마트 교육의 활성화의 밑거름이 되고 스마트 교육의 활성화에 관한 연구 및 개발에 도움이 되기를 바란다.",
		"KEYWORD": "디지털교과서,빅데이터,음악교육"
	},
	{
		"ID": 684,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "강원대학교 대학원",
		"TITLE": "집단지성 기반 사용자 맞춤형 음식점 추천 시스템 =User-customized restaurant recommender system based on collective intelligence ",
		"AUTHOR": "김다솜",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수 : 이승준 참고문헌 : L36-37.",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "최근 인터넷 서비스 및 모바일 기기의 발전에 따라, 콘텐츠와 서비스가 기하급수적으로 증가하였다. 우리 주변을 둘러싸고 있는 정보의 홍수 속에서 빠르고 현명한 선택을 위해 추천시스템(Recommender System)의 필요성이 증대되었다. 모든 사용자들을 평균화, 일원화하여 동일한 아이템을 추천하는 것은 요즘같이 관심사가 다양해지고 있는 시대에 알맞지 않다. 따라서 본 논문에서는 추천 시에 사용자의 성향을 고려하여 사용자에게 맞춤화된 추천 목록을 제공하는 방법을 제안하였다. 본 논문의 추천시스템에서는 사용자 정보를 이용하여 사용자의 성향을 고려하도록 하였다. 또한 유클리디안 거리(Euclidean Distance) 및 피어슨 상관계수(Pearson Correlation Coefficient)를 이용하여 사용자와 유사 사용자를 찾는 집단지성 기반 협업 필터링을 수행하였다. 추천시스템을 평가하기 위해 정확도(Precision)과 재현률(Recall)을 사용하였다. 실험 결과, 제안한 추천시스템은 평균 정확도가 72%, 재현율이 51.3%로서 기존의 추천 시스템과 비교하여 정확도가 5%, 재현율이 4.3% 향상된 것을 확인하였다.",
		"KEYWORD": "사용자 맞춤형,집단지성,추천 시스템,협업필터링"
	},
	{
		"ID": 685,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "친환경 패션 광고의 소비자 언어와 주장 유형이 광고효과에 미치는 영향 연구 ",
		"AUTHOR": "김민영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 고은주",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "패션 산업은 패스트 패션 (Fast fashion)의 확산으로 인해 다양한 환경 문제를 야기하고 있으며, 환경 파괴의 주범으로 손꼽히고 있다. 패션 브랜드들은 이러한 기업의 이미지 재고를 위해 친환경적 경영 철학을 강조하고 있으며, 이는 사회적으로 중요한 문제로 주목 받고 있다. 소비자들은 과거에 비해 친환경 패션 제품의 중요성을 깨닫고 있으며, 기업은 소비자들의 환경에 대한 관심을 구매까지 이어지게 유도하기 위해 친환경 패션 광고를 진행하고 있다. 하지만, 친환경 패션 광고는 국내 소비자들의 낮은 환경에 대한 인식과 일천한 친환경 마케팅 경험에 의해 역효과가 나타나고 있고 이에 따라 국내 소비자의 인식에 맞는 친환경 패션 광고가 구현되어야 한다. 현재 친환경 패션 광고에 관한 연구는 친환경 소비자 언어 유무에 따른 소비자 반응에만 집중하고 있으며, 구체적인 광고 내용에 따른 광고효과를 살펴보는 연구는 부족한 실정이다. 본 연구는 효과적인 친환경 패션 광고를 도출하는데 그 의의가 있다. 본 연구에서는 친환경 패션에 대한 소비자의 의견과 인식을 빅 데이터 분석을 통해 파악하고, 이를 광고 메시지로 제작하였다. 또한, 소비자 언어의 유무와 친환경 주장 유형에 따른 친환경 패션 광고효과를 실질적으로 분석하고자 하였다. 구체적인 연구 목적은 다음과 같다. 첫째, 친환경 패션에 대한 소비자의 의견을 빅 데이터 분석을 통해 소비자 언어로 도출하고 이를 통해 친환경 패션에 대한 소비자 의견을 살펴본다. 둘째, 친환경 패션 광고에서 소비자 언어 유무와 친환경 주장 유형에 대한 상호작용효과를 규명한다. 셋째, 친환경 패션 광고에서 광고태도, 소비자인지, 브랜드태도, 구매의도의 관련성을 살펴본다. 본 연구에서는 트위터에서 언급된 친환경 패션에 대한 빅 데이터를 추출하여 분석하였으며, 추가적으로 소비자 인터뷰를 진행하였다. 이를 통해 친환경 패션에 대한 소비자의 의견을 소비자 언어로 도출하였으며, 도출된 소비자 언어를 제품 관련 언어 (실체적 주장)와 브랜드 이미지 관련 언어 (연상적 주장)로 구분하고 이를 통해 광고 메시지를 제작 후 제공하였다. 연구는 2 (소비자 언어: 유/무) × 2 (친환경 주장 유형: 실체적/연상적)의 요인설계로 진행되었으며, 광고효과를 비교하기 위해 설문조사를 실시하였다. 설문지는 온라인을 통해 배포되었으며, 총 305부의 응답이 분석에 사용되었다. 수집된 데이터는 SPSS 21.0을 활용하여 기술통계, 신뢰도 분석, t-test, 이원변량분석 (Two-way ANOVA), 회귀분석 등을 실시하였다. 연구 결과, 친환경 패션 소비자 언어 중 제품 관련 언어 (실체적 주장 유형)로는 무해한, 천연의, 쾌적한, 유기농의, 깨끗한 등이 나타났으며, 브랜드의 친환경 활동 관련 언어 (연상적 주장 유형)로는 믿음이 가는, 착한, 진실된, 윤리적인, 사회적인 등이 나타났다. 도출된 소비자 언어를 바탕으로 소비자 언어 유무와 친환경 주장 유형에 따른 광고 효과를 살펴본 결과 소비자 언어 유무와 친환경 주장 유형은 광고태도와 브랜드 인지 모두에 유의한 상호작용을 보인다. 광고태도는 연상적 광고에 소비자 언어가 있을 때 가장 긍정적으로 나타났으며, 브랜드 인지는 실체적 광고에 소비자 언어가 있을 시 가장 긍정적으로 나타났다. 또한, 광고태도는 브랜드 인지와 브랜드태도에 긍정적인 영향을 미치며, 브랜드 인지는 브랜드태도에 긍정적인 영향을 보이고 브랜드태도는 최종적으로 구매의도를 유발할 수 있음이 증명되었다. 본 연구는 빅 데이터 분석을 통한 소비자 의견을 언어로 도출하고 이를 광고로 제공함으로써 광고 분야에서 빅 데이터 활용 방안을 제시하였다. 또한, 친환경 패션 광고와 관련하여 친환경 주장 유형에 따른 광고효과를 입증함으로써, 제한적이었던 기존 연구를 확장하는 역할을 하였다. 실무적인 측면에서 본 연구는 친환경 패션 광고 진행 시 지침이 될 수 있다는 점에서 의의가 있다.",
		"KEYWORD": "advertisement attitude,big data,brand attitude,brand cognition,eco fashion advertisement,environmental claim types,purchase intention,광고태도,구매의도,브랜드 인지,브랜드태도,빅 데이터,친환경 주장 유형,친환경 패션 광고"
	},
	{
		"ID": 686,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려사이버대학교 융합정보대학원",
		"TITLE": "해외마케팅 서비스의 효과적 이용에 관한 실증 연구 :중소기업 해외수출 지원활동을 중심으로 ",
		"AUTHOR": "정영종",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정대석",
		"STORE_LOCATION": "고려사이버대학교 도서관",
		"ABSTRACT": "본 연구는 수출지원정책의 일환으로 정부와 지자체, 수출유관기관들이 제공 하고 있는 수출지원 프로그램들 가운데 가장 많이 사용되고 있는 해외전시회 참 가 등 해외마케팅 서비스를 많이 이용하면 할수록 실제 수출이 그 만큼 더 증가 하는 지를 과거 해외마케팅 서비스 이용 실적 데이터를 이용하여 양적분석의 방 법으로 검증함과 동시에 질적 분석의 방법으로 해외 마케팅 성공 사례 분석을 통 하여 실제 우리기업들이 어떻게 하면 수출에 성공하고 동시에 마케팅 효과를 극 대화 할 수 있는 지를 알아보는 것이 연구의 주목적이었다. 양적 연구 결과, 해외전시회와 지사화사업 서비스를 같이 복합적으로 이용할 경우에는 이 두 가지 서비스를 이용한 횟수와 수출 증가율 간에 정의 상관관계가 있는 것으로 확인되었으나, 해외마케팅 서비스를 독립적으로 이용할 경우 그 이 용횟수와 수출 증가율 간에 정의 상관관계는 없는 것으로 확인되었다. 질적 분석 의 방법으로써 KOTRA의 지사화 서비스 성공사례 69건의 내용을 분석한 결과, 기 업의 수출역량과 수출품목, 지역적 특성에 맞추어 해외마케팅 서비스를 2개 이상 혼합하여 사용한 많은 수의 기업들이 수출 성공을 포함한 해외마케팅 목적을 달 성하였음이 확인되었다. 이것은 양적분석의 결과 해외전시회와 지사화 서비스를 복합적으로 이용할 경우 평균수출 증가율이 정의 상관관계를 갖는 결과와 동일하 였다. 또한 기업들은 해외마케팅 성공의 내용으로 수출금액 뿐만 아니라 밴더 등 록, 유명 유통망 입점, 정부조달절차 완료 등 다양한 성공의 내용을 제시하였다. 수출에 성공한 기업들은 수출기업과 해외 지사화 서비스를 담당하는 무역관 직원 과의 유기적 협업 즉 빈번한 커뮤니케이션이 가장 중요하고 바이어와 빈번하게 접촉하는 것 역시 매우 중요한 성공요인으로 소개하였다. 해외마케팅 서비스 사용 이후 수출에 소요된 기간은 평균 1.3년 이었으며, 해 외마케팅서비스 이용 매트릭스 중 수출에 걸리는 시간이 가장 짧은 것은 지사화 서비스와 무역사절단을 함께 이용한 경우로 1.0년이 소요되었다. 따라서 수출기업들은 단순히 해외마케팅 서비스를 가급적 많이 이용하는 방법 에서 벗어나 기업의 수출역량과 수출품목 특성에 맞는 해외마케팅 서비스를 선택 하여 복합적으로 이용하는 방식으로 전환하는 것이 필요하다. 또한 현재 정부, 지 자체, 수출지원기관들의 양적인 수출 지원 정책을 수정할 필요가 있으며 본 연구 의 질적인 분석 결과에 근거하여 기업들의 수출역량과 품목 특성에 맞게 맞춤형 지원정책으로 전환하여야 할 것으로 판단된다. 아울러 해외 마케팅의 성과 역시 단순한 수출금액을 평가하는 방법에서 벗어나 세분화할 필요가 있으며, 수출기업 들의 해외마케팅 서비스 이용 목적에 따라 성과를 측정하는 방향으로 지원정책이 발전해 가야 할 것으로 판단된다.",
		"KEYWORD": "맞춤형 서비스,무역사절단,빅데이터,서비스 이용횟수,세일즈출장,수출기간,수출성과,수출역량,수출지역,수출지원,수출품목,양적분석,중소기업,지사화사업,질적분석,해외마케팅 서비스,해외시장,해외전시회"
	},
	{
		"ID": 687,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 공학대학원",
		"TITLE": "특허 검색을 통한 인공지능 기반 음성인식 유망 기술 분석 ",
		"AUTHOR": "정소라",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이철웅 참고문헌: 장 48-50",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "우리나라의 4차 산업혁명 관련 산업 중 가장 빠르게 발전될 산업으로 ‘음성인식 기술’이 꼽히고 있다. 음성인식 기술은 인공지능(AI)과 결합하여 음성비서, 자율주행차, 실시간 음성 통역 등 다양한 분야에서 활용되고 있다. 특히 최고의 사용자 인터페이스(UI)로 각광받고 있는 가운데 인공지능 음성인식 시장을 선점하기 위하여 SKT, KT, 삼성, LG, 네이버 등 국내업체는 물론이고 IBM, 아마존, 애플, 구글, 마이크로소프트, NTT, 소프트뱅크 등 글로벌 IT 업체들이 치열한 무한 경쟁에 돌입하고 있다. 시장조사기관인 트랜드포스에 따르면 글로벌 음성인식 시장은 ‘16년 26억 달러이며 ‘21년에는 160억 달러 규모로 추산되며, 5년 동안 약 6배의 성장을 예상하고 있다. 이에 4차 산업혁명 시대의 인공지능 기반 음성인식 마켓 동향과 기술개발현황에 대해 특허 분석을 통해 전망해 보고자 한다.",
		"KEYWORD": "4차 산업혁명,딥러닝,빅데이터,음성인식,인공지능,특허"
	},
	{
		"ID": 688,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "온톨로지와 텍스트 마이닝을 활용한 서비타이제이션 연구토픽에 관한 연구 :(A)study of research topics in servitization using ontology & text mining :연구 문헌의 트렌드 마이닝을 중심으로 =focused on trend mining of literatures ",
		"AUTHOR": "이윤상",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박선영",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "Although the Korean economy has a very high reliance on manufacturing, Korea’s domestic and international competitiveness, and the growth rate of its manufacturing industry, has been in transition, seeing a sustained decline. Recently, servitization - a combination of services and products - has, in consideration of the characteristics of the Korean economy, attracted attention as a sustainable growth engine for the future. Servitization is an industry-developing policy and new business model differentiated from that of developing countries, such as China and India. Therefore, a lot of industry policies for activating servitization, and business models applying servitization, have emerged globally, in a large number of economically-advanced countries. Because research literature reflects the reality of the industry, it is possible to understand the current states and the global trends of servitization, and how it has changed, through an analysis of relevant sources. Through such analysis, it is possible to derive a high volume of suggestions regarding servitization and its implementation. Existing research about servitization has been performed several times already; however, such studies have been conducted using a qualitative methodology, which is dependent on experts’ opinions. Because of this, it is imperative to use a quantitative methodology, through which is secured objectivity, to analyze servitization literature. Therefore, in this study, ontology and text mining have been used to determine the status of servitization, and the trends of important research topics in servitization studies. In the conclusion of this study, the suggestion of depth in the direction of the fusion of the future of manufacturing and services is presented. In order to try to run trend mining, on the basis of the text mining and ontology method, meta-data and abstracts of servitization-related papers have been collected from Scopus, a famous global academic database. The ontology analysis process used the TopBraid Composer 5.0.1, and the text mining analysis process used STATA 13 and WordStat for STATA 7.0. In the text mining process, the clustering method based on the cosine similarity, and the topics extraction method based on the principal component analysis, were utilized. It suggested that, based on the trend mining, the results of this study are as follows: First, while servitization studies have been deployed worldwide, in South Korea servitization research contributions have fallen. For the global competitiveness of the domestic servitization model, there is a need for increased interest in global joint research, done in cooperation with developed countries in the manufacturing sector. Second, servitization studies have been carried out most actively in Germany, a country with a highly-developed manufacturing sector, and Germany has led servitization research trends. The German government, using German manufacturing as the subject of benchmarking, continues to carefully observe German industry policies and corporate strategies, realizing it must introduce policies and corporate strategies to meet Germany’s domestic situation. Third, it is possible to apply the Fast Follower strategy for developed countries in the manufacturing industry sector, for the purpose of activating future domestic servitization, and determining policy directions and future research planning, through the tracking of servitization research topics. With the ongoing tracking of future research topics, there exists a foundation to help Korea jump to First Mover status in the field of future servitization. The results of this study can contribute to an increase in interest about servitization in the academic community, and by extension, it is believed can also contribute to increasing industrial interest in, and the development of industries related to, servitization. In the future, if a high degree of convergence of services and products from the fusion technology infrastructure is accelerated, even amidst a slowdown in the growth of the domestic economy, a scaffolding can be provided that will help Korea lift itself up and leap ahead in manufacturing. Following the related example of developed countries, such as Germany, can help Korea maximize the global competitiveness of its manufacturing industry.",
		"KEYWORD": "PSS,빅데이터,서비타이제이션,온톨로지,텍스트마이닝,트렌드마이닝"
	},
	{
		"ID": 689,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "남서울대학교 복지경영대학원",
		"TITLE": "개인정보현황 인지효과 향상 시각화 연구 =The study on visualization about the enhanced privacy information status recognition effect ",
		"AUTHOR": "최순찬",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 690,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "규제에?대한?법경제학적?고찰 :보건의료정보?보호와?이용의?정책방향?모색 ",
		"AUTHOR": "정종구",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 691,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "병렬처리를 활용한 비모수적 회귀함수 추정 =Estimation of non-parametric regression function using parallel processing ",
		"AUTHOR": "조가영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 노호석 참고문헌: p. 34",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "빅데이터의 시대가 열림에 따라 빅데이터의 빠른 처리와 분석을 위한 다양한 연구가 활발히 진행되고 있다. 빅데이터는 기존의 데이터 베이스 관리도구의 한계를 넘어서는 대량의 정형 데이터 또는 데이터 베이스 형태가 아닌 비정형 데이터의 집합을 의미한다. 이런 경향과 연관하여 통계학에서는 대용량 자료의 처리와 통계분석을 위해 R 병렬처리(parallel computing)를 위한 패키지 계발이 활발하게 이루어지고 있다. 본 논문에서는 국소선형회귀(local linear regression)에 기반한 평균회귀함수(mean regression function)과 분위수 회귀함수(quantile regression function) 추정을 위한 평활량(bandwidth) 선택 문제에 멀티프로세서 환경의 병렬컴퓨팅을 적용함으로써 연산속도가 어떻게 빨라질 수 있는지 조사하였다.",
		"KEYWORD": null
	},
	{
		"ID": 692,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "강원대학교 대학원",
		"TITLE": "KVM 기반 가상화 클러스터 환경에서 IPoIB를 사용한 하둡 성능 분석 =Performance analysis of Hadoop using IPoIB over KVM based virtualized cluster ",
		"AUTHOR": "최성윤",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:최미정 참고문헌 : L.42-43",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "빅데이터, 머신 러닝 등의 중요성이 증가해지며 이를 위한 데이터 분석 기술이 발전하고 있다. 이러한 데이터 분석 기술들의 하나인 하둡은 저렴한 PC들을 클러스터로 구성하여 대용량의 데이터를 처리하는 데이터 처리 플랫폼이다. 하지만 기본 하드웨어의 사양이 높아지고 가상화 기술이 발전됨에 따라 클러스터 환경을 가상화하여 가용성을 높이고, 운영비용을 줄이는 것이 가능해졌다. 또한, 클라우드의 기술이 고도화됨에 따라 클라우드 환경에서 데이터 분석을 실행하는 것이 구축비용, 운영비용 등의 여러 측면에서 효율적이다. 하드웨어 리소스를 가상화하는 기술은 크게 호스트 OS형, 하이퍼바이저형, 컨테이너형으로 나뉜다. 호스트 OS형은 하드웨어에 OS를 설치하고 그 위에서 논리적 리소스를 할당받아 가상 머신을 운영한다. 하이퍼바이저형은 물리적 하드웨어에서 OS를 설치하지 않고 하이퍼바이저 소프트웨어가 물리적 하드웨어 위에서 가상 머신을 운영한다. 컨테이너형은 물리적 하드웨어에서 OS를 설치하고 가상 머신과 비슷한 개념인 컨테이너라는 독립적 커널 환경을 만들어주어 물리적 하드웨어 리소스를 논리적으로 나누어줄 수 있다. KVM은 호스트 OS형 기술의 하나로 리눅스 커널 기반으로 가상화 기술을 지원한다. 인피니밴드 네트워크는 고성능 네트워크 기술의 하나로 높은 대역폭, 낮은 지연시간, RDMA(Remote Direct Memory Access) 등의 특징을 가지고 있다. IPoIB(Internet Protocol over InfiniBand)는 이더넷 기반의 애플리케이션과 호환성을 맞추기 위하여 지원하는 기술로 인피니밴드 네트워크 위에서 이더넷 기반 애플리케이션을 소켓 기반으로 통신 가능하게 해준다. 가상머신에서 인피니밴드를 사용하기 위해서는 SR-IOV(Single Root I/O Virtualization) 기술이 필요하다. SR-IOV 기술은 I/O PCI Express 하드웨어 인터페이스를 다수의 가상머신이 공유하여 사용가능하게 해준다. 본 연구에서는 KVM 소프트웨어를 사용하여 다수의 가상머신을 구현하고 SR-IOV 기술을 사용하여 인피니밴드 네트워크 카드를 공유하여 가상화 클러스터 환경을 구축하였다. 대용량 분산 처리 플랫폼 하둡은 가상화 클러스터 환경에서 이더넷과 인피니밴드 네트워크를 변수로 비교하였고 인피니밴드 네트워크를 사용하였을때 비교적 높은 성능을 보여주었다. 또한, 높은 File I/O 성능을 보여주는 RamDisk를 사용하였을때 이더넷보다 인피니밴드에서 성능 향상이 높다는 것을 확인하였다.",
		"KEYWORD": "가상화,빅데이터,인피니밴드,클러스터,하둡"
	},
	{
		"ID": 693,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "변화동인 분석을 통한 코넥스(KONEX) 미래전망 =(The)future scenario of KONEX by driving force analysis ",
		"AUTHOR": "김현준",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 694,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "Sequential multiget: an improved multiget method leveraging sequential access to boost SSD performance =Sequential Mutiget: 순차적 접근을 이용하여 SSD 성능을 끌어 낸 향상된 Multiget ",
		"AUTHOR": "Kyung-TaeSong",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 695,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "Efficient estimation of influenza epidemics based on seasonal ARIMA models =계절형 ARIMA모형을 기반으로 한 효율적인 유행성 독감 추정 ",
		"AUTHOR": "정지훈",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "The issue of big data has received a lot of attention from researchers working in various fields as big data sets have been considered to have great potential in detecting or predicting future events such as epidemic outbreaks and changes in stock prices. Reflecting the current popularity of big data, a number of studies have been published to propose models that track influenza epidemics by using internet-based information. The most recent version of influenza tracking model was ARGO, which harnesses search queries from Google and reports from the Centers for Disease Control (CDC). Although the ARGO appears to predict the outbreaks of influenza accurately and outperform other existing methods such as Google Flu Trends (GFT), in this study, a classical seasonal autoregressive and integrated moving average (SARIMA) model is demonstrated to show that it outperforms the ARGO. Compared to the ARGO, the time series model incorporates more accurate seasonality of the past influenza activities, and takes less input variables into account since it utilizes only the reports provided by the CDC. The findings in this study show that the SARIMA model is a more efficient tool for estimating influenza epidemics.",
		"KEYWORD": "ARGO,Big data,Disease detection,Influenza epidemics,Influenza-like illnesses activity estimation,SARIMA model,Seasonal effect"
	},
	{
		"ID": 696,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "라이프로깅을?활용한 문화생활?큐레이션?서비스?디자인?연구 =(A)study on service design for cultural activity curation through life-logging with emphasis on app JOYLOG :JOYLOG 어플리케이션을 중심으로 ",
		"AUTHOR": "김신혜",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 697,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "연세대학교 공학대학원",
		"TITLE": "SNS을 활용한 실시간 이슈 전조 관리 방안 연구 ",
		"AUTHOR": "전창환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이원석",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "The former CEO of Google Inc, Eric Schmidt, once said that ‘every 2 days we create as much information as we did up to 2003.’ In this big-data era, countless numbers of researches are being done for innovative technology improvement through the data analysis. Lately, the data analysis by utilizing Social Network Service(SNS) stands out in the industry. If it is capable of analyzing or forecasting the trends through the messages on SNS which are projected users’ ideas or thoughts, this will provide beforehand counter-measure or marketing strategies. For this reason, our research for analyzing issues from Twitter messages among the typical domains. The research will be processed by three steps of compiling processes. First, Data Preconditioning. From the aggregate data, preconditioning process will filter scripts in Korean alphabet or Hangeul only. By generating formal dictionary rather than slang dictionary, the preconditioning process will be done. The formal dictionary is technically difficult or limitedly possible to extract neologism or proper nouns. In order to overcome these technical difficulties, we added the Wikipedia data and compile. Second, Extracting issue keywords on a real-time basis. After the preconditioning process, frequent occurred keywords get extracted as an ‘issue keyword’. Third, compiling the frequent occurred issue keyword from the extracted issue keywords and defines the ‘final issue keyword’ among the suddenly increased keywords. All of these steps explained above will be processed on a real-time basis. Throughout this analysis, we are able to figure out the trends of media or opinions on a real-time basis.",
		"KEYWORD": "big data,real time frequent occurrence pattern,real-time issue extraction,SNS analysis,SNS 분석,trends analysis,빅데이터,실시간 빈발 패턴,실시간 이슈 추출,트렌드 분석"
	},
	{
		"ID": 698,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "Nosql기반 보안로그 분석시스템 ",
		"AUTHOR": "김태흥",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이동훈 참고문헌: 장 43-47",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 APT와 같은 지능적 공격이 증가함에 따라 이에 대한 피해사례가 늘어나고 있다. 예로 보안시스템에 적발되지 않을 만큼 적은양의 데이터를 오랜 기간 동안 유출한 사건이나 내부 직원의 정보 유출 사건과 같은 사례는 단순히 정보유출로 끝나는 것이 아닌 기업의 이미지 하락, 고객 정보 유출로 인한 2차 피해 발생 등 기업에 있어서 부정적 영향을 미치는 중요한 사건으로 이러한 지능적 공격에 대한 대응의 필요성이 높아지고 있다. 본 논문에서는 기존 개별로 저장, 분석되는 보안로그 및 관련된 로그들을 Nosql 기반의 시스템을 통해 통합 저장하며 분석할 수 있는 정형화된 프레임워크의 제안을 통해 지능화되어가는 공격에 대응하고자 한다.",
		"KEYWORD": "Nosql,보안로그"
	},
	{
		"ID": 699,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "Take me to SSD: a hybrid block-selection method on HDFS based on storage type =저장장치 타입 정보를 활용한 HDFS내의 하이브리드 데이터블록 선택기법 ",
		"AUTHOR": "MinkyungKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 700,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "광운대학교 대학원",
		"TITLE": "RDB 환경에서 데이터 통합을 위한 MapReduce기반 클라우드 시스템 설계 =Cloud system design MapReduce-based for data integration in a relational database environment ",
		"AUTHOR": "허세준",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 최영근 참고문헌 수록",
		"STORE_LOCATION": "광운대학교 중앙도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 701,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "맵리듀스 기반 웨이블릿 히스토그램 생성 시스템의 설계 및 구현 =Design and implementation of the wavelet histogram construction system based on mapreduce ",
		"AUTHOR": "양세옥",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한기준",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "최근 스마트 폰, 웹/SNS의 발전으로 인하여 데이터 규모가 폭발적으로 증가하고 있으며, 이에 따라 빅 데이터의 중요성이 강조되고 있다. 빅 데이터는 방대한 양, 빠른 생성 속도, 그리고 다양한 속성을 가지고 있기 때문에 빅 데이터 자체보다 빅 데이터 요약 정보를 처리하는 것이 더 효율적이다. 데이터 요약 정보 생성 기법 중 하나인 웨이블릿은 멀티미디어 데이터에 대한 특징 추출 등에 적용하였다. 웨이블릿 히스토그램은 웨이블릿을 데이터베이스 시스템의 질의최적화와 개략 질의처리 등에도 사용되어 온 대표적인 정보 요약 기법인 히스토그램에 접목하여 생성한 요약 기법이다. 웨이블릿 히스토그램은 웨이블릿과 히스토그램의 장점을 합쳐 원본 데이터의 정보 손실이 크지 않은 최적의 데이터 요약 정보를 생성할 수 있다. 맵리듀스는 구글의 데이터 처리 플랫폼으로 사용되어 뛰어난 확장성 및 안정성으로 최근 다양한 분야에서 각광을 받고 있다. 따라서 맵리듀스 기반 빅 데이터 요약 정보를 생성하는 시스템에 대한 연구가 활발히 수행되고 있다. 기존 맵리듀스 기반 웨이블릿 히스토그램을 생성하는 연구에서는 한 번 이상의 맵리듀스 잡을 거쳐 각 노드에 저장된 부분 데이터에 대한 지역 웨이블릿 히스토그램을 생성한다. 그리고 각 지역 웨이블릿 히스토그램을 합병하여 전역 웨이블릿 히스토그램이 생성되기 때문에 생성 시간이 많이 필요하다. 또한, 웨이블릿 히스토그램으로부터 복원된 데이터에 대한 오차 경계를 고려하지 못하기 때문에 그 복원 데이터의 오차를 사전에 조절할 수 없다는 단점이 있다. 본 논문에서 개발한 웨이블릿 히스토그램 생성 시스템은 한 번의 맵리듀스 잡을 통해 빠른 시간 내에 웨이블릿 히스토그램을 생성할 수 있다. 또한 웨이블릿 히스토그램 생성 전에 사용자가 오차 경계를 미리 지정할 수 있으므로 웨이블릿 히스토그램으로 복원된 데이터에 대한 오차를 오차 허용 범위 안으로 조절할 수 있다. 마지막으로 다른 맵리듀스 기반 히스토그램 생성 시스템과의 성능 평가를 통해 본 논문에서 개발한 웨이블릿 히스토그램 생성 시스템의 효율성을 검증하였다.",
		"KEYWORD": "데이터 요약,맵리듀스,빅 데이터,웨이블릿 히스토그램"
	},
	{
		"ID": 702,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한국해양대학교 대학원",
		"TITLE": "조선소 의장품 조달관리를 위한 데이터마이닝 방법론에 관한 연구 =(A)study of data-mining methodology in offshore plant`s outfittings procurement management ",
		"AUTHOR": "함동균",
		"REGION": "부산",
		"PROFESSOR": "한국해양대학교 논문은 저작권에 의해 보호받습니다. 참고문헌 수록",
		"STORE_LOCATION": "한국해양대학교 도서관",
		"ABSTRACT": "선박 및 해양플랜트 건조에는 방대한 물량의 의장품이 사용되며 공급되는 경로 또한 공급망 프로세스와 협력업체에 따라 다양한 경로가 존재한다. 최근 해양플랜트 건조의 경우 다양한 의장품의 사양과 경로에 따른 조달지연이 충분히 고려되지 못하고 있어 조기에 공급되어 불필요한 적치가 증가하거나 공급이 지연되어 설치가 연기되는 등 손실이 발생하고 있다. 이를 해결하기 위해서는 우선적으로 의장품의 사양과 공급경로를 고려한 공급 리드타임에 대한 예측이 필요하다. 이러한 예측모델 구축을 위해 최근 이슈가 되고 있는 빅데이터 기술을 살펴보고 이를 조선해양 생산 분야에 적용하여 효용성을 살펴보고자 한다. 빅데이터의 기술은 데이터의 생성, 수집, 저장, 분석, 표현의 전 과정에 걸쳐 사용되며 이 중 분석, 표현의 기술은 여러 데이터마이닝 기법 및 시각화 기법을 사용하여 데이터를 통해 유의미한 정보를 찾아내는 것이다. 본 논문에서는 선박 및 해양플랜트의 배관재 공급망 데이터를 여러 데이터마이닝 기법을 사용하여 예측 모델을 개발하였다. 예측 모델은 다중선형, Ridge, PLS, Poisson, 의사결정나무, 인공신경망을 SPSS와 R 그리고 Microsoft Azure의 기계학습을 사용하여 구축하였고 각각의 예측 성능을 MAE(Mean Absolute Error)와 MAPE(Mean Absolute Percentage Error)를 통해 비교하였다. 또한 변수 민감도분석을 통해 예측모델에 대한 각각의 변수들의 영향력 분석하였고 현업의 공정개선 시 이를 참고할 수 있도록 하였다. 본 연구의 예측모델과 민감도분석 결과를 통해 기존 배관재 생산계획 단계에서 보다 합리적인 의사결정을 할 수 있을 것으로 예상한다.",
		"KEYWORD": "Big data 빅데이터,Machine learning 기계학습,Production planning 생산계획,Shipbuilding 선박건조"
	},
	{
		"ID": 703,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 언론대학원",
		"TITLE": "드라마 시청률과 소셜미디어 버즈량 간의 상관관계 연구 ",
		"AUTHOR": "황정연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김성태 부록: 1. 프로그램별 시청률 자료, 2. 프로그램별 소셜미디어 버즈 데이터, 3. 프로그램별 소셜미디어 분석대상 데이터 현황 외 참고문헌: 장 50-53",
		"STORE_LOCATION": "고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "시청률은 방송프로그램 성과측정의 주요기준이며, 최근 핵심콘텐츠(드라마, 예능 등)에 대한 시청률 예측이 더욱 중요해지고 있다. 최근 다양한 ‘스마트기기’의 등장으로 촉발된 ‘영상콘텐츠의 소비행태 다양화’와 ‘광고시장의 변화’는 전통적인 ‘텔레비전 수상기’에 기반 한 시청률조사의 한계를 여실히 보여주고 있으며, ‘스마트기기’ 등에 대한 시청률 조사의 필요성이 대두되고 있다. 이러한 상황에서 최근 시청률 측정에 대한 대안으로 제시되고 있는 것이 빅데이터(Big Data)를 활용한 시청률 분석이다. 시청률 분석에 빅테이터 분석을 사용하는 근거로 시청률과 소셜미디어(Social Media) 버즈(Buzz)량 간의 상관관계가 제시되고 있는데, 이에 대한 국내 드라마 사례를 대상으로 한 연구는 서로 상반되는 연구결과가 나오고 있다. 그러나 상관관계에 대한 충분한 검증이 이루어지지 않은 상황에서 소셜미디어를 이용한 다양한 시청률 측정 방안 등이 제시되고 있고 프로그램 제작과 마케팅 등에서의 이용이 증가하고 있는 만큼, 추가적인 연구를 통한 상관관계에 대한 검증이 조속히 이루어질 필요가 있다. 따라서 본 연구에서는 연구결과가 엇갈리고 있는 드라마 사례에 대한 시청률과 소셜미디어 버즈량 간의 상관관계를 검증해 보고자 지상파 3사의 미니시리즈 드라마 6편을 대상으로 2015.2.23부터 2015.3.15.까지 3주간의 트위터(twitter), 블로그(blog), 카페(cafe) 등 소셜미디어 버즈데이터를 취합하여 동기간 및 1주후 시청률과의 상관관계 분석을 실시하였다. 분석 결과, 트위터의 방송일 버즈량과 개인시청률 간에 상관관계가 유의미하다는 것을 확인할 수 있었고 시청률 예측 가능성 탐색을 위한 1주전 소셜미디어 버즈량과 시청률 간의 관계에서도 트위터의 방송일 버즈량이 개인시청률과 유의한 상관관계를 보였다. 이 같은 점은 개인 시청을 통한 시청자 반응이 트위터를 통해 어느 정도 반영되고 있다는 것을 보여준다고 볼 수 있어, 트위터 버즈량을 활용한 개인시청률 분석에 대한 가능성을 확인한 것에 그 의의를 두고자 한다.",
		"KEYWORD": "SNS,드라마,버즈,블로그,빅데이터,상관관계,소셜미디어,소셜분석,시청률,시청률 예측,카페,트위터"
	},
	{
		"ID": 704,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "한국인의 기업시민성 개념의 특징과 경제 교육적 함의 :토픽모델링을 활용한 언론매체 및 기업신년사 분석 ",
		"AUTHOR": "양선희",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "경제원론적 지식이 아닌 현실 경제를 교실수업과정에 어떻게 도입할 것인가의 문제는 경제교육학의 오래된 과제 중 하나이다. 그렇다고 시장에 나타나는 잡다하고 단기적인 경제 현상들을 모두 수업에 가져올 수는 없다. 여기에서 우리는 가르쳐야 할 가치가 있는 현실 경제 개념을 발견하고 내용을 선정할 필요가 생긴다. 본 연구에서는 교육할 가치가 있는 현실 경제를 ‘동시대적 경제의제’(contemporary economic agenda)로 명명하고, 이를 사회적·경제적 흐름에 부합하며 이론적·실천적으로 지속성과 확장성을 가진 경제 개념으로 정의하였다. 그리고 동시대적 경제의제로서 ‘기업시민성’(CC:Corporate Citizenship) 개념에 주목하고, 이를 경제교육 내용으로 구성하기 위해서 선행해야 하는 탐색연구로 진행하였다. 우선‘기업시민성’개념이 수업할 가치가 있는 ‘동시대적 경제의제’인지, 우리 사회와 기업들이 인식하고 있는‘기업시민성’개념의 특성은 무엇이며 이를 통해 우리는 어떤 경제 교육적 함의를 찾을 수 있는지가 주요 탐색과제였다. 먼저 본 연구에서는 이론적 탐색을 통해 기업시민성 개념을 경영 전략적 필요-사회 윤리적 정당성-창조적 자본주의 등 세 가지 관점에서 현재 사회적으로 진행되고 있는 논의를 정리하였다. 또한 연구문제에 대한 본격적 탐색을 위해 빅데이터 분석 방법을 활용하여 1990~2017년 상반기까지 언론과 기업인들의 신년사에 나타난 기업시민성 개념을 분석하였다. 언론은 사회적 담론 형성에 중요한 영향을 미친다는 점에서 기업시민성의 사회적 담론의 현주소를 파악하기 위한 텍스트로, 신년사는 기업인들의 기업시민성 인식을 분석하는 주요 텍스트로 판단했기 때문이다. 분석을 통해 우리는 다음과 같은 결과를 도출할 수 있었다. 첫째, 언론의 경우 보수적 성향의 매체는 ‘사회공헌’과 같은 경영 전략적 측면을, 진보적 성향의 매체는 기업의 사회 윤리적 정당성의 측면을 주목했다. 둘째, 언론과 기업인 모두 시간이 흐름에 따라 기업시민성 어젠더를 점점 더 큰 비중으로 다루고 있다는 점에서 개념의 지속성과 확장성이 있음을 확인할 수 있다. 셋째, 기업과 경제단체들은 시대에 따라 사회적·정치적으로 기업에 요구되는 어젠더를 중심으로 기업시민성 관련 개념을 구성하는 경향을 보인다. 이처럼 기업시민성은 실천적이고 논쟁적인 동시에 사회적 관심이 증가하는 어젠더라는 점이 분석에서 드러났다. 이 같은 역동적 개념은 현재의 경제수업처럼 단정적이며 고정된 교과서적 경제 개념을 교육하는 방식으로는 가르치기 힘들다. 즉 새로운 경제수업의 방식이 요구되는 것이다. 본 연구에서는 이를 위해 문제제기와 지식교육을 결합하는 새로운 형태의 수업 방안을 제안했다. 특히 경제교육방식으로 최근 제시된 ‘실천과 탐구의 인식공동체’로서의 교실, 그리고 학생들도 지식의 주체적 탐구자로 참여하는 지식의 공동구성수업 방식은 유용하게 활용될 수 있다. ‘기업시민성’이라는 한 개념을 중심으로 이와 관련한 다양한 문제들을 탐구하고, 개념 탐색과정에 경제뿐 아니라 일반사회, 역사, 법 등 다양한 분야의 지식을 동시에 학습하면서 한 개념을 둘러싼 학제적 수업과 함께 모든 개념들이 연결되어 있는 사회구조를 함께 학습하는 방법은 탈현대사회의 수업방식으로 고려해볼 과제이다. 주요어 : 기업시민성, 기업의 사회적 책임, 동시대적 경제의제, 실천과 탐구의 인식공동체, 빅데이터 학 번 : 2004-30492",
		"KEYWORD": "기업시민성,기업의 사회적 책임,동시대적 경제의제,빅데이터,실천과 탐구의 인식공동체"
	},
	{
		"ID": 705,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "순천향대학교 대학원",
		"TITLE": "개인정보 비식별화 제도의 쟁점 및 개선방안에 관한 연구 =A study on improvements for the data de-identification techniques ",
		"AUTHOR": "이루리",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 염흥열 참고문헌: p. 40-42",
		"STORE_LOCATION": "순천향대학교 도서관",
		"ABSTRACT": "빅데이터는 수많은 정보들을 수집·저장·분석·처리하여 서비스를 제공하는 그 특징 상 불가피하게 개인에 관한 정보들이 수집될 수밖에 없으며, 이러한 개인정보 수집으로부터 정보주체의 프라이버시를 보호하기 위하여 우리나라는 개인정보 비식별화에 대한 기술과 제도 마련에 힘써왔고 기존의 비식별화 관련 제도들을 통합·개정한 『개인정보 비식별 조치 가이드라인』을 발간하였다. 그러나 현행 비식별화 제도는 정보주체의 개인정보 보호와 빅데이터 활성화의 두 가지 목적을 달성하기엔 여러 한계점 및 문제점을 갖고 있다. 이에 본 논문에서는 국내·외 비식별화 관련 법제도의 비교·분석과 국내 비식별화 제도의 쟁점 분석을 통하여 현행 비식별화 제도의 개선방안에 대해 연구해보았다. 이를 통해 정보주체의 프라이버시를 실질적으로 보호하는데 일조할 수 있을 것으로 판단되며 더 나아가 개인정보의 보호와 빅데이터 산업 발전에 이바지 할 수 있을 것으로 사료된다.",
		"KEYWORD": "개인정보,개인정보 보호법,개인정보 비식별 조치 가이드라인,비식별,빅데이터,재식별,프라이버시"
	},
	{
		"ID": 706,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "한국외국어대학교 대학원",
		"TITLE": "중국 문학지도콘텐츠 개발 연구 =(A)study on developing contents for Chinese literary map ",
		"AUTHOR": "김금미",
		"REGION": "서울",
		"PROFESSOR": "한국외대 논문은 저작권에 의해 보호받습니다. 지도교수: 이영구 참고문헌 : p. 142-159",
		"STORE_LOCATION": "한국외국어대학교 글로벌캠퍼스 도서관,한국외국어대학교 서울캠퍼스 도서관,한국학중앙연구원 도서관",
		"ABSTRACT": "중국 문학지도콘텐츠 개발 연구 본고는 중국(계) 노벨문학상 수상자인 모옌과 가오싱젠의 창작생애와 작품을 둘러싼 시공간을 통해 어떻게 새로운 형태의 문학지도를 구현해낼 것인지를 고찰한 연구이다. 필자의 관찰에 따르면, 한중 양국에서 기존에 구축한 문학관 내지 문학지도는 관련 정보의 데이터베이스화를 통한 교육과 연구라는 공공성에 의존할 뿐, 문화산업적 측면을 크게 고려하지 않은 것이었다. 그러나 모옌과 가오싱젠으로 대표되는 중국계 작가들은 전세계 여행객들의 지오투어리즘을 가능케 해줄 만큼 중국 현대사와 민간문화에 대한 풍부한 산업적 콘텐츠를 지니고 있다. 이 점은 중국 정부가 앞으로 문학지도를 구축함에 있어 반드시 주목해야 할 부분으로 보인다. 새로운 문학지도의 구축에 있어 본고는 크게 두 가지 측면을 고려하였다. 첫째, 새로운 문학지도는 글로벌 네트워크 시대, 스마트폰을 통한 실시간 커뮤니케이션 시대에 발맞추어 ‘집단지성’이라 불리는 수용자들이 콘텐츠 생산과 지도 구축에 적극적으로 참여할 수 있는 방식으로 고안되어야 한다. 이러한 방식은 기존에 생산자와 수용자가 명확하게 분리되어 있는 것과는 완전히 다른 쌍방향적 성격을 지닌다. 수용자들은 사이버 문학지도를 통해 자신들이 얻고자 하는 정보를 얻는 동시에, 자신들의 체험과 지식을 플랫폼 상에 남김으로써 부지불식간에 정보 생산자 역할을 담당하는 것이다. 둘째, 새로운 문학지도는 전국적으로 흩어져 있는 다양한 플랫폼과 관련 정보들을 통합하고, 인간의 ‘삶’과 지역의 문화자원을 연결시켜 그물망과 같은 형태를 취해야 한다. 또한 기존 문학지도가 인물중심으로 구축되었던 것과 달리 테마 위주로 구축될 필요도 있다. 이러한 문학지도는 기존에 문학관이나 문학지도가 지니고 있던 교육적 기능 뿐만 아니라 일종의 ‘스토리뱅크’로서 지역 문화콘텐츠를 쌍방향적으로 개발, 관리, 공유, 생산하는 새로운 기능을 보유하게 된다. 이러한 기능을 통해 새로운 문학지도는 창조적인 콘텐츠를 획득할 수 있고, 도시재생의 기능과 지역경제 발전의 부수적인 목적도 달성할 수 있을 것이다.",
		"KEYWORD": "가오싱젠,모옌,모옌옛집농촌전통문화관광체험구역,문학지도,빅데이터,중국 노벨문학상,중국 문학여행,지오투어리즘"
	},
	{
		"ID": 707,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "Convolutional Neural Network를 활용한 딥 러닝 기반 농작물 피해 탐지 연구 =Crop damage detection with deep learning based convolutional neural network ",
		"AUTHOR": "하진관",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 문현준",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "최근 4차 산업혁명시대에는 융합연구의 중요성이 더욱 커지고 있으며, 특히 농림ㆍ수산 등 전통산업의 부활을 위해 Information & Communication Technology (ICT) 기반 융합연구의 필요성이 대두되고 있다. 더불어, 인공지능 기술의 발전과 함께 다양한 딥 러닝 알고리즘이 컴퓨터비전 분야에 적용되면서 인식률 향상에 큰 기여를 하고 있다. 본 논문에서는 이러한 사회적 수요에 대응하기 위하여 무인기로 촬영한 무 재배지역 영상을 토대로 재배지역의 영역(무, 땅, 포장)에 따른 영역화 방법 및 시들음 무 검출 방법을 제안한다. 또한 Convolutional Neural Network (CNN), AutoEndoder, softmax 분류기 등 인공신경망 기반의 딥 러닝 알고리즘을 적용하여 인식률 향상에 기여하였다. 본 연구에서 구현된 재배지역의 영역화 및 무 시들음 병 검출과정은 다음과 같다. 첫 번째로, Local Binary Pattern (LBP)과 AutoEncoder를 통해 재배지 영역의 질감 및 히스토그램 특징을 추출한다. 다음, 추출된 특징을 기반으로 Wilcoxon rank-sum Test 및 Out-of-Bag Estimation (OOB 추정)을 통해 주요한 재배지 영역의 특징을 선택한다. 최종적으로 선택된 유효한 특징을 입력으로 하는 인공신경망 기반의 softmax 분류기를 학습하여 재배지 영역을 분류하고 k-means 알고리즘을 통해 재배지역을 영역화 하였다. 영역화 결과, 3-fold cross validation 방법을 통해 정확도를 검증한 결과, 93%의 정확성을 보이는 것으로 확인 되었다. 두 번째로, 재배지역에서 발생한 무 시들음 병을 검출하기 위해서 Convolutional Neural Network(CNN) 기반의 분류 모델을 학습하여 정상영역과 무 시들음 병을 분류하였으며 학습결과, 98.4%의 정확도를 가지는 것으로 나타났다. 이후, 재배지역 영역화 결과 중 무 영역 이미지를 대상으로 Sliding-Window를 적용하였다. 최종적으로, Sliding-Window를 통해 선택된 무 영역을 CNN으로 학습된 분류 모델을 통해 정상 무 또는 시들음 무 여부를 판별하였다. 본 논문은 농업과 IT 분야 간의 기초 ICT 기반 융합연구로써, 자동화된 재배지역 관리 및 병충해 예찰 시스템 구축에 관한 연구에 기여 할 수 있을 것으로 기대된다.",
		"KEYWORD": "기계학습,딥 러닝,빅 데이터,시들음 병 검출,인공지능,재배지역 영역화,컨볼루션 신경망"
	},
	{
		"ID": 708,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "동 단위의 아파트가격지수 추정 연구 :강남구를 대상으로 ",
		"AUTHOR": "강한울",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "우리나라 주거 부동산 시장에서 아파트는 가장 중요한 유형이다. 사람들에게 아파트는 거주하는 공간일 뿐만 아니라 핵심 자산으로서 가격 변화에 대한 관심이 매우 높은 대상이다. 이러한 아파트 시장의 가격 변화는 지수를 사용하여 관측한다. 선행연구에서는 기존 시/군/구 단위의 아파트 시장이 하나의 단위로서 작동한다는 것을 전제로, 다양한 방법론을 이용하여 지수를 작성하고 이를 분석했다. 하지만 오늘날 강남을 포함한 서울 곳곳에서 주거 지역의 상업화가 이루어지고 있으며, 구 내부에서도 지역에 따라 다양한 모습이 나타나고 있다. 아파트 시장의 움직임을 읽어내려면 지역의 국지적인 특성 차이를 파악하고, 이를 반영해야 한다. 본 연구에서는 구 단위로 분석해온 아파트 시장을 세분화하여, 동 단위에서 발생하는 국지적인 시장 움직임을 연구했다. 특히, 강남구를 대상으로 10년간의 실거래기록 빅데이터를 전수조사하고, 이를 기반으로 지수를 작성하였다. 주요한 결과는 다음과 같다. 첫째, 실거래가를 사용한 가격지수에서 기존 시세기반의 지수와 다른 변동성이 관측되었다. 실거래가를 기반으로 한 국토교통부 지수와 연구의 강남구 지수는 KB국민은행과 한국감정원의 시세기반 지수와 비교할 때 가격변동 시점에서 변동폭이 축소되는 모습을 나타냈다. 이는 선행연구에서 지적한 평활화의 영향으로 추정된다. 둘째, 강남구 내부에서 다양한 아파트시장이 관측된다. 2008년 3분기, 미국 발 금융위기로 인한 아파트 시장 침체는 강남구 전역에서 공통적으로 확인된다. 하지만 그 외 시점에서 동 마다 다른 움직임이 나타난다. 특히, 서로 인접한 지역이라 할 지라도 높은 상관관계를 보이지 않으며, 동의 인접성과 가격움직임의 유사성은 크게 관련이 없어 보인다. 연구에서 작성한 동 단위의 지수는 기존 지수에서 반영되지 않는 하부단위의 주택 특성과 시장 상황이 반영되었다. 특히, 시장상황에 영향을 주는 정책이 구 단위로 적용된다 할지라도, 지역에 따라 영향은 다를 수 있다. 본 연구에서 정책의 영향력을 변수로 직접 설정하지는 못했지만, 시간 더미에서 그 영향이 드러날 것으로 기대된다. 따라서 동 단위의 강남구 지수는, 동 마다 서로 다르게 나타나는 정책의 영향력이 반영된 지수라는 점에서 의의가 있다.",
		"KEYWORD": "빅데이터,아파트,지수,헤도닉모형"
	},
	{
		"ID": 709,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "딥 러닝 기반 토픽 모델링을 이용한 스케일러블 다중 문서 요약 ",
		"AUTHOR": "김원철",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 송민",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "빅데이터 시대가 도래함에 따라 온라인에서 엄청난 수의 문서가 교류되고 접근 가능해졌다. 이러한 정보의 홍수 속에서 신속한 의사결정을 하기 위해 정보를 효율적으로 관리하고 검색하는 문제가 중시되었으며, 핵심적인 내용만을 자동적으로 파악하고 중복된 정보는 제거하는 도구의 필요성이 대두되었다. 이에 따라 1950년대에 들어서며 등장했던 다중 문서 요약 기법에 대한 연구는 최근까지도 활발하게 진행되었다. 다중 문서 요약 기법에 대한 기존의 연구에서는 다양한 방법을 통하여 문서를 요약하고자 하였다. 그러나 기존 연구는 주로 소량의 데이터에 대해서만 실험을 진행하였으며, 대량의 데이터를 대상으로 같은 기법을 적용하였을 때의 성능 차이를 살펴보는 연구는 잘 이루어지지 않았다. 또한, 최근 텍스트 마이닝 연구에서는 대량의 데이터 처리 시 뛰어난 성능이 입증된 딥 러닝 알고리즘이 활발히 사용되었으나 다중 문서 요약 분야에서는 이러한 연구가 미흡한 수준이다. 따라서 소량의 데이터뿐만 아니라 빅데이터 차원에서 딥 러닝 기반 다중 문서 요약 기법이 어떠한 성능을 보이는지 살펴보는 것이 필요하다. 본 연구에서는 딥 러닝 기반 토픽 모델링을 이용한 스케일러블 다중 문서 요약 시스템을 개발하고자 하였다. 이때 딥 러닝 기반 토픽 모델링 기법으로써 Gan 등(2015)에 의해 제안된 심층 포아송 요인 분석을 사용하였다. 심층 포아송 요인 분석이란 딥 러닝으로 생성된 토픽 구조에 베이지안 포아송 요인분석을 적용하여 문서에 잠재된 토픽을 추출하는 기법이다. Gan 등(2015)의 연구에 따르면 해당 기법은 대량의 데이터를 대상으로 토픽 모델 생성 시 높은 안정성과 속도를 보여주었다. 더불어 LDA(latent Dirichlet allocation)와 같은 기존 토픽 모델링 기법과는 다른 구조로 토픽을 추론함으로써 더 정확한 토픽 모델을 생성한다는 점에서 토픽 모델링을 통한 스케일러블 다중 문서 요약 기법에 적합하다고 판단된다. 본 연구가 제안하는 시스템의 다중 문서 요약 과정은 다음과 같다. 복수 개의 문서를 대상으로 문장 분할, 어간 추출 등의 전처리를 수행하고 딥 러닝 기반 토픽 모델링, 즉 심층 포아송 요인 분석을 적용한다. 그 결과 문장의 토픽 분포가 산출되고, 이를 바탕으로 문장 간 토픽 유사도를 계산한다. 문장 간 토픽 유사도 행렬에 순위화 알고리즘을 적용하고 문장별 중요도가 측정되면, 중요도가 높은 순으로 문장을 나열하여 요약문을 작성한다. 성능 평가 기준으로는 ROUGE(recall-oriented understudy for gisting evaluation) 값을 사용하였으며 기존의 연구에서 일반적으로 사용되는 DUC(document understanding conference) 문서 집단을 사용하여 타 문서 요약 시스템과 비교하였고, 최신 문서 요약 데이터인 CL-SciSumm(computational linguistics scientific document summarization)을 이용해 작은 양의 데이터에서의 성능을 측정하였다. 그리고 빅데이터 차원에서의 성능을 알아보기 위하여 무작위로 다운로드한 Wikipedia 문서 1,000만 건을 사용하여 요약 시스템의 성능을 비교하였다. 또한, 실제 문서 요약 시스템을 웹으로 접근하여 실행해 볼 수 있도록 웹 시스템을 구현했다. 본 연구에서 진행한 실험의 결과는 다음과 같다. 첫째, 예비 실험 결과 SBN과 Gibbs 알고리즘의 조합이 64개의 토픽 개수에서 가장 좋은 성능을 보였다. LDA의 실험 결과는 가장 낮은 수치를 기록하였고 토픽 개수에 따라 그 성능 차이가 심하게 나타나는 것으로 나타났다. 반대로 심층 포아송 요인 분석을 사용한 결과들은 토픽 개수에 영향을 크게 받지 않고 안정적인 성능을 보여주어 실험 데이터 안에 존재하는 토픽의 개수에 크게 영향을 받지 않는 점을 알 수 있었다. 이러한 점을 통해 심층 포아송 요인 분석이 많은 토픽을 가지고 있는 데이터인 빅데이터를 대상으로 더 유용하다는 점을 알 수 있었다. 둘째, 소규모 데이터에 대한 문서 요약 실험에서는 첫 번째 실험과 동일하게 평균적으로 SBN과 Gibbs 알고리즘의 조합이 가장 우수한 것으로 나타났지만 조합들 간의 성능 차이는 아주 미세하였다. LDA를 사용한 시스템은 이번에도 모든 결과들 중 가장 낮은 성능을 기록하였다. 앞선 실험 결과와 함께 분석을 해보면 토픽 개수가 적고 소규모의 데이터인 경우에는 SBN과 Gibbs 조합이 가장 적합하다고 보여진다. 셋째, 빅데이터 대상 성능 실험은 문서 개수를 기준으로 만개, 10만개, 100만개, 1000만개로 나누어 수행한 결과 만개와 10만개에서는 SBN, Gibbs 조합, 100만개에서는 RBM, SGNHT 조합, 가장 큰 1000만개에서는 SBN, SGNHT 조합이 최고의 성능을 보여주었다. 그 결과, 데이터의 크기가 비교적 작을 경우에는 Gibbs 샘플링을 사용면 적합하고 대량의 데이터를 대상으로 문서 요약을 수행할 때에는 SGNHT 알고리즘이 알맞은 것을 확인하였다. 넷째, 타 문서 요약 시스템과의 성능 비교 실험 결과 DUC 2002, 2004 데이터 집합에서 SBN, Gibbs 조합이 DUC 참가 시스템 중 최고 성능의 시스템과 비슷한 결과를 기록했다. 또한 기존의 토픽 모델링 방법인 LDA를 사용한 시스템과의 확연한 성능 차이를 보였다. 실험 결과 다른 문서 요약 시스템과 비교해서도 우수한 성능을 나타낸다는 것을 알 수 있었다. 본 연구는 토픽 모델링을 이용한 다중 문서 요약 연구에서 이제까지 시도되지 않았던 딥 러닝 알고리즘을 적용했다는 의의가 있다. 그리고 대용량 문서 요약 시에도 안정적인 성능을 보이는지에 대해 다루지 못한 기존 연구의 한계점을 극복하여, 정확하고 빠른 대용량 문서 요약 연구의 발전 방향을 제시하였다. 이로써 점점 더 급증하고 있는 온라인상의 정보를 빠르게 요약하고 효율적인 의사결정을 하는 데 해당 연구가 기여할 수 있을 것으로 기대된다.",
		"KEYWORD": "big data,deep learning,deep neural network,multi-document summarization,text mining,topic modeling,다중 문서 요약,딥 러닝,빅데이터,심층 신경망,텍스트 마이닝,토픽 모델링"
	},
	{
		"ID": 710,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "대선 후보자에 대한 유권자들의 온라인 화제성 지표 활용 가능성에 대한 연구 :A study on the possibility of utilizing the indicator of the voter`s on-line responses to presidential candidates : comparative analysis with election polls ",
		"AUTHOR": "이슬비",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박천일 참고문헌: p. 110-115",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "급변하는 흐름 속에서 유권자들의 민심을 파악하는 방식이 여론조사 단일 방식에서 나아가 유권자들의 온라인에서의 화제성 지표를 활용한 변화가 필요하다는 것이 본 연구의 출발점이다. 본 연구는 지난해 실시된 대한민국 19대 대선 기간 중 조사된 여론조사와 온라인 화제성 지표를 분석대상으로 선정하였다. 후보자는 문재인, 안철수, 홍준표, 심상정, 유승민 후보자를 대상으로 선정하였다. 본 연구는 19대 대선 기간 중 2월 1일부터 5월 7일 사이에 중앙선거관리위원회 홈페이지에 등록된 141개 여론조사와 굿데이터코퍼레이션의 온라인 화제성 지표를 연구에 활용하였다. 각 변인 간의 관계를 고려하여 연구문제 1과 연구문제 2는 피어슨 상관관계 분석을 실시하였고, 연구문제3과 연구문제 4는 다변량 분산분석을 통해 검증하였다. 연구결과 여론조사와 온라인 화제성의 상관관계 분석의 경우 통계적으로 유의미한 상관관계가 나타났고, 여론조사와 온라인 화제성 각 채널 간의 상관관계도 유의미한 상관관계가 나타났다. 또한 다변량 분산분석 결과 모든 변인에서 유의미한 차이가 발생했고, 집단 간 사후 검증을 통해 집단 별 평균 비교가 가능했다. 본 연구는 상관관계 정도에 따라 온라인 화제성 지표를 토대로 여론조사를 예측할 수 있음을 검증하였다. 이를 통해 대선 후보자의 온라인 화제성 지표가 여론조사를 보완할 수 있는 지표로서 기능할 수 있는 가능성을 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 711,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "연세대학교 경제대학원",
		"TITLE": "스마트사회에서 정보통신(ICT) 융합기술 및 서비스 활용의 사회경제적 의의와 활성화 유인을 위한 연구 ",
		"AUTHOR": "허유민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현중",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "스마트기기의 확산에 의해 지능화, 자동화의 스마트사회가 도래했다. 스마트사회에서는 과거의 수직적 사회구조가 소셜 네트워크 서비스(SNS)의 확산으로 소통과 참여 그리고 정보공유가 가능해지면서 개방화, 수평화 구조로 변하고 구성원들의 삶의 행태가 변화 하고 있다. 스마트사회는 정보통신 융합기술과 서비스가 발전 및 확산되어 새로운 가치의 창출이 가능한 시대이다. 또한 개개인과 사회 전 구성원의 만족감을 높여 국민의 행복을 증진시키고 사회 전반의 삶의 질을 향상하면서 지속적인 경제성장의 선순환을 견인 할 수 있다. 이러한 정보통신 융합기술과 서비스는 스마트사회에서 경제성장의 핵심이고 원동력이다. 기술의 발달도 중요하지만, 기술과 서비스가 활용되어 수요창출로 연결되는 것이 중요하다. 그러나 현재 우리나라의 제도적, 사회문화적 한계는 성장의 장애 요소가 되고 있다. 정보통신 기술융합의 기반으로 양극화를 해소하고 개인의 삶의 질을 향상시켜야 장기적인 경제성장이 가능하다. 그러기 위해서는 근본적인 문제를 해결해야 한다. 기업과 개인의 자발적인 정보의 공유, 그리고 협업을 통한 상생과 지속적인 성장의 선순환을 위한 환경이 제공되어야 한다. 제도의 개선과 기업과 국민의 인식 전환을 위한 유인책을 제공하는 정부의 노력이 필요하다. 이 연구에서는 정보통신 융합기술과 서비스의 활성화가 우리경제에 미치는 파급효과와 중요성을 설명하고, 지속적인 성장을 견인하는 융합기술과 서비스의 활성화를 저해하는 한계점을 분석한다. 그리고 해외사례를 통해 한계점을 극복하기위한 개선점 및 시사점을 설명한다.",
		"KEYWORD": "대-중소기업 상생,빅데이터,사회서비스,사회적 자본,소셜 네트워크 서비스,스마트 사회,장기적 경제 성장,정보 공유,정보통신 융합기술 및 서비스,제도적 한계,클라우드"
	},
	{
		"ID": 712,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "동국대학교 대학원",
		"TITLE": "형사사법정보시스템에 관한 연구 =(The)study on Korea information system of criminal justice services ",
		"AUTHOR": "조정우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이명복",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "At the end of the 20th century, IT technology and storage media developed very rapidly. In information society having highly advanced information technology as its infrastructure, it is actively done to collect, produce, process, and transmit information. Through that, our society is being transformed dramatically and unimaginably when compared to the past. On the other hand, the massiveness of information, monopolization of information, imbalance in the distribution of information, human rights violation attributed to the improper distribution of information, or inappropriate legal protection of information has put individuals as the objects of information into new types of risks such as fundamental rights violation and the government’s monopoly of power. In this information society, either the government or private enterprises can obtain any kinds of records about individuals extensively. On account of that, private information may turn into a database and become stored even if each individual does not want it. In the criminal procedure, too, we are using the world’s highest level of IT infrastructure and have standardized and digitalized tasks related with criminal justice. Also, to reduce the waste of time and resources by sharing information of criminal justice and provide people-oriented e-criminal justice services, a brand new type of electronic system, ‘KICS (Korea Information System of Criminal Justice Services)’, has been introduced. It is expected that this will bring tremendous changes in the investigative or court system by realizing an electronic court system or such. The digitalization of criminal justice, however, can control or restrict each individual’s decision-making process in surveillance society like a ‘big brother’. It is because it is possible that all the private information about those concerned in the case or information about the case collected in carrying out the criminal procedure can become digitalized and stored by the investigative agency for its investigative procedure, and the information collected can be used by the government as a means of surveillance on its people. Among the kinds of private information, the information collected in KICS include private information not trivial but sensitive enough to cause critical damages on individuals; therefore, “the integration and utility of information about criminal justice can be critical violation on human rights regarding private information corresponding to cumulative penalties and also violate individuals’ right to make their own decisions based on their private information.”The investigative agency currently operating KICS can collect and process the information, which implies it restricts individuals’ right to make their own decisions based on their private information, one of the basic articles protected by the act of personality rights. In fact, private information about those concerned in the case and information collected through investigation are being used importantly to prevent crimes and facilitate investigation; however, it is needed to examine the criteria of storing and discarding information by KICS more thoroughly according to the principle of proportion. Therefore, this study is going to examine legal, procedural, and technical problems regarding the criteria of storing and discarding information and find out ways to solve the problem of setting the term of storage uniformly and suggest a valid ground about the reasonable term of storage and information utility so as to secure purposefulness and efficiency in operating KICS. The ultimate goal of KICS is to digitalize all the criminal cases and carry out the criminal justice procedure without paper. But the current KICS adopts digitalization only for electronic summary proceedings, so digitalizing the criminal justice procedure which KICS genuinely pursues has not been realized yet. In other words, as the current KICS is being operated only for the investigative agency to store information systematically, the role it is playing is quite different from that originally intended when it was introduced, which is to digitalize the criminal law procedure. Accordingly, this study will discuss pending issues to be settled regarding the storage and utility of private information among the potential problems that may take place while operating KICS in order to help realize digitalizing the criminal justice procedure which KICS pursues even faster.",
		"KEYWORD": "KICS,형사사법정보시스템"
	},
	{
		"ID": 713,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서강대학교 경영전문대학원",
		"TITLE": "Forecasting market trends of technologies using Bigdata :an application of percentage analysis, decision tree analysis, data visualization analysis to forecasting ",
		"AUTHOR": "Cho,YongHwack",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 714,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "매체의 기술적 속성과 주체구성에 관한 연구 :트위터(Twitter)에 드러난 기록체계와 주체화 양상을 중심으로 ",
		"AUTHOR": "박민정",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 오성균",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "This study investigates how the technical attributes of media construct subjects. To begin with, it points out unique communication situations occur when interaction structures are subordinated to the technical attributions inherent in media. The premise for the argument is the existing media democracy discourse on media environment in reality and the impact of the new media referred to as Social Network Services (SNS). The user interface of new media has always been noticed as cultural space, as a place creating politically relevant discourses as well as revolutionary space in which infinite digital networks combined with users’ multiple communication abilities through ‘technical imagination’ can subvert the landscape of the reality. Among many other services, ‘twitter’ has been noted as the public sphere where media democracy is to be achieved and as the site for hegemonic struggles. In discourses on so-called SNS, internet users are repeatedly represented as citizen subject in alternative/counter public sphere and SNS are defined as user-centric media as opposed to mainstream press. Particularly, twitter users had been regarded as the most political subject since the results of a few local by-elections had coincided with the flow of support/participation rate presented in twitter. However, as the results of several important elections that followed were in discord, now SNS are confronted by the serious question, “Can they change the world?” This study aims to overcome the viewpoint which defines SNS as the public sphere containing democratic possibility and as the medium tool purposefully available. The study tries to apprehend them as controlling measures or the tools for revolution, along with present media environment. Accordingly, this study employs Kittler’s notion of media a priori that argues humans are no longer subjects producing meanings. In this present paper, twitter is defined as a network of technology and institution that reveals the structural conditions of power and thinking in the society, therefore shows symptoms of ‘discourse networks’. By analyzing twitter’s technical attributes which determine the communication structure, the paper shows how the virtual communities in particular forms within twitter and context of subjectivity operated by writing process in SNS space are identified. The paper continues to analyze how the information capitalism had its beginning on the base of overly interpellated media culture after progress of internet technology. Consequently, it is induced that the process of subjectification within twitter promotes dominant cultural phenomena out of twitter. However, it should be pointed out that new media require ongoing examination and that products of technology have the possibility to subvert the transcendental ground of technology and strategies operated by technology. The purpose of present paper is to dialectically recognize and reconstruct pessimistic reality and revolutionary possibility of SNS, simultaneously identify both possibility and limitation of media’s subjectification process, and ultimately investigate whether new media’s technological attributes and users’ technological imagination can be employed as the tool of resistance. In this regard, along with cases where twitter is actively used as means for struggle, media experiment within twitter demonstrate that technical conditions of new media contain both possibility and limitation, therefore claims that a clear recognition of reality is needed for the enhancement of media application.",
		"KEYWORD": null
	},
	{
		"ID": 715,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "Building a civic hacking model in the era of big data ",
		"AUTHOR": "JaegyuKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 716,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "서울대학교 환경대학원",
		"TITLE": "GPS 차량 통행 자료를 이용한 미관측 도로구간의 AADT 추정 ",
		"AUTHOR": "정인택",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "최근 IT기술의 발전으로 인하여 루프검지기, 영상검지기 등과 같이 고정된 조사지점에서 교통정보를 수집하는 기존의 단순관측 및 고정센서 조사 수집체계에서 스마트폰, 내비게이션 등과 같이 도로상에서 개인 또는 개별 차량의 GPS 이동궤적을 수집할 수 있는 이동센서 조사 수집체계로 변화하고 있다. 이로 인해 가용할 수 있는 데이터의 양과 질, 그리고 시·공간적 범위가 전국으로 확대되면서 그야말로 대용량 자료의 시대로 진입하게 되었다. 차량용 내비게이션은 운행 중인 거의 모든 차량에 설치되어 있는 필수장비로서 현재 내비게이션 데이터를 수집 및 저장하기 위한 기술적인 안정성도 충분히 확보되어 있는 상태이다. 또한 정부 3.0의 10대 추진과제 중 하나인 빅데이터의 활용이라는 측면에서 차량용 내비게이션에서 수집되고 있는 GPS 차량 통행 자료에 대한 적극적인 활용이 필요한 시점이다. 위의 자료가 도로구간별로 통행하는 전체 차량의 표본인 점을 고려해 볼 때, 미관측 도로구간의 연평균 일교통량(Annual average daily traffic, 이하 AADT) 추정과 관련된 연구의 입력 자료로서 활용이 가능할 것으로 판단되었다. 이와 관련된 선행연구들을 고찰해 본 결과, 기존 AADT 추정모형의 입력 자료들은 과거 데이터 수집 및 저장 기술의 한계로 인하여 특정 지역 또는 구간에서의 교통량 자료와 거시적 단위의 사회·경제적 지표(인구수, 자동차 등록대수, 근로자수 등)에 의존해왔으며, 일부 미시적 단위의 자료로는 GIS에서 일반적으로 제공하고 있는 링크정보(차로수, 연장, 제한속도 등)와 실제 관측 값이 아닌 TransCAD 등과 같은 교통수요모형에 의해서 산출된 추정 값들(통행배정량, 최단경로거리 등)만이 제한적으로 활용되고 있었다. 이러한 입력 자료의 환경이다 보니 기존 모형들은 특정 통계모형의 파라미터에 의존하는 모수 모형만을 적용할 수밖에 없는 실정이었다. 또한 향후 시스템의 내부모듈로서 모형을 탑재할 경우, 기존 모형들은 입력 자료의 구축문제, 파라미터의 최적화 문제 등과 같은 모형의 구조적인 문제도 발생하게 된다. 따라서 본 연구에서는 미관측 도로구간의 AADT 추정에 대한 불확실성을 극복하기 위하여 대용량 GPS 차량 통행 자료 기반의 비모수 모형을 적용한 AADT 추정모형, 즉 KL모형을 개발하였다. KL모형은 비모수 모형인 개의 최근린 이웃(-nearest neighbors)기법과 모수 모형인 국부 가중선형회귀(Locally weighted linear regression)모형이 결합된 추정모형으로 추정모형 식의 형태와 적용 가중치의 종류에 따라 총 6가지 형태의 모형으로 개발하였다. 개발모형의 입력 자료는 기존 모형들과는 달리 본 연구의 GPS 차량 통행 자료를 이용하여 개별 도로구간 단위로 집계한 연평균 일프로브통행량(Annual average daily probe)을 예측변수로 적용하고, 3가지의 KNN 추출방법(연결성지수, 최단경로거리 유클리디안거리)에 따라 추출한 값을 개발모형의 가중치로 적용하였다. 여기서, AADT 추정에 대한 불확실성 극복 방안은 하나의 전역적인 추정모형 또는 특정 통계모형에서 산출되는 가중치 값으로 개별 미관측 도로구간의 AADT를 추정하는 것이 아니라, 비모수 모형인 KNN 기법을 이용하여 해당 도로구간별로 공간적인 패턴을 탐색하고 이에 따라 최종의사결정 군집을 구축하여 AADT를 추정하는 국부적인 추정모형의 형태로 개발함으로서 이러한 불확실성을 감소시켰다. 또한 향후 본 개발모형은 시스템 탑재가 목표이므로 모형의 일반화, 입·출력 자료구조 변경의 용이성, 파라미터의 자동정산, 연산 수행속도 등을 고려하여 개발하였다. 본 연구에서 개발한 KL모형의 성능은 전국 지역간 도로(고속도로, 일반국도)를 대상으로 네트워크 단위의 사례분석 구간을 선정하고 정확도와 신뢰도 평가지표를 이용하여 평가하였다. 그 결과, 본 연구에서 개발한 모형들이 기존의 비교모형들에 비하여 전체적으로 우수한 결과를 나타냈다.",
		"KEYWORD": "k개의 최근린 이웃,국부 가중선형회귀,미관측 도로구간,비모수 모형,빅데이터,연평균 일교통량,연평균 일프로브통행량"
	},
	{
		"ID": 717,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "MapReduce?환경에서?LSH?기반의?K-NN?그래프?생성?알고리즘의?개선 =(An)improvement in K-NN graph construction with locality sensitive hashing on MapReduce ",
		"AUTHOR": "이인회",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 718,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "Novel platform for the development of refrigerator operating software using virtualization, automation, and remote control =냉장고 운영 소프트웨어 개발을 위한 가상화, 자동화, 원격제어 기반의 플랫폼 구축 ",
		"AUTHOR": "SangOhKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 719,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "하둡 분산 파일 시스템을 위한 동적 프로세서 친화도 프레임워크 =Dynamic processor affinity framework for hadoop distributed file system ",
		"AUTHOR": "조중연",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 진현욱",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "데이터의 폭발적인 증가에 따라 빅데이터의 효율적인 저장과 접근을 위해 분산 파일 시스템이 사용된다. 분산 파일 시스템은 네트워크를 통해 다수의 노드가 연결된 구조적 특징에 기인하여 네트워크와 디스크 I/O 성능에 의존적이다. 멀티코어 시스템에서 성능 향상을 위해 프로세서 친화도 기법이 연구되고 있지만 두 가지 I/O가 동시에 집중적으로 발생하는 분산 파일 시스템에는 적용하기 어려운 부분이 있다. 본 논문에서는 하둡 분산 파일 시스템을 기반으로 프로세서 친화도가 디스크와 네트워크 I/O의 성능에 미치는 영향에 대해 분석한다. 또한 프로세서 친화도가 하둡 분산 파일 시스템의 성능에 미치는 영향에 대해 실험한다. 실험 결과를 이용해 프로세서 친화도가 분산 파일 시스템의 성능에 미치는 영향에 대해 분석하여 멀티코어 프로세서 환경에서 최적의 프로세서 친화도 결정을 위해 고려해야 할 사항들에 대해 논의한다. 분석 결과를 이용하여 하둡 분산 파일 시스템을 위한 프로세서 친화도 정책을 결정하고 동적 프로세서 친화도 프레임워크를 제안한다. 제안된 프레임워크는 시스템 정보를 수집하여 하둡 분산 파일 시스템의 서비스 스레드를 위한 최적의 코어를 동적으로 결정한다. 리눅스 운영체제에 구현된 프레임워크는 하둡 분산 파일 시스템의 파일 업로드 성능을 최대 43%까지 향상시키고 더 나은 확장성을 제공한다.",
		"KEYWORD": "멀티코어,빅데이터,친화도,프로세스 스케줄링,하둡 분산 파일 시스템"
	},
	{
		"ID": 720,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "소셜빅데이터 위험에 대한 SNS이용자의 위험인식 특성 연구 :SNS users` risk perception on social big data risk : focus on the relationship between risk variables for social big data ",
		"AUTHOR": "이윤경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 송해룡 참고문헌: p. 141-169",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "본 연구는 스마트미디어 환경에 새롭게 등장한 고도화된 기술로서 소셜빅데이터에 대한 정확한 이해와 관련 위험에 대한 논의의 필요성을 제기한다. 소셜빅데이터란, 스마트미디어 환경에서 SNS를 통해 생성되는 다양한 비정형과 정형의 데이터들의 집합이다. 여기에는 빅데이터, SNS, 스마트미디어 기기의 위험특성이 모두 내재돼 있기에, 복합적이고 심화된 디지털 위험을 초래할 것으로 예측된다. 이에, 본 연구는 SNS이용자를 대상으로 설문조사를 실시해 소셜빅데이터 관련 위험들의 유형 및 특징, 소셜빅데이터 위험인식에 영향을 미치는 관련 위험변인들(소셜빅데이터 관련 위험유형, 위험평가-발생가능성과 피해심각성, 편익, 심리적불안감)의 관계를 경로분석과 구조모형분석을 통해 심층적으로 분석했으며, 주요 결과는 다음과 같다. 첫째, 소셜빅데이터 관련 위험들을 분류한 결과, 프라이버시 위험, 인포데믹스 위험, 보안위험, 시스템오류조작 위험 총 4가지 위험으로 유형화되었다. 이에 본 연구에서는 소셜빅데이터 관련 위험들은 그 특성에 따라 프라이버시 위험과 보안 위험을 개인적 차원의 위험으로 인포데믹스 위험과 시스템오류조작 위험을 사회적 차원의 위험으로 재분류하였다. 이 위험들이 소셜빅데이터 위험변인들에 미치는 영향을 종합적으로 분석한 결과, 프라이버시 위험, 보안 위험, 시스템오류조작 위험을 높게 인식할수록 소셜빅데이터 위험평가가 높아지는 것을 확인하였다. 또한 프라이버시 위험을 높게 인식할수록 소셜빅데이터 편익이 감소하는 것을 발견했으며, 시스템오류조작 위험을 높게 인식할수록 심리적불안감이 증가하는 것을 확인하였다. 반면, 인포데믹스 위험은 심리적불안감에 부정적인 영향을 미치는 것으로 나타나 기존 연구와는 상충된 결과를 확인하였다. 그리고 프라이버시 위험과 보안 위험을 높게 인식할수록 소셜빅데이터 위험인식이 증가하는 것으로 나타났다. 셋째, 소셜빅데이터 위험변인들 간의 관계를 확인한 결과 다음과 같다. 먼저 피해심각성이 높아질수록 심리적 불안감이 높아지는 것을 확인하였다. 한편, 기존 연구와는 달리 본 연구에서는 소셜빅데이터 위험의 피해심각성과 소셜빅데이터 편익의 정적인 관계, 소셜빅데이터 편익과 심리적불안감의 정적인 관계를 확인하였다. 다음으로, 소셜빅데이터 위험평가와 심리적불안감을 높게 인식할수록 소셜빅데이터 위험인식이 높아지는 것으로 나타났다. 하지만 기존 연구와는 달리 본 연구에서는 소셜빅데이터 편익과 소셜빅데이터 위험인식의 정적인 관계를 발견하였다. 마지막으로, 소셜빅데이터 위험평가(발생가능성과 피해심각성)는 심리적불안감을 통해 소셜빅데이터 위험인식을 더욱 높이는 것을 확인했으며, 편익이 심리적불안감을 통해 소셜빅데이터 위험인식을 더욱 높이는 것으로 나타났다. 즉 소셜빅데이터 위험인식에서 미치는 영향에 있어서 심리적불안감의 매개적 역할을 확인하였다. 이와 같은 소셜빅데이터 위험변인들 간의 영향 관계를 통해 본 연구의 주제인 소셜빅데이터 위험에서는 기존의 디지털 위험과 다른 특징이 발견되었다. 즉 소셜빅데이터 위험에서는 SNS이용자들이 자신의 필요성과 이익을 위해서 이 위험을 감수하거나, 개인의 기호, 취향, 취미에 의해서 오히려 이 위험을 즐기는 모습을 확인하였다. 이는 SNS이용자들이 소셜빅데이터 위험을 하나의 모험으로 인식하고 있는 것으로 해석할 수 있다. 이와 같은 결과를 통해 본 연구는 소셜빅데이터 위험을 통해 새로운 디지털 위험의 양상을 확인했으며, 소셜빅데이터 위험에서 기존 디지털 위험과 차이점을 발견했다는 점에 있어서 그 의의를 찾을 수 있다.",
		"KEYWORD": "SNS이용자의 위험인식,디지털 위험,소셜빅데이터,스마트미디어,위험의 심리학적 접근,위험커뮤니케이션"
	},
	{
		"ID": 721,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "사회보장부문의 공공빅데이터 활용 미래전략 =Strategic foresight for the social security sector through the full utilization of public big data ",
		"AUTHOR": "조현두",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 722,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "인성데이터를 활용한 조기퇴사자 예측 ",
		"AUTHOR": "김영박",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 20-21",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "본 연구는 기업에서 채용 전형 시 진행되는 인성시험 결과 데이터를 기반으로, 입사 3년 미만의 조기 퇴사자를 분석하였다. 예측 모형은 적합성 및 향후 활용성을 고려하여 제조(manufacture)직군과 R&D직군 2개 그룹으로 구분하여 분석하였으며, 독립변수 선택은 전진(stepwise)선택법에 따라 직군별로 유의미한 독립변수를 선택하였다. 예측 모형은 지도학습(supervised learning) 방법 중 로지스틱 회귀분석 알고리즘을 선택하였으며, 과잉적합(overfitting)과 과소적합(underfitting)을 방지하고자 K-fold 교차 검증(cross validation)을 통해 예측 모형을 훈련시켰다. 혼동행렬(confusion matrix)을 통해 2개 그룹의 정확도(accuracy)를 확인하였으며, 조기 퇴직에 가장 영향을 많이 미치는 요인으로 제조직군에서는 ‘몰입’, R&D직군에서는 ‘반사회성’ 항목으로 확인되었다. 기존 퇴직 관련 연구는 설문 방식으로 데이터를 수집하고, 퇴직과 관련성이 높은 요인을 확인하는데 집중하였다면, 본 연구는 채용 전형 시 진행되는 인성 결과 분석을 통해 향후에도 지속 가능한 조기 퇴직 예측 모형을 제시했다는 면에서 의의를 갖는다.",
		"KEYWORD": "K-fold 교차 검증,로지스틱 회귀분석,조기 퇴직"
	},
	{
		"ID": 723,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "비정형 데이터 매칭을 통한 미확인 항공기 추적 시스템 구현 ",
		"AUTHOR": "조지현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤지원 참고문헌: 장 33-35",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 들어 테러의 표적이 되고 있는 국제공항들은 공항의 안전과 보안을 강화하기 위해 최첨단 보안장비를 확충하는 등 늘어가는 테러의 위협과 항공보안 사고에 빠르게 대응하려는 강한 의지를 보여주고 있다. 또한 비정형 데이터인 이미지 및 동영상을 처리할 수 있는 IT기술의 발전으로 디지털 방식의 영상처리를 활용한 다양한 연구와 활동이 활발히 진행되고 있다. 또한 미국 정부가 상업 위성이 촬영할 수 있는 이미지의 해상도를 50Cm급에서 초정밀 25Cm급으로 완화해 주는 결정을 내린 후 구글은 자동차의 브랜드 마크를 식별할 수 있을 뿐 아니라 지나가는 사람의 얼굴까지 확인 할 수 있을 정도로 정밀한 위성사진을 구글맵과 구글어스에 적용하여 서비스를 제공하고 있다. 이러한 초정밀 영상과 이미지를 통해 자연재해를 예방하고 인터넷 사각지대를 해소하는 데 활용할 계획을 구글은 밝히고 있지만 사실상 가장 우려되는 문제 중 하나는 구글이 지닌 각종 개인 데이터들과 개인 이미지 등을 결합하여 보다 지능적인 범죄와 테러에 이용 할 가능성이 높다는 것이며 그 위협의 강도는 훨씬 더 커질 것으로 보여 진다. 본 논문에서는 디지털글로브가 구글에 공급하고 있는 위성사진인 구글맵을 통해 중국의 허브 공항으로 주요 거점이 되는 베이징 서우두 국제공항의 모습을 모니터링 하였다. 이 국제공항을 이용하는 북한의 고려항공기를 미확인 비행체로 간주하고 이 항공기가 내포하고 있는 특성과 패턴을 OpenCV 함수 인 Canny(), goodFeaturesToTrack() 등을 이용하여 추출하고 이미지 매칭 알고리즘을 적용하여 미확인 항공기를 추적하는 시스템을 구현하였다. OpenCV 함수를 이용하면 빠른 이미지 검색과 매칭이 가능하며 매칭 정확도는 유클리디안 법을 이용하여 유사도를 검증하여 그 정확도를 높인다. 이를 통해 테러의 위협 및 기타 지능적인 범죄에 보다 빠르게 대응할 수 있도록 기여할 시스템을 제안하고자 한다.",
		"KEYWORD": "미확인 항공기 추적"
	},
	{
		"ID": 724,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "Apache Spark를 활용한 교통빅데이터 분석 및 처리성능 평가 =Transportation bigdata analysis and performance evaluation in apache spark ",
		"AUTHOR": "김상호",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.45",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "빅데이터 시대를 맞이하여 일상 어느 곳에서건 수많은 종류의 데이터들이 발생하고 있다. 이렇게 발생된 데이터들은 다방면으로 수집되고 있으며, 그에 대한 다양한 분석들이 이루어지고 있다. 데이터의 크기가 늘어남에 따라 기존의 데이터베이스로 처리하는 데에는 한계가 나타났고, 이를 해결하는 새로운 빅데이터 기술들이 쏟아지고 있다. 본 논문은 교통분야에서 발생하고 있는 빅데이터를 신속하고 효율적으로 분석하기 위하여 Apache Spark를 활용하여 교통빅데이터 분석 시스템을 제안하였다. 또한 시스템의 처리성능을 평가하기 위해 대안이 되는 시스템들과의 처리속도를 비교 평가하였다. 기존의 단일머신 환경하에서 구축된 교통데이터 분석시스템을 빅데이터 환경으로 이전하는 과정은 ETL도구인 Talend를 사용하였고, 데이터의 저장은 하둡, 분석은 인메모리 기반의 분산병렬처리를 지원하는 Spark를 사용하였다. 분석 결과를 시각적으로 보여주기 위하여 Zeppelin을 사용하여 다양한 차트를 보여 주었다. 단일 머신에서의 성능 평가는 MSSQL, DB2, Hive, Tajo에 대하여 수행되었다. 성능평가 결과 인메모리 기반인 Spark와 DB2의 성능이 가장 우수한 것으로 나타났다. 클러스터 환경에서의 성능평가는 분산컴퓨팅이 가능한 Spark, Hive, Tajo 3가지로 한정하여 수행하였다. 성능평가 결과 Spark가 가장 빠른 성능을 보여주었다. 종합하면 인메모리 기반의 솔루션들이 가장 좋은 성능을 보여 주었고, 그 중 인메모리 분산처리가 가능한 Spark의 성능이 모든 환경에서 가장 좋은 성능을 보여주었다.",
		"KEYWORD": "Apache Spark,OLAB,데이터웨어하우스,스파크"
	},
	{
		"ID": 725,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "효과적인 순찰 활동을 위한 범죄예측 분석에 관한 연구 ",
		"AUTHOR": "최인숙",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이상진 참고문헌: 장 51-52",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "최근 우리 사회는 정보통신의 급속한 성장으로 인터넷이라는 기술과 대용량의 데이터를 처리 할 수 있는 IT 기술이 눈부시게 성장하였다. 또한 대용량의 데이터를 처리 할 수 있는 IT 신기술이 도입되면서, 빅 데이터를 활용한 분석 영역이 다양해지고 있는 추세이다. 이러한 빅 데이터 시대가 도래 하면서 세계 각국에서도 빅 데이터를 활용한 다양한 서비스를 창출하고자 하는 전략과 연구가 활발히 진행되고 있으며, 국내에서도 정부 3.0을 통한 공공 부문에서의 빅 데이터를 활용, 확산을 지원하고 있다. 이에 공공데이터를 활용하여 범죄 정보를 분석하는 분야에도 적용 할 필요성이 있다고 볼 수 있다. 범죄가 시간, 공간, 기후, 인구 분포 등에 영향을 받을 것이라는 생각은 있으나, 실제 공공데이터를 융합하여 통계 분석으로 검증한 연구는 많지 않으며, 많은 범죄 분석에 관한 연구들이 있지만 일일단위의 실질적인 순찰 활동을 지원할 수 있는 예측모델을 제시하는 연구는 많지 않아서 보다 적극적인 일일단위, 지역별, 시간대에 대한 예방 순찰 활동을 지원할 수 있는 예측모델이 필요하다. 따라서, 본 연구에서는 과거 범죄 통계 데이터와 공공데이터를 융합하여 범죄 정보를 분석하였다. 정형화된 공공데이터를 활용하여 데이터마이닝 기술을 적용하였으며, 환경의 특수성을 고려한 범죄 정보를 분석하였고 시간, 공간, 기후, 인구 분포 등 요인별 분류에 의한 범죄를 분석함으로써 효과적인 순찰 활동을 위한 실질적인 도움이 될 수 있는 예측모델을 제시하고자 하였다.",
		"KEYWORD": "공공 데이터,범죄 분석,범죄 지수,빅 데이터 마이닝,순찰 활동,시각화,예측 모형"
	},
	{
		"ID": 726,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "스마트폰 애플리케이션 이용행태를 활용한 사용자 인구통계특성 예측 ",
		"AUTHOR": "서선영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "Under the current situation where advertising is focused on mobile advertisements, it is necessary to consider mobile users’ features for marketing beyond only performing mobile centered advertisements itself. Information about demographic characteristics is the most basic and important information in mobile marketing but it is also difficult to collect the data due to personal information spill problems. Therefore, this study provides a model which predicts gender and age of users using smartphone application information extracted from smartphone log data. In order to generate the predictive model of demographic characteristics, the study used 1,000 South Korean smartphone users’ demographic data and smartphone log data collected from January 1st, 2014 to January 31st, 2014. To solve the imbalanced data problem, after balancing data through down sampling, the study generates and compares the performances of predictive models based on accuracy using three different types of classifications each according to whether principal component analysis, a way of dimension reduction, was applied. In case of gender prediction, the principal component analysis out of the six different combinations of predictive models showed the best performance with 92.67% accuracy of logistic regression, and again, the principal component analysis showed the best performance with 82.29% accuracy of random forest in case of age prediction. The principal component analysis had the most accurate prediction for both gender and age prediction. Whereas, when applying all independent variables, the accuracy of the test data has been reduced because of the overfitting problem. This study is significant in the fact that the study only used smartphone application usage data which is relatively easy to collect compare to other smartphone log data. Moreover, it is significant in practical terms due to a fact that it is possible to focus its marketing to certain groups in mobile or off-line through verifying groups who had good advertising response rate in mobile environment, and it is also possible to applicate to mobile marketing considering users features such as audience targeting.",
		"KEYWORD": "classification,demographic prediction,dimension reduction,smartphone log data,분류모형,스마트폰 로그 데이터,인구통계특성 예측,차원축소"
	},
	{
		"ID": 727,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "LDA 토픽 모델링을 활용한 판례 검색 및 분류 방법 =A searching method for legal case using LDA topic modeling ",
		"AUTHOR": "심준식",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 14",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "판례정보는 법률 체계에 맞게 분류되어 있어, 법을 모르는 일반인은 원하는 판례를 쉽게 찾기 힘들다. 이를 지원하기 위한 법령 검색 시스템 역시 법률 전문 용어를 키워드 검색으로 사용하게끔 설계되어 있어, 법률지식이 부족한 일반인이 사용하기에는 어렵다. 본 논문에서 제안하는 시스템은 LDA 토픽모델링을 이용하여 판례를 분류한다. 일반인들이 쉽게 이해할 수 있는 단어를 주제어 태그로 부여하여, 법을 전혀 모르는 일반인들도 쉽게 판례를 검색하고 분류하도록 했다.",
		"KEYWORD": "LDA,토픽모델링,판례분류"
	},
	{
		"ID": 728,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "스마트폰 앱 로그데이터를 활용한 라디오 청취자 유형분석 :SBS 고릴라(Gorealra)를 중심으로 ",
		"AUTHOR": "이경렬",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 37-39",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "이 연구는 라디오 청취자 파악을 위하여 기존의 설문조사 방식을 벗어나 스마트폰 애플리케이션(이하 앱) 로그데이터를 활용한 좀 더 효율적인 방법을 제시함과 함께 청취행태에 따른 청취자 유형을 살펴보고, 이러한 청취유형의 특징을 다양한 인구통계학적 변인을 통해 설명하는데 그 목적이 있다. 이를 위해 2017년 7월부터 두 달 동안 SBS라디오의 스마트폰 앱인 Gorealra(이하 고릴라)를 통해 실시간 라디오를 청취한 누적 495만명의 청취자에 대한 로그데이터 1억3천만여건을 분석하여 인구통계학적 변인을 통한 청취행태의 차이를 살펴보고, 프로그램별 이용량을 중심으로 군집분석을 실시하였다. 최종적으로 5개의 라디오 청취유형별 집단이 추출되었으며 군집별 청취행태의 차이를 토대로 ‘FM-출근/오후’, ‘AM-심야/아침’, ‘FM-심야’, ‘AMFM-Always’, ‘FM-Heavies’ 집단으로 구분하였다. 각각의 군집들의 인구통계학적 특성을 살펴본 결과 각 청취유형별로 연령대, 직업군 및 가입통신사와 사용하는 스마트폰 기기 등에 있어 동질성을 가진 이용자의 특성들이 발견되었다. 아울러 이 연구는 로그데이터 분석이 기존 청취자 수용도 조사에 비해 분석의 시간과 비용을 크게 감소시킴과 동시에 보다 심층적인 분석이 가능함을 증명함으로써 로그데이터 분석 방법의 유용성을 제시하였다. 끝으로 군집분석 방법을 사용한 이 연구결과의 타당성 검증을 위한 후속연구의 필요성과 로그데이터 분석이 가진 한계점 등이 논의되었다.",
		"KEYWORD": "고릴라,군집분석,라디오 청취행태,로그데이터 분석,스마트폰 앱"
	},
	{
		"ID": 729,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2018",
		"UNIVERSITY": "경기대학교 정치전문대학원",
		"TITLE": "한국정치에서의 정치빅데이터와 유용성 분석 :선거전략과 여론분석 활용을 중심으로 ",
		"AUTHOR": "동성혜",
		"REGION": "서울",
		"PROFESSOR": "지도교수:박상철 경기대학교 논문은 저작권에 의해 보호받습니다. 참고문헌 : p.241-262",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "본 논문은 한국정치에서 정치빅데이터가 선거캠페인 차원에서 소셜미디어의 활용에, 선거 결과 예측은 포털의 검색어 추이 분석에 한정지어졌다는 문제의식에서 시작하였다. 정치빅데이터의 유용성을 정치적 커뮤니케이션의 본질 가운데 선거전략과 여론형성 및 분석이라는 정치과정 차원에 초점을 맞추었다. 이를 중심으로 2012년 미국 대통령 선거 당시 오바마 캠프의 정치빅데이터 활용과 2017년 한국 대통령 선거에서의 문재인 캠프가 정치과정 차원에서는 선거전략과 여론분석, 선거캠페인 차원에서도 적극적으로 정치빅데이터를 활용한 내용을 비교 분석하였다. 이에 대한 결과로 한국정치에서의 정치빅데이터 유용성을 도출하고, 정치빅데이터 활용의 한계와 과제를 제안하는 것을 목적으로 한다. 제4차 산업혁명 시대의 핵심 기술인 빅데이터는 사회변화와 기술혁신의 연결고리로 인간과 사회, 자연과 사물에 기술을 접목시켜 만들어낸 ‘초연결성 네트워크’의 모든 정보들의 집합체이다. 이러한 방대한 양의 빅데이터는 존재 자체가 갖는 의미보다는 수집과 분석, 공유를 통하여 무엇을 분석하고 어떻게 해석하느냐에 대한 ‘통찰’이 전제되어야 미래를 예측할 수 있다. 정치 영역에서의 빅데이터도 마찬가지다. IT기술의 발전과 확산은 정당, 정치인, 유권자 모두의 정치적 인식과 행위에 영향을 줌으로써 정치과정의 패러다임을 변화시키고 있다. 정치 영역에서의 빅데이터에 대한 접근은 ‘인간에 대한 정보’와 ‘상호작용’이라는 점에서 정치적 커뮤니케이션 차원에서 바라보았다. 본 논문은 정치빅데이터 활용을 정치권력의 획득과 유지를 위한 정치활동으로 여론형성과 선거 등 정치과정 차원에서 접근하였다. 특히 인터넷 상에서 참여?공유?개방의 웹 2.0을 기반으로 정보를 생산하는 소셜미디어의 등장은 쌍방향 소통 방식으로 이루어진다. 이는 정치적 여론과 이슈의 생성, 정치세력의 조직화까지 정치적 영향력에서 그 효과를 극대화, 일상화, 활성화시키는 잠재력을 보여주고 있다. 이러한 맥락에서 본 논문은 정치빅데이터의 개념을 정치적 목적, 혹은 정치 활동에 필요한 정보를 수집?저장하고 정치적으로 유의미한 ‘인사이트’를 찾아내어 새로운 형태의 정치적 가치를 추출해내는 일련의 과정으로 규정하였다. 이러한 정치빅데이터의 특징은 두 가지다. 사회현실을 파악하고 사회변화의 방향을 예측하여 그에 맞는 적절한 정책 혹은 정치적 방향을 세우는 것과 소셜미디어를 통한 개개인의 정치적 욕구를 표현하는 정치참여의 통로가 되고 있다는 점이다. 정치빅데이터의 활용 성공 사례로 평가를 받고 있는 2012년 미국 대통령 선거 당시 오바마 캠프와 2017년 한국 대통령 선거에서 문재인 캠프의 선거캠페인을 분석하여 선거전략과 여론조사 활용을 통한 정치빅데이터의 정치적 유용성을 확인하였다. 분석구조는 캠프의 빅데이터 전문가들, 유권자 데이터 집적 과정, 이를 기반으로 한 맞춤형 선거전략, 기존 여론조사와 포털별 정치빅데이터의 교차분석을 통한 여론분석을 살펴보았다. 그 결과 정치빅데이터가 선거전략으로써 또한 여론분석으로써 유용하며, 유권자 데이터 집적 과정 자체가 또 다른 선거캠페인의 전 과정임을 확인하였다. 또한 집적과 분석을 통해 세대별, 연령별, 지역별 마이크로 타기팅 전략 수립의 가능성을 살펴보았다. 아울러 여론조사와 포털별 정치빅데이터 교차분석을 통하여 선거전략을 수립하기 위한 국민여론 파악이 가능하였음을 확인하였다. 이는 정책공약을 확정짓는데도 유용하였지만 전략적 방향성을 바꾸는 데도 상당히 유용하게 활용되었다. 오프라인에서는 각 지역단위까지의 조직선거에 영향을 미쳤을 뿐 아니라 인터넷 상에서는 소셜미디어를 활용한 선거캠페인에 다양한 방식으로 유용하게 활용되었다. 그러나 공직선거법과 개인정보보호법에 의한 유권자 데이터 집적의 어려움, 정치빅데이터를 전문적으로 분석할 수 있는 전문가의 부재, 정치빅데이터를 바라보는 인식의 부재로 인하여 정치빅데이터 활용이 한계에 왔다. 앞서 언급한 것처럼 정치빅데이터를 소셜미디어의 활용이나 포털의 검색어 추이 분석에 한정시켰기 때문이다. 향후 정치빅데이터의 적극 활용을 위해서는 유권자의 데이터 확보와 동시에 개인정보 침해를 방지하기 위한 대책마련, 지속적인 경험의 축적과 이를 정확히 분석할 수 있는 전문가의 확보, 선거캠페인에서 소셜미디어 활용 여부를 놓고 정치빅데이터의 전부인양 생각하는 차원에서 넘어 정치빅데이터가 선거전략에서 패러다임의 전환을 일으키고 있다는 인식의 변화 등이 요구된다.",
		"KEYWORD": "19대 대통령선거,마이크로 전략지도,맞춤형 선거전략,문재인 캠프,여론분석,정치빅데이터,정치빅데이터 유용성"
	},
	{
		"ID": 730,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "인터넷검색어를 통한 인플루엔자 치료제 판매 예측 ",
		"AUTHOR": "서주완",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 15-16",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "국내 인플루엔자는 매년 겨울철에 유행하여 건강인에서 업무상의 차질을 일으키고 고위험군에서 이환률 및 사망률의 증가를 초래해 사회 경제적 손실을 유발하는 질환이다. 질병관리본부(KCDC)는 인플루엔자 의사환자(ILI)를 1주 단위로 발표하고 있고 인플루엔자 치료에 쓰이는 항바이러스제중 하나인 Oseltamivir는 ILI를 통해 판매를 예측하고 있다. 최근에는 비임상적 자료인 인터넷 검색 키워드를 통해 ILI를 예측하려는 연구가 이루어지고 있는 반면에 GFT(Google Flu Trend)의 예측 능력 실패를 다루며 GFT와 CDC(Centers for Disease Control and Prevention)의 표준예측결과를 조합했을 때는 실제로 더 나은 결과를 보여 준다는 연구 결과가 있다. 본 논문에서는 Oseltamivir의 판매를 예측하는 회귀 모형을 개발하고자 한다. ILI를 이용한 Oseltamvir 판매 회귀모형을 기반으로 인터넷 검색 키워드 20개를 이용한 다중회귀모형과 ILI와 인터넷 검색 키워드 20개를 모두 이용한 다중회귀모형을 만들었다. 모형적합성 측면에서 ILI와 인터넷 검색 키워드 20개를 모두 이용한 모형이 우월한 결과를 보였다.",
		"KEYWORD": "오셀타미비르,유행성 독감,인터넷 검색어,인플루엔자 의사환자,회귀모형"
	},
	{
		"ID": 731,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "바이오템플릿 비트분할 분산 저장기법을 통한 생체인증 시스템 설계 ",
		"AUTHOR": "홍윤기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 尹之源 부록: 테스트 수행 코드 참고문헌: 장 33",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "보안 시스템에 있어 생체정보는 본인 소유와 사용의 편리성으로 매우 유용하나 일반적으로 불법 유출 시 변경이 불가능하여 타인의 재사용에 따른 범죄와 개인 프라이버시 침해의 위험성이 있으므로 최근 생체정보의 저장관리에 대한 보안의 중요성은 지속적으로 증가하고 있다. 기존의 일반적인 생체인증 시스템은 단일 저장 장소에 하나의 완전한 생체정보 템플릿을 암호화 하여 보관 하였지만 본 논문에서는 XOR 암호화(비트연산)로 원본의 생체정보와는 다른 새로운 파일을 생성하고 이 파일을 분할한 후 개인 식별 정보와 서로 다른 저장장소에 보관하여 인증 시에만 원본의 바이오 템플릿으로 복원 후 삭제함으로써 생체정보의 템플릿 보안 문제와 사용자의 고유의 생체정보 보관에 대한 불안 심리를 해소할 수 있는 바이오템플릿 비트분할 분산저장 시스템을 설계하였다.",
		"KEYWORD": "XOR 암호화,개인정보,바이오템플릿,분산 저장,분할,생체정보"
	},
	{
		"ID": 732,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "대용량 웹로그 프로파일링을 통한 하이브리드 여행상품 추천시스템 ",
		"AUTHOR": "이규식",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤지원 참고문헌: 장 27-28",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "현재 연구되어지고 있는 많은 상품 추천 시스템(Collaborative Based Filtering, Contents Based Filtering)은 고객의 구매내역을 기반으로 상품을 추천해주는 방법이 주로 연구되고 있으며 좋은 성능을 내는 많은 연구가 진행되어져 왔다. 이러한 연구들은 로그인 정보 혹은 예약 구매정보를 통하여 고객의 정보를 프로파일링 하기 쉽거나, 상품 구매 빈도수가 빈번하며, 동시에 여러 상품을 구매하거나 혹은 같은 상품을 반복 구매하는 환경과 같은 일반적인 환경에서는 좋은 성능을 보이고 있지만, 특수한 판매환경(여행 상품, 특수 상품)하에서는 적용이 불가능하거나 혹은 좋은 성능을 보이지 못하고 있다. 이러한 열악한 환경 하에서 상품을 추천해야 하는 경우 기존과는 다른 방법이 필요하게 되며, 이에 본 논문에서는 해외여행상품 추천과 같은 열악한 환경 하에서 동작하는 상품 추천 시스템 및 방법을 제시하고 시스템 구현 및 검증을 통해 높은 적중률을 보일 수 있었다. 해외여행시장은 매년 가파르게 성장하고 있는 산업중 하나이며 2016년 11조의 시장을 형성하고 있다. 거대한 시장형성과는 달리 해외여행상품 추천에 대한 국내연구는 전무한 상태이다. 많은 상품 추천 방법들의(협업적 필터링, 내용기반 필터링) 조건과는 완전히 다른 환경을 가지고 있으며, 일반적인 환경이 기존 구매 내역을 대상으로 하거나 혹은 상품의 유사성을 이용한 연구들이 주를 이루고 있다. 이러한 연구들은 연산할 데이터의 양이 많아질 경우 속도의 저하와 데이터가 충분히 확보되지 못한 상황 하에서는 좋은 성능을 보여주지 못하고 있다. 해외 여행상품의 특성상 1-2년에 한번정도의 구매패턴과 상품들의 가격대가 상대적으로 높으며, 동일 상품의 구매가 거의 없는 특징이 있기 때문에 일반적인 상품추천 시스템의 고객 프로파일링 방법으로는 적용에 한계가 있다. 이에 웹사용성(Web Usage Mining)을 통한 고객 프로파일링 기법, 데이터의 희소성 문제를 해결하기 위한 연관규칙 알고리즘 과 규칙 기반 알고리즘을 결합하고 Cold-Start 문제를 해결하기 위해 내용기반 필터링(Contents Based Filtering)을 결합한 고속의 상품 추천시스템 방법을 제안한다. 본 논문에서는 연관규칙 방법에서 가장 많이 사용되어지는 Apriori , 내용기반 필터링 (Contents Based Filter), 규칙기반 (Rule Base) 과 웹로그를 결합한 새로운 하이브리드 형태의 상품추천 시스템을 구축하고, 이를 실제 여행사의 웹로그를 사용하여 검증한 결과 50%라는 높은 정확도를 나타냈으며, 상품의 개수와 고객의 수가 상품 추천 처리 속도에 영향을 주지 않으며, 실제 커머셜한 환경 하에서도 1초이내에 상품을 추천해줄 수 있는 결과를 보여준다.",
		"KEYWORD": "상품추천,아프리오리,연관규칙,웹로그,웹사용성,협업필터링"
	},
	{
		"ID": 733,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "Convolutional Neural Network를 활용한 자소기반 한국어 감성 분석 알고리즘 개발 및 검증 ",
		"AUTHOR": "성원경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이중정",
		"STORE_LOCATION": "연세대학교 학술정보원",
		"ABSTRACT": "Sentiment analysis refers to the use of natural language processing (NLP) techniques for analyzing subjective data such as attitudes, opinions, and propensity of people in text. Although recent, studies employing Korean sentiment analysis have been steadily increasing, its practical use is still difficult. First there is a lack of open emotional dictionaries. First, there is a lack of open Korean lexicon for sentiment analysis up to the present. Second, in the fields of specific domains, the linguistic characteristics of Korean, which is an agglutinative language and based on Chinese, makes it difficult to sort new words and technical terms as well as to learn words by distributed representation. Thus, this research proposes the Korean sentiment analysis employing the character level Convolutional Neural Network. Through this, the model was able to generate syllable vectors based on the array structure of Korean character, and then minimize the problems caused by low frequency words and by out of vocabulary while avoiding morphological analysis. Finally, this proposed model records 88% of accuracy, and it is not much influenced by the Unstructured characteristic of input data as well as is able to be analyzed through of context of the text.",
		"KEYWORD": "character level model,convolutional neural network (CNN),sentiment analysis,감성 분석,문자 기반 모델,컨볼루션 신경망"
	},
	{
		"ID": 734,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "검색결과 역배열 제시를 통한 순서 기반 정보탐색 유형 실증연구 ",
		"AUTHOR": "조봉관",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 20-21",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "일반적으로 검색엔진은 이용자가 검색하고자 하는 내용의 정보를 제공하는 사이트를 우선 탐색할 수 있도록 검색결과의 주요 내용을 요약하여 이용자에게 제공하고 있다. 본 연구에서는 이용자의 검색 결과 클릭이 검색 엔진에서 제공하는 요약 내용 기반으로 진행되는 것인지 검색결과 배치 순서에 기인한 것인지를 검색 결과 역배열 제시를 통한 실증 연구 결과를 제시하였다. 검색엔진 업체에서 제공하는 API를 활용하여 검색결과를 정배열과 역배열로 제시해 주는 검색사이트를 제작하여 각 이용자들의 검색결과에 대한 클릭 행동을 실제 클릭 순서와 클릭 위치, 클릭 수, 검색결과 내에서의 페이지 간 이동경로 등과 같은 이용자 검색 유형을 분석하였다. 분석 결과 대부분의 이용자들은 검색결과 정배열 또는 역배열 제시와 상관없이 첫 번째와 두 번째 노출된 검색 결과를 우선 클릭하는 이용자가 60% 이상 차지하였다. 이는 검색 결과 요약 내용과 상관없이 검색 결과 배치 순서에 따라 이용자의 정보탐색 우선순위가 결정되는 것으로 확인되었다.",
		"KEYWORD": "검색순서,조작,클릭순서,클릭스트림,클릭행동"
	},
	{
		"ID": 735,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "Generative Advasarial Networks를 이용한 Face Morphing 기법 연구 ",
		"AUTHOR": "한윤",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 22-23",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관",
		"ABSTRACT": "최근 컴퓨팅 파워의 폭발적인 발전으로 컴퓨팅의 한계 라는 장벽이 사라지면서 딥러닝 이라는 이름 하에 순환 신경망(RNN), 합성곱 신경망(CNN) 등 다양한 모델들이 제안되어 컴퓨터 비젼의 수많은 난제들을 풀어나가고 있다. 2014년 발표된 대립쌍 모델(Generative Adversarial Network)은 비지도 학습에서도 컴퓨터 비젼의 문제들을 충분히 풀어나갈 수 있음을 보였고, 학습된 생성기를 활용하여 생성의 영역까지도연구가 가능하게 하였다. GAN 은 여러가지 모델들과 결합하여 다양한 형태로 발전되고 있다. 기계학습에는 데이터 수집의 어려움이 있다. 너무 방대하면 노이즈를 제거를 통한 효과적인 데이터셋의 정제가 어렵고, 너무 작으면 작은 차이도 큰 노이즈가 되어 학습이 쉽지 않다. 본 논문에서는 GAN 모델에 영상 프레임 내의 얼굴 영역 추출을 위한 deepCNN 모델을 전처리 필터로 적용하여 두사람의 제한된 수집데이터로 안정적으로 학습하여 다양한 표정의 합성 이미지를 만들어 낼 수 있는 방법을 제시하였다.",
		"KEYWORD": "face morphing,Generative Adversarial Network,Machine learning"
	},
	{
		"ID": 736,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "트렌드 지수를 반영한 블로그 랭킹 알고리즘 개선에 대한 연구 ",
		"AUTHOR": "이용석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金炯中 참고문헌: 장 38-39",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "블로그의 성장은 다양한 정보제공이라는 긍정적 측면과 마케팅적 활용이라는 부정적 수단으로 사용되고 있는 문제를 가지고 있다. 본 연구는 대형 포털의 블로그 포스트의 랭킹 결과에 대하여 OpenAPI를 이용하여 수집하였고, 탐색적 데이터 분석기법을 통해서 상위 랭크된 블로그의 특징들을 조사하였다. 분석 결과를 보면 상위 랭크에 영향을 주는 요소로는 블로거의 영향력과 포스트의 최근 생성일에 관련성이 높은 것을 알 수 있었다. 이런 평가 알고리즘의 약점으로 인해 파워 블로거의 포스트 중심으로 검색 결과를 편중되게 보여주는 문제가 있었다. 본 연구에서는 다양한 대중의 관심사를 나타내는 트렌드 지수를 통해 랭킹 점수 적용의 공정성을 확보하고, 전문가에 의해 검증된 신뢰 DB정보를 추가하여 컨텐츠 신뢰성을 높이는 알고리즘을 제안하였다. 개선된 알고리즘을 맛집 검색 결과가 실제 지역 학생들의 추천 맛집 정보와 유사도가 높은 것을 확인하였다. 개선된 알고리즘으로 좀 더 신뢰할 수 있는 정보제공이 가능해 졌으며, 방문자수 증가시키는 불법 앱에 의한 순위 조작이 어려워지는 부가적 개선 효과가 기대된다.",
		"KEYWORD": "랭킹 알고리즘,블로그,트렌드 지수,포스트"
	},
	{
		"ID": 737,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "FACTORIZATION MACHINE을 이용한 추천시스템 설계 ",
		"AUTHOR": "정승윤",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金炯中 참고문헌: 장 20-21",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "데이터의 양이 기하급수적으로 증가함에 따라 추천 시스템(recommender system)은 영화, 도서, 음악 등 다양한 산업에서 관심을 받고 있고 연구 대상이 되고 있다. 추천시스템은 사용자들의 과거 선호도 및 클릭스트림(click stream)을 바탕으로 사용자에게 적절한 아이템을 제안하는 것을 목적으로 한다. 대표적인 예로 넷플릭스의 영화 추천 시스템, 아마존의 도서 추천 시스템 등이 있다. 기존의 선행 연구는 협업적 여과, 내용 기반 추천, 혼합 방식의 3가지 방식으로 크게 분류할 수 있다. 하지만 기존의 추천 시스템은 희소성(sparsity), 콜드스타트(cold start), 확장성(scalability) 문제 등의 단점들이 있다. 이러한 단점들을 개선하고 보다 정확도가 높은 추천 시스템을 개발하기 위해 실제 온라인 기업의 상품구매 데이터를 이용해 factorization machine으로 추천시스템을 설계했다.",
		"KEYWORD": "Factorization machine,추천시스템,협업필터링"
	},
	{
		"ID": 738,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "기술 기대주기는 IT 융합기술의 발전 궤도를 해석하는 기준으로 타당한가? :IT 융합 기술의 기술 기대주기에 대한 탐색적 연구 :사회·기술적 시스템 이론 관점에서 ",
		"AUTHOR": "홍단비",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 739,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2018",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "유통채널 소비 분석 :대형마트 소비 감소를 중심으로 ",
		"AUTHOR": "박진영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형중 참고문헌: 장 25-27",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "스마트폰 보급 이후 국민 대부분이 인터넷에 접속할 수 있게 되면서 오픈마켓, 소셜커머스 등의 온라인 유통채널은 매년 높은 성장률을 기록하고 있다. 한편으로는 1인 가구 비중 및 간편함 추구하는 소비자들이 증가하면서 편의점 점포수가 크게 늘어나고 있으며 이를 바탕으로 급격한 성장률을 나타내고 있다. 이러한 소비 환경 변화 속에서 기존 유통 시장의 주축이었던 대형마트는 매출이 감소하면서 최근 3년 동안 마이너스 성장률을 기록하고 있지만 대형마트 매출 관련된 연구는 주로 영업규제에 따른 효과 분석 위주였으며 다른 유통채널과의 영향관계 분석이나 소비 이동 사유에 대한 조사는 부족한 실정이다. 본 연구는 카드사 매출 빅데이터를 활용하여 대형마트 성장률 감소를 소비자의 인구통계학적 변수 및 소비시점 등에 따라 분석하고 로지스틱 회귀 분석을 통하여 대형마트 소비 감소와 다른 유통채널 매출비중 변화와의 관계 등을 실증적으로 규명하였다. 또한 실제 카드소비 데이터 기반 대형마트 소비 감소 소비자를 대상으로 설문조사를 수행하여 다른 유통채널 선택 사유가 무엇인지 밝혔다. 이는 유통채널 소비 변화에 대한 정량적 분석 결과와 정성적인 사유 조사 결과를 융합하여 소비에 대한 입체적인 조망을 하였다는 점에서 의의가 있다.",
		"KEYWORD": "로지스틱회귀분석,빅데이터,유통소비"
	},
	{
		"ID": 740,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 정보보호대학원",
		"TITLE": "주가지수 방향성 예측을 위한 증권 맞춤형 감성사전 구축방안 ",
		"AUTHOR": "김재봉",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 金炯中 참고문헌: 장 31-33",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "개인용 모바일 디바이스의 눈부신 발달은 개인들이 보다 손쉽게 네트워크에 접속할 수 있게 하였으며, 수많은 참여자에 의한 쌍방형 의사소통의 활성화는 커뮤니티와 소셜미디어의 폭발적인 증가를 가져왔다. 특히 음악, 미술, 과학 등의 분야는 전문화, 세분화 과정을 거치며 전문가 중심의 커뮤니티로 발전하고 있다. 전문 커뮤니티들이 쏟아내는 방대하고 다양한 의견들은 사회적으로 강한 영향력을 발휘하고 있어, 기업이나 정부는 이들의 의견을 빠르게 파악하고 대책을 마련해야 하는 필요성이 증가하고 있다. 실제로 많은 기업들이 소비자들의 의견을 수렴하기 위해 다양한 노력을 경주하고 있으며, 그 일환으로 다양하게 연구되고 있는 분야 중 하나가 감성사전이다. 감성사전은 오피니언 마이닝의 한 방법으로 방대한 양의 비정형 데이터를 빠르게 파악할 수 있어 쇼핑몰, 유통업체 등에서 많이 활용되고 있으며, 주식시장의 감성사전에 관한 연구도 활발하게 진행되고 있다. 주식시장은 사회의 다양한 요인들을 반영하여 시시각각 변화하기 때문에 정확한 예측이 매우 어려운 분야이다. 최근에는 많은 연구자들이 경제적 동향을 반영하는 연구방법 외에 사회의 동향을 반영하는 빅데이터 분석을 접목하려는 시도를 하고 있으며, 특히 뉴스와 같은 텍스트데이터 분석을 활용하는 연구들이 지속적으로 발표되고 있다[1]. 본 논문에서는 정제된 형식과 한정된 어휘만을 사용하는 뉴스의 한계점을 보완하기 위해 증권전문 사이트 ‘Paxnet’의 게시글을 분석대상으로 하였으며, 명사위주의 한정된 품사를 벗어나 형용사와 동사도 포함하였다. 특화사전에 효과적인 말뭉치 방식으로 사전을 구축하기 위해 추출된 단어들의 빈도, PMI값 등을 사용하여 핵심어를 기준으로 유사어, 반의어 등을 포함한 말뭉치 사전을 구축하였다. 주식시장에 관한 인터넷 커뮤니티 게시글에 구축된 사전을 적용하여 그 유의성을 검증하였다.",
		"KEYWORD": "감성분석,감성사전,말뭉치,오피니언마이닝"
	},
	{
		"ID": 741,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "동의대학교 대학원",
		"TITLE": "경제성을 고려한 CEP 기반의 의료기관 데이터 실시간 분석 시스템 구현에 관한 연구 ",
		"AUTHOR": "김미진",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다 참고문헌: p. 146-150",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "스마트 시대의 소셜 네트워크, 사물인터넷, 라이프 로그 데이터 등은 빅데이터 시대 진입에 중요한 요소들이다. 스마트 단말기는 수많은 데이터를 생산하고, 그 기기들로부터 생산되는 수많은 데이터들은 분산 파일 형태로 수집되어 중요한 정보로 가공된다. 빅데이터 분야는 최근 많은 기술 및 학문 분야에서 각광받고 있는 분석 기술 경향의 하나로, 이 기술이 소개됨에 따라 기존에는 분석하기 어려웠던 여러 가지 데이터들에 대한 새로운 분석 및 해석이 가능하게 되었다. 이에 따라 다양한 분야에서 빅데이터 수집 및 분석기법을 적용하여 유의미한 분석 결과를 내놓고 있어 앞으로 활용가능성이 매우 높을 것으로 보고 있다. 개개인의 데이터가 비즈니스적으로 중요하지 않을 수 있지만, 대량으로 모으면 그 안에 숨겨진 새로운 정보를 발견할 가능성이 있는 데이터의 집합체로 빅데이터 분석 활용 사례는 점차 늘어나는 추세이다. 빅데이터 분석 기술 중 전통적인 데이터 분석 방법인 Hadoop은 예전부터 배치성 처리 시스템으로 데이터가 많아질수록 응답 지연이 발생할 가능성이 높아, 현재 기업 경영환경과 시장환경에 대한 엄청난 양의 고속 이벤트 데이터에 대한 실시간 분석이 어려운 상황이다. 또한 다양한 기업군에서 빅데이터 분석 정보를 활용하길 원하지만, 빅데이터 솔루션은 대부분 고비용의 문제로 도입해서 사용하기 힘든 실정이다. 빅데이터 분석 활용 중 특히 주목받고 있는 분야가 의료보건 분야이다. 인구 고령화에 따른 만성병 및 퇴행성 질환의 증가로 인해 보건의료 분야에서는 빅데이터를 의료비 절감, 전염병 예방, 의료 서비스의 질 향상에 활용하고자 다양한 연구들이 시도되고 있으며, 효율적인 진단 및 처치 방법의 탐색, 예후 예측 등에 효과적인 대안 방법들이 제시되고 있다. 맥킨지 보고서에서도 의료분야 가치는 국민의료비의 절감과 혁신적인 임상연구를 가능케 하는 것과 연관이 매우 깊을 것이라 보고하고 있다. 본 논문에서는 빅데이터 기술을 활용하여 중·소규모의 의료기관들을 대상으로 저비용의 빅데이터 시스템을 구축하였다. 구축된 실시간 빅데이터 분석 시스템은 CEP 기반 오픈 플랫폼을 기반으로 구현하였으며, 이벤트 기반 실시간 분석 메커니즘을 보완하여 보건의료 분야에서 생성되는 방대한 양의 데이터를 실시간 분석 가능하도록 설계하여 효율적인 진단 및 처치 방법과 의료관련 정보 등 효과적인 환자 관리 및 의료기관의 경영관리 등을 체계적으로 제공할 수 있도록 시스템을 구축하였다. 또한, CEP 기반의 실시간 분석을 위해서 실시간으로 유입되는 데이터의 이벤트 처리에 대한 알고리즘을 설계하였고, 실시간 데이터 처리 알고리즘에 대한 성능검증을 통해 전체시스템의 성능 개선효과를 입증하였다.",
		"KEYWORD": null
	},
	{
		"ID": 742,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "효율적인 데이터 관리를 위한 데이터 품질관리 시스템 설계 및 구현 =Design and implementation of data quality management system for efficient data management ",
		"AUTHOR": "안하철",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 박석천",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "오늘날 스마트 폰의 보급이 보편화 되면서 모바일 시장이 크게 성장하게 되었다. 또한 수많은 사용자들이 이용함에 따라 더 많은 양의 콘텐츠를 제공을 해야 하기 때문에 데이터는 점점 증가 할 수밖에 없는 상황이다. 하지만 잘못된 데이터 정보를 마케팅 같은 곳에 활용하여 피해를 보기 때문에 신뢰성 있는 데이터를 사용자에게 제공해야 한다. 따라서 본 논문에서는 이러한 문제점을 해결하기 위해 향상된 데이터 품질관리 시스템을 제안하였다. 본 논문에서 제안하는 시스템을 설계하기 위하여 데이터 품질관리의 기술을 파악하고 데이터 검출과 분석에 관한 연구를 하였다. 또한, 데이터 흐름을 분석하여 정의된 기술 요소를 기반으로 개선 된 측정 및 분석 알고리즘을 설계하였다. 이를 통하여 시스템 기능 모듈과 UI를 설계하였으며 전체 동작 절차를 구성하여 최적화된 데이터 품질관리 시스템을 설계하였다. 본 논문에서 설계한 시스템을 구현하기 위하여 Windows 7 운영체제 기반의 이클립스를 사용하였으며 언어는 자바의 JSP를 이용하였다. 기존 알고리즘에 데이터 오류 측정의 업무규칙을 적용한 개선 된 측정 및 분석 알고리즘과 데이터 측정, 데이터 분석, 데이터 관리에서 신뢰성 있는 데이터를 획득하기 위하여 향상된 데이터 품질관리 시스템을 구현하였다. 마지막으로 본 논문에서 설계 및 구현한 시스템을 평가 및 테스트 하기 위하여 한국데이터베이스진흥원의 품질가이드라인 기준으로 완전성, 유효성, 일관성, 유일성 테스트에서 오류 없는 데이터베이스에 오류데이터를 각각 10개, 30개, 50개, 100개를 삽입 한 테스트를 수행하였다. 그 결과 99%의 오류데이터를 검출할 수 있다는 것을 확인하였다.",
		"KEYWORD": "데이터 품질관리"
	},
	{
		"ID": 743,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "인제대학교 대학원",
		"TITLE": "생체데이터 분석을 위한 하둡 플랫폼의 확장 ",
		"AUTHOR": "박광호",
		"REGION": "경상남도",
		"PROFESSOR": "지도교수: 김희철 참고문헌: p. 32-38",
		"STORE_LOCATION": "인제대학교 백인제기념도서관",
		"ABSTRACT": "현대사회 의료 서비스는 수요자를 중심으로 하는 예방적 건강관리 차원의 능동적 서비스로 변화되고 있다. 이러한 변화에 따른 생체신호를 이용한 유비쿼터스 헬스케어 시스템은 생체신호의 분석 및 처리, 실시간 응답, 생체데이터의 저장 등의 기술이 접목되어야 한다. 생체신호란 사람의 신체에서 발생되는 신호에 대하여 측정하는 순간의 값을 의미하며, 수집되는 데이터의 형태에 따라 체온, 혈압 등과 같이 단순한 특징값들을 가지는 데이터와 심전도, 호흡과 같이 연속적으로 유입되는 선형구조를 가진 데이터로 구분할 수 있다. 이러한 두 분류의 데이터들을 저장함에 있어 특징값을 갖는 생체데이터는 데이터베이스 저장에 적합한 데이터형을 띄지만 선형구조의 생체데이터는 데이터베이스의 저장에 맞지 않는 데이터 형과 양이다. 따라서 선형구조의 생체데이터는 일반 데이터가 아닌 빅데이터로 분류하여 처리해야 할 필요성이 있다. 분석, 통계에 사용되는 일반적인 빅데이터의 기술은 텍스트마이닝이며, 비/반정형 텍스트 데이터에서 자연 언어 처리 기술에 기반하여 유용한 정보를 추출, 가공하는 것을 목적으로 하는 기술이다. 이것은 데이터값의 가공없이 분석, 통계에 사용 가능함을 의미한다. 하지만 생체신호 자체는 가공되지 않은 선형구조의 원데이터이며, 분석 가능한 데이터가 아니다. 따라서 생체신호는 신호 분석 알고리즘을 통하여 특징값들을 추출하고 유효한 데이터 포맷으로 변환하여 분석 가능한 데이터로 가공해야 한다. 빅데이터를 처리하는 플랫폼으로서는 하둡이 있으며 일정기간 축척되어진 배치(batch)형태의 데이터를 분석하고자 할 경우에 유용하다. 하둡은 생체신호를 실시간으로 처리해야하는 헬스케어 시스템에는 부족한 면이 있으며 서비스 차원의 생체데이터 처리에 옳지 않다. 따라서 본 논문에서는 생체데이터를 빅데이터로 정의하고 이를 분석, 서비스하기 위한 하둡 플랫폼을 확장한다. 이것은 생체신호로부터 특징값을 추출하는 알고리즘을 포함하고, 표준화된 생체데이터의 표현인 HL7 기반 표준문서 포맷 변환을 위한 변환엔진, 생체데이터를 분석하는 맵/리듀스 그리고 개방형 표준 플랫폼인 서비스 플랫폼(SOA)을 포함한다. 적용사례에서는 초당 약 60Hz의 가속도 신호를 계측할 수 있는 스마트폰에서 신호를 수신받아 생체데이터를 분산 저장하고 분석하는 시스템을 구현함으로서 사용성과 효용성을 검증한다.",
		"KEYWORD": "Big-data,Biometric data,Hadoop,Service-Oriented-Architecture,SOA,빅데이터,생체데이터,서비스지향아키텍쳐,하둡"
	},
	{
		"ID": 744,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "질의응답 성능 향상을 위한 효율적인 다차원분석 알고리즘 설계 및 구현 =Design and implementation of efficient multidimensional analysis algorithm for performance improvement of questions and answers ",
		"AUTHOR": "송태준",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 박석천",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "최근 정보통신의 발달과 기하급수적인 정보량의 증가로 인해 빅데이터 및 빅데이터 처리기술이 IT분야의 화두로 떠오르고 있다. 그러나 수많은 데이터 중에서 가치 있는 데이터는 소수에 불과하므로 대용량의 데이터를 분석하여 의미 있는 데이터로 추출하는 기술이 필요하다. 의미 있는 데이터를 추출해 내기 위해 최신 기술을 도입하여 분석이 이루어지고 있지만 복잡한 관계의 다차원분석에서는 처리시간이 매우 길어지고 있으며 실시간성이 중요한 시스템에서 이러한 처리시간 지연은 매우 치명적이다. 따라서 본 논문에서는 기존의 다차원분석 처리시간 지연 문제점을 해결하기 위해 효율적인 다차원분석 알고리즘을 제안한다. 본 논문에서 제안하는 알고리즘을 설계하기 위해 하둡 및 어플라이언스에 대하여 분석하였으며, 컬럼 및 그래프 데이터베이스의 장점을 이용하여 다차원분석 알고리즘을 설계하였다. 본 논문에서 제안한 알고리즘을 구현하기 위하여 컬럼 데이터베이스로 InfiniDB를 사용하였고, 그래프 데이터베이스로 Neo4j를 사용하였다. 또한 컬럼 데이터베이스와 그래프 데이터베이스의 데이터 마이그레이션을 위해 ETL Tool인 Talend를 사용하여 테스트 환경 및 알고리즘을 구현하였다. 본 논문에서 설계 및 구현한 다차원분석 알고리즘을 평가?테스트하기 위하여 2010년 구제역 사태의 데이터를 이용하여 동일한 조건에서 단일차원 및 다차원분석에 대한 질의 응답시간에 대하여 제안 알고리즘을 적용한 시스템과 적용하지 않은 하둡 및 각각의 어플라이언스 제품에서 테스트 하였다. 본 논문에서 제안한 다차원분석 알고리즘이 Sum, Join의 질의 응답시간은 30% 향상되었으며, Update시 50%의 응답시간이 향상 되었음을 확인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 745,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "사물인터넷을 활용한 효율적 회전초밥 시스템 실증 연구 =(A)study of efficient conveyor-belt sushi systems using internet of things ",
		"AUTHOR": "김수엽",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김광용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "인터넷시대는 1969년의 알파넷으로부터 시작되어 1990년 들어 본격적으로 확산된 이후, 2010년을 기점으로 복잡한 관계망 연결은 가속화되고 있다. 인터넷은 연결대상을 사람 간에서 사물로까지 확대하여 진정한 초연결시대를 맞이하고 있으며 본격적으로 사물인터넷(Internet of Things, 이하 IoT라고 함) 시대가 도래 하고 있다. 이에 본 논문에서는 IoT 기술을 회전초밥 시스템에 적용해서 실증시험을 진행하고, 다양한 방법으로 정보를 수집하고 분석하여 IoT 기술의 효과를 검증 하였다. 본 연구에서는 이론적 접근을 통하여 실현 가능성에 대한 확인을 할 수는 있었지만, IoT 관련 기술 전부(보안, 빅데이터, 상황인식 등)를 적용하여 검증하지는 못했다. 따라서 향후 본 연구 결과를 토대로 해당분야 대해 추가적으로 연구가 계속 이루어져야 할 것이다. 본 연구를 통해 기술의 진화와 인간욕구의 변화를 2대 동인으로 하는 미래사회의 새로운 패러다임 속에서, 다양한 객체를 연결하는 IoT에서의 수많은 데이터 속의 가치를 찾아내 활용하는 모바일 시대 이후의 미래사회에서, 새로운 인간중심의 가치를 실현하는 서비스 개발에 활용될 것으로 기대 된다.",
		"KEYWORD": "IoT,사물인터넷"
	},
	{
		"ID": 746,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "철강산업에서의 프로세스 마이닝 프레임워크의 개발 :U사 MES 중심으로 ",
		"AUTHOR": "장종익",
		"REGION": "부산",
		"PROFESSOR": "지도교수:김민수 참고문헌",
		"STORE_LOCATION": "부경대학교 도서관",
		"ABSTRACT": "많은 기업들이 경쟁력 확보를 위해 ERP, MES, APS 및 SCM과 같은 다양한 정보시스템에 투자를 해왔으며, 이런 정보시스템들의 활용이 수년에 걸쳐 이루어지면서 기업 내에 축적되고 있는 데이터와 응용 프로그램들에서 생성해 내는 로그의 종류와 양 또한 급격히 증가하고 있다. 특히 로그 데이터의 경우 운영기간에 따라 상당한 규모의 데이터가 시스템 내에 축적되었지만 이를 효과적으로 저장하여 추출 및 분석할 수 있는 도구나 방법론이 미비하여 대부분의 로그가 정기적으로 버려지는 실정이었다. 그러나 최근 프로세스 마이닝 기법을 이용하여 이러한 로그 데이터를 효과적으로 분석하여 잠재적인 비즈니스 가치를 발굴해내는 사례와 연구가 발표되면서 이에 대한 관심이 국내외적으로 높아지고 있는 실정이다. 특히 빅데이터 시대로 접어들면서 대용량 데이터의 저장과 분석을 위한 도구와 방법론이 활발히 연구되면서 이들 분야의 연구 결과를 프로세스 마이닝 분야에 효과적으로 활용할 수 있는 방법이 체계적으로 제시될 필요가 있겠다. 본 논문에서는 로그의 종류를 유형화하고, 빅데이터를 위한 데이터 저장과 분석 도구로써 많이 활용되고 있는 Hadoop과 Hive를 이용하여 프로세스 마이닝 관점에서 이를 저장 및 분석하는 과정을 체계화하고자 한다. 로그의 유형과 분석 상황에 맞게 필요한 정보를 추출하여 이를 Hive상에 저장하고, 분석 주제에 따라 Hive로부터 데이터를 조회 및 정제하여 그 분석결과를 생성해내는 방법을 제안한다. 제안한 방법론을 실제 철강산업의 로그 데이터에 적용하여 DISCO를 통해 분석함으로써, 본 논문의 방법론이 실제 프로세스 마이닝의 분석 방법론으로 활용될 수 있음을 예시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 747,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "공공데이터 품질 요인이 공공데이터 개방정책의 신뢰에 미치는 영향에 관한 연구 =(A)study on public data quality factors affecting the confidence of the public data open policy ",
		"AUTHOR": "김현철",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김광용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "본 연구는 최근 이슈가 되고 있는 공공데이터의 품질 요인을 정립하고, 이들 품질 요인이 기술수용모델의 관점에서 이용 만족에 미치는 영향을 분석하고, 이용 만족이 공공데이터 개방이라는 정부 정책에 대한 신뢰에 어떻게 영향을 미치는가를 규명하는데 있다. 이를 위해 공공데이터를 MIT의 TDQM(Total Data Quality Management)에 의해 공공데이터의 품질 요인을 구분하였으며, 공공데이터가 고유하게 가지고 있는 내재적 데이터 품질(Intrinsic Data Quality), 상황적 데이터 품질(Contextual Data Quality), 표현적 데이터 품질(Representational Data Quality), 그리고 접근적 데이터 품질(Accessibility Data Quality)까지 4개 차원으로 구분하였다. 이 중 상황적 데이터 품질을 제외한 3개의 품질 요인을 중심으로 연구하되, 내재적 데이터 품질 요인으로 정확성(Accuracy), 신뢰성(Reliability), 공정성(Fairness)을, 접근적 데이터 품질 요인으로 접근성(Accessibility), 보안성(Security)을, 표현적 데이터 품질 요인으로 표현의 일관성(Consistent Representation)과 이해가능성(understandability) 등 7개의 독립변수 요인들을 선정하였다. 공공데이터 품질 요인이 기술수용모델을 기반으로 한 지각된 이용용이성(Perceived ease of Use), 지각된 유용성(Perceived Usefulness), 그리고 이용 만족에 미치는 영향과 이러한 이용 만족이 공공데이터 개방이라는 정부 정책의 신뢰에 어떠한 영향을 미치는가를 연구모델로 구성하였다. 본 연구를 위해 행정 정보 공개와 데이터 품질과 관련한 선행연구 및 관련 기사 등의 최근 자료들을 조사하였고, 해당 변수들에 대한 조작적 정의를 통해 설문을 구성하였으며, 사전 조사 과정을 시행하여 문항과 용어에 대한 수정 작업을 거쳐 최종 측정도구를 완성하였다. 설문을 실시한 결과 450여 부를 회수하여 항목이 누락되었거나 불성실하게 답변한 설문지를 제외한 346개를 표본으로 사용하였다. 실증분석 방법은 타당성 확인을 위하여 SPSS 18.0을 통해 각 변수들의 기초통계와 요인분석(Factor Analysis)을 실시하였고, 이에 대한 신뢰성을 검증하고자 크론바흐 알파(Cronbach`s α) 값을 확인하였다. 또한 가설검증을 위해 AMOS 18.0을 이용하여 변수별로 확인적 요인분석(Confirmatory Factor Analysis)을 실시하고, 가설의 최종 검증을 위해 변수 간의 구조방정식 모형(Structural Equation Modeling) 분석을 실시하여 경로계수를 구하고 각 가설에 대한 채택여부를 확인하였다. 연구 결과 공공데이터 품질 요인들의 요인분석 결과는 양호하게 나왔으며, 각 요인들의 신뢰성인 크론바흐 알파(Cronbach`s α) 값도 높게 나왔다. 독립변수와 매개 및 종속변수를 구분하여 확인적 요인분석을 실시한 결과 유의미한 결과들이 나왔으며, 전체적으로 연구 모형의 적합도도 우수하게 도출되었다. 연구의 결과로는 정확성, 공정성, 이해가능성은 지각된 이용용이성과 지각된 유용성 모두에 영향을 미쳤으며, 신뢰성, 표현의 일관성, 보안성, 접근성은 지각된 이용용이성에만 영향을 미치는 것으로 나타났다. 지각된 이용용이성이 지각된 유용성에 미치는 영향이나, 기술수용모델 관점에서의 두 요인들이 이용 만족에 미치는 영향은 기존에 많은 연구에서 제시한 바와 같이 유의미하게 나타났다. 그리고 이러한 공공데이터 이용에 대한 만족은 공공데이터 개방이라는 정책에 대한 신뢰로 이어지는 것으로 조사되었다. 본 연구는 비정형 데이터 중심의 공공데이터 개방과 관련된 초기의 연구로서 공공데이터의 품질과 관련된 특성들을 종합적으로 정리하여 공공데이터를 제공하는 기관들이 관심을 가져야 할 품질 요인들을 도출하였고, 향후 공공데이터 개방 정책의 운영 방안을 제시했다는데 연구의 의의가 있다.",
		"KEYWORD": "공공데이터 개방,데이터 품질,이용 만족,정부3.0,정책 신뢰,행정정보공개"
	},
	{
		"ID": 748,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "공공데이터 개방에 따른 개인정보보호에 관한 연구 =(A)study on the personal information protection according to public data disclosure ",
		"AUTHOR": "정성민",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 박규식",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "빅데이터의 효용가치는 다방면에서 논의될 수 있으며, 특히 국가사회적인 측면에서 보면 더욱 그 의미가 크다. 미래 국가 경쟁력은 ‘빅데이터’의 활용에 달려있다고 해도 과언은 아니다. 하지만, 이러한 데이터의 활용에만 초점이 맞추어져 개인정보의 보호에 대한 방안이 등한시되어서는 안 될 것이다. 특히, 박근혜정부의 ‘정부 3.0’의 핵심정책 중의 하나인 ‘공공데이터 제공 및 이용 활성화에 관한 법률’에 따라 투명한 정부를 지향하고 국민에게 편익을 제공하고자 하고 있으나 개인정보보호법과의 충돌도 무시할 수는 없다. 본 연구는 빅데이터시대의 공공데이터 개방에 따른 개인정보보호에 관하여 이론적 연구와 설문조사를 통해 다음과 같은 결론을 도출하였다. 첫째, 일반 사용자들은 동의가 없이도 수집?분석?활용이 가능한 공공데이터의 개방에 대해 가장 큰 이슈로 생각하고 있다. 둘째, 일반 사용자들은 소극적이나마 개인정보를 제공시에는 나름대로의 보호대책을 강구하고 있으며 이러한 개인정보가 유출되었을 경우에는 데이터의 원천적인 삭제를 요구하고 있다. 셋째, 사용자들은 향후 사회생활에 불이익을 줄 수도 있는 정보보다는 당장 현실적으로 직접 피해를 줄 수 있는 성명, 주민등록번호, 개인 연락처 등 기본적인 개인정보에 대해 더 민감한 것으로 판단할 수 있으며, 이의 보완을 위해 ‘주민등록번호 대체수단 마련’, ‘개인정보보호 인증제도 마련’, ‘개인의 요청에 의한 개인정보 데이터 삭제제도 마련’, ‘정보유출시 보상체계 강화’ 등의 보완대책이 필요하다. 빅데이터라는 거대한 물결에서 공공데이터의 개방에 따라 이의 활용에만 중점을두어 등한시 되기 쉬운 개인정보보호에 대해 제한적이나마 보완대책을 제시함으로써 본 연구에 대한 의미를 부여할 수 있다.",
		"KEYWORD": "개인정보보호,공공데이터,공공데이터 개방"
	},
	{
		"ID": 749,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "(A)memory-resident index structure to enhancing read performance for NoSQL ",
		"AUTHOR": "In-SuKang",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 750,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "순천향대학교 대학원",
		"TITLE": "개인정보보호 정책 공시 데이터를 이용한 개인정보보호 성과 수준 예측모델에 관한 연구 =(An)estimation model of the personal information protection performance level using the privacy policy disclosure data ",
		"AUTHOR": "이재근",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 염흥열",
		"STORE_LOCATION": "순천향대학교 도서관",
		"ABSTRACT": "개인정보처리자의 개인정보보호 현황과 수준을 파악하고 분석하는 일은 우리나라의 개인정보보호 정책 수립 및 추진에 매우 중요하다. 그러나 개인정보처리자의 개인정보보호 현황과 수준을 시의 적절하게 조사하고 분석하는 일은 많은 시간과 비용이 필요하여 실질적으로 수행하기는 매우 어렵다. 본 논문에서는 개인정보처리자가 개인정보보호 관련법에 따라 개인정보처리자의 홈페이지에 공시하게 되어 있는 개인정보 처리 정책, 즉 개인정보처리방침(이하 처리방침) 데이터를 이용해서 개인정보처리자의 개인정보보호 현황과 수준을 설명할 수 있는 개인정보보호 성과 수준에 대한 예측모형을 제시한다. 이를 위해 처리방침 데이터를 수집하고 분석하기 위한 인코딩 스킴과 허용 값을 개발하고, 홈페이지에 공개되어 있는 처리방침 데이터를 실증적으로 수집한다. 이렇게 수집된 처리방침 데이터를 정보화통계조사 결과 등 기존의 관련 자료와 비교분석 하여, 처리방침 데이터가 고유품질, 맥락품질, 접근품질, 표현품질 등 네 가지 데이터 품질 특성을 충족하고 있으며, 빅데이터의 3대 특성인 규모(volume), 형태(variety), 속도(velocity) 등을 가지는 중요한 정보 원천임을 검토한다. 그리고 1,274건의 처리방침 직접 및 연관 데이터를 이용해서 개인정보처리자의 규모, 개인정보 민감도, 처리방침 공시 수준, 개인정보보호 성과 수준 간의 관계에 대해 탐색적 가설을 설정하고, 해당 변수를 정의한 다음 상관관계분석, 회귀분석 등 통계적 방법을 이용해서 검증한다. 분석결과 이들 네가지 특성간에 양(+)의 상관관계가 있으며, 개인정보처리자의 규모(SC), 개인정보 민감도(SE), 처리방침 공시 수준(PPDL) 정보를 이용해서 개인정보처리자의 개인정보보호 성과 수준(PPL)을 예측할 수 있는 회귀모형을 제시한다. 본 논문은 개인정보처리자의 처리방침 데이터를 수집 분석하는데 필요한 제반 공시이론, 데이터의 품질 특성, 데이터의 수집을 위한 인코딩 스킴 및 허용값, 처리방침 공시 수준(PPDL) 및 개인정보보호 성과 수준(PPL) 측정 방법, 개인정보처리자의 규모(SC), 개인정보 민감도(SE), 처리방침 공시 수준(PPDL), 개인정보보호 성과 수준(PPL)간의 상관관계, 개인정보보호 성과 수준(PPL)의 예측 등에 대해 체계적으로 정리한 최초의 논문으로, 제시된 방안은 데이터의 품질이 보장되고 시간과 비용을 절감할 수 있어 기존의 조사 방식에 비해 결과에 대한 정확성과 현황 파악에 대한 신속성에 있어 유리하다. 또한 이 과정에서 수집이 가능한 개인정보 위탁 및 제공 데이터를 이용한 사회관계망 분석 등을 통해 개인정보보호 관련 실태 파악의 새로운 발전 방안을 제시한다.",
		"KEYWORD": "data analysis,privacy policy,statistics,개인정보보호,빅데이터"
	},
	{
		"ID": 751,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "SNS상의 개인정보 보호행동에 영향을 미치는 사용자 동기 요인에 관한 연구 =A study on user`s motivation factors affecting personal information protection behavior of SNS ",
		"AUTHOR": "박성배",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한경석",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "One of the most fascinating industries in the 21st Century is BigData. It is amply proved by the majority of BigData research in the New York Times and Harvard Business Review. Furthermore, the world`s greatest scholars in the field of economics and business management anticipate BigData as a bright future and It is an attractive industry which has a thriving business currently. As Big Data era is realistically coming up all the more, smartphone penetration rate in Korea is very high. As much as a large proportion of the populace is using smartphones. Additionally the using of SNS(Social Network Service) is expanding over entire generations. Likewise, the meaning of SNS at present is able to define an amusement, leisure and pursuit that smartphone users can readily access and use with ease. SNS can be viewed as a means of interactive communication which find a stream of empathy in a market with customers in companies apart from general users. As preceding research and what we know, general users post their life events, opinions, and likings online and the majority of people are consuming content such as friend`s news, songs, and videos through SNS. On the Internet using smartphones except for SNS, contents that retrieved are also recorded anywhere and the number of times inputting specific keyword through various search engines such as, Google and Naver are saved in a server of relevant companies. Thus, it is impossible to improve Big Data industry unless information is leaked online. It means that Big Data is technology which is based on leakage and gathering basic user information through SNS or smart devices it starts leaking, individual information now become a thing which is not social norms. In these circumstances, having awareness individuals should know how important their own information is and how to keep it prudently. Moreover, the most important thing is an action according to realization. However, in reality hundreds of people just have thinking about what they should do or do not even recognize a situation that personal information is traded and exchanged as merchandise in social media. They mostly consider these situations with disregard if the damage is insignificant despite an individual experiences information leaking and invasion of privacy. They react only if they are damaged by a monetary problem or riskier troubles. The main purpose of this thesis is that SNS users will do protection of personal information if they are aware of protection of personal information grafting SNS onto Big Data unlike exiting privacy preceding research. At this point of time that propagation of smartphone has been popularized and so-called `Big Data era` has come, a research model is selected for executing analysis of actual proof because everyone encounters a danger of personal information leaking. Listing five points of emphasis in this research, it is tried to investigate a connection with SNS user`s each motives and an awareness of personal information protection firstly. For the second time, it is inquired how users who have the personal information protection awareness affect a privacy concern. Thirdly, it is also established the Privacy Paradox that users do not take actions to protect personal information in spite of having a privacy concern in this research as contrast with the existing preceding study that users behave to protect personal information when they have the privacy concern. Fourthly, it is sought that users who have personal information protection awareness will even conduct a personal information protection behavior. Finally, it is analyzed the regulation effect to know difference in gender, age, and SNS use time being considered as dominant factors in a privacy research. In an independent variable, there show subjective norm, information seeking motive, self-disclosure and entertain motive in order as the most affecting main causes for personal information protection awareness. To summarize, in having an effect on personal information protection behavior. There are privacy paradox and concern. Also, as a result of moderating effect analysis, it shows that there are differences between groups which have all different gender, age, SNS use time.",
		"KEYWORD": "SNS,개인정보,빅데이터,사용자 동기,프라이버시"
	},
	{
		"ID": 752,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "관계형 데이터베이스 기반 검색성능 향상을 위한 다중 데이터접근 알고리즘 설계 및 평가 =Design and evaluation of multiple data access algorithm for improving retrieval performance based on relational database ",
		"AUTHOR": "최로환",
		"REGION": "경기도",
		"PROFESSOR": "",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "최근 개인 디바이스의 확산과 소셜 네트워크의 급격한 확산으로 데이터의 양이 폭발적으로 증가하였다. 이에 대용량 데이터를 활용하기 위한 많은 방안이 연구되었고 빅데이터라는 용어가 여러 관점에서 정의되었다. 그 중에서도 NoSQL이 개발자들 사이에서 많은 주목을 받고 있지만 대부분의 경우에는 예산 및 데이터의 정합성 보장 등의 이유로 기존의 RDBMS를 계속 사용할 수밖에 없는 실정이다. 그러나 RDBMS는 WEB 2.0 사이트의 대용량 데이터를 처리 할 경우, 데이터의 병목현상이 발생되어 성능의 저하가 발생함과 동시에 수평적 확장마저 불가능한 한계가 존재하기 때문에 이에 대한 해결이 필요하다. 또한 빈번한 쿼리 때문에 발생하는 지연에 대한 문제도 개선이 필요하다. 따라서 본 논문에서는 이러한 문제점을 해결하고 기존의 RDBMS를 사용하면서도 검색 성능의 향상을 위하여 NoSQL과 RDBMS의 장점을 결합한 방식을 적용한 다중 데이터접근 알고리즘을 설계하였다. 본 논문에서 설계한 다중 데이터접근 알고리즘을 구현하기 위하여 리눅스 기반의 Centos 6.5를 이용하여 데이터베이스를 구축하고 Windows기반의 PC에서 Eclipse를 이용하여 JAVA 언어를 사용해 HandlerSocket plug-in과 InnoDB를 연결하여 구현하였다. 마지막으로 본 논문에서 구현한 다중 데이터접근 알고리즘을 평가?테스트하기 위하여 실험 테이블을 지정하여 10건, 100건, 1000건, 1만 건 10만 건의 데이터를 기준으로 반복 테스트를 진행하였다. 데이터 삽입, 갱신, 삭제, 조회 처리를 하고 데이터 건수의 증가에 따른 건별 처리시간과 QPS를 측정하고 결과를 비교 분석하였다. 테스트 결과 삽입 처리의 건별 처리시간과 QPS는 기존 연구 대비 큰 성능의 차이를 보이지 않았다. 하지만, 조회 처리의 건별 처리시간은 10만 건 기준, 기존 연구 대비 평균 18%의 성능이 향상되었고 조회 처리의 QPS 측정 테스트에서도 스레드 수가 50개일 경우 기존 연구 대비 56%의 향상으로 삽입처리 대비 현저하게 향상된 결과를 확인하였다. 위 테스트의 결과로 본 논문이 제안하는 다중 데이터접근 알고리즘이 적용된 데이터베이스의 조회 성능이 개선된 것을 확인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 753,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "대용량 추천 시스템을 위한 유사 사용자 인덱스 기법 ",
		"AUTHOR": "이해성",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 권준희",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "급증하는 모바일 인터넷 사용자들은 언제, 어디서나 콘텐츠를 만들어 내는 생산자가 되면서 웹은 빠른 속도로 방대해져가고 있다. 수많은 콘텐츠와 서비스가 범람하고 있는 가운데, 사용자 자신이 원하는 콘텐츠를 원하는 시점에 접할 수 있도록 하는 개인화 정보 서비스가 더욱 필요시 되고 있다. 개인화 정보 서비스는 사용자가 직접 검색 키워드를 입력하였던 기존의 정보 검색 시스템에서 발전한 차세대 정보 서비스라 할 수 있을 것이다. 개인화 정보 서비스에 있어 가장 일반적인 형태는 추천 서비스이다. 사용자가 선호할 것으로 예상되는 콘텐츠 및 상품을 추천하는 시스템이 전자 상거래 분야뿐만 아니라 다양한 도메인 영역에 범용 적으로 활용되고 있으며, 이러한 추천 시스템을 활용한 개인화 서비스 개발에 대한 연구가 활발히 진행되고 있다. 즉, 맞춤화나 개인화 서비스가 전자 상거래 시장이나 미디어 콘텐츠 서비스 분야의 중요한 마케팅 성공요인으로 여겨지고 기존 정보 검색 방식에서 탈피한 차세대 정보 서비스 수단이 요구되면서 추천 시스템에 대한 필요성과 관심이 그 어느 때보다 증대되고 있는 것이다. 추천 시스템에 있어서 사용자 선호도 예측을 위한 협업 필터링 과정은 가장 연산이 복잡하며 많은 시간이 요구된다. 따라서 사용자 선호도 예측 분석을 위해 고려되는 히스토리 데이터의 양이 방대할수록 추천의 정확도와 효율성이 떨어지고 확장성을 저하시킴으로써 추천 시스템의 전체 성능 떨어뜨리는 중요한 요인이 된다. 또한 추천 항목의 정확성이 떨어지면서 추천 항목에 대한 사용자의 신뢰도 역시 감소하게 된다. 추천 시스템의 정확도과 확장성 감소, 그리고 사용자의 신뢰성 저하의 세 가지 이슈는 추천 시스템의 성능 평가와도 깊은 관련이 있기 때문에 효과적인 개인화 서비스의 제공에 있어서 추천 시스템이 반드시 해결해야할 주요 문제로 아주 오래전부터 다루어져 왔다. 때문에 이들 세 가지 이슈를 해결하기 위한 학계의 연구개발 노력은 꾸준히 이루어지고 있으며 최근 까지도 계속 되고 있다. 본 논문에서는 추천 기법의 정확성, 확장성, 그리고 신뢰성에 관한 세 가지 이슈 각각의 해결 방안을 모두 고려하고 빅데이터 환경에서의 추천 시스템의 성능을 개선시키는 것을 목표로 새로운 유사 사용자 인덱스 제안하고, 유사 사용자 인덱스 기반으로 한 추천 시스템의 성능 개선 효과를 검증한다. 또한 유사 사용자 인덱스를 구성함에 있어, 소셜 분석기법이 적용된 3단계 유사사용자 클러스터링을 제안한다. 제안하는 3단계 유사 사용자 클러스터링은 소셜 분석기법을 적용하였기 때문에 데이터 희소성에 대한 고려 없이 유사 사용자 집합을 구성하여 추천 기법의 정확성을 높이고 추천 항목에 대한 사용자의 신뢰성을 개선시킬 수 있다. 또한 제안한 유사 사용자 인덱스가 대용량 추천 시스템의 성능 개선에 효과적임을 검증하기 위해 클라우드 컴퓨팅 기술과 하둡 기반의 분산 컴퓨팅 기술을 사용하여 실험 환경을 구현하였다. 구현된 실험환경에서 정확성과 확장성 개선에 대한 실험을 실시하였다. 실험을 통해 본 논문에서 제안한 유사 사용자 인덱스의 사용으로 기존의 추천 기법이 적용된 대용량 시스템의 정확성과 확장성 측면에서의 성능이 개선되었음을 보였다.",
		"KEYWORD": "대용량 데이터 처리,유사 사용자 인덱스,추천 시스템"
	},
	{
		"ID": 754,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "가상화 환경에서의 분산 질의와 맵리듀스 처리 성능 최적화 =Performance optimization of distributed query and MapReduce processing in virtualized environment ",
		"AUTHOR": "김태원",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수 : 나연묵 참고문헌 : 85-88장",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "다양한 인터넷 기술의 출현과 수많은 정보를 생산하는 모바일 장치의 대중화 그리고 네트워크 속도의 발전으로 인하여 빅 데이터에 대한 관심이 증가 하고 있다. 이에 빅 데이터를 효율적으로 다룰 수 있는 솔루션으로 Hadoop과 이에 관련된 다양한 프로젝트들이 등장하였다. 그 중 Hive는 페이스북에서 개발된 Hadoop 기반 대용량 데이터베이스이다. Hive는 SQL과 비슷한 HiveQL을 제공함으로써 Hadoop의 단점 중 하나인 맵리듀스 프로그램에 대한 불편함을 해결하였다. Hive는 질의를 Hadoop의 맵리듀스 작업을 수행하는 방법으로 처리하고 있고 이로 인해 관계형 데이터베이스가 가진 장점들을 제공하지 못하고 있다. 이러한 문제점을 해결하기 위하여 Hive와 관계형 데이터베이스 통합 시스템인 허니비를 제안하였고 질의 처리 성능이 향상됨을 보여주었다. 하지만 허니비는 조인 질의를 처리하지 못하는 문제점과 질의 결과가 캐시에 저장되지 않았을 때 성능상의 문제점을 보이고 있다. 본 논문에서는 이러한 문제점들을 해결하기 위해 허니비에서 조인 질의 처리가 가능하도록 개선한다. 또한 HoneyBee-Miss 시 질의 처리 성능을 높이기 위하여 관계형 데이터베이스에서 직접 질의를 처리하는 방식인 IRP를 제안한다. 제안된 질의 처리 방식과 기존 질의 처리 방식의 질의 처리 비용 및 데이터 전송 비용을 실험을 통하여 비교 및 분석 하고 두 가지 방식을 선택적으로 사용함으로 분산 질의 처리 성능이 향상됨을 입증한다. 맵리듀스 질의 처리 성능을 높이기 위한 방안으로 가상화 Hadoop 클러스터 구축 및 가상화 클러스터 기반의 태스크 스케줄러를 제안한다. 다양한 실험을 통하여 제안된 태스크 스케줄러가 이 기종 컴퓨팅 환경에서 노드간의 성능 불균형 문제를 해결함을 보이고 기존 스케줄러에 비해 전체적인 클러스터의 성능이 우수하다는 것을 입증한다. 본 논문에서는 위에서 언급한 사항들을 반영하여 허니비를 개선하였고 이를 실험을 통해 검증하였다. 이러한 질의 처리 방식과 태스크 스케줄러를 허니비에 적용하는 것은 질의 처리 성능을 향상시킬 수 있다. 그리고 대용량 데이터를 다루는 의사 결정 시스템이나 데이터 마이닝 시스템에서 허니비를 보다 효과적으로 활용할 수 있을 것으로 보인다.",
		"KEYWORD": null
	},
	{
		"ID": 755,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "데이터 분석 도구 성능 비교 연구 :A performance comparison study on data analysis tools : based on machine learning ",
		"AUTHOR": "권태희",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 최용락 참고문헌: p. 29-31",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "As IT(Information Technology) develops, various types of data are being produced and collected dramatically. These data are also being utilized in many ways, so importance of data roles and range of utilization are being high and wide. In the current big data environment, the concept of data has extended to broad sense which includes informal data as well as formal data, and category of big data includes this concept of data and estimate of future using efficient management and analysis of data. ‘Information of Everything’ in 「Top 10 Strategic Technology Trends 2016」 announced The Gartner Group means that industries which analyze a lot of information will develop, and ‘Advanced Machine Learning’ predicts development of ‘Machine Learning’ which is one of big data analysis technologies. When considering that principle of ‘Alphago’ lately unveiled by Google is data analysis using machine learning, we can know that the interest in data analysis technology is increasing. Many companies and organizations have developed data analysis tools for data analysis technology, and R which is data analysis tool based on statistic and open-source has widely known and used in many ways. As the interest of open-source software grows globally and rapidly, IT companies are releasing their own technologies based open-source. Apache Software Foundation is managing open-source projects and allows anyone to use technologies in these projects. Hadoop, MapReduce and Apache Spark which are typical big data technologies are managed by Apache Software Foundation. Apache Spark has received a lot of attention because it uses In-Memory technique to raise performance of data processing and analysis and was released as open-source software which embeds various libraries related to data analysis. As considering Apache Spark and R in machine learning which is rapidly growing in big data analysis, we have difficulty in choosing which data analysis tool is better because Apache Spark can conduct fast analysis due to In-Memory technique and R has mass data analysis functions based on statistic and library which supports distributed processing environment of Hadoop. In other words, we have trouble in predicting which case has higher performance in data analysis using machine learning among two cases which are data analysis using Spark MLlib of Apache Spark and data analysis using machine learning method of R. Therefore I conduct study using Random Forest method which is one of machine learning ensemble methods in this paper to compare data analysis performances of Apache Spark and R. I perform experimentation and deduce results using Spark MLlib which is one of functions of Apache Spark and ‘randomForest’ package of R.",
		"KEYWORD": null
	},
	{
		"ID": 756,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Large-scale incremental processing for mapreduce =맵리듀스를 위한 대규모 점진적 처리에 대한 연구 ",
		"AUTHOR": "Lee,Daewoo",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 757,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "ETL 데이터 이관의 성능 향상에 관한 연구 =(A)study on performance increase of ETL data migration ",
		"AUTHOR": "박상현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최용락",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 사물인터넷(Internet of Things)과 클라우드 컴퓨팅(Cloud Computing), 빅데이터(Big Data) 환경에서 기업의 데이터 웨어하우스(Data Warehouse)에 포함되는 데이터는 단순히 운영계 데이터의 수집, 보고 기능뿐 아니라 다각화된 데이터 소스 환경에 대한 분석, 예측을 통해 올바른 분석 정보를 제공해야하는 중요성이 더욱 증가되고 있다. 따라서 정보계 시스템의 데이터 웨어하우스 환경에서 늘어나는 데이터의 빠른 이행을 요구하고 있다. 데이터 마이그레이션(Data Migration) 수행 시 여러 데이터 소스 환경에 따라 담당자는 최적화된 ETL(Extract/Transform/Load) 솔루션을 고려해야한다. 이를 위해서는 ETL Tool의 단순 사용보다는 해당 툴의 특성과 데이터 마이그레이션 환경에 대한 이해를 필요로 한다. 본 논문에서는 대량의 동일한 데이터 셋(Data Set)을 대상으로 다양한 환경에서 데이터 이관 성능향상 연구를 위해 ETL 오픈소스(Open Source) 인 Talend Open Studio와 MS-SQL 서버 군에 제공되는 SSIS(Sql Server Integration Services)를 이용하여 이 기종 데이터베이스에서 데이터를 이관할 때의 ETL 성능 측정을 진행하고, Tool 특성에 따른 성능 차이를 비교한다. 그리고 Procedure 와 ETL Tool 의 이관 성능을 비교하기 위해 동일한 소스의 데이터 이관 로직을 각각 Procedure와 ETL Tool 의 Task를 사용하여 ETL을 구현한다. 두 비교대상의 성능 측정을 진행하여 상황에 따른 효율적인 ETL 방법 적용 및 Tuning을 통해 성능향상 방법 등을 제안한다. 데이터 이관 시 성능과 관련하여 고려해야하는 사항들을 데이터 이관 테스트 기반으로 분석하고자한다.",
		"KEYWORD": "Datamart,DW,ETL Tuning"
	},
	{
		"ID": 758,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "이기종 하둡을 위한 동적 데이터 복제 =Dynamic data replication for heterogeneous Hadoop ",
		"AUTHOR": "박대신",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 홍지만 참고문헌: p. 32-33",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "사물인터넷 기반 서비스 증가로 인해 대규모 데이터가 매일 생산되고 있으며 기업과 공공기관에서는 데이터 수집 및 분석 활동으로 새로운 가치를 창출하고 있다. 또한 빅 데이터를 효율적으로 처리 및 관리하기 위한 분산 처리 시스템 연구가 활발하게 진행 되고 있다. 그 중 가장 대표적으로 사용되는 오픈 소스 프레임워크인 하둡은 분산 처리 프로그래밍 모델(MapReduce)과 분산 파일 시스템(HDFS)으로 구성된다. 이기종 클러스터로 구성된 하둡에서는 동시에 실행 할 수 있는 태스크들에 개수인 슬롯 개수가 데이터노드들마다 다르다. 그리고 하둡은 입력 데이터를 저장하고 있는 데이터노드 맵 슬롯에서 맵 태스크를 실행하게 될 경우 가장 좋은 성능을 얻을 수 있다. 하지만 입력 데이터를 저장하고 있는 모든 데이터노드가 작업을 수행할 경우에는 입력 데이터를 복사하여 작업을 수행한다. 이로 인해 지연 시간이 발생하며 맵리듀스 프로그램에 성능 저하가 발생한다. 또한 HDFS에 저장된 각 데이터들의 접근 요청 횟수는 모두 다르지만 모든 데이터를 동일한 복제본 수 만큼 저장하는 기존 하둡 기법은 효과적이지 못하다. 본 논문에서는 이기종 클러스터로 구성된 하둡에서 각 데이터노드 맵 슬롯 개수를 이용하여 맵 태스크가 최적의 데이터노드 맵 슬롯에 할당될 확률을 측정하는 알고리즘과 이를 이용한 동적 데이터 복제 기법을 제안한다. 또한 데이터 접근 빈도를 기반한 데이터 복제본 회수 기법을 제안하고 제안한 기법을 하둡에 적용하여 기존 하둡과 맵리듀스 프로그램 수행 시간을 비교하는 실험을 통해 제안한 기법의 성능을 평가한다.",
		"KEYWORD": "동적 데이터 복제,하둡"
	},
	{
		"ID": 759,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "멀티코어 환경에서 다중 큐를 이용한 멀티 스레드 기반 IPS 시스템의 설계 및 구현 =Design and implementation of a multi-threaded IPS system using multiple queues in multi-core environments ",
		"AUTHOR": "유상규",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박성용 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Recently as big data becomes an issue and huge amounts of data floods, how to process such innumerable data is the question. We have IDS/IPS solutions such as Snort and Suricata, however there is some problem with their processing capability. Besides, Snort and Suricata are lacking in real-time analysis of large amounts of data in multi-core CPU environment while the programming methodology is being developed suitable for multi-core CPU environment following the hardware development. Therefore data optimization in the multi-core environment must be performed, and this thesis presents a way to solve the problem. It is two-step solution as below: Step 1. To smoothly analyze and properly distribute load of data through the Methodology of the queue more than one mapping, Step 2. To control the CPU utilization through Suricata Instance proposed in this thesis which has received the distributed data from Step 1 using OpenMP. In order to apply the two-step solution as shown above, this thesis will analyze the source of the multi-threaded Suricata existing and apply ways to improve performance and resource through a multi-core distribution using OpenMP. With the results of the whole process of application, (following the data comparison and analysis) we will have the conclusion of the proposed methodology.",
		"KEYWORD": null
	},
	{
		"ID": 760,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "MapReduce의 성능개선을 위한 효율적인 정렬 알고리즘 =(An)efficient sorting algorithm for improved performance of MapReduce ",
		"AUTHOR": "김남형",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조인휘",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "현재 우리는 데이터 폭증시대에 살고 있으며 스마트폰과 같은 디지털 기기의 보급, 소셜네트워크서비스(SNS)의 부상과 모바일 기기의 확산이 결합되면서 급격하게 데이터가 증가 하고 있다.이에 따라 데이터를 분석하고 처리하고자 하는 시도가 활발히 이루어 지게 되었고 이러한 연구는 빅데이터 분석 연구라 불리며 현재 데이터 베이스와 데이터 마이닝 분야에서 가장 활발히 연구되는 주제 이다 특히 대량의 데이터를 분석하고 처리하는 기술과 이를 실생활에 접목하는 기술이 집중적으로 연구 되고 있으며 빅데이터 분석 연구에 가장 널리 사용되는 시스템은 Hadoop 이다. 본 논문은 Hadoop core Project에 해당하는 MapReduce의 정렬 병합 처리시간 단축을 위한 알고리즘 방법을 제안한다. MapReduce잡의 입력 데이터는 논리적인 단위인 입력 split으로 분리 된후 스필릿별로 맵 테스크가 실행 된다. Shard된 데이터를 MapReduce의 단계중 Map함수에서 데이터를 읽어 Reduce함수로 보내는 과정중 Shuffle이 발생하고 Shuffle 단계중 스필과 Reduce 함수 사이에서 데이터의 정렬과 병합이 일어 난다. Shuffle과정중 데이터의 정렬과 병합 과정은 Hadoop의 속도에 가장 영향을 주며 Hadoop에서 제공하는 기본 정렬기법은 작업처리시간이 증가하는 문제점이 발생 하였다. 이러한 문제를 해결하기 위해 본 눈문에서는 정렬알고리즘중 MapReduce에 가장 적합한 정렬알고리즘을 선택 후 제안하는 알고리즘과 함께 적용하여 실험하였다. ASA(American Standard Association:미국 규격협회)에서 제공하는 데이터중 16만건을 기준으로 실험 하였고 shuffle에서 정렬알고리즘의 퀵정렬을 사용하였을 때 Hadoop에서 제공하는 기본 정렬기법에 비해 약 30%이상 감소 하였다. 제안 알고리즘과 퀵정렬을 적용 했을 때 Hadoop에서 제공하는 기본 정렬기법에 비해 약 40%이상 감소 하였다.",
		"KEYWORD": "빅데이터 스필릿별,소셜네트워크서비스(SNS),스마트폰"
	},
	{
		"ID": 761,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "학습과정 관리를 위한 데이터 사이언스 활용 :위험그룹 예측을 중심으로 ",
		"AUTHOR": "최재원",
		"REGION": "경기도",
		"PROFESSOR": "아주대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 고 욱 참고문헌: p.91-100",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "빅데이터(Big Data) 시대를 맞이하여 사회 각 분야에서 데이터 사이언스 활용에 대한 관심이 증가하고 있다. 이러한 흐름은 교육 분야에도 영향을 미쳤는데 2000년대 초반부터 학습자와 학습 환경에 대한 다양한 데이터를 수집, 분석하고, 그 결과를 활용하여 학습 환경을 개선하고 효과적인 학습을 지원하는 방안에 대한 연구가 시작되었다. 이러한 연구에는 학습 콘텐츠 추천, 학생의 학업 성과 예측, 학생들간의 소셜 네트워크 분석 등이 있는데, 해외의 경우 학업 성과 예측(Prediction)은 가장 활발하게 연구가 진행되고 있는 분야이다. 이에 반해 국내의 경우, 학습에 관한 다양한 데이터를 통합적으로 수집, 분석할 수 있는 환경적, 제도적 인프라가 구축되어 있지 않기 때문에 아직 연구가 활성화되지 못하고 있다. 본 연구에서는 한국의 대학 교육 상황에서 학생들의 성적을 학기 초(학기의 1쿼터 시점)에 조기 예측하는 모형을 구축하고 모형에 투입된 데이터의 종류에 따른 모형의 성능을 평가하였다. 이를 위해 학습과 관련된 네 가지 범주의 데이터, 즉 인구통계학 데이터, 학교 생활 데이터, 심리 데이터, 학습관리시스템(LMS)데이터를 수집, 분석하였고 시험 성적 예측을 위해 다중회귀모형을, 최종 성적이 C학점 이하인 위험그룹 학생을 예측하기 위한 의사결정트리 모형을 구축하였다. 연구 결과 조기 예측 모형을 개발함에 있어 일부 영역의 데이터만을 활용하는 것 보다는 다양한 측면(학습자 개인, 학습환경, 학습과정)을 반영하는 서로 다른 범주의 데이터를 통합적으로 이용할 때 모형의 예측력이 가장 높았고 이러한 결과는 수치형(성적) 예측과, 범주형(위험군) 예측에서 동일하게 확인되었다. 수치형(성적) 예측에서 최적 모형은 학년(인구통계학 데이터), 직전학기평점(학교 생활 데이터), LMS 접속간격일, LMS 접속지연일수, LMS 과제제출횟수, 난이도가 높은 과제에 대한 선호도(심리 데이터) 예측 변인을 포함하였고 범주형(위험군) 예측 모형에서는 성격 5요인 중 신경성(심리 데이터), 직전학기평점(학교 생활 데이터), 학년(인구통계학 데이터), LMS 접속간격일이 의사결정트리의 분할 기준으로 이용되었음 확인하였다. 한편, 본 연구 결과의 의의와 관련해서 모형 연구가 일반적으로 안고 있는 일반화 가능성에 대한 제한점이 존재한다. 연구 대상으로 삼은 표본은 특정 단과대학 소속 학생들만 포함되었고 학업 성과 역시 수학적 지식을 요하는 과목이라는 특수성이 고려되어야 하므로 연구 결과를 모든 전공 학생들과 과목에 적용하기에는 무리가 있을 수 있다. 이러한 문제점을 해결하기 위해서 학습 환경과는 독립적인 변인과 학습환경에 종속적인 변인들에 대한 가중치를 조정하여 동일한 문화권(국가)내에서 전공(단과대학)에 따라 모형을 세분화하는 수준에서 일반화 가능성에 대한 해결책을 모색해 볼 수 있을 것으로 생각한다. 향후 학습환경의 디지털화는 더욱 가속화 될 것으로 예상되고 그러한 미래 환경에서 데이터 사이언스를 활용하여 학습과정과 교육현장에서 직면하는 다양한 문제를 해결하는 것은 매우 중요한 연구 분야가 될 것으로 기대하며 본 연구가 향후 이 분야 연구의 발전에 작은 밑거름이 되기를 희망한다.",
		"KEYWORD": "교육 데이터마이닝,데이터 사이언스,빅데이터,학습관리시스템,학습분석"
	},
	{
		"ID": 762,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 첨단영상대학원",
		"TITLE": "텍스트 시각화 이미지의 텍스트성 발현 양식 분석 =Analyzing pattern of manifestation of textuality in text visualization images ",
		"AUTHOR": "김효영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박진완 지도교수: 이상근 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "빅데이터 이슈의 확산과 데이터 이용 인구의 증가로 인지 불가능한 데이터를 시각적으로 표현하여 데이터의 의미와 숨은 정보 및 지식을 파악하고자 하는 요구가 급증함에 따라 데이터 시각화를 위한 표현 기법 또는 시각화 도구 개발 등의 관련 연구가 지속되고 있다. 그 중에서도 텍스트 데이터를 재료로 하는 시각화 연구가 최근 급증하는 추세를 보이고 있는데, 이는 현재 생산 및 유통되는 대부분의 문서가 디지털 문서의 형태를 갖는다는 점과, 기술의 발달로 점차 디지털 이전 시대에 출판되었던 모든 문서들이 전자문서화 되어가고 있는 시대적 상황에 기인한다. 이러한 상황에서 지식의 보고인 텍스트 데이터를 이용 및 처리하기 위한 다양한 연구와 시도들이 나타나고 있는데, 방대한 양의 데이터를 인간이 인지하기 용이한 시각적 형태로 표현하기 위한 다양한 연구들이 텍스트 시각화 분야에 등장하고 있다. 텍스트 데이터는 그 데이터의 특성상 언어의 형식을 갖으며, 따라서 개별 데이터 하나만으로는 의미 파악이 불가능한, 내용과 서사, 주제 및 줄거리를 갖는 의미의 구조체라 할 수 있다. 이러한 텍스트 데이터의 특성은 다른 데이터 시각화의 재료 데이터에서는 발견할 수 없는 독특한 특질로, 먼저 대상 데이터 자체에 대한 이해가 선행되어야만 한다. 이러한 맥락에서 본 연구는 텍스트 시각화를 위한 기초 연구로서, 텍스트가 데이터로서 갖는 고유한 특성에 대한 이해에서 출발하여, 이러한 텍스트 데이터가 시각화를 통해 이미지로 재현되는 과정에서 변형 또는 재 발현되는 텍스트성에 주목하고자 하였다. 언어와 이미지의 상호 관계에 대한 연구는 철학에서부터 언어학, 기호학에 이르기까지 오랜 시간 방대한 양에 걸쳐 지속되어 왔다. 본 연구는 기존 연구를 통하여 정립된 텍스트성을 기준으로 이를 텍스트의 시각적 변형물인 텍스트 시각화 이미지에서 발현되는 텍스트성을 분석함으로써, 텍스트 데이터의 특성에 대한 이해와 동시에 이러한 데이터의 특성이 시각적 표현 기법에 어떠한 방식으로 적용되는지 고찰하고자 하였다. 이를 위하여 먼저, 다양한 텍스트언어학자들의 텍스트 정의를 아우르면서 인간의 의사소통 기반 활동이라는 텍스트의 기본 맥락을 바탕으로 Beaugrande와 Dressler(1981)가 주장한 텍스트가 갖추어야 할 7가지 기준인 ‘텍스트성(textuality)’을 바탕으로 언어 텍스트 맥락에서 나타나는 텍스트성에 대한 체계적 정리를 선행하였다. 이후 이러한 문자 텍스트 중심의 텍스트성을 단순한 이미지가 아닌 텍스트 시각화 결과 이미지에 적용하기 위한 텍스트 속성 재정의 및 분류 작업을 거쳐 텍스트 시각화 결과 이미지가 시각화 과정을 위한 기본적 필요조건으로 작용하는 결속구조, 응집성, 의도성, 용인성을 ‘기본 속성’으로 정의하였다. 이러한 기본 속성을 근간으로 하여 이미지의 표현을 통해 그 속성을 발현하게 되는 정보성과 상호텍스트성을 각각 텍스트 시각화의 특징 속성으로 정의하고, 각각의 속성이 텍스트 시각화 이미지를 통하여 발현되는 양상에 대하여 다양한 사례 분석을 통하여 고찰하였다. 이러한 연구 과정을 통하여 도출된 결론은 다음과 같다. 첫째, 정보성은 텍스트 시각화 이미지가 갖는 특징속성으로, 정보의 요약과 압축, 데이터 참신성의 확보, 제작자의 해석의 개입, 데이터와 데이터 간의 비교, 데이터의 해체와 재구성을 통하여 시각화의 대상 텍스트가 갖는 정보성을 고도화 시켜 발현한다. 둘째, 상호텍스트성 또한 텍스트 시각화 이미지의 특징속성으로 기존 텍스트에서 나타나는 상호텍스트성을 시각화의 재료로 활용함으로써, 이미지 수용자의 배경 지식과 관습을 시각적 표현에 적용함으로써, 그리고 기존 시각화 표현 양식의 모방을 통하여 재료 텍스트가 갖는 상호텍스트성을 재 발현한다. 본 연구가 갖는 연구의 의의는 다음과 같다. 첫째, 다양한 데이터의 유형을 갖는 데이터 시각화 연구 중 텍스트 시각화에 초점을 맞추어 진행한 연구로서 점차 그 중요성이 증가하고 있는 텍스트 시각화 연구 분야의 이론적 기초로서 활용될 수 있다. 둘째, 언어 텍스트에 기반 한 텍스트성을 시각화 이미지에 적용하기 위하여 재정의 된 텍스트성의 개념은 향후 데이터 시각화 작품 뿐 아니라 기타 시각 이미지 작품의 분석 도구로서 활용 가능하며, 본 연구에서 제안하는 텍스트성의 이미지 적용 과정의 타 연구 적용을 통하여 다양한 이미지의 해석 방법 및 기준이 도출될 수 있는 가능성을 제시한다. 셋째, 데이터 시각화의 표현적 측면을 대상 데이터의 속성과 연결시켜 데이터 특성에 따른 시각적 재현 관계를 규명을 시도한 연구로서 효율적 표현 기법에 의해 제공 정보의 질과 수용의도 및 이해가능성이 좌우되는 데이터 시각화의 표현 측면 연구 전반에서 활용함으로써 궁극적으로는 데이터 시각화의 질적 향상에 기여할 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 763,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "학위",
		"YEAR": "2014",
		"UNIVERSITY": "대학",
		"TITLE": "Aided decision-making through visual analytics systems for large multivariate, spatiotemporal, hierarchical and network data ",
		"AUTHOR": "SungahnKo.",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 764,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "오픈소스를 활용한 결합형 데이터웨어하우스 구축에 관한 연구 =(A)study on the implementation of hybrid DW based on OSS ",
		"AUTHOR": "진도현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 양승민",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "모바일 인터넷과 소셜 미디어 서비스의 발달로 방대한 고객 정보들이 축적되고 있다. 이러한 대량의 복잡한 데이터 분석 요구사항을 이유로 기업의 경쟁력 강화를 위한 데이터 분석 기술은 통합된 데이터웨어하우스를 전제로 한다. 인프라 기술 측면에서 대용량 정형, 비정형 데이터를 효과적으로 관리하고 다양한 사용자의 접근을 효율화하는 것은 기존 데이터웨어하우스 환경만으로는 어렵다. 최근 오픈소스 빅데이터 기술의 도입으로 속도 및 처리능력의 확장성을 제공하지만, 중소기업관점에서 이를 도입하여 기술을 내재화하고 활용하는 것은 많은 어려움이 따른다. 본 논문에서는 오픈소스 빅데이터 처리 기술을 보다 효율적으로 사용할 수 있는 SQL on Hadoop 기술과 정보계 분석 전용 데이터베이스의 성능 한계를 극복하기 위한 MPP 기반 데이터베이스 및 오픈소스 툴들을 결합하여 기존의 문제점을 개선한 통합 데이터웨어하우스 시스템을 제안한다. 제안하는 결합형 시스템은 중소규모 데이터웨어하우스 도입 및 운영관점으로 범위를 최소화하여 연구함으로써 제한적인 비용 및 담당 기술 인력의 시간적 한계 속에서 효율적인 데이터 분석 환경을 구성 할 수 있다.",
		"KEYWORD": "Datawarehouse,DW,SQL on Hadoop,Tajo"
	},
	{
		"ID": 765,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한국산업기술대학교 대학원",
		"TITLE": "다차원 데이터 처리를 위한 맵리듀스 기반의 그리드 파일 생성기법에 관한 연구 ",
		"AUTHOR": "정주혁",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이상호",
		"STORE_LOCATION": "한국산업기술대학교 도서관",
		"ABSTRACT": "2007년부터 전 세계에서 생산되는 데이터양이 활용 가능한 저장 용량을 초과하는 데이터 홍수 시대, 즉, “빅데이터 시대”가 시작되었으며 향후에도 데이터는 기하급수적으로 증가하여 2020년에 이르면 현재 대비 50배로 폭증할 것으로 예측된다. 이에 따라 대용량 데이터에 대한 처리가 큰 이슈로 떠오르고 있다. 많은 기업에서는 대용량 데이터 처리의 중요성을 인지하고 이를 위해 많은 노력을 하고 있다. 현재 아파치에서는 대용량 데이터를 처리하기 위해 Hadoop을 개발하여 대용량 데이터 처리에 대한 해결책을 제시하고 있다. 하지만 대용량 데이터 중 영상, 의료 및 센서 데이터 등 다차원 데이터의 효율적인 처리방안에 관한 연구는 미비한 상태이다. 기존의 다차원 데이터 처리를 위해 다양한 다차원 색인 기법들이 제안되었지만, 이들은 단일 머신 하에서의 기법들이기 때문에 대용량 다차원 데이터 처리 시간 지연, 병렬처리의 한계 등의 비효율적인 측면이 많았다. 이러한 문제점을 해결하기 위해 본 논문에서는 다차원 색인 기법인 그리드 파일을 분산 처리 환경을 지원하는 하둡의 맵리듀스 기반으로 생성하는 기법을 제안한다. 또한 생성된 그리드 파일을 사용하여 질의 처리하는 방법을 제안한다. 본 논문에서는 제안한 그리드 파일 구축 기법과 질의 처리 기법의 우수성을 실험을 통해 보인다. 실험 결과는 본 논문에서 제안한 그리드 파일 구축 기법과 질의 처리 기법이 각각 기존 기법에 비해서 약 2.2배, 2.3배 빨리 처리함을 보였다.",
		"KEYWORD": "BigData,GridFile,Hadoop,MapReduce"
	},
	{
		"ID": 766,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "연관 규칙을 위한 상식 기반 유용성 척도 ",
		"AUTHOR": "이인기",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 용환승 참고문헌: p. 75-79",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "Since the introduction of data mining, more efficient and expansive mining algorithms aimed at detecting patterns and rules from mass data have been proposed, and more advanced research performance has been demonstrated. In particular, association rule mining has been widely used in diverse areas including commerce, communications, insurance, and bioengineering. However, together with such performance improvements, the sizes and dimensions of actual commercial databases have been greatly increased, and thousands?or even millions?of association rules requiring users’ analyses have been generated. Moreover, recent efforts to find useful knowledge from the huge volumes of data accumulated on the internet as well as countless electronic documents have focused on the potential problems of association rule mining and have been expanded to define different forms of interestingness measures. Interestingness measures, i.e., representative research on data mining post-processing techniques, which help users to interpret the meaning of knowledge by improving the quality of the generated rules and patterns, provide only useful rules to users. At the core of the quality evaluation of association rules, which are aimed at defining useful knowledge, lie users’ expressions of knowledge, which seek to screen out interesting knowledge they did not expect. In other words, the issues that should be resolved by this study include the knowledge environment of domains that objective measures to evaluate information theory-based association rules fail to consider, and users’ knowledge collection and application that may change according to age and experience. This study utilizes common sense for users’ expressions of knowledge. Common sense knowledge may be expressed as basic knowledge that is necessary for social communications but is uninteresting because it is predictable and already known to people. Therefore, the interestingness measures proposed by this study evaluate how close association rules are to common sense knowledge itself. These measures may be defined by utilizing the similarity between association rules and common sense knowledge expressed through natural language by common people. This similarity estimation is proposed so as to overcome the problems of similarity techniques, which are much used in existing text mining, and to more precisely measure semantic relatedness and the similarity of rules and common sense knowledge with different structures. In order to embody common-sense measures, interestingness measures based on common sense knowledge, association rules and common sense knowledge are defined as vectors in a vector space model. In order to find the common sense knowledge method closest to the association rules, common sense matching techniques of association rules using semantic networks are used. Such matching techniques enable the detection of common sense knowledge with the highest semantic-related similarity through common sense networks with consideration to the structural characteristics of association rules. The matched common sense knowledge outcomes are not restricted to mere sentence forms but include knowledge that may be inferred through common sense networks. In order to calculate the semantic-relatedness similarity between matched association rules and common sense knowledge in a vector space model, the cosine distance similarity technique with distance in semantic networks as weight is used. According to the results of the estimating similarity proposed by this study, higher evaluation results were obtained in a similarity evaluation of structured knowledge, like association rules and common sense knowledge, than in the existing similarity techniques used for text mining. The experimental evaluation result of the common-sense measures was compared with the result of the association rule evaluations by domain experts. This experimental result showed that, as we predicted, the common-sense measure and usefulness evaluation by experts were in inverse proportion. In other words, rules with a high common-sense measure were evaluated as not being useful rules by experts. The experimental result of the common-sense measures was consistent with 76 percent of experts, and 87 percent of those rules whose common-sense measure was 0.5 or higher were evaluated as not useful. The result also showed that unnecessary rules not removed by the existing objective measures were able to be screened out effectively. Therefore, it is anticipated that the common-sense measures proposed by this study will be used as a data mining post-processing technique for the quality evaluation of association rules in order to support analyses of users’ rules and patterns and to screen out only useful knowledge.",
		"KEYWORD": null
	},
	{
		"ID": 767,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "초 연결시대의 5세대(5G) 이동통신 기술과 웨어러블 디바이스 이용한 헬스케어 기술 구현 연구 =(A)study on the implementation of healthcare technology using 5th generation mobile communication technology and wearable devices in hyper-connectivity era ",
		"AUTHOR": "정성훈",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:정재진 참고문헌 : 57-58장",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "스마트폰의 등장으로 이동통신의 생태계에 큰 변화가 생겼다. 기존 이동통신의 환경은 폐쇄적인 환경이었지만, SNS의 등장으로 모든 사람들에게 개방적인 환경으로 이동통신 시장의 새로운 환경이 등장하게 되었다. 2020년에는 4세대(4G) 이동통신 시장을 넘어선 5세대(5G) 이동통신 시장이 구현 될 것으로 전망이 된다. 5세대 이동통신 대표적인 서비스는 홀로그램 및 멀티미디어 기반 서비스, AR/VR서비스, 초실시간 제공, Massive Connectivity 기반 IoT 서비스, 빅데이터 기반 지능형 서비스 등을 제공한다. 수 많은 5세대 이동통신 서비스에서 중에서 IoT 서비스와 빅데이터 서비스를 결합한 ‘지식정보통신서비스’를 통하여 인간친화적이고 사용자 맞춤형의 고차원 지식 서비스를 제공 할 것이다. 앞으로 기존 음성 및 데이터 통신의 한계를 넘어 모든 기기들이 연결되어 데이터를 전송할 수 있는 지식통신망을 만드는 것을 목표로 삼고 있다. 이에 본 논문은 초 연결 시대의 5세대 이동통신 기술을 기반으로 지식통신망 서비스의 발전을 통한 헬스케어 서비스 제공에 대해 분석하고 제안한다.",
		"KEYWORD": null
	},
	{
		"ID": 768,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "Finding the minimum MBRs embedding K points =k데이터를 포함하는 최소MBR 탐색 ",
		"AUTHOR": "KeonwooKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 769,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "명지대학교 대학원",
		"TITLE": "공공데이터를 이용한 기종점 통행량 추정방안 연구 =Origin-destination trip matrices estimation with open data ",
		"AUTHOR": "우왕희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조중래",
		"STORE_LOCATION": "명지대학교 도서관(서울),명지대학교 도서관(용인)",
		"ABSTRACT": "일반적으로 교통수요예측을 위한 기종점 통행량의 추정은 가구통행실태조사를 통해서 수집된 통행자료를 전수화하여 구축한다. 이는 시간과 비용이 많이 소요되어 현재 5년 주기 소존(행정동) 단위로 시행하고 있다. 소존의 경계 내에는 많은 노드와 링크가 존재하며, Assignment 수행시 Zone Connector에 직접 연결된 링크에는 교통량 집중 현상이 발생한다. 또한 Zone 내부에서 발생하는 통행량은 통행배정시 제외되는데 이러한 내부통행량이 전체 통행량 중에서 많은 비율을 차지하고 있다. 본 논문에서는 공공데이터를 이용하여 소존(행정동)보다 작은 규모인 Block 단위로 O/D를 추정하는 방안에 대한 연구를 수행하였다. Block 단위 Zone은 존경계 데이터와 Polygon으로 변환된 Link 데이터를 이용하여 구축하였다. Network는 KTDB에서 배포하는 자료를 이용하고, Block Zone의 좌표설정과 Block Zone과 Node간의 Connector 연결 작업은 프로그래밍을 통해 수행하였다. Trip Generation에 필요한 공공데이터는 건축물 연면적, 세대수 등으로 대부분 수집이 가능한 것으로 나타났으며, Block 단위 Trip Generation 추정이 가능한 것으로 나타났다. 목적 O/D를 추정하기 위한 주요 공공데이터는 국세청, 국민건강보험, 교육부, 신용카드업계가 보유하고 있는 개인관련 주소자료이다. 주소는 개인정보이기 때문에 Point 등으로 가공해서 배포해야 하는데 이러한 유형으로 데이터를 배포하는 공공기관은 현재 없는 것으로 나타났다. 수단 O/D 추정시 대중교통 O/D, 택시 O/D, 고속버스 O/D, 철도 O/D, 항공 O/D, 항만O/D는 구축이 가능한 것으로 나타났다. 공공데이터를 이용하여 오전첨두 출근?등교 목적 O/D와 수단 O/D를 추정하였다. 출근?등교 O/D를 추정하기 위해 필요한 공공데이터는 거주지 주소, 직장 주소, 학교 데이터이나 자료수집의 어려움으로 인하여 KTDB의 출근?등교 O/D를 Block 단위로 연령별 인구, 종사자수, 수용학생수 데이터를 집계하여 그 비율로 분할하였다. 대중교통카드 이용내역 데이터에서 출발시간기준 7시～9시 사이의 오전첨두 데이터를 추출하여 Bus, Subway Block O/D를 추정하였다. KTDB 출근?등교 Block O/D에서 Bus, Subway Block O/D를 제거하여 Auto, 기타 수단 O/D를 추정했다. 추정된 오전첨두 Block O/D 중 Auto, Bus O/D를 이용하여 Traffic Assignment 테스트를 수행했다. Block 단위 통행배정 방식이 소존(행정동) 단위 통행배정 방식에 비해 Zero Volume Assign Link의 개수가 감소했으며, 통행배정 관련 MOE 값도 상대적으로 우수한 것으로 나타났다. Block 단위의 대중교통 Assignment시 수행결과의 정확성을 높이기 위하여 Bus, Subway Block O/D Calibration을 수행하였다. 대중교통카드 데이터의 Station별 승하차량과 Assignment 결과를 비교하여 오차가 최소가 되는 Station 접근거리를 검토하였다. Origin Block의 거주인구와 Board Station과의 거리에 의한 분포비율, Destination Block의 종사자수?수용학생수와 Alight Station과의 거리에 의한 분포비율을 기준으로 KTDB O/D를 분할하여 Assignment를 반복적으로 수행하였다. 검토결과 Block의 적절한 Station 접근 반경은 Bus, Subway 모두 1,000m인 것으로 나타났다.",
		"KEYWORD": "공공데이터,교통수요,기종점통행량,빅데이터"
	},
	{
		"ID": 770,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "GPU와 CPU를 이용한 베이시안 데이터 감축 알고리즘의 병렬화 =Parallelizing Bayesian data reduction algorithm using GPU and CPU ",
		"AUTHOR": "김인우",
		"REGION": "인천",
		"PROFESSOR": "",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "최근 IT 산업 전반에서 빅 데이터라는 용어가 사용되기 시작하였다. 스마트 폰을 비롯한 모바일 디바이스의 발달과 페이스북, 트위터 등으로 대표되는 SNS는 하루에도 수백 테라바이트 이상의 데이터를 만들어 내고 있는데, 정부나 기업에서는 이렇게 만들어진 데이터를 이용하여 정책 개발, 미래 예측, 상품개발, 마케팅 등 다양한 분야에 활용할 수 있다. 이러한 빅 데이터를 분석하는 기술로는 기계 학습, 자연어 처리, 데이터 마이닝 등이 있는데 이러한 데이터 분석 기술에 관한 관심이 증가하고 있다. 이에 따라, Dr. Robert Lynch는 BDRA(Bayesian Classification and Feature Reduction Algorithm)라는 데이터 마이닝 알고리즘을 제안했다. 이 알고리즘은 다른 데이터 마이닝 알고리즘과 비교하여 상대적으로 적은 연산으로도 신뢰할만한 마이닝 결과를 보여준다. 그렇지만 BDRA는 탐욕(greedy) 알고리즘을 사용하기 때문에 대상 데이터에 따라 항상 최적의 결과를 제시하지 못한다는 단점이 존재한다. 항상 최선의 결과를 보장하기 위해서는 탐욕 알고리즘을 제거하고 조합 가능한 모든 경우의 수를 계산해야하는데, 이는 데이터가 커질수록 연산 시간이 크게 증가하게 된다. 이러한 문제점을 극복하고자 본 논문에서는 병렬시스템을 이용한 BDRA의 개선 기법에 대해 제안한다. GPU와 CPU를 사용하여 병렬화를 수행하고, 입력된 데이터에 따라 적절한 병렬화 기법을 사용함으로써 데이터의 연산 시간을 줄임으로써 조합 가능한 모든 경우의 수를 계산하고 기존의 알고리즘과 비교하여 수행시간에 있어 큰 차이가 없도록 개선함으로써 항상 최선의 결과를 보장할 수 있도록 알고리즘을 개선하였다.",
		"KEYWORD": null
	},
	{
		"ID": 771,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "계명대학교 대학원",
		"TITLE": "Requisite skills and knowledge of data scientists :데이터 과학자에게 필요한 스킬과 지식에 관한 연구 :content analysis of internet job advertisements =인터넷 구인광고 내용 분석 중심으로 ",
		"AUTHOR": "김존요한",
		"REGION": "대한민국",
		"PROFESSOR": "지도교수: 유상진",
		"STORE_LOCATION": "계명대학교 동산도서관",
		"ABSTRACT": "최근 기업들은 시장에서의 경쟁우위를 점하기 위한 빅데이터 분석 능력의 중요성을 깨닫기 시작했다. 하지만, 이를 가능하게 해주는 적절한 자원을 보유하지 못한 기업들에게는 쉽지 않은 일이다. 따라서 기업들은 대량의 데이터를 분석하는 능력을 지닌 전문 인력을 수급하기 위해 노력하기 시작했다. 기존에 일반적으로 데이터 분석을 이행해 왔던 컴퓨터 사이언스, 통계, 그리고 비즈니스 인텔리전스 인력들은 해당 분야 지식만 가지고는 필요한 분석 업무를 수행하기에는 부족했다. 따라서 기업들이 필요로 하는 빅데이터 분석을 해줄 새로운 종류의 전문가 집단인 데이터 과학자가 등장하게 되었다. 데이터 과학자는 상당히 최근에 등장한 직종으로, 아직 그 정의가 불분명하고 이해가 부족한 편이다. 데이터 과학자와 관련된 연구는 매우 적으며, 학계에서는 아직 많은 의견들이 혼재되어 있다. 그러나 구인 시장은 이미 데이터 과학자를 찾는 수요가 높다. 이미 다수의 기업들이 자신들의 실질적인 필요를 바탕으로 한 데이터 과학자에 대한 정의를 내리고 있다. 데이터 과학자라는 직업이 실용적인 목적을 위해 탄생 하였기에, 실질적으로 데이터 과학자를 고용하는 기업들이 제시하는 데이터 과학자에 대한 윤곽이 가장 정확할 수 있다. 이 연구의 목적은 이러한 기업 및 산업에서 받아들여지는 모습을 통해 데이터 과학자의 정의를 탐구하고, 그에 필요한 스킬과 지식에는 어떠한 것들이 있는지 밝히는 것에 있다. 또한 데이터 과학자로 전향하고자 하기 위해 필요한 조건에 무엇이 있는지 조사하는 것이다. 기업에서 실질적으로 요구 되어지는 지식과 스킬을 이해하기 위해, 본 논문에서는 온라인 구인 사이트를 통해 데이터 과학자 구인광고를 모으고 분석하였다. 1240개의 구인광고에 대한 내용분석이 진행되었다. 그 결과, 데이터 과학자는 석?박사 이상의 학위를 지닌 경력이 풍부한 전문가가 요구되었다. 핵심 역량은 통계, 모델링, 기계학습, 그리고 분석기법 이었으며, 대부분의 데이터 과학자는 R이나 Python 프로그래밍 언어 사용 능력을 지니도록 요구 되었다. 또한, 데이터 과학자라는 직업은 비즈니스 인텔리전스 분석가, 데이터 분석가, 경영과학 분석가, 통계학자, 그리고 프로그래머/분석가와 같은 기존의 직업들과는 분명한 차이가 존재함을 볼 수 있었다. 이러한 결과들은 데이터 과학자 직업을 추구하기 위해 필요한 스킬에 대한 시사점을 제공하며, 인접 분야의 학생 및 인력들이 데이터과학 분야로 전향하기 위해 계발해야 하는 지식과 스킬을 제시한다. 본 연구의 한계점은 다음과 같다. 첫째, 구인 광고는 이상적인 후보를 묘사하기 때문에 그 내용이 실질적으로 고용 되어진 데이터 과학자와 차이가 있을 수 있다. 둘째, 본 연구에서는 미국 구인광고만을 대상으로 분석하였기 때문에 연구의 범위가 데이터 과학자 인력 시장 전체를 포괄하지 못한다. 셋째, 내용분석을 위한 분류 체계가 데이터 과학자 스킬을 중심으로 설계 되어 비교한 다른 직종들에게 일부 불리하게 편향 되었을 수 있다. 데이터 과학자는 최근에 등장한 성숙하지 못한 분야이기 때문에 향후 지속적으로 변화하고 진화할 확률이 높다. 따라서 본 논문의 한계점을 보완하고, 지속적인 진화 과정을 추적하기 위해, 대상과 시간의 범위를 넓힌 연구가 향후에 계속 지속되어야 한다.",
		"KEYWORD": "Content Analysis,Data Scientist,Job Advertisement,Skills,Transferability,데이터 과학자"
	},
	{
		"ID": 772,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한국산업기술대학교 지식기반기술·에너지대학원",
		"TITLE": "DistributedCache를 이용한 Hive 조인최적화기 설계 및 구현 ",
		"AUTHOR": "정형용",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 이정준",
		"STORE_LOCATION": "한국산업기술대학교 도서관",
		"ABSTRACT": "In recent years, there is growing interests and studies in big data. In the past, it was impossible to utilize Big Data due to its high cost and the lack of analyzing and managing techniques. However, recent advances in Cloud-Computing technologies make it possible to manage and analyze Big Data more easily and cost-effectively. Thus, Big Data is being used in a wider range of fields such as politics, society, economy and culture. Cloud-computing is being applied to the field of existing data warehouses. A data warehouse operates big databases which are created by integrating and extracting data from a variety of operating systems. Its key features are represented by many repeating query patterns and large amounts of data to be uploaded periodically. In this system, Hadoop and Hive are also utilized to process large amounts of structured and unstructured data. Apache Hadoop is an open source project which is considered as a typical Cloud-computing technology. It consists of Hadoop Distributed File System (HDFS) for storing large amounts of data and MapReduce for distributed processing of large amounts of data. Hive is based on the Hadoop and provides an SQL-like language called HiveQL to use and maintain MapReduce more easily. However, Hadoop and Hive, unlike a traditional relational DBMS, have characteristics which have to be considered for efficient data processing operations because they have a different structure from a relational DBMS. MapReduce has a shared nothing structure in which large data sets are processed for Hive and Hadoop. MapReduce have a simple structure for data processing while it has the advantage to get a variety of input data. The MapReduce process can be divided into Map and a Reduce. Distributed data is processed on each Map node, and the results are moved to a few Reduce nodes for processing further. At this point, bottleneck takes place in data transfers between the Map and Reduce stages in the distributed structure, since it is the unique point that the massive data transfer over network occurs at. In this paper, we improve join operation of Hive, which is one of the most expensive operations in Hive. Hive basically uses Reduce-Side Join. The Reduce-Side Join requires high costs by the network bottlenecks mentioned above and by sorting data. In this paper, we use filtering techniques to improve the join operation of Hive. The join key values are extracted from the results of the previous query, and a filter is created by using these values. If there is a similar query, the filter is used to eliminate records which are unnecessary to create the join results, from each Map node before they are transferred to Reduce nodes. As a result, we can reduce network bottlenecks caused by Reduce-Side join and high costs caused by data sorting. We propose a Bitmap for Interval Filter (BIF) to remove the records which are not required for join results. Since a relational database mainly uses integers as join keys, we assume the join keys is the integer data type in BIF. In case of dealing with big data, there are too many integer join key values extracted from the pre-processing query results; therefore, it is very inefficient or impossible for each map node to load these keys in memory and to use them as filters. In this paper, the integer domain is divided into intervals and they are checked if there exist join key values generated by query execution in each interval. After that, the existences of join key values in the each interval are expressed and saved as a bitmap, which is utilized as a filter. We modified Hive to make it transfer the bitmap to each Map-node via Distributed Cache and remove the records not required for join results from Map nodes. As a result, this method reduces bottlenecks caused by data transmission to Reduce-nodes and high costs caused by sorting the data. Experiments were conducted by varying the data size and the number of Hadoop nodes which Hive is based on. The impact of intervals in the BIF also examined. The Hive with BIF showed normal operations inboth binary join and multi-way join. Also, it showed better performance as the number of nodes increases. Regarding the query with about 15% join selectivity, the Hive with BIF showed up to 25% performance improvement with the binary join, compared to the Hive. In addition, it showed up to 38% performance improvement with the multi-way join. Furthermore, regarding the query of about 15% join selectivity, it showed always more than 20% better performance than the Hive even if the data size increases. In addition, the process for creating the BIF had little effect on performance. In conclusion, in this paper, we proposed the concept of the BIF. Also, we applied and implemented it to the Hive. During Hive query execution, the BIF divides the domain of the join keys of the records participating in Join operations into the intervals and existences of the join key values in each interval are expressed in the form of a bitmap. When there is a similar query, the BIF is distributed to each node to remove the records which belongs to the filter-out interval. The proposed BIF enables a memory-optimized filter. BIF make it possible to filter more than the existing methods introduced in other papers. In addition, the Hive with BIF showed better performance due to the reduced network bottlenecks during Hive query execution and the sorting process. The proposed Hive with BIF can be utilized in various areas in which the traditional Hive is used, and the BIF can also be utilized in MapReduce joins in Hadoop. Furthermore, it can be highly recommended to use the Hive with BIF in data warehouse systems. In the future research, the BIF is necessary to extend its application to other data types, while it is currently applicable only to the join keys of integer data type; In addition, it is necessary to research on more effective BIF intervals for various distributions of join key values",
		"KEYWORD": "BIF,Bitmap for Inter Filter,Hadoop,Hive,조인최적화기"
	},
	{
		"ID": 773,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "홍익대학교 국제디자인전문대학원",
		"TITLE": "인터페이스 환경변화에 따른 인터페이스 3.0에 관한 연구 :(A)study on interface 3.0 :ICT기기를 중심으로 =focused on ICT devices ",
		"AUTHOR": "전소현",
		"REGION": "서울",
		"PROFESSOR": "홍익대학교 논문은 저작권에 의해 보호받습니다. 지도교수:나건 참고문헌 (p.153-158)포함",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "The study is an attempt to understand the future ICT device market by strategically redefining interface that used to have limited usage to some degree in the changing interface environment, and to add value to products and provide them more durability as a mega-trend by presenting improved interface. With rapid technology development, progress has been made in a major part of interface. Some of the progress were expected and have been verified with time. Moore’s law saying that the number of transistors on integrated circuits doubles approximately every two years has contributed to the development of systems that have been applied to diverse fields of human life. With high-tech development and decrease in product sizes and prices, various new ICT devices such as smart phone, PDA, digital camera and MP3 player have been produced. Besides, as platforms like internet have been developed and novel networks such as GPS and Bluetooth widely used, a content-based new software market has emerged, and mobile-based applications such as SNS and Cloud service have taken center stage. The changes have rapidly permeated all strata of society, transcending place, time and method. As a result, communication and interaction methods of people have been changed. The interface environment is transforming with technology development and change of multilateral factors in society and economy, which has significant effects on design. Socially, population aging and low birth rate issues have come to the fore and the size of households is getting smaller from family-based households to one-person households. Communication methods are also changing in the same direction. Economically, value shifting has taken place from traditional hardware manufacturing industry to new manufacturing and service industries distributing contents based on ICT, in other words, to a software market. Technologically, scientific technology has shown innovative development, which resulted in increased functional complexity. Communication between things as well as between human beings started to take place and the system has been embedded in most products. The communication method and functional complexity have brought about a rapid change of the interface environment, which, in turn, is heavily influencing design. The most notable change was made in smart design due to the traits of ICT devices, among four mega trends in design: universality, durability, sensibility based on analog, and smart design. As mentioned above, ICT devices are closely related to technology development in particular, and the interface is considered to serve as a means adding durability to smart design, one of the mega trends. According to Crossing the Chasm by Geoffrey Moore, when the performance, reliability and cost do not satisfy consumer needs, the market is led just by initial adopters who have a tendency of early adopters and are users eager to adopt the technology early. However, most of the general customers belong to late adopters who accept only the technology that has been tested, and want usability, great user experience and value. As a design method to create ICT devices with durability that cross the chasm and satisfy the desire of late adopters, namely, general customers, it is necessary that multilateral studies be conducted on the interface that provides usability and great user experience, and the extent of the interface be strategically broadened according to the change in the interface environment. Therefore, the study strategically expanded the definition of interface to interface 1.0 as place where independent systems meet and interact, interface 2.0 as interaction that takes place in the place, which includes the meaning as a means, and interface 3.0, as Eco-system surrounding the Place and Means. In addition, by organizing terms that used to have narrow meanings, or mixed usage, analyzing the related technology, predicting the future interface environment with scenarios based on persona, and suggesting an interface circumstances of @Home, @Work and @3rd Place for ICT devices, this study aims to lay the foundation for understanding and assessing the interface environment for ICT devices of the near future.",
		"KEYWORD": null
	},
	{
		"ID": 774,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "대구한의대학교 대학원",
		"TITLE": "귀무가설을 이용한 유의한 증상 조합 도출 방법 연구 ",
		"AUTHOR": "오용택",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 김은하",
		"STORE_LOCATION": "대구한의대학교 학술정보관",
		"ABSTRACT": "1) 연구목적 본 연구에서는 한의학 전문가들의 분석 과정을 대신하여 빅데이터나 실시간으로 데이터가 축적되는 임상 빅데이터 등에 적용이 가능한 유의성 있는 증상 조합을 분석할 수 있는 방법을 찾고자 하였다. 2) 연구방법 귀무가설을 이용한 수학적 방법으로 상대적 다빈도 증상-치법 조합을 찾은 후 이를 전문가의 증상-치법 조합 유의성 분석 결과와 비교하여 상대적 다빈도 조합이 유의함을 확인한 후 동의보감 주치데이터에 본 연구 방법을 적용하여 유의한 증상 조합을 찾았다. 3) 결론 본 연구에서는 다음과 같은 결론을 얻었다. (1) 상대적 다빈도 조합은 전문가의 조합 유의성 분석 결과와 어느정도 일치하여, 목적에 따라 상대적 다빈도 조합을 유의한 조합으로 판단하고 활용할 수 있음을 알 수 있었다. (2) 문자로 구성된 조합의 상대적 다빈도 조합을 구하는데 있어 귀무가설을 이용한 수학적 방법은 적절하였다. (3) 痛症의 치료와 관련된 처방에서 찾아낸 유의성 있는 증상-증상, 증상→조건, 조건→증상 조합은 39개가 있었다. 본 연구가 『東醫寶鑑』에서 痛症 관련 처방의 정보에 국한하여 진행된 것이라는 한계가 있으나, 이는 연구 대상 데이터의 영역을 확대하는 것으로 극복할 수 있다. (4) 다만 “특정 연구 대상에서 등장 횟수가 상대적으로 많은 조합이 그렇지 않은 조합보다 유의할 가능성이 높다”는 가정에서 벗어난 조합은 찾을 수 없으며, 등장 횟수가 상대적으로 많진 않으나 유의한 조합 역시 찾을 수 없다는 한계가 있어 가정을 검증하는 연구나 가정 외의 조합도 찾을 수 있는 연구가 지속되어야 한다.",
		"KEYWORD": "귀무가설,증상조합,증상치법조합"
	},
	{
		"ID": 775,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "강원대학교 대학원",
		"TITLE": "RDBMS 기반 하둡 메타데이터 관리의 설계 및 구현 =Design and implementation of RDBMS-based metadata management of Hadoop ",
		"AUTHOR": "손시운",
		"REGION": "강원도",
		"PROFESSOR": "강원대학교 논문은 저작권에 의해 보호받습니다. 지도교수:문양세 참고문헌 : L. 57-59",
		"STORE_LOCATION": "강원대학교 도서관",
		"ABSTRACT": "In recent years, Big Data has become a hot research topic due to the occurrence of a huge volume of data, and Hadoop has been widely used in many areas as a representative Big Data technique. Hadoop is an open source framework that stores and processes the large-scale data in multiple distributed nodes, and it is constructed by a master and slave architecture. Hadoop manages all metadata in NameNode to store and process big data of multiple nodes. In particular, the original Hadoop manages all metadata in main memory of NameNode, which is corresponding to a master node. Also, it manages all update logs in separate files of a local file system. However, this legacy method incurs severe memory overhead in NameNode because the metadata rapidly increases as the amount of data increases, or the Hadoop cluster is extended. Also, users and applications which want to access Hadoop metadata must go through NameNode in the legacy Hadoop. In this paper, we solve these problems by improving the metadata management scheme of Hadoop by two stages. In the first stage, we analyze ACL metadata information first, and we then change Hadoop by managing the ACL information in RDBMS rather than in main memory. For this, we redesign the management scheme of ACL information and actually implement the scheme in Hadoop. We next verify the validity of RDBMS-based ACL management by testing a series of use cases of HDFS ACL. Through this implementation, we can solve the limitation of 32 ACL files/directories, which is enforced in the legacy Hadoop system to reduce the memory overhead. In the second stage, we extend the metadata management scheme by moving all Hadoop metadata from memory to RDBMS. We present an overall architecture, related database design schema, and implementation details for the enhanced RDBMS-based metadata management. We then make a series of test scenarios for all Hadoop operations and prove its validity through testing the scenarios. We believe that this is an outstanding research effort that significantly enhances stability of Hadoop by reducing the overhead of NameNode, and at the same time, it proves scalability of Hadoop by allowing many external users and applications to independently access Hadoop without passing NameNode.",
		"KEYWORD": "HDFS,RDBMS,메타데이터,빅데이터,하둡"
	},
	{
		"ID": 776,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "공공도서관의 희망도서 이용에 관한 연구 :수서 및 대출데이터 분석에 기초하여 ",
		"AUTHOR": "조영희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 남영준",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "I investigated the percentage of the user application materials of public library. I examined the utility of data by checking the record of the circulation. In order to examine the validity of the book selection, I analyzed the use factor by carrying out correlation analysis with circulation information and material selection. I used the data of the 22 public libraries in the Seoul City, and the data were collected by using SQL, an analysis method of the database. The collected data were 1,075,007 of bibliographic data and 11,992,347 of circulation data. Summary of the research results and recap below. First, the books of user application accounted for 16.4% of the collection of the Public Library. Second, with the results of analyzing the circulation number of books and circulation frequency, the ratio of the book collected by the library became 87.5% and the ratio of application library users was 97%. The ratio of Application books of user was 15% higher. If you look at the circulation number of book, the number of the library selection materials was 10.49 times, and the number of user application materials was 14.52 times. The frequency of user application materials was founded to be as high as 1.5 times. When the circulation number based on one or more borrowed book was checked, The frequency of the library selection materials was 12 times, and that of the user application materials was 15. That of the user application materials is 1.25 times more. Third, the correlation analysis was done in selection and circulation to know the validity of this selection. The result of the analysis was that the library selection materials was higher than the user application materials in correlation though the both were a very high correlation. Also, when I analyzed the Use factor, it seemed that the library selection materials and user application materials had been actively used. Use factor of the library selection materials is higher. It is expected that the results of this study become the basic data for collection development efficient. Since this is a study based only on quantitative aspects, it is not possible to make generalized collection evaluation. Therefore, in-depth research in the future will be actively engaged by the qualitative value such as the user satisfaction research.",
		"KEYWORD": null
	},
	{
		"ID": 777,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "고려대학교 공학대학원",
		"TITLE": "특허 청구범위 키워드를 이용한 구간별 기술트렌드 분석 및 기술 예측 =Period technology trend analysis and technology forecast using patent claim keyword ",
		"AUTHOR": "김시용",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 朴相城 참고문헌: 장 53-54",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "제4차 산업혁명(fourth industrial revolution, 4IR)은 산업사회가 새롭게 변화하는 시대로, 로봇을 기반으로 인터넷과 인공지능 등의 기술이 융합되어 변화하는 시대를 말한다. 이에 따라, 로봇과 인공지능에 대한 관심도가 국가적으로 매우 높아지고, 국가나 기업이 많은 비용을 투자하고 있는 실정이며, 로봇과 인공지능에 대한 기술개발이 더욱 활발하게 이루어지고 있다. 특히, 로봇은 산업용 로봇과 서비스용 로봇으로 분류되며, 향후 로봇산업의 발전은 물론, 어떠한 분야의 개발이 이루어질 것인가에 관심이 모아지고 있다. 또한, 로봇산업에 대해 분석하고자 할 때, 이용할 수 있는 데이터가 특허데이터이다. 이 특허데이터 중에서 청구범위는 권리를 행사할 수 있는 내용이 작성됨에 따라, 청구범위를 분석하면 로봇산업의 R&D를 진행할 수 있다. 이러한 R&D는 특허데이터의 분석을 통하여 기술트렌드를 파악할 수 있으나, 빅데이터의 특허데이터를 분석하는 시간이 오래 걸리고 분석하는 전문가의 주관적인 성향에 따라 달라질 수 있다. 이에 따라, 본 연구에서는 로봇의 기술 트렌드 및 변화를 특허데이터의 청구범위를 통해 기술 트렌드를 분석하고, 향수 기술을 예측하고자 한다. 이를 위하여, 먼저 로봇분야의 특허데이터를 수집하고, 수집한 특허데이터를 2년 단위로 총 10구간으로 분할한다. 그리고 분할된 각 구간별 청구범위 중 독립청구항을 텍스트마이닝하여 독립청구항에서 사용된 용어를 추출한다. 추출한 용어를 빈도순으로 나열하여 N-gram 데이터로 추출하고, N-gram 데이터마다 연결관계를 통하여 각 구간별 키워드를 추출한다. 그 후, 각 구간별 키워드를 이용한 기술 트렌드를 분석한다. 기술 트렌드 분석과 더불어 구간별 변화를 파악할 후, 향후 기술을 예측해본다. 따라서, 본 연구를 통해 빅데이터의 객관적인 분석으로 기술 트렌드 분석과 변화에 따른 향후 기술을 예측할 수 있는 전략을 수립하고자 한다.",
		"KEYWORD": "N-gram,기술트랜드,청구범위,텍스트마이닝"
	},
	{
		"ID": 778,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인천대학교 정보기술대학원",
		"TITLE": "데이터베이스 질의어 감리점검항목 도출을 통한 감리개선방안 =System audit improvement through identifying database query audit inspection item ",
		"AUTHOR": "김종원",
		"REGION": "인천",
		"PROFESSOR": "지도교수:최진탁",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "최근 공공기관 및 민간기업의 빅 데이터 이슈와 데이터 관리의 중요성이 증가됨에도 불구하고 실질적으로 데이터베이스 품질에 대한 감리 활동이 미흡한 상황이다. 데이터베이스 시스템은 데이터 구조 설계가 사업목적에 타당하게 설계 구축되었다 하더라도 이를 사용하는 개발자의 숙련도에 따라 데이터베이스 시스템의 응답속도나 성능에 크나큰 영향을 미치게 됨에도 불구하고 데이터베이스 질의어에 대한 점검은 감리 시 비중 있게 다루어지지 않고 있다. 또한, 정보시스템 구축 시 데이터베이스의 비가시적인 특성으로 인하여 프로젝트 구축단계에서 구축된 비효율적 SQL은 운영 시 시스템 전반의 성능에 큰 영향을 미치고, 운영개선업무 또는 차세대 프로젝트로 전가되기 쉽다. 이에 데이터 서비스 품질의 확보 차원에서 데이터베이스 질의어에 대한 감리점검항목을 도출하고 이를 정확하고 신속하게 진단할 수 있는 감리 진단도구가 필요하다. 본 연구에서는 데이터 품질관리 관점에서 이를 관리하는 지표 등을 도출하고, 감리 시 점검목록으로 반영 하여, 이를 점검할 수 있는 지표를 제시할 것이며, 정보시스템감리에서 효율적인 데이터베이스 감리진단 업무가 수행될 수 있도록 감리지원 점검도구를 개발하고, 감리수행 활동에 대한 지원 가능성을 제시하여 체계적인 감리 활동을 지원할 수 있는 방안을 제시하였다.",
		"KEYWORD": "SQL,데이터 품질,데이터베이스감리,자동화 도구,질의어 점검"
	},
	{
		"ID": 779,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "대용량 데이터 기반의 통신망 관리 시스템의 개선방안에 관한 연구 =(A)study on the enhancement process of the telecommunication network management based on large-scale data ",
		"AUTHOR": "구성환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신민수 권두 국문요지, 권말 Astract 수록 참고문헌 : p. 87-97",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "시장의 변화 및 소비자의 요구 변화를 비롯한 기업 내외부의 상황변화에 대응해서 얼마나 빠르게 적응할 수 있는가 하는 것이 실시간 기업의 핵심요건이다. 이러한 실시간 기업이 가진 변화의 속도를 지원하기 위해서 최근 대용량 데이터 처리 기술이 각광받고 있다. 특히 최근 유무선 통신망의 진화 및 고도화가 가속되고 있는 상황에서 대규모 통신 트래픽을 실시간으로 처리하여 안정된 서비스를 제공하는 것과 강력한 보안 관제 기능은 매우 필요하다. 본 논문에서는 선행연구로 실시간 기업의 정의, 클라우드 컴퓨팅, 대용량 데이터 처리 기술에 대해서 고찰하고 기존 통신망 관리 시스템이 안고 있는 문제점을 정리하였다. 더불어 통신망 구축을 둘러싼 경영층의 요구사항을 정리하여 기존의 문제점을 개선하고 경영층의 요구사항을 반영한 대용량 사용자 데이터 분석 기반의 통신망 관리 시스템을 설계 및 구현하였다. 구현된 시스템은 클라우드 컴퓨팅 인프라를 기반으로 하여 오픈소스인 Hadoop 프레임워크를 적용하였다. 고속의 통계 데이터 처리를 위해서 메모리-HDD 형태를 결합한 하이브리드 DBMS를 추가 적용하였다. 기본적인 대용량 데이터 정보처리 Flow는 소스데이터 수집 -> 데이터 통합과 관리 -> 데이터 분석과 결과 제시 -> 결과의 발견과 개선으로 이루어진다. 이러한 정보처리 Flow을 지원하기 위해서 본 논문에서는 각 단계별로 솔루션을 제시하였다. 먼저 소스 데이터 수집단계를 위해서는 실시간 Packet을 수집하여 전처리 하기 위한 PCS(Packet Capture System)을 설계 및 구현하였으며 각종 교환장비 및 M2M 단말에서 전송하는 장애 이벤트 데이터를 수집하기 위한 CEP(Complex Event Processing) 서버를 구현하였다. 데이터 통합과 관리단계를 위해서는 오픈 소스인 Hadoop 프레임워크를 기반으로 컴퓨팅 자원을 가상화 시키고 분산 파일 시스템과 Map-Reduce기법을 도입한 NMS(Network Management System)플랫폼 을 구현하였다. NMS 플랫폼은 소스 데이터 수집 단계에 있는 PCS와 CEP 서버를 통해서 수집된 데이터를 실시간으로 처리하여 저장한다. 데이터 분석과 결과 제시 단계에서는 데이터 통합과 관리단계에서 저장된 데이터를 가상화된 메모리 영역으로 로딩하여 사전에 정의된 통계 스케줄링을 실행하여 데이터를 분석한다. 이 단계에서는 메모리-HDD기반의 하이브리드 DBMS 솔루션을 도입하여 처리하였다. 대용량의 데이터를 메모리 영역에서 처리하기 때문에 고속으로 처리가 가능하며 불필요한 데이터는 HDD로 파일형태로 전송하여 저장시킨다. 끝으로 결과의 발견과 개선 단계에서는 데이터 분석과 결과 제시 단계에서 분석된 데이터를 운영자 GUI을 통해서 실시간으로 제시하며 필요한 의사결정을 내릴 수 있도록 지원하는 역할을 수행한다. 운영자는 제공된 데이터를 기반으로 실시간으로 필요한 정책을 변경하여 적용할 수 있고 데이터 분석과 결과 단계에서 추출된 데이터는 기존의 경영 프로세스 및 운영 프로세스에 정확하고 유연성 있는 데이터를 제공함으로써 실시간 경영 및 데이터 중심의 BI(Business Intelligent) 시스템을 운영할 수 있는 기반을 확보하게 되었다. 구현된 시스템의 성능을 검증한 결과 NMS 플랫폼에서 처리되고 관리되는 데이터는 기존에 운영중인 경영 관리 시스템(IT-OSS)에 연동 인터페이스를 통해서 실시간으로 제공됨으로써 경영층이나 임직원들은 현재 및 과거의 통화품질 통계나 장애 알람 통계 데이터를 손쉽게 접근할 수 있게 되었다. 또한 경영상의 정책 변경이 발생한 경우 기존에는 최소 일주일 이상이 걸리던 작업이 5분 이내로 실행되어 거의 실시간으로 적용되는 효과를 거두었다. 실시간 통합 관제 기능이 적용됨에 따라서 기존에는 장비별로 개별적인 운영관리 시스템을 통해서 관제기능을 수행함으로써 장애 발생 시 영향도 파악 및 장애 감지시간이 오래 걸렸지만 제안된 시스템에서는 통합된 장비 관제 기능을 구현함으로써 장애 발생 시 영향도 및 장애 감지 시간을 기존의 60분에서 5분 이내로 대폭 낮추었다. 이러한 성능개선의 효과는 실시간 Packet을 수집, 처리, 분석하기 때문에 가능하였다. 다른 사용자의 인증정보를 이용하여 불법적으로 서비스를 이용하는 불법 호 시도는 통신사업자에게 많은 비용을 발생시켰다. 이에 통신사업자들은 다양한 불법 호 시도 검출 알고리즘을 개발하였지만 이러한 시도는 교환장비에서 15분 마다 생성하는 CDR 데이터를 기반으로 분석하기 때문에 필연적으로 늦은 대응이 될 수 밖에 없는 구조였다. 하지만 제안된 시스템은 실시간으로 모든 사용자 데이터를 수집하는 구조이기 때문에 1분이내에 불법 호 시도를 검출하고 즉시 차단하는 기능을 수행할 수 있다. 이러한 구조 덕분에 기존에는 불법 호를 탐지하는데 20분의 지연시간이 발생하였지만 지금은 1분이내로 탐지할 수 있게 되었다. 실제 이러한 기술 적용으로 A 기업은 불법 호 시도 비용을 기존대비 90%까지 낮출 수 있게 되었다. 본 논문은 기존의 통신망 관리 시스템이 가진 문제점과 경영층의 요구사항을 기반으로 클라우드 인프라 기술과 대용량 데이터 처리, 분석 기법을 적용함으로써 복잡화되고 있고 사용자 데이터가 급격히 증가하고 있는 통신사업자의 경영환경을 실시간 기업의 형태로 전환할 수 있도록 지원할 수 있게 되었다.",
		"KEYWORD": "경영정보"
	},
	{
		"ID": 780,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "하둡에서 대규모 소형파일 문제 해결을 위한 클러스터링 기반의 Map/Reduce 성능을 개선하는 데이터 병합 기법 =(A)data merging technique based on clustering for solving problems of massive small files in Hadoop with performance enhancement of Map/Reduce ",
		"AUTHOR": "이원재",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박석 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Hadoop is a framework which stores and processes a large volume of data efficiently and the most typical one supporting the era of Big data. In light of this fact, the number of Internet applications providing various data services based on Hadoop is increasing sharply. However, Hadoop is not good at dealing with a number of data consisting of very small-sized files but good at dealing with a small number of data consisting of very big-sized files. If Hadoop is utilized for the former, It may suffer from considerable performance degradation, also called small files problem. Therefore, many Hadoop-based applications generating the very small-sized files can’t easily achieve advanced QoS. In this thesis, I explained some disadvantages Hadoop has when dealing with the very small-sized files and suggested a data merging technique based on Clustering to solve this problem. In particular, Resolving the traditional small files problem, the proposed technique focuses on improving degraded latency of Map/Reduce analysis taking a number of data consisting of very small-sized files as input, which existing techniques have not resolved effectively. For this, I explained some factors that affect the latency of Map/Reduce analysis and made the data merging technique include Mixed Integer Programming appropriately reflecting these factors.",
		"KEYWORD": null
	},
	{
		"ID": 781,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "성균관대학교 정보통신대학원",
		"TITLE": "데이터 중심의 상호운용성 관리를 통한 정보화 정책 개선에 관한 연구 :(A)study on the improvement of information policy based on data-driven interoperability management :데이터 거버넌스 모델을 중심으로 =focusing on data governance model ",
		"AUTHOR": "오창익",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 朴炅珍 참고문헌 : p. 100-102",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "인터넷을 중심으로 네트워크의 성능과 규모가 확대됨과 동시에 다양한 기기들에 정보처리 기능이 내장되어 네트워크에 연결됨에 따라, 정보통신기술의 적용 범위가 양적이나 질적으로 급속히 팽창하고 있다. 이러한 추세를 반영하여 네트워크 중심의 지능화된 정보화 환경을 구축하기 위해서는 다양한 융합기술을 탑재한 제품을 개발하거나 도입하여야 한다. 따라서 기존의 업무 처리용 정보관리시스템 운용 환경에 비해 훨씬 복잡하며, 이들을 서로 연계하여 통합 시스템을 구축하는 과제는 지금의 정보화 거버넌스 체계로는 풀기 쉽지 않은 문제이다. 이러한 문제를 해결하기 위해서는 1) 조직 전체의 정보자원을 일관성 있게 통제하기 위한 기준인 EA 구축 및 유지 관리, 2) EA를 통해 정보자원을 통합하기 위한 상호운용성 관리, 3) 상호운용 중에 발생하는 정보의 손실 또는 침해를 막기 위한 정보보호 활동 등이 필요하며, 이를 체계적으로 정렬하여 거버넌스 체계에 포함하여야 한다. 또한, 현재의 정보화 거버넌스의 중점 관리 요소도 기존의 HW, SW를 벗어나 보다 근본적인 자원인 데이터로 전환하여야 한다. 데이터는 정보통신기술의 근원이며 조직의 핵심 자산으로 새로운 지식을 무한히 만들어낼 수 있는 경쟁력의 원천이다. 본 연구에서는 기존의 소프트웨어 공학, 개발 방법론, 정보화 정책 등에서 비중 있게 다루지 않았던 데이터 품질과 상호운용성을 조합하여, 다수의 정보시스템을 조직의 목표에 부합하도록 개발하기 위한 정보화 거버넌스 모델을 제안하였다. 정보시스템 구축 사업 추진 절차에 개선 모델을 적용하여 기존 방식과 비용 중심으로 비교함으로써 효과를 검증하였고, 모델에 포함되어 있는 프로세스를 시행하기 위한 데이터 관리 전담 조직의 업무를 구체화하여 제시하였다. 추가적으로, 데이터 중심의 정보화 환경 구축 모델을 사례와 함께 제시하고 평가를 통해 검증함으로써, 이를 관리 전담 조직의 혁신적인 업무로 제안하였다. 본 연구를 통해 데이터 품질 관리에 있어서 통합적 관점의 접근으로 보다 체계적인 품질 관리체계를 확립하는 기초를 제공하였고, 기존의 상호운용성 통제 모델에 있어서도 연계 데이터 관리에 집중하도록 개선하여 보다 효율화된 모델로 활용이 가능토록 하였다. 이는 데이터 중심으로 정보화 정책과 사업 관리 절차를 재편하기 위한 과학적인 근거를 제공하는 데에도 의의가 있다. 소방, 치안, 국방 등 정부부처 뿐 아니라, 병원, 유통업 등 다양한 최신 정보기술이 지속적으로 도입되고 이들이 모두 네트워크에 연결되어 정보를 주고받는 업무환경이 필요한 조직에는 반드시 적절한 정보화 거버넌스 모델이 필요하다. 데이터 거버넌스 모델은 현재와 미래의 복잡한 정보통신 기술 도입에 대한 의사결정과 사업 관리에 대한 기준 모델로서, 통제 대상을 단순화, 집중화하여 정보화의 성과를 극대화하는 데 기여할 뿐만 아니라, 임베디드SW 중심의 정보기술 융?복합 체계에 있어서도 공통 기준으로써의 데이터에 대한 적절한 통제를 통해 데이터를 중심으로 정보화 거버넌스 대상 영역을 확대하는 효과를 제공한다.",
		"KEYWORD": "데이터 거버넌스,데이터 품질,상호운용성,연계 데이터,정보화 정책"
	},
	{
		"ID": 782,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 정보통신대학원",
		"TITLE": "선순환적 플랫폼을 활용한 공공정보의 효율적 제공방안 =Efficient methods to provide public information by utilizing the virtuous cycle platform ",
		"AUTHOR": "이경수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김문현 부록: 연구논문 설문조사 결과 참고문헌: p. 108-110",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "스마트폰의 등장은 일상생활과 밀접한 관련이 있는 교통, 기상, 환경 등의 공공정보를 모든 국민이 접할 수 있는 빅데이터로서의 활용가치와 관련 산업을 활성화시켜 경제성장의 원동력으로 평가받는 계기가 되었다. 2000년대 중반 이후 세계 각국은 인터넷의 양방향성에 주목하고 공공정보 개방정책에 시민의 참여를 확대시켜 나가고 있다. 공공정보의 효율적 개방은 공공정보 이용자 측과 제공자 측 모두에게 도움이 되고 이용자와 제공자가 협력할 수 있는 협업채널을 확보하여야 한다. 양방향적 협업채널을 확보하는 것은 단순한 공공정보 개방이나 양적규모 확대를 강조하는 것이 아니라 개인이나 기업이 개방된 공공정보를 능동적으로 활용할 수 있도록 데이터를 개방하고 이용자의 다양한 활용 수요에 효율적으로 대응할 수 있도록 다양한 부가기능이 제공되어야 한다. 본 논문에서는 공공정보의 효율적 제공을 위한 세 가지 방안을 제시하였는데 첫 번째는 오픈소스 데이터 플랫폼인 CKAN의 다양한 기능과 평준화된 기술을 활용하여 선순환적 플랫폼을 구축하는 것이고, 두 번째는 사회적 이슈사항 반영과 이용자 의견수렴을 위한 크라우드소싱 워킹그룹 활용하는 것이다. 마지막 세 번째는 데이터셋을 모바일 인터넷 단말기 이용환경에 적합한 시각화 된 형태의 데이터를 원데이터와 함께 개방함으로써 이용자의 선택권을 보장하고 활용편의를 위한 모바일 웹 UI를 도입하는 것이다. 한국은 CKAN과 같은 오픈소스 데이터 플랫폼의 핵심 모듈을 사용하면서 생산ㆍ제공자로서 정부와 이용자인 개인ㆍ기업이 단방향적 기능만 수행하고 있어, 이용자의 융합ㆍ매핑ㆍ매쉬업 된 창의적 데이터의 효과적인 활용을 지원하지 못하고 있다. 공공정보의 효율적 제공을 위해서는 오픈소스 데이터 플랫폼의 다양한 기능과 평준화된 기술을 적극 활용하고 공공정보에 기반 한 이용자의 재생산 데이터를 플랫폼에 개방할 수 있도록 선순환적 플랫폼을 구축하여야 한다. 선순환적 플랫폼 구축은 소셜 플랫폼의 소통, 창의, 신뢰를 바탕으로 참여ㆍ협업 정신을 실현하고 기술적으로는 오픈소스 데이터 플랫폼의 개방성ㆍ양방향성 기능에 착안한 것이다. 공공정보 공유 플랫폼에는 이용자가 재생산한 매쉬업 데이터를 플랫폼에 등록할 수 있는 별도 메뉴 신설과 다른 이용자의 피드백을 위한 평가하기, 활용신청 등 선순환적 기능이 설계에 반영되도록 하여 이용률 제고와 고품질의 데이터 생산에 기여할 수 있도록 하여야 한다. 두 번째 제안은 크라우드소싱 워킹그룹 활용이다. 크라우드소싱은 무선인터넷 기술의 발달과 많은 온라인 커뮤니티 이용자들을 기반으로 집단지성을 활용한 문제해결 방안으로서, 크라우드소싱은 집단지성을 활용하여 공공정보 데이터셋이 가진 문제들을 효율적으로 개선할 수 있으며 기관마다 강점있는 분야의 업무 특성을 반영하여 특화된 크라우드소싱 워킹그룹을 운영하는 것이다. 일반적으로 크라우드소싱은 아이디어 수집, 기업 혁신, 효율적 문제해결 방법 정도로 인식 되었지만 국내에서는 민간부문 이외의 공공정보 개방정책에 크라우드소싱을 활용한 사례는 확인하지 못했지만, 미국의 경우에는 지식발견과 집단지성 분산작업 등의 공공영역에서 폭넓게 활용되고 있어 한국실정에 맞게 공공정보 개방정책에 활용을 제안하였다. 세 번째 방안은 데이터셋을 모바일 인터넷 단말기 이용환경에 적합한 시각화 된 형태의 데이터셋을 원데이터와 함께 개방하는 방안을 제안한다. 현재 국내 공공기관에 운영 중인 공공정보 공유 플랫폼은 대부분 동일한 데이터를 중복 개방하거나 링크서비스를 제공함으로써 콘텐츠와 기능에 차별성이 없기 때문에 데이터셋은 정부가 추진한 행정업무 전산화의 성과물로서 사회적 이슈사항을 반영하지 못하거나 시의성이 없을 뿐만 아니라 즉시 업데이트가 필요한 경우도 있다. 게다가 스마트폰의 급격한 보급으로 인하여 스마트폰 이용자의 높은 인터넷 활용률을 감안한다면 모바일 인터넷 단말기 이용자 환경에 적합한 공공정보를 개방하는 것은 개방목록의 양적 확대 못지않게 중요한 과제이다. 하지만 이미 공공정보 공유 플랫폼에 개방된 대부분의 데이터셋은 이용자의 인터넷 이용환경을 감안하지 않고 단일 문서 형태로만 개방되어 있다. Open API와 달리 데이터셋은 어플리케이션 소스로 사용되기 보다는 단순 조회용으로 활용되는 것이 일반적이다. 이용자의 데이터 뷰를 감안하면 정부는 모바일 이용환경에 적합한 그리드, 차트, 이미지, 매핑지도 등의 다양한 형태로 변환, 가공하여 원데이터와 함께 개방함으로써 이용자의 선택권을 보장할 수 있도록 하여야 한다. 엑셀형식은 상용 시각화 도구를 활용하면 제공자는 데이터 변환이 용이하고 이용자는 데이터 내용을 이전보다 쉽고 오래 기억할 수 있다. 아울러 많은 이용자가 변환된 데이터를 편리하게 활용할 수 있도록 모바일 웹 UI의 도입도 적극 검토하여야 한다. 공공정보의 효율적 제공방안으로 제시한 위 세 가지 개선안에 대한 적용가능성과 실효성 검증을 위하여 공무원 및 일반인을 대상으로 설문조사를 실시하였다. 응답자 108명은 선순환적 플랫폼 구축 등 1안 69.5%, 크라우드소싱 워킹그룹 활용 2안 61.2%, 데이터 시각화 등 3안 69.5%가 ‘그렇다’나 ‘매우 그렇다’는 긍정적인 답변을 보였고 특히, 공공정보 서비스를 사용하는 응답자는 이보다 3～4% 포인트 높게 평가하는 것으로 조사되었다.",
		"KEYWORD": "공공데이터,공공정보,선순환,플랫폼"
	},
	{
		"ID": 783,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "대규모 소형 이미지 데이터의 분산 데이터베이스 저장 및 처리 성능 분석 =Storing and processing performance comparison of large volume of small image data on distributed database systems ",
		"AUTHOR": "옥돌샘",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:나연묵 참고문헌 : 23-24 장",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "현대 우리사회는 매순간 엄청난 규모의 디지털 데이터가 생산되는‘빅데이터’시대다. 기존 데이터베이스 시스템으로는 빅데이터를 감당할 수 없어 분산 데이터베이스 플랫폼이 등장하게 되었고 많은 기업들이 이를 이용한 데이터베이스 시스템을 구축하고 있다. 본 논문에서는 대규모 소형 이미지 데이터가 발생하는 웹 환경을 가정하여 분산 데이터베이스 시스템의 저장 및 처리 성능을 측정하고자 한다. 다양한 빅데이터 관련 시스템 중 기본 프레임워크라 할 수 있는 Apache Hadoop을 파일 저장 시스템으로 사용하고 이와 연계가 용이한 Apache HBase를 데이터베이스 관리 시스템으로 활용하여 분산 데이터베이스를 구축한다. 데이터를 압축하거나 병합하여 저장시간을 측정하고 이미지 외곽선 검출에 걸리는 시간을 비교하여 데이터 저장 및 처리 성능이 향상되었는지 확인해본다.",
		"KEYWORD": null
	},
	{
		"ID": 784,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "확장이 용이한 실용적 대용량 고속 스토리지 시스템 연구 =(A)study on scalable, cost-effective, high-capacity, high-speed storage systems ",
		"AUTHOR": "김태진",
		"REGION": "서울",
		"PROFESSOR": "국, 영문초록수록 指導敎授 : 盧三赫 참고문헌(장 75-79)수록",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "최근 클라우드 및 엔터테인먼트 데이터의 급속한 증가가 발생되고 있으며 이러한 데이터 증가로 인해 빅데이터 (Big Data) 시대가 촉발하였다. 과거에는 경험하지 못했던 규모의 데이터 증가는 지금까지의 스토리지 시스템에서 더 이상 감당하기 어려운 문제점들이 발생하기 시작하였으며, 이와 관련한 많은 연구들이 진행 중이다. 본 연구는 기존 국내외 스토리지 기술과는 다르게 Ethernet 네트워크 저장장치 기술인 E-AD 기술과 분산파일시스템의 표준 기술인 NFS을 활용한 차별화 된 스토리지 시스템 기술 연구이다. 데이터 저장 방식으로 사용하는 E-AD 기술의 장점은 Ethernet 네트워크에서 무한히 장착이 가능하고 가격 면에서 부담이 없다. 데이터 관리 방식으로 사용하는 NFS는 시스템 간의 호환성을 보장해주며, 최근에 pNFS 기술까지 포함되어서 고성능 데이터 입출력이 가능하게 되었다. 본 연구는 E-AD기술과 NFS을 활용하여 스토리지 시스템을 구현하였으며, 다양한 실험과 벤치마크를 수행하였다. 디스크, 파일, 파일 크기, 클라이언트 수 증가에 따라서 스토리지 시스템의 확장성 보장을 확인하였으며 벤치마크를 통해서 NFSv4 방식의 스토리지 시스템 보다 우수함을 보였다. 특히 클라이언트 증가로 발생되는 각 클라이언트의 성능 저하를 디스크 확장을 통해서 해결 할 수 있음을 실험을 통해서 보였다. 마지막으로 작은 읽기 연산의 성능 개선과 pNFS 성능 강화에 영향을 주는 디스크 구성을 제시하고 있다.",
		"KEYWORD": null
	},
	{
		"ID": 785,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "메모리 사이즈가 하둡과 스파크의 성능에 미치는 영향 분석 =Impact analysis of memory size on Hadoop and Spark processing performance ",
		"AUTHOR": "한승혜",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수: 나연묵 참고문헌: 29 장",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "스마트폰과 PC, 웨어러블 컴퓨팅 기술의 발달에 따라 거대한 양의 데이터가 빠른 속도로 생성되고 있다. 이러한 데이터를 단일 컴퓨터에서 처리하기에는 컴퓨팅 성능의 한계에 대한 부담이 따른다. 분산 처리는 데이터를 여러 서버에 분산 저장하여 동시다발적으로 처리하는 기술이다. 분산 처리를 활용하여 데이터를 처리하는 경우 서버의 수평적 확장이 가능하여 컴퓨팅 성능의 한계에 대한 부담이 적다. 대표적인 오픈 소스 분산 처리 플랫폼으로는 아파치 하둡(Apache Hadoop)과 아파치 스파크(Apache Spark)가 있다. 하둡은 저장소인 HDFS(Hadoop Distributed File System)와 처리 알고리즘인 맵리듀스(MapReduce)를 이용하여 데이터를 저장하고 처리한다. 하둡은 디스크 기반 기술이기 때문에 물리적인 처리 속도로 인한 작업 성능의 한계를 가지고 있다. 특별히 데이터 세트에 대한 접근이 빈번하게 발생하는 머신러닝과 같은 반복 작업에 취약하다. 이러한 한계를 극복하기 위한 목적으로 아파치 스파크가 설계되었다. 스파크는 메모리 기반의 오픈 소스 빅데이터 플랫폼으로 RDD(Resilient Distributed Dataset)의 개념을 도입하여 메모리에 입력 데이터 세트를 생성하는 방식으로 메모리 속도의 빠른 연산을 가능하게 한다. 하지만 스파크 역시 입력 데이터 세트를 메모리에 저장하여 처리하는 특수성 때문에 처리 성능이 메모리 캐시 크기와 같은 물리적 자원에 의존적이라는 한계가 존재한다. 하둡과 스파크는 분산 빅데이터 처리 플랫폼이라는 측면에서 공통점을 갖지만 그 처리 방법이 다르기 때문에 두 플랫폼의 성능 비교에 관한 연구가 진행 중이다. 스파크는 하둡 반복 작업의 한계를 극복하기 위한 목적으로 설계되었지만 하드웨어 자원에 의존적이기 때문에 하둡의 처리 성능을 대체할 수 있는지에 대한 연구가 진행 중이다. 본 논문에서는 메모리와 같은 물리적 하드웨어 자원이 빅데이터 처리 성능에 미치는 영향을 확인하기 위한 목적으로 하둡과 스파크 클러스터의 메모리 사이즈가 제한된 실험 환경을 구성한다. 구성된 클러스터가 다양한 사이즈의 입력 데이터를 처리하는데 소요되는 시간을 측정하고 분석하여 메모리 사이즈가 하둡과 스파크의 처리 성능에 미치는 영향을 확인한다.",
		"KEYWORD": null
	},
	{
		"ID": 786,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "충남대학교 대학원",
		"TITLE": "규모확장성 있는 인터넷 트래픽 분석 시스템 ",
		"AUTHOR": "이연희",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수:이영석 참고문헌 : p. 113-118",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "Internet traffic measurement and analysis has been used for a long time to analyze and monitor the status of the network devices and links, and the behaviors of the network user. Recently, due to the disseminateion of the mobile devices, the enhancement of the Internet connection technology, the network analysis job has been faced with many challenges in the aspects of the its scalability and its managability. This paper suggests a Hadoop-based scalable traffic measurement and analysis system to perform scalable and flexible analysis on the network data. We presents the platform for the analysis of the packet, NetFlow, and BGP data, and suggests algorithms that perform IP, TCP, HTTP, and NetFlow analysis of multi-terabytes of Internet traffic in the MapReduce manner on top of Hadoop. For the ad-hoc query from the user, we adopted SQL-like query interface using Hive that can run the MapReduce Job. From experiments with a large-scale Hadoop cluster up to a 200-node testbed and case studies, we shows the scale-out feature of our approach using commodity hardware. We discuss the issue of the realtime analysis and presents the case study of the realtime DDoS detection. We believed our approach to the distributed traffic measurement and analysis with Hadoop is the first attemp that dealed the network data within the Bigdata context and considered with many different use cases. We expect that it will progress to the comprehensive network analysis infra according to the Bigdata technology and gives the insight of the Internet system.",
		"KEYWORD": null
	},
	{
		"ID": 787,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "관동대학교 대학원",
		"TITLE": "Big Data를 이용한 실시간 관광정보 SNS 이슈분석 플랫폼 설계 =(A)platform design for a tourism SNS issue analysis in real time using big data ",
		"AUTHOR": "유지대",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 이병관",
		"STORE_LOCATION": "가톨릭관동대학교 중앙도서관",
		"ABSTRACT": "요약 네트워크 기반의 소셜 정보인 SNS(Social Network Service)의 회원 수 및 활용 빈도수는 현재 폭발적으로 증가하는 추세이다. 따라서 회원에게 필요한 정량적 정보를 가장 빠르게 제공해 주기 위한 정책이 절실히 필요하게 되었다. 제안한 논문에서는 SNS사이트를 통하여 게더링 한 정형화 된 이슈 정보를 빅데이터의 하둡과 같은 엔진을 이용하지 않고도 정량적 정보로 DB화 및 시각화 서비스할 수 있도록 한다. 먼저, 정책수립 단계에서 SNS에 업데이트된 문장을 수집한 후 필요한 데이터를 필터링하기 위한 정책을 생성하며, 신뢰성 있는 데이터만을 수집하기 위해 SNS 데이터의 감성정보를 추출, 추적, 분석을 수행한다. 이렇게 생성된 감성정보와 필터링 정책을 병렬검색 및 집중검색에 적용하여 강한 신뢰형 감성정보 즉, SNS의 대량의 데이터 가운데 최종 사용자가 필요한 정보만을 추출하여 DB화 한다. 결국, 검증된 SNS회원의 유효 정보를 경험자를 통하여 예비경험자에게 제공함을 목적으로 하며, 더욱이 하둡을 배제한 빅데이터 설계 및 시각화 서비스 구현을 최종 목적으로 한다.",
		"KEYWORD": "Big Data,real time using Big Data,관광스케쥴링,빅데이터,실시간 관광정보"
	},
	{
		"ID": 788,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "시계열 데이터 전처리와 특징 선택을 활용한 기계 학습 기반의 주가 예측 모델 =(A)machine learning-based stock prediction model using time series data preprocessing and feature selection ",
		"AUTHOR": "박종일",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 양지훈 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "A stock index is one of the important indices to forecast the economy and business. There have been many researches on the prediction of stock market. Stock index and price is time series data and it has a correlation with other economy and business indices. This paper compares and evaluates various algorithms to find the prediction model that has the cost effectiveness and accuracy. We use many stock indicies from important countries’ stock indices such as Dow Jones, Nikkei, Dax as well as economy indies such as a rate of interest, USD exchange rate and WTI. This paper uses the technical indices of moving average and Relative Strength Index (RSI) to preprocess the data such as removing the noise of time series data and keeping the stationary. In addition, this paper uses Granger Causality Test (GCT), Principal Component Analysis (PCA) and Recursive Feature Elimination (RFE) as feature selection methods to find the effective feature subsets. We use Support Vector Machine (SVM) and Artificial Neural Network (ANN) learning algorithms to train and predict data along with feature selection methods and the data preprocessing. We introduce the Receiver Operating Charateristic (ROC) curve and the Area Under the ROC curve (AUC) to compare the performance. Briefly, in Artificial Neural Network (ANN), data preprocessing with Recursive Feature Elimination (RFE) and Granger Causality Test (GCT) show the performance enhancement by 36.1%~37.6% against without the preprocessing, without the feature selection methods, and by 6.7% against without feature selection methods. Normally, we can assume that it would mean the decrease of the cost of big data processing such as the computation complexity, storages size, and data gathering time via network.",
		"KEYWORD": null
	},
	{
		"ID": 789,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "동서대학교 대학원",
		"TITLE": "(An)efficient PKI-based authentication protocol and secure data storage framwork using ECC in cloud storage =클라우드 스토리지에서 ECC를 사용한 효율적인 PKI-기반 인증 프로토콜 및 보안 데이터 스토리지 프레임 워크 ",
		"AUTHOR": "XiaoChunYin",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 790,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "마이그레이션 사업 성공 요인에 관한 연구 :(A)study on the factors making migration business into success :최신 IT 플랫폼을 중심으로 =focusing on the advanced IT platforms ",
		"AUTHOR": "김성덕",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수:한경석 참고문헌 수록",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 IT 시장은 전통적인 IT 기술 및 서비스 영역에서는 성장의 한계를 나타내지만 클라우드 컴퓨팅, 빅 데이터, 오픈소스 소프트웨어, 사물인터넷, 핀테크에 이르기까지 IT 역사에서 가장 혁신적인 플랫폼이 출현하여 시장을 주도하고 기업의 성장과 경쟁 측면으로 새로운 변화를 주도하고 있다. 기업에서 최신 IT 플랫폼 환경을 갖추기 위해서는 마이그레이션이 필수적으로 동반됨에 따라 본 연구에서 최신 IT 플랫폼을 중심으로 마이그레이션 사업에 대한 성공 요인을 연구하고자 하며 Davis의 기술수용모델을 이용하여 최신 IT 플랫폼 수용 의도에 영향을 미치는 조건과 요소에 대한 연구 모델을 설정하고 수용 의도에 대한 외부 변수로는 시스템 기능성, 시스템 보안성, 시스템 혁신성, 시스템 신뢰성 그리고 가치 측면에서 경제적 가치와 감성적 가치를 관련성 지각의 선행 요인으로 설정하여 실증 분석을 하였다. 연구 방법은 최신 IT 기술 동향 및 시장 현황을 조사하고 최신 IT 플랫폼 중 기업에 가장 큰 변화와 영향을 미치는 클라우드 컴퓨팅, 빅 데이터, 오픈소스 소프트웨어 대한 문헌 조사를 하고 IT 기술 전환 및 유사한 서비스의 도입 및 수용에 미치는 영향에 대한 문헌과 사례를 조사하였다. 최신 IT 플랫폼을 활용 중이거나 관련성 있는 IT 관련 업무 종사자를 대상으로 Sample Survey 방법으로 설문조사를 하고 분석을 위해 변수의 타당성 및 신뢰성 검증을 위해 SPSS를 활용한 탐색적 요인 분석을 측정 모델의 적합도 및 신뢰도/타당성 검증을 위해 AMOS 활용한 확인적 요인 분석을 하였으며 최종 가설 검증을 위해 구조방정식 모델 분석을 하여 검증하였다. 실증 분석 결과 15개의 가설 중 4개의 가설이 기각되고 11개의 가설이 채택되었으며 인지된 유용성과 인지된 용이성 모두 최신 IT 플랫폼 전환 수용의도에 긍정적인 영향을 미치는 것으로 검증되었다. 시스템 신뢰성과 경제적 가치는 유용성을 인지하는데 영향을 미치지 않고 시스템 기능성과 시스템 혁신성은 사용자에게 사용 용이성을 인지하는 요인으로 영향을 미치지 않음을 알 수 있다. 결과를 요약하면 사용자가 IT 환경에 덜 익숙하고 기업의 효율성, 생산성 향상을 목표로 시스템을 도입하던 초기 IT 시장에서 사용 용이성의 중요성은 이용자가 IT 환경에 익숙한 최근 IT 시장에서는 IT 기술의 동향, 특징, 비즈니스 환경 등 IT와 비즈니스 측면에서 편리성, 안정성 등 인지된 용이성보다 위험도가 상대적으로 높을지라도 경쟁력 제고시킬 수 있는 인지된 유용성이 전환수용에 높은 영향을 미치는 중요 요인임을 판단할 수 있다. 또한, 클라우드 컴퓨팅, 빅 데이터, 오픈소스 소프트웨어와 같은 최신 IT 플랫폼은 전문 분석 기관과 IT 회사에서 기술적 성숙도와 높은 완성도를 강조하지만, 기업의 사용자들은 기업에 미치는 변화와 영향이 큼에 따라 기술에 대한 더욱 높은 완성도와 신뢰도를 요구하고 있음을 알 수 있고 최신 IT 플랫폼으로의 전환은 큰 비용이 소요되며 최신 IT 플랫폼의 수용에 가장 큰 영향을 미침을 판단할 수 있다. 전문 분석 기관과 IT 기업은 클라우드 컴퓨팅 환경과 오픈소스 소프트웨어와 같은 최신 IT 플랫폼은 앞으로 운영 방식과 다양한 기법에 따라 기업의 ROI를 극대화할 수 있다고 주장하지만, 사용자는 초기 전환에 드는 막대한 비용에 대한 부담이 수용에 큰 영향을 미침을 판단할 수 있다. 인지된 유용성에 대한 가설 검증 결과를 보면 최신 IT 플랫폼으로의 전환이 유용하다고 인지하는 가장 큰 요인은 시스템 기능성으로 나타났으며 이는 기업이 급변하는 비즈니스 환경에 민첩하게 대응하고 경쟁사 대비 차별화된 경쟁 요소를 갖추기 위해서는 최신 IT 플랫폼의 시스템 기능이 유용하다고 판단함을 알 수 있다. 최신 IT 플랫폼 기술 환경이 상대적으로 현재 시스템 환경 대비 정보 및 데이터에 대한 접근 통제, 개인정보의 보호 체계, 외부에서 해킹 등에 대한 위협 공격의 대비 정도 등 시스템 보안성 부분에 대해서도 유용하다고 판단함을 알 수 있다. 인지된 용이성에 대한 가설 검증 결과를 보면 최신 IT 플랫폼은 지금까지와는 차원이 다른 다양한 기능과 사용자의 요구 사항에 대해 다양하고 민첩한 서비스 구현 능력과 혁신적인 서비스가 기업의 경쟁력과 가치를 높일 수 있음을 강점으로 주장하지만, 사용자는 아직 제공되는 기능과 오류에 대한 완성도, 시스템 혁신성 등이 최신 IT 플랫폼 이용의 편리함을 인지하는 수단으로 설명되지 않는 것으로 보이며 이는 초기 도입 단계로 현행 시스템 환경보다 사용자의 친숙도, 편이성 부분에서 미흡함을 판단할 수 있다. 하지만 시스템 보안성은 유용성을 인지하는데 영향을 미치는 요인으로 분석된 것과 마찬가지로 최신 IT 플랫폼의 각종 보안에 대한 요인이 사용의 편리성을 인지하는 요인으로 영향을 미침을 알 수 있다. 사용자는 보안성과 더불어 최신 IT 플랫폼에 대한 신뢰가 결국 사용을 편리하게 하는 수단이라고 본 연구 결과에서는 설명하고 있다. 연구 결과에 대한 시사점은 최신 IT 플랫폼은 분명 기업의 가치 창출과 경쟁력 제고를 위해 다양한 기능과 수단으로 활용",
		"KEYWORD": "IT Platform,마이그레이션,빅데이터,오픈소스소프트웨어,클라우드컴퓨팅"
	},
	{
		"ID": 791,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "사용자 관심 이슈 분석을 통한 추천시스템 성능 향상 방안 =Improving recommendation systems using topic modeling ",
		"AUTHOR": "최성이",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김남규 참고문헌 수록",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "많은 기관들이 데이터에 기반을 둔 의사결정을 수행해 왔으며, 특히 수치자료를 비롯한 정형 데이터가 이러한 목적으로 널리 활용되어 왔다. 하지만 최근에는 스마트기기와 소셜미디어의 발달로 인해 다양한 형태를 가진 방대한 양의 정보가 축적되면서, 전통적인 정형 데이터 기반 의사결정으로부터 비정형 빅데이터 기반 의사결정으로 관심의 전환이 이루어지고 있다. 데이터 기반 의사결정의 대표적 분야인 추천시스템 분야에서도 성능 향상을 위해 비정형 데이터를 활용해야 한다는 필요성이 최근 꾸준히 제기되고 있다. 특히 사용자의 성향이나 선호도는 고객의 니즈와 직결되기 때문에, 비정형 데이터 분석을 통해 사용자의 성향을 파악하고 이를 통해 상품 추천 및 구매 예측의 정확도를 향상시키기 위한 노력은 매우 시급하게 이루어질 필요가 있다. 따라서 본 연구에서는 사용자의 성향을 측정하여 재구매 카테고리의 예측 정확도를 높임으로써, 궁극적으로 추천시스템의 성능을 향상시킬 수 있는 방안을 제시한다. 구체적으로는 사용자의 일상적인 인터넷 사용 패턴을 분석하여 다양한 이슈에 대한 고객의 관심을 계량화하고, 이를 활용하여 고객의 카테고리별 재구매 여부를 예측하는 모델을 제안하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 792,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "기계학습을 이용한 특허문서의 다중 IPC 자동분류 방법 ",
		"AUTHOR": "박찬정",
		"REGION": "서울",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수:성동수 참고문헌 : p.101-111",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "Recently, interest in big data has grown all over the world. To this end, the analysis of the technical documents such as papers and patent documents on the online, and studies on the extraction of useful information are being carried out actively. In particular, patent documents contain technically diverse contents and other technical documents can be written relatively in the objective form. Also a patent document is given to the patent classification codes such as IPC, and the technique of the patent document may be analyzed hierarchically using this code. However, the patent document classification codes are directly given by person. Therefore, there are time and cost problems. Worldwide patent applications and study for automatic classification of patent documents are increasing. Previous studies on the single IPC classification study is mainly done. However, most of IPC codes of patent documents has been granted a multiple. In this paper, several algorithms to improve classification accuracy are proposed using machine learning to automatically classify patent documents with respect to the multiple IPC study. To this end, first, the general documents using machine learning classification and relevant previous research at home and abroad are examined. Especially the differences between patent documents and general document classification are compared. In addition, a patent document classification using machine learning, patent search and patent related to extracting the core keyword research looks at trends in the flow. Second, conventional machine learning techniques related to the following methods are described: data set collecting, preprocessing, feature extraction, feature selection, term clustering, weighting method, and data indexing. Third, the advantages of the proposed method for feature selection using the dominant information are described, and the proposed method is compared with existing methods for feature selection experiments. In addition, the automatic IPC classification method using term clustering from intimacy, IPC sections and multiple classifiers for each class hierarchy are proposed. Finally, the automatic classification of patent documents for multiple IPC is described in the step-by-step procedure. In particular, automatic IPC classification methods using the proposed methods in this paper such as dominant information, term clustering from intimacy and multiple classifiers for each class hierarchy are compared experimentally.",
		"KEYWORD": "기계학습,문서분류,특허분류"
	},
	{
		"ID": 793,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "Big Data 환경에서 Needle Points 선정을 위한 생체 데이터의 패턴분석 =Pattern analysis of biometric data for the needle points selection in big data environments ",
		"AUTHOR": "신윤환",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수 :류근호 참고문헌 (111-125 p.) 수록",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "의학의 발달로 인간의 수명은 점점 늘어나고 있다. 의료 환경 또한 개인의 건강관리 위주로 변해가고 있는 추세이다. 이와 관련하여 USN 환경에서의 의료서비스도 점점 다양해지고 편리한 서비스가 지원되고 있다. 한의학 분야에서는 침구술을 사용하여 인체의 특정 위치에 침을 놓아 혈관작용이나 근육운동을 원활하게 해 준다. 인체의 침자리는 침구술에 의해 이미 결정되어 있지만, 사람에 따라 약간의 오차를 가지고 있다. 그 이유는 유전적인 성향과 육체적 특징에 따라 사람의 체질이 제각각 다르기 때문이다. 그러므로 침구술의 효과를 높이기 위해서는 침자리의 선정이 중요하다. 이러한 연구 동기를 계기로 이 논문에서는 침자리 선정에 따른 생체 데이터에 대한 패턴분석을 수행한다. 이를 위해 UB-IOT 패턴분석 모델을 제안하였다. UB-IOT 패턴분석 모델은 실시간으로 전송되는 생체 데이터의 패턴을 분석하여 최적의 침자리를 선정할 수 있도록 하였다. 인체의 침자리 선정을 위한 수행과정은 다음과 같이 전개하였다. 먼저, 생체 데이터를 기반으로 패턴분석을 수행하여 생체인식 벡터를 생성한다. 이 때, 생성된 생체인식 벡터는 환자에 대한 건강상태를 나타내는 파라미터이다. 이렇게 생성된 생체인식 벡터를 대상으로 치료효과를 증진하기 위한 진단패턴 타입을 제시하였다. 진단패턴 타입은 패턴분석 엔진을 통해 제시되며 진단패턴 타입에 따라 자침할 침자리가 선정되도록 하였다. 이러한 과정으로 이 논문을 전개하였으며 UB-IOT 패턴분석 모델을 적용하여 생체 데이터에 대한 패턴분석 실험을 수행하였다. 이 실험을 통하여 기존 연구와의 차별화를 비교 평가하였다. 이 논문에서 제안한 UB- IOT 패턴분석 모델은 기존 연구에서의 한계점을 극복하고 침구술에 대한 치료효과를 증진할 수 있는 장점이 있다. 향후 이 연구를 기반으로 사용자가 언제 어디서든지 실시간으로 스마트한 건강관리를 위해 UB-IOT 패턴분석 모델의 활용이 요구되며 개인 프라이버시 보호를 위한 정보보호 관련 연구가 추가적으로 필요하다.",
		"KEYWORD": "U-헬스케어,패턴분석"
	},
	{
		"ID": 794,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "Large Object 성능 향상에 관한 연구 :(A)study for large object to improve performance :K사의 연동 시스템을 중심으로 =focused on the interface system of K corps ",
		"AUTHOR": "정한교",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최용락",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "빅데이터 시대가 시작됨에 따라서 대용량 데이터 처리에 대한 논의가 활발하게 이루어지고 있지만 아직까지 RDBMS(Relational DataBase Management System)는 가장 광범위하게 사용되는 DBMS이다. RDBMS가 가지는 다양한 데이터 타입중 대용량을 지원하며 비정형 데이터인 문서, 이미지 또는 미디어등을 관리 및 처리할 수 있는 데이터 타입인 LOB(Large Object) 타입이 있다. 본 논문에서는 LOB 타입이 가지는 대용량 특성으로 인한 성능저하를 막기 위해 RDBMS 벤더가 제공하고 있는 중요한 옵션들에 대하여 테스트를 진행하였으며 LOB 칼럼의 Storage Option에 따라서 성능의 차이가 있음을 확인하였다. LOB 칼럼이 사용된 SQL의 경우 사용빈도와 LOB 칼럼에 저장되는 데이터 길이 그리고 저장 옵션에 따라서 SQL의 성능이 달라질 수 있기 때문에 각각의 경우를 테스트하였으며 실제 시스템에 적용한 사례를 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 795,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "K-Means 알고리즘 기반의 신용거래 이상치 탐지를 위한 분산 실시간 분석 방안 =(A)distributed real-time analysis method for anomaly detection of credit transactions based on the K-means algorithm ",
		"AUTHOR": "양승영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조인휘 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 60-61",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "현재(2015년) 스마트 기기의 발달과 고속 통신이 보급되면서 빅데이터, 클라우드, IoT(Internet of Things) 기술들이 연계되어 활용되고 있다. 컴퓨터의 크기가 초소형화되고 네트워크가 가능해짐에 따라 각종 사물과 결합하여 통신을 하게 된다. 사물 간의 상호작용을 하면서 발생하는 대용량의 데이터는 수집 후 클라우드에 저장하여 숨겨진 패턴을 발굴하기 위해 머신런닝 알고리즘 등으로 분석할 수 있게 되었고 기업 내 의사 결정을 데이터 기반에서 판단할 수 있게 되었다. 그 어느 때 보다 포괄적인 큰 데이터 집합을 다루면서 지금까지 불가능했던 새로운 비즈니스 모델을 발굴할 수 있게 되었다. 결제 시장에서도 실사용 편의성에 중심을 둔 모바일 기반의 간편 결제 서비스와 기존 온라인/오프라인 결제와 함께 다양한 환경에서 대용량의 신용 거래 데이터가 실시간으로 발생하고 있다. 특히 VAN(Value Added Network) 시스템은 다수의 가맹점 및 카드사들을 중계하여 신속, 안전하게 결제가 이루어질 수 있도록 구성된 시스템이다. VAN 시스템에서 가맹점과 카드사와 송/수신하는 과정에서 발생하는 데이터를 실시간으로 분석하여 이상징후를 사전에 파악할 수 있다면 적시에 적절한 조치를 할 수 있으므로 장애 위험을 최소화할 수 있다. 본 연구에서는 글로벌 기업에서 사용하는 검증된 오픈 소스를 활용하여 적은 비용으로 대용량의 데이터를 실시간 분석이 가능한 분산 시스템을 설계하고 구현하였다. 실시간 분석에서는 과거 데이터의 기반에서 K-Means 알고리즘을 통해 정상적인 신용거래이지만 다양한 형태의 거래들로 군집화 시킬 수 있는데 이것은 여러 군집 중 이상치로 의심되는 군집을 발굴 후 학습하여 실시간으로 끊임없이 들어오는 거래를 입력으로 하여 학습 기반 결과를 도출해 내는 방법을 제안하였다. 성능평가에서는 실시간으로 들어오는 이상치 데이터가 학습 데이터 기반의 이상치 군집으로 소속되는지 다섯 가지의 케이스를 가지고 정확도를 평가한 결과 10만 건의 이상치 유형의 데이터를 입력으로 하여 96% 수준의 정확도를 측정할 수 있었다. 또한, 제안한 분산 시스템에서 지속해서 끊임없이 발생하는 신용거래를 학습 데이터 1,000만 건 기반에서 15,000 TPS(Throughput per Second) 를 처리 할 수 있음에 따라 K-Means 알고리즘 기반에서 실시간 분석이 가능함을 확인할 수 있었다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 796,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "소셜 미디어 기반 미디어 아트의 전시공간에 대한 연구 =(A)study on the social media-based media art exhibition space ",
		"AUTHOR": "최윤성",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤준성",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "미디어 아트는 그 시대에 메시지를 전달 할 수 있는 매체를 통해서 표현하는 종합 예술로 볼 수 있다. 예술의 획기적 변화의 시기마다 등장해온 그 시대의 기술 발달에서 오는 미디어를 보면 확실히 알 수 있다. 따라서?예술과 기술은 서로 상반되거나 대립되는 개념이 아니며 상호의존 관계에 있다고 볼 수 ?있다. 그 시대의 기술은 그 시대를 살아가는 사람들에게 삶의 의식의 변화를 가져온다. 한 예로 카메라의 발명은 초상화를 그려왔던 근대 화가들에게 커다란 위협이었다. 초상화가들의 입지는 점점 좁아졌지만 이 때문에 진정한 예술가들은 발상자체를 바꾸는 계기가 되었던 것이다. 이와 같이 그 시대마다 기술 발달에 의해 사진, 동영상, 텔레비전, 컴퓨터 등 각각의 발명은 미디어 아트 표현의 새로운 미디엄으로 반향을 일으켰으며 또한 기술의 발달은 대량생산의 레디메이드의 예술작품화, 대량소비문화에 대한 인식 변화 그리고 결과물 중심에서 비 물질의 프로세스의 중심화 등 문화예술의 창작에 대한 인식 변화도 가져왔다. 20세기를 넘어 21세기를 살아가는 현대에는 컴퓨터와 네트워크 그리고 인터넷의 발달로 스마트 모바일 기기를 탄생 시켰으며 사용자들의 폭발적인 증가로 우리들의 삶 자체가 급진적으로 변하고 있다. 이러한 빠른 속도의 기술 발달은 미디어 아트 분야의 많은 부분에서 애매한 범주의 작품들이 쏟아져 나오고 있다. 인터렉티브아트, 웹아트, 넷아트, VR아트, 디지털아트, 모바일아트 등이 그것이다. 인터넷이라는 미디어는 현재 우리가 살아가는 삶 그 자체라고 할 수 있다. 범주는 애매하지만 위에서 말한 대부분의 예술 작품들은 웹을 기반으로 하여 표현되어진다고 볼 수 있다. 따라서 웹의 다양한 특성에 대한 이해가 필요하다. 웹의 가장 중요한 특징은 상호소통이며 ?집단 지성을 이룬다는 것이다. 이는 작가 위주의 작품 창작 활동이 작가와 관객이 상호 소통 관계 속에서 함께 이루어진다는 것이다.? 작가와 관객의 상호 소통은 소셜 미디어의 발달로 더욱 깊어진다.? 소셜 미디어는 관객을 대중으로 확장하고 대중을 적극적인 참여자로 만든다. 웹기반 나아가 소셜 미디어 기반의 미디어 아트는 기존의 관심 있는 관객들만을 위한 것이 아니라 일반 대중들을 위한 창작 예술로 나아가야 한다는 것이다. 따라서 전시공간은 화이트 큐브의 전시관, 실험 예술을 위한 대안 공간 그리고 가깝지만 멀게 느껴질 수 있는 컴퓨터 화면 등에서 벗어나 일반 대중들이 삶 속에서 쉽게 접할 수 있는 공간으로 찾아 나가야 한다. 이러한 환경 조성은 현재의 기술 발달로 가능해 졌다. 스마트 모바일 기기는 언제 어디서든 소셜 미디어를 사용할 수 있으며, 인터넷의 기술과 디스플레이의 기술은 우리가 살아가고 있는 전철역, 광장, 시장 그리고 화장실의 개인 소변기 앞에까지 곳곳에 들어와 있다. 소셜 미디어를 기반으로 하는 미디어 아트는 참여자들의 어떠한 목적을 기반으로 하는 정형 데이터 또는 삶 속에서 여러 가지로 나누는 목적 없는 ?비정형 ?데이터 등에 의해 작가와 함께 미디어 작품을 만들어 가고, 그러한 작품들은 삶 속에서 쉽게 만날 수 있을 것이다. 또한 삶 속에서 누리는 소셜 미디어 기반의 미디어 아트는 작가와 참여자의 정신에 따라 사회적으로 영향력을 발휘할 수 있을 것이며 캠페인의 성격까지 포함하게 되는 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 797,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "Orthogonal polynomial coefficients transformation generalized ESD based online anomaly detection =실시간 서버장애탐지를 위한 직교다항계수변환 일반화 ESD 모형 ",
		"AUTHOR": "이운섭",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이기천 권두 Abstract, 권말 국문요지 수록 참고문헌: p. 33-36",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "In the new era of big data, numerous information and technology systems are able to collect huge log data in real time. In addition, the importance of anomaly detection using big log data in application management systems is rapidly increasing. One of the biggest challenges in anomaly detection is to carry out real-time anomaly detection. In this paper, we focus on online anomaly detection in measurements collected by application performance management systems and time series log data with seasonality and trend. Most anomaly detection algorithms have several weaknesses in that they have difficulty in dealing with input log data that trends and seasonality. They are also suitably implemented for offline anomaly detection and hardly provide a systemic way to include supervised and unsupervised settings. To address these issues, we propose a new algorithm of online anomaly detection based on Grubbs’ outlier test which is a relatively accurate and efficient method by performing statistical hypothesis testing. We transform input log data using orthogonal polynomial coefficients, and then apply Grubbs’ test to the transformed data. We also use sliding windows to detect anomalies for streaming input data. Experiments with synthetic data, real-traffic data from Yahoo Webscope, and real-life response-time data from application management systems show that our method performs better than several existing methods for online anomaly detection in recall and false positive ratios.",
		"KEYWORD": "생산관리"
	},
	{
		"ID": 798,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "대용량의 수심측량데이터를 활용하기 위한 NoSQL 데이터베이스 기반의 시스템 설계 ",
		"AUTHOR": "이지환",
		"REGION": "인천",
		"PROFESSOR": "지도교수:박수홍 인하대학교 논문은 저작권에 의해 보호받습니다. 참고문헌 : p.59-60",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "수심측량데이터는 항해도나 해저지형도와 같은 해양 GIS 자료 제작에 반드시 필요한 데이터로서 선박의 안전한 항해와 레저·스포츠, 해양자원개발, 해양과학, 기상예측 등에 활용되고 있다. 특히 항만, 항행수로, 연안지역과 같이 수심이 매우 중요한 해역의 경우에는 완전한 해저면 탐사를 통한 정밀한 수심정보의 획득을 필요로 하고 있다. 하지만 현재 대부분의 수심측량데이터 제공 서비스는 단순한 형태의 데이터 저장 방법인 ASCII 텍스트 파일 포맷을 사용하고 있으며 제공 가능한 해상도는 최대 30m로 매우 낮다. 이는 고해상도의 수심정보를 저장·관리하는데 있어서 비효율적이다. 또한 파일 형태의 데이터 저장 방식은 GIS 및 해양 소프트웨어와의 연동이 어려우며 추가적인 측량에 의한 수심정보 획득으로 인한 데이터 갱신 등의 한계가 있기 때문에 DBMS의 도입이 필요하다. 이러한 배경으로 이 연구에서는 빅 데이터의 저장 기술 중 하나인 NoSQL을 도입하고자 하였다. NoSQL은 비-관계형 데이터베이스로서 분산 환경에서의 확장성이 매우 뛰어난 장점을 갖고 있다. 먼저 NoSQL 도입의 타당성을 입증하기 위하여 간단한 실험을 통해 RDBMS(mySQL)과의 비교분석을 수행하였으며, 이를 토대로 NoSQL에 적합한 그리드 기반의 다중-색인(Gridded Multi-Index) 모델을 제시하였다. 제시된 모델의 목표는 궁극적으로 색인의 크기를 줄여 RAM에 적재되는 작업량(Working-set)을 최소화함으로써 사용되는 메모리를 절약하고 검색 성능을 향상 시키는데 있다. 더불어 데이터베이스의 분산과 복제를 통해 확장성과 높은 가용성을 보장하는 분산 데이터베이스 시스템과 미들웨어 서버를 설계하였다. 미들웨어에는 라우터를 비롯한 분산 환경을 위한 작동하며 Java Multi-Thread를 이용하여 개발된 병렬처리 모듈이 데이터베이스의 검색 쿼리 수행 시 구현될 수 있도록 하여 성능을 향상 시키고자 하였다. 제안된 방법은 수심측량데이터 뿐만 아니라 포인트 형태의 대용량 공간데이터를 저장·관리할 수 있으며, 비교적 저사양의 서버들을 이용하여 경제적으로 분산 시스템을 구축할 수 있다.",
		"KEYWORD": "NoSQL,대용량,데이터베이스,빅 데이터,수심측량데이터"
	},
	{
		"ID": 799,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "가변샘플 이산코사인변환을 활용한 시계열 데이터 압축률의 향상방법 =(A)method to increase compression ratio of time-series data using discrete cosine transform with variable sample size ",
		"AUTHOR": "문병선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최명환 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "While the factory manufactures products, a number of time-series data have been generated in real time, and it helps increase efficiency and quality of product as a result of making information after gathering and analyzing it. However the collecting time-series data requires a lot of storage space to gather, store and analyze it. Big data technology becomes an alternative to resolve the problems mentioned above, but its technoloty cannot be applicable because it bascally requires the Cloud system architecture and the environment of plant did not allowed internet connection due to security-related issues. This paper suggests a method of using DCT(discrete cosine transform) technology to compress a number of time-series data as a solution to resolve problems. Also this paper shows that the effective way to compress time-series data is not by using fixed-samle but variable-size, and the coefficient of adjacenct variation is a superior than the coefficient of variation in the finding optimum sample size.",
		"KEYWORD": null
	},
	{
		"ID": 800,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "사물인터넷 서비스의 품질 평가 모델 =A quality assessment model for Internet-of-thing(IoT) services ",
		"AUTHOR": "김민선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김수동",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 전 세계적으로 사물인터넷(IoT) 관련 제반 기술이 성숙됨에 따라, 사물인터넷 기반의 헬스케어, 스마트 홈, 스마트 시티, 스마트 공장뿐 아니라 농업, 국방 등의 다양한 산업에서 서비스 개발이 본격적으로 진행되고 있다. IoT 서비스는 기존의 사람과 기계(컴퓨터 머신)간의 상호작용 범위에 포함되지 않았던 사물과의 상호작용, 사물간의 상호작용으로까지 범위가 확장된 개념인 만큼 서비스의 다양성이 무궁무진하고 사람의 행동 및 생활과 밀접하게 관련된다. 따라서 IoT 서비스로 구현되는 전 영역이 크고 작은 품질 이슈에 직접적으로 노출되어 있는 상태이고 경우에 따라 직접적으로 심각한 영향을 받을 수 있다. SW 기술 및 산업의 변천과 더불어 다양한 SW 품질 연구들이 진행되어 왔으나 IoT 및 IoT 서비스의 품질에 대해서는 현재까지 연구가 미흡한 실정으로, 본 연구를 통해 IoT 서비스의 품질 모델을 정립하여 이후의 세분화된 검증 기법 및 인증체계 수립과 관련한 연구 및 산업 적용에 참조될 수 있도록 하고자 한다. 선행연구들을 기반으로 IoT 서비스의 특징들을 고찰하여 IoT 서비스에 요구되는 품질 주특성과 부특성 및 메트릭을 정의하였고, 정립한 IoT 서비스 품질모델을 헬스케어 분야의 IoT 서비스 실사례에 적용하여 품질모델의 평가 효과성을 제시하였다.",
		"KEYWORD": "IoT Service,IoT 서비스,IoT 서비스 품질,Quality of IoT Service"
	},
	{
		"ID": 801,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "실시간 데이터 통합 가상화 모델에 관한 연구 =(A)study on real-time virtualization model for data integration ",
		"AUTHOR": "허희도",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 전삼현 참고문헌: p. 35-36",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "1994년 국내 최초로 웹이 소개되고 커뮤니티가 활성화 된 지 20년이 지났다. 웹은 그 자체로 모든 정보가 모여 있는 거대한 데이터베이스를 형성하게 되었다. 그만큼 데이터는 우리가 인지할 수 없을 정도의 많은 정보와 가치로 존재한다. 따라서 최근 데이터의 활용은 어느 때 보다 비즈니스 경쟁력을 갖추는데 가장 중요한 요인이 되었다. 이러한 시기에 데이터를 통합 및 축소하고 즉각적인 판단 체계로 시스템을 효율화·차별화해야 한다. 현재는 데이터웨어하우스(Data Warehouse, DW) 구성을 통해 통합된 데이터를 비즈니스에 활용하고 있다. 따라서 데이터를 효율적으로 통합 할 수 있는 연구가 추가적으로 필요하다. 이에 본 연구는 가상화 기술을 접목하여 데이터를 효율적으로 통합하는 모델을 제시하였다. 본 연구의 기술 개발은 저 비용으로 실시간 데이터 통합 및 분석이 가능하게 할 것이며, 다 변화되는 시장 환경에서 경쟁력을 갖추는 기반 시스템을 제공하게 될 것이다. 하지만, 데이터 통합 시 성능 개선과 UI에서 편리하게 데이터를 효율적으로 관리 할 수 있는 기술에 대한 연구가 추가적으로 필요하며, 본 연구로 빅 데이터, 클라우드 환경에 큰 변화를 가져오는데 기여할 수 있을 것으로 기대된다.",
		"KEYWORD": "논리적DW,논리적데이터통합,데이터 가상화"
	},
	{
		"ID": 802,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "조경 설계를 위한 Geodesign 방법론 연구 =(A)study on a geodesign methodology for landscape design ",
		"AUTHOR": "고재용",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 김은형 참고문헌 : p.76-77",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "오늘날 도시화와 산업화로 인하여 도시경관의 질은 물론 생활환경의 질 또한 점점 악화되는 상황이다. 이러한 환경악화에 대응하기 위해 도시의 생태?환경을 개선하고 경관의 질을 향상시켜 지구의 지속가능한 개발을 하기 위한 노력이 조경 및 관련분야에서 이루어져 왔다. 지구의 지속가능한 개발에 대한 방법은 과거부터 상당히 오랜 기간 자연과정을 존중하는 계획에 대한 많은 논의에도 불구하고 자연의 과정과 도시환경을 존중한 통각적(Apperceptive), 전체론적(holistic) 설계방법은 아직까지도 명확하게 정의가 되어 있지 않다. 이에 본 논문에서는 지구의 지속가능한 개발을 위한 Ian Mcharg의 조 경 설계 방법에 대한 이론을 고찰하고 선행연구의 분석을 진행하였으며, Geodesign 기술과 도구의 적용 방법에 대한 고찰을 통해 지구의 지속가능한 개발을 구현하기 위한 조경설계 Geodesign 방법론을 연구하였다. 또한, 제시된 방법론을 기술적 가능성, 활용 방안 등의 측면에서 검토하였고, 실제 조경 사례에 방법론을 적용하여 본 방법론이 가지는 장점과 필요성을 입증하였다. 이러한 입증을 통해 Geodesign을 활용한 조경설계의 잠재력과 효율성을 제시하였다. 따라서 향후 지속가능한 개발을 위해서는 조경설계의 방법과 과정이 Geodesign을 통해 수행됨이 바람직한 것으로 판단된다.",
		"KEYWORD": "Geodesign 방법론,조경 설계 방법론,지속 가능한 개발"
	},
	{
		"ID": 803,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "트위터 분석에서 중립극성 감소를 위한 감성사전 구축 및 감성강도 적용 =Twitter neutral polarity in the analysis to reduce the development of sensitivity dictionary and the application of intensity of sensitivity ",
		"AUTHOR": "장진웅",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박석",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Social Networking Services and all major mass media were heated when the news regarding “Namyang Scandal” which clearly showed predatory behavior of conglomerates that eventually led to apology to the public from the management went viral in the early May of 2013. This case clearly showed the power of the overwhelmingly prompt dissemination of information through social networking services (here in after referred to as SNS) and how it could influence the society at large since it enabled the government to take measures and eventually led the board members to apologize to the public. Therefore, researches are actively being done on SNS information as well as efforts are being made to effectively analyze bulk information lately. However, there still exist limits on tracking or analyzing users’ opinions based on SNS information which only were randomly created based on simple numbers or mentioned words. Also, Korean language itself always has the problem in analyzing what is really happening in both positive and negative sensitivity intensity on users’ specific targets. Traditional method of tweeter analysis used basic analyzing tactics of distinguishing polarity after understanding morpheme of the mentions written by users. However, most of the researches have been experiencing difficulties in significant annalistic results by statistic stochastic way in tweeter analysis. Therefore, diverse technical studies have been tried in consideration of quantitative analysis of words and vocabulary, differentiating the sensitive of sentences and intensity of polarity of sensitivity. This study presents the basic method of polarity analysis and also suggests the method that can reduce neutral polarity that reduces the effectiveness of analysis by applying the method of analysis of sensitivity on documentation. Thus, the researcher suggests quantification of sensitivity and algorithm that were applied by the sensitivity of intensity for more detailed analysis in establishing sensitivity dictionary and producing quantitative polarity calculation. In particular, the research suggests the formation of sensitivity analysis system with the application of Big Data based on Hadoop for the application of visualization analysis. The development of sensitivity dictionary to the reduce the polarity of sensitivity and the application of the intensity of sensitivity is considered to be utilized in system research that would produce more effective result in analyzing Korean tweeter users’ sensitivity written in complicated language of Korean.",
		"KEYWORD": "감성강도,감성극성,빅데이터분석,오피니언분석,중립극성"
	},
	{
		"ID": 804,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "홍익대학교 영상대학원",
		"TITLE": "원형 캐릭터 `광해`의 미디어 간 확산 과정과 요인에 관한 연구 :시너제틱스 구성요소의 인과고리를 중심으로 ",
		"AUTHOR": "윤나래",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 박장순 참고문헌: 장 108-116",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "‘Masquerade’ (Gwanghae, The Man Who Became King) was adapted by CJ E&M into a novel(2012), a film(2012) and a stage play(2013), which ran in a chain of production by OSMU(One Source Multi Use). The Prototype `Gwanghae` has been jointed with another stories and produced; musical ``Gwanghae Goes to the Shining Sea`(2013), web based novel, `Gwanghae`s Lover`(2013), fusion epic drama `The King`s Face`. This trans-media phenomenon based on the prototype spreads out in the TV drama, `Goddess of Fire`(MBC, 2013), `You Came From The Stars`(SBS, 2014) and the faction epic, `Hwajung`(MBC, 2015). This study aims to describe a trans media naissance of the historical prototype of Gwanghae by exploring its media process by Haken`s Syn ergetics theory: synergetic elements as system components(production). control-parameter(distribution) and order- parameter(consummation). The theory would reveal some driving factors how Gwanghae, from the icon of king abdicated, tyrant, bastard complex, foolish etc could become a figure needing to historically reevaluate(the 1st figure that high school teachers have to reevaluate in Korean history, Sport Choson, 2013/02/25) after the publication of `Gwanghae, The Man Who Became King`(2012), which has gave birth to this figure as a trans media idol in 21st century Korea. Firstly, as systemic element concerning its production, the prototype is described by historical factor, cultural factor, social and entertainment factors. The historical factor involves the `Gwanghae History` and the `Diaries of the Royal Secretariat`(`Seunjungwon Ilgi`) which the novel has been written with motive. The Jeju island, where Gwanghae was sent to die, is presented as the cultural factor. The social factor involves Korean collective memory and identity and their desire and world vision. These production factors are transmitted to the viewers/users by the control-parameter(distribution) like a stage play or a cinema. For the `Gwanghae``s case, owing to the control parameter, film market factor, it became the 7th biggest hit film at the 2015 South Korean box office, having attracted 11.04 million admissions in only 49 days of release. The viewers/users response would be on the side of the order-parameter(consummation), the popularity of the heroes(Lee Byung-hun), of the entertainment factor as system element(production), could be considered a factor for this success. The system element could draw praise for being suitable for the environmental factors like energy-fluxes, information, properties etc, these which becomes the control-parameter(distribution): publication market, film market, performing arts market, web based novel market, fusion epic drama market. Within synergetics, the systemic elements, in a macroscopic system consisting of many nonlinearly interacting subsystems, depend on the external control-parameters with an reduction of degrees of freedom. This entropy equation tells us that the revaluation of the prototype Gwanghae has been made by the order-parameter; the `routes of exile` of the Jeju Culture and Arts Center as cultural factor and the Korean collective memory and identity with their desire and world vision as social factor. As a consequence of the order-parameter, enacts again an entropy of system components(production). control-parameter(distribution) and order- parameter(consummation) by positive feedback, as the prototype Gwanhae has been enacted as a boom in case.",
		"KEYWORD": null
	},
	{
		"ID": 805,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "기준정보 통합관리시스템의 도입이 조직의 경영성과에 미치는 영향에 관한 연구 =(A)study on the influencing relationship of master data management system and business performance ",
		"AUTHOR": "신철식",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 심상천",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "기준정보 통합관리는 빅 데이터 시대에 데이터를 통한 경영효율화를 달성하기 위한 필수적인 사항이다. 경영정보 데이터를 관리하는 초기부터 기준정보는 존재 해 왔고 발전되어 왔었다. 이에 본 연구의 배경은 기업의 정보화 시스템에 구축에 가장 중요한 기준정보를 연구 하고, 기준정보 통합관리를 통해 조직의 경영성과를 분석하고자 한다. 연구방법에 있어서는 선행연구와 기존문헌에 기록된 사료나 데이터를 바탕으로 한 ‘문헌적 연구 방법론’과 국내유수의 기업들의 사례에 관련된 자료를 수집 및 분석 하여 결과를 도출하는 ‘사례 연구 방법론’을 도입 하였다. 그리고 민간 기업들 및 공공기관의 실제 사례들을 상호 비교하여 분석하는 ‘비교 방법론’과 기존의 선행연구를 바탕으로 설계한 가설을 검증하는 방식이 아닌 사례분석 결과를 통해서 새로운 명제를 찾아내는 ‘탐색적 연구 방법론’을 채택 하였다. 본 논문의 사례 연구대상은 한국의 대표적인 민간기업인 삼성토탈, SK하이닉스 2곳과 대표적인 공공기관인 정보통신산업진흥원(NIPA)으로 선정 하였다. 아울러 연구범위는 국내 주요기업의 “MDM시스템의 도입이 조직의 경영성과에 미치는 영향에 관한 연구”로 한정 되어 있다. 이를 바탕으로, 먼저 기준정보에 대한 개념 및 MDM시스템의 특징과 의의에 대한 설명에 대한 핵심요인들에 대한 선행연구들과 조직유효성간에 관계성에 대한 것들을 찾아서 정리 하였다. 그리고 MDM시스템 설계및 구축을 독립변수로 정의하고, 기존정보시스템의 변화를 매개변수로 하며, 그에 따른 결과인 경영성과를 종속변수로 하는 연구 분석틀을 구성하여 연구하였다. 이에 따라 MDM시스템 도입이 조직의 기업의 경영성과에 미치는 영향에 대한 사례분석 과정을 거치었다. 이러한 연구방법과 분석틀을 기초로 사례연구결과 다음과 같은 유사점을 찾아 볼 수 있었다. 첫째, 3개사 모두 조직을 확장하고 업무가 증가함에 따라 기준정보와 관련된 업무가 매년 증가 하고 있다. 둘째, 기업들은 고 품질의 기준정보를 얻기 위해서는 많은 노력과 비용을 지불하고 있다. 세 번째는 기업들은 기준정보 통합관리를 하고자 한다. 상이점은, 첫째, MDM시스템의 도입의 동기가 다르다. 둘째, 기준정보 관리는 조직문화에 따라 다르게 운영되었다. 셋째, IT인프라가 다르다. 이러한 연구 결과로 얻어낸 유사점과 상이점을 토대로, “MDM시스템의 데이터 거버넌스 체계를 수립하면 연계 시스템수가 증가 하고, 그 결과 연계 시스템들의 기준정보 운영비가 절감된다.” 는 명제 외 17개의 명제를 도출하였다. 본 연구를 통해 나타난 시사점으로는, 첫째 MDM시스템 구축에 따른 경영정보시스템의 변화에 능동적으로 대처하여야한다. 둘째 전사 공통의 통합관리가 가능한 시스템을 보유하여 회사내부의 통일된 경영정보 서비스를 제공하여야한다. 셋째 외부의 사회적 정보서비스와 기업내부정보를 기준정보로 관리하는 경영정보시스템을 구축해야 한다. 본 논문의 한계점으로는 연구에서 기업환경에 따른 능동적인 지표를 사용하지 못한 문제이다. 즉 일반적인 기업모두를 대상으로 하는 데는 한계를 보이고 있다. 향후 본 논문의 명제를 중심으로 가설을 설정하고, 일반기업을 대상으로 하는 실증분석을 통하여 본 논문의 한계성을 극복할 수 있으리라 생각된다. 주제어: MDM, 기준정보,데이터거버넌스, 정보시스템, 경영정보시스템, 경영성과.",
		"KEYWORD": "MDM,경영성과,경영정보시스템,기준정보"
	},
	{
		"ID": 806,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "다중 온톨로지 속성 기반 개체 식별을 이용한 Linked Data 연계 플랫폼 =Linked data integration platform using entity resolution on multiple ontology attributes ",
		"AUTHOR": "김태홍",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정한민",
		"STORE_LOCATION": "과학기술연합대학원대학교",
		"ABSTRACT": "Open Data의 상호운용성과 표준화의 해결책으로 부상한 Linked Data가 소개된 이후 약 7년이 지났지만, 아직까지 Linked Data는 연구자들의 기대만큼 널리 활용되지 못하고 있다. Linked Data가 쉽게 활용되지 못하는 가장 주요한 요인은 Linked Data의 핵심인 데이터셋 간 연계를 의미하는 링크의 정량적인 수가 전체 트리플 수 대비 약 15\\%에 그쳐 Linked Data의 궁극적 목적인 글로벌 데이터베이스의 역할을 수행하기에 부족하기 때문이다. Linked Data의 연계를 확장하기 위한 기존 연구로는 Zencrowd, Linked Enterprise Data, Chem2BioRDF, sameAs.org, OKKAM, Sig.ma, LOD2 등의 연구가 있으나 데이터셋 간 1:1 매칭을 통한 스키마 매칭 레벨 방식, 전문가에 의한 큐레이션 방식 등을 사용하고 데이터셋 내의 모든 개체 유형을 식별 대상으로 하기 때문에 정확성이 떨어지고 활용에 어려움이 있었다. 또한, 데이터 연계에서 활용까지의 모든 과정이 개별적으로 연구되고 있어 Linked Data의 연계 링크 생성에 많은 어려움이 있다. 따라서 본 논문에서는 Linked Data 연계를 위한 통합 솔루션으로 데이터 통합에 필요한 일련의 과정을 하나의 흐름으로 제공하는 Linked Data 통합 플랫폼을 제안한다. 제안하는 플랫폼은 개별적으로 연구되었던 세부 과정을 유기적으로 결합하여 Linked Data 분석, 활용에 대한 일관적인 시스템 구축을 가능하게 한다. Linked Data 플랫폼은 시맨틱웹 어플리케이션에 활용되는 데이터가 어플리케이션의 특성에 따라 소수의 제한적인 유형만을 사용하는 점에 착안하여 시맨틱웹 어플리케이션에서 실제 필요한 개체 식별 유형만을 대상 유형으로 선정하여 개체 식별 및 검색의 효율성을 도모한다. 제안된 다중 온톨로지 속성 기반 개체 식별을 이용한 Linked Data 통합 플랫폼은 시맨틱웹 어플리케이션에 필요한 개체 식별을 효율적으로 수행하고 Linked Data의 동일 개체를 수집하고 저장을 하나의 흐름으로 연결한다. 그에 따라 지속적이고 효율적으로 Linked Data를 연계하고 활용할 수 있는 토대가 될 것으로 기대된다. 또한 신뢰할 수 있는 데이터셋 간 연계로 확장된 풍부한 데이터는 최근 이슈가 되고 있는 빅데이터 분석과 활용의 기반 데이터로 활용되어 다양한 분야에서 과거를 분석하고 미래를 예측하기 위한 중요한 기본 자료로 활용될 수 있을 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 807,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "트윗에서 추출한 스트레스 감성과 토픽의 공간적 특성 연구 ",
		"AUTHOR": "강애띠",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 강영옥 참고문헌: p. 124-130",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "트위터 사용자들이 트윗데이터에 표현한 스트레스 감성과 토픽이 공간상에서 보이고 있는 특성을 찾아내기 위해 본 논문은 다음과 같은 단계를 거쳤다. 첫 번째 단계는 트윗데이터에서 스트레스 감성과 스트레스 토픽을 추출하기 위한 텍스트 마이닝 단계이고, 두 번째 단계는 첫 번째 단계에서 추출된 스트레스 감성과 토픽을 공간적으로 매핑하기 위한 타당한 공간적 연결고리를 찾아내기 위해 트위터 사용자의 거주지역 정보를 유추하는 단계였다. 세 번째 단계는 스트레스 감성과 토픽의 지역차를 시각화하고 확인하는 것이다. 스트레스 트윗데이터에서 스트레스 감성과 토픽을 추출하기 위해 본 연구에서는 텍스트 마이닝의 하위 방법론인 “감성분석”과 “토픽모델링”을 적용했으며, 라쏘기법을 적용하여 빅데이터의 분석에서 발생하는 모델의 과대적합 문제를 해결하였다. 본 연구에서 스트레스 감성은 스트레스에 대한 부정적인 표현이 주를 이루는 누적반응을 의미하며, 스트레스 해소로 긍정적인 표현이 주를 이루는 해소반응을 스트레스 긍정반응으로 정의하였다. 스트레스 감성분석을 통해 수집된 트윗데이터는 감성점수를 부여받았고, 트윗텍스트를 구성하고 있는 단어들을 이용해 스트레스 감성사전을 작성할 수 있었다. 스트레스 토픽은 트위터 사용자가 스트레스에 대해 표현하고 있는 표현의 화제를 의미하는 것으로서 본 연구에서는 LDA알고리즘을 적용하여 15개의 토픽을 추출하였다. 15개 토픽 중 “스트레스관련 광고 및 뉴스”와 “타인스트레스위로”토픽을 제외하고는 스트레스 원인, 결과, 해소방법이라는 3가지 주제로 분류할 수 있었다. 스트레스 원인 주제에는 “성격”, “학업”, “직무”, “가정”, “SNS사용”토픽이 포함되었으며, 스트레스 결과 주제에는 “질병”, “심리적상태”, “두피및탈모”토픽이 포함되었다. 스트레스 해소방법 주제에는 “그림”, “게임”, “운동및문화생활”, “음식섭취”, “노래등”의 토픽이 포함되어 있었음을 확인하였다. SNS데이터의 위치누락을 해소하기 위한 두 번째 단계에서는 SNS사용자들의 일상 이동 및 지역인식 패턴을 활용한 기계학습 기반의 로지스틱회귀모델이 만들어졌다. 이 모델을 활용하여 트위터 사용자가 가장 많은 트윗데이터를 생성한 지역 및 그들의 트윗데이터에서 가장 많이 언급한 지역이 그들의 거주지역일 확률을 구하는 판별식을 구축하였고, 이 판별식을 이용하여 스트레스를 표현한 스트레스사용자의 거주지역을 유추하여 지오태그된 데이터를 이용할 때보다 34배 더 많은 위치취득 트윗데이터를 확보하였다. 또한 본 연구에서는 트윗데이터에서 추출한 스트레스 감성점수와 토픽, 사용자 거주지역 정보를 토대로 지역적 차이를 지속적으로 분석하기 위해서 스트레스 트윗데이터 데이터베이스를 설계하여 지속적인 스트레스 트윗데이터를 수집·분석할 수 있는 기반을 마련하였다. 트윗데이터에서 추출한 스트레스 감성, 토픽을 시도차원에서 다각적으로 분석하여 시도별로 스트레스에 대한 주제와 감성이 차이가 있음을 확인하였다. 토픽별 스트레스 감성점수와 트윗데이터 수와의 관계가 비례하지 않은 경우 시도에서 사용된 단어빈도를 통해 그 이유를 탐색했으며, 각 시도에서 사용된 단어의 감성점수가 시도의 스트레스 감성점수에 영향을 미침을 알 수 있었다. 따라서 특정 토픽이 차지하는 비율만으로 그 시도의 성격을 판단하는 것보다 내부 포함된 단어들의 스트레스 감성점수의 분포를 통해 시도의 특성을 파악하는 것이 더 타당하다는 것을 확인하였다. 토픽별 스트레스 감성점수를 이용하여 토픽간 상관관계를 도출해본 결과 총 8가지의 유의미한 상관관계가 도출되었으며 이들 토픽간의 월별 스트레스 감성점수를 비교하여 시계열간에도 상관관계가 도출하는지 살펴보았다. 결과 정적상관관계를 보인 5개의 관계 중 “가정”토픽과 “학업”토픽은 시간차원으로 보아도 거의 비슷한 스트레스 감성점수를 보이고 있어 시간적으로도 유사한 패턴을 보인다고 보인다. 그러나 나머지 정적관계를 보이는 토픽간의 관계는 유사하다기 보다는 역의 패턴을 보여 시간적으로는 정적관계가 보이지 않음을 확인하였다. 그러나 부적상관을 보이는 토픽들간의 관계는 시간차원의 그래프에서도 부적관계를 확실하게 보이고 있어 부적상관관계는 시간차원에서도 유사하게 나타남을 확인할 수 있었다. 본 논문은 사용자 거주지역 유추 방법론의 정확도 문제, 좁은 범위에서의 단어사용이라는 한계가 있으나, 스트레스라는 사회적 현안에 대한 사람들의 느낌과 이를 표현하는 방법, 이들의 지역차를 규명했다는데 의미가 있으며 비가시적 감성적 현상을 지도화하여 공간데이터의 장을 확장시켰다는데 의의가 있다고 볼 수 있다. 향후 본 논문이 기초가 되어 다음과 같은 발전방향을 모색할 수 있다. 트윗데이터 뿐만 아니라 다른 SNS데이터로 스트레스 감성과 토픽모델을 확장시킬 수 있으며, SNS사용자 거주지역 유추모델의 정확도를 향상시키고, 기계학습 기반 형태소 분석 방법론을 추가하여 스트레스 감성점수와 토픽추출의 신뢰도를 높일 것이다. 또한 토픽별 스트레스 관련 감성점수를 이용한 토픽간 상관관계를 시계열적으로 확장하여 스트레스의 감성과 토픽이 사회적 신호로서 활용 가능성을 높이는 예측모델로 발전시킬 필요가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 808,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "광운대학교 대학원",
		"TITLE": "클라우드 컴퓨팅 서비스를 위한 XMDR 기반의 효율적인 DBaaS 시스템 =(An)effective DBaaS systems based on XMDR for cloud computing service ",
		"AUTHOR": "첸드아유시",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 최영근 참고문헌 수록",
		"STORE_LOCATION": "광운대학교 중앙도서관",
		"ABSTRACT": "인터넷과 클라우드 컴퓨팅의 발전에 따라, 데이터베이스들은 매일매일 기하급수적으로 증가되는 빅 데이터의 저장과 처리하는 능력이 요구된다. MySQL, Microsoft SQL 서버, 오라클과 같은 관계형 데이터베이스는 과거 수십 년간 폭 넓게 사용되었지만, 클라우드 컴퓨팅 환경에서 방대한 데이터의 수집과 통합 시 높은 성능을 요구하는 새로운 도전에 직면하게 되었다. 본 논문에서는, 클라우드 환경에서 로컬 시스템들이 XMDR(eXtended MetaData Registry)를 이용한 데이터 통합을 효율적으로 수행하기 위한 협업을 지원하고, 빅데이터를 위한 데이터 수집 및 통합을 위한 문서지향데이터베이스 기반의 DBaaS 시스템을 설계 및 구현했다. 기존 관계형 데이터베이스, 즉 정형화 데이터베이스에서 문서기반의 빙정형성 기반으로 변환하여 수집하기 위해서는 여러 가지 이질성이 발생하는데, 본 논문에서는 이를 메타데이터 레지스트리인 XMDR을 적용하여 해결하였다. 이 XMDR은 메타데이터 스키마의 구문적, 구조적 이질성을 극복할 뿐만 아니라 실제 로컬 시스템에서 사용되는 인스턴스값, 즉 데이터의 의미적 연관성을 표현한 온톨로지를 이용하여 의미적 이질성도 극복할 수 있다. 이질적인 데이터들의 교환을 위하여 JSON 메시지를 사용하며, 글로벌 스키마 기반의 표준 쿼리를 이용하여, 클라우드 상의 로컬 시스템에서도 협엽상의 빅데이터 처리 및 수집이 가능하도록 지원하였다.",
		"KEYWORD": null
	},
	{
		"ID": 809,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "홍익대학교 산업대학원",
		"TITLE": "수치적 정보유형에 따른 효과적인 시각화 연구 :(A)study on effective visualization consequent on numerical information type :신용카드이용명세서를 중심으로 =with focus on credit card use statement ",
		"AUTHOR": "김재영",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 부록: 설문지 지도교수:김덕용 참고문헌(p. 102-103)수록 서지적각주수록",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "With the coming of the Big Data era and with numerable information appearing & disappearing, Info-graphic researches for effectively delivering vast information are becoming an issue, but the research on visualization of the numerical data, which are delivered through the credit card use statement, is very insufficient in comparison with its importance. Moreover, in visualizing the numerical information, due to inefficient visualization caused by putting emphasis on the aesthetic part only other than delivery of accurate information, it`s difficult to do intuitive cognition and to grasp information, which lead to the decrease in information utility and obstruction of information. Particularly in case of the use status information of credit card statement, which is composed of numerical information, its effect could be amplified by the augmentation of its usefulness when the information is visualized to make it easy for users to understand intuitively and to remember. Accordingly, this study did research on what is the effective visual expression method according to numerical information characteristics by classifying the information informing the card use status in line with numerical information types into 5 categories. The numerical information types include first, `use status information by product` indicating the ratio; second, `use status information by business type` for comparative analysis; third, `monthly use amount information` indicating the relations; fourth, `use status by the day of the week` for trend analysis; fifth, `monthly number of uses information` for distribution of number of uses. As a result of investigating what is the suitable visualization when the classified information like above is visualized on the basis of the questions on the level of understanding, memory and concern, this study got the conclusion as follows: In case of `Use Status Information by Product` for ratio information, pie chart and bar chart were found to be the most effective in the degree of understanding while bar chart in the degree of memory, and pie chart in the degree of concern were found to be the most preferred, respectively. In information type for comparative analysis like `Use Status Information`, bar chart in the degree of understanding and memory, and pie chart in the degree of concern were found to be the most preferred, respectively. In the information type indicating relations like `Monthly Use Amount Information`, stacked bar chart was found to be the most effective in the degree of understanding, memory, and concern while in the information type for trend analysis like `Use Status Information by the day of the week`, bar chart was found o be the most effective in the degree of understanding, memory, and concern. Lastly, in `Monthly Number of Uses (cases) Information` as the information type for distribution, histogram was found to be the most effective in the degree of nderstanding, memory, and concern. As for the visual method consequent on numerical information characteristics, which card use status information connotes, it was found that information was cognized more quickly and accepted with ease mostly through the form of bar chart or pie chart, which is familiar and well adapted to our eyes. In addition, generally unaccustomed forms of bubble graph, tree map graph, radar graph, band graph, or partition bar graph, etc. were found to be very low in users` preference irrespective of data characteristics. It was learned that the form of graph rather than color had the most influence on understanding of numerical data. This study is aimed at inquiring into effective visualization consequent on numerical information type with focus on credit card use statement; through the research process, this study confirmed what visualization produced much higher intuitive cognition and was easy to understand and memorize in relation to each information type, and suggested effective visualization to each numerical information type through the application of numerical data on the basis of the result of solution to problems in visualization exposed in the credit card use statement. Accordingly, this study addressed effective visualization for delivery of numerical information by suggesting an important visual form to the information having a numerical characteristic like credit card use information. In addition, this study is intending to suggest the visualization standard point suited for numerical information type and implications to information design practical business.",
		"KEYWORD": null
	},
	{
		"ID": 810,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 첨단영상대학원",
		"TITLE": "소셜 미디어에 공유한 정보를 통한 개인 성격유형 분석 앱 개발 =Development of personal character analyzing application based on the opened information at the social media ",
		"AUTHOR": "한정화",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박진완 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "스마트폰의 빠른 보급과 소셜 미디어의 급격한 성장에 힘입어 온라인 상에 기록되고 있는 개인의 정보의 양 또한 급격히 증가하고 있다. 이러한 환경의 변화에 따라 사용자들이 생성한 정보를 분석하여 새로운 정보를 얻기 위한 노력이 증가하고 있다. 기존의 성격유형 분석 방법의 경우 자기 보고 문항을 통해 사용자의 유형을 탐색하는데, 이는 검사 대상자의 정보들을 심리학 전문가가 확보하기 어려웠기 때문이다. 하지만 유명인의 경우 그들의 정보를 쉽게 취득할 수 있고 이러한 정보를 통해 해당 인물의 성격 유형을 분류하는 연구들이 다양하게 이뤄진다는 점에서 볼 때, SNS 에 기록된 개인 사용자들의 정보를 통해 성격유형 분석이 가능할 것이라는 가설을 세울 수 있었다. 본 연구에서는 이를 증명하고자 분류지표를 설계하여 페이스북 네이티브 앱을 개발하였고, 이를 통해 사용자가 소셜 미디어 상 공유한 정보에는 정보 소비 기호가 반영되어 있으며, 이를 통해 성격 유형을 파악할 수 있음을 확인할 수 있었다.",
		"KEYWORD": null
	},
	{
		"ID": 811,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "스토리지 부하 최적화를 위한 영상분석정보 관리 시스템 설계 및 구현 =Design and implementation of image analysis information management system for storage load optimization ",
		"AUTHOR": "서정석",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 박석천",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "최근 지능형 영상서비스가 확산됨에 따라 영상정보 분석엔진에서 분석되는 영상정보는 연속적인 움직임을 감지하기 위해 1초에 30프레임의 XML 데이터가 생성된다. 즉, 한 대의 영상감시기기에는 하루 약 259만 개의 XML 파일이 생성되어, 영상분석정보 스토리지에 저장 및 관리되고 있으며 이로 인한 부하가 심각한 실정이다. 따라서 본 논문에서는 지속적으로 증가하고 있는 영상분석 및 저장에 대한 부하를 최적화하기 위한 영상분석정보 관리 시스템을 설계 및 구현하였다. 본 논문에서 제안하는 시스템을 설계하기 위해서 지능형 영상감시 기술과 영상정보 스토리지 부하와 관련된 연구를 통해 문제점을 분석하였다. 이를 바탕으로 영상분석정보 관리 시스템에서의 데이터 구조와 시나리오 매칭을 위한 상황코드 정의, 영상정보 요청 및 응답을 위한 메시지 구조를 정의하여 OVA-Parsing 알고리즘과 EVS-Filtering 알고리즘을 설계하였다. 본 논문에서는 시스템 구현을 위해 Window7과 Windows Server 2008 Enterprise 환경에서 .net Framework 3.0, Visual Studio 2010, C#을 사용하였다. 앞에서 설계한 영상정보 요청 및 응답 메시지 구조 정의를 통해 영상정보 데이터 교환 프로토콜을 구현하고, 이를 바탕으로 OVA-Parsing 모듈과 EVS-Filtering 모듈을 구현하여 제안하는 시스템을 구현하였다. 본 논문에서 설계 및 구현한 스토리지 부하 최적화 시스템을 테스트한 결과 CPU 점유율 45%, 메모리 사용률 16%, 영상분석정보의 크기 23%가 절감된 것을 확인하였다. 또한 영상정보 조회를 위한 영상정보 요청 및 응답에 대한 검색 시간을 평가한 결과 74.12%의 시간을 단축하여, 기존 시스템 보다 제안하는 시스템이 우수한 것을 확인하였다.",
		"KEYWORD": "CCTV,영상정보분석엔진,지능형 영상감시"
	},
	{
		"ID": 812,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "Data-driven drug discovery by chemical genomics approaches ",
		"AUTHOR": "이해승",
		"REGION": "대한민국",
		"PROFESSOR": "지도교수: 김완규 지도교수: 이상혁 Includes bibliographical references (p. 112-126)",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "방대한 화학유전체 데이터의 축적과 더불어, 이를 이용한 다양하고 새로운 방법들이 효율적인 약물 개발을 위해 개발되어 왔다. 그 중 컴퓨터를 사용한 신약 재창출 (computational drug repositioning) 은 빅데이터 시대에 맞춰 기존 의약품의 새로운 약효를 발굴할 수 있는 기회를 제공한다. 그 동안 약물의 타겟, 구조, 오믹스 데이터, 대용량 스크리닝 데이터 등과 같은 새로운 데이터 타입들이 생산되어왔으며, 이를 이용한 다양한 예측 알고리즘들이 신약 재장출을 성공적으로 이끌어 왔다. 최근, 대량의 화학 유전체 데이터들이 공개적으로 제공되면서, 다음과 같은 데이터베이스가 관심을 받고 있다. 1) LINCS (Library of Integrated Network-based Cellular Signature) 는 20,000 여 개의 화합물을 여러 암 세포주에 처리한 약물 유도 전사체 프로파일을 제공한다. 2) PubChem BioAssay 데이터베이스는 현재까지 다양한 분자 타겟에 대해 2,000,000여 개의 화합물을 처리한 생물학적 검정 실험(bioassay) 결과를 제공한다. 이 데이터베이스들은 약물의 작용 양식(mechanism of action)을 도출할 수 있는 정보를 전사체와 유전체 수준에서 제공한다. 이 논문은 이러한 화학 유전체 데이터 기반으로 약물을 개발하는 것에 초점을 맞추고 있다. 이 논문은 크게 세 가지 단원으로 구성된다. 첫 번째 단원에서는 컴퓨터를 사용한 신약 재창출의 배경을 설명하고, 그 것을 위한 다양한 연구 전략들을 소개한다. 두 번째 단원에서는 뇌종양, 폐암, 유방암에서 효과를 내는 신약재창출 후보를 예측하는 연구를 다루었다. 먼저, 새로운 후보를 예측하는 것에 약물 전사체 데이터가 약물 타겟, 약물 구조를 이용한 예측보다 우수함을 보였다. 약물 전사체 데이터에 기반하여 뇌종양에 항암효과를 나타낼14개의 약물 후보를 예측하여 뇌종양 환자 유래 세포주에 세포 독성(cytotoxicity)실험을 수행하였다. 전사체 데이터기반 점수는 세포독성 수치의 상관관계를 보였으며, 14개 중 8개의 약물 (ivermectin, trifluridine, astemizole, amlodipine, maprotiline, apomorphine, mometasone, and nortriptyline)에서 유의한 항암효과를 확인하였다. 이 실험을 통해 약물 전사체 기반 예측력이 기존의 HTS와 비교하였을 때 약 20배가량 Hit이 농축되어 있는 것을 확인하였다. 각 후보약물의 본래 작용질병이 다름에도 불구하고, 모든 후보들의 생체경로(pathway) 활성 패턴이 다른 항암 약물과 유사하였고, 이로부터 이들 약물의 작용 양식을 해석하였다. 세 번째 단원에서, PubChem BioAssay의 생물학적 검정 데이터 (Bioassay)로부터 대용량 화합물-화합물 네트워크를 구축한 방법을 소개한다. 이 네트워크는 대용량으로 화합물 간에 생활성 프로파일의 유사도를 계산하여 생성되었다. 이 네트워크를 기반으로 가상 탐색 실험, 타겟 인식, 그리고 신약 재창출에 대한 적용가능성을 검증하였다. 가상 탐색 실험에 적용할 때, 이 네트워크는 구조적으로 다양한 활성 화합물을 예측해내었다. 특히, 타겟에 대한 활성이 알려진 화합물 세트를 예측하는데 우수한 결과를 나타내었다. 또한, 이 화합물 네트워크를 약물 타겟 규명에 적용시켰을 때, 약 50%의 알려진 타겟을 정확하게 예측해내는 것을 확인하였다. 더 나아가, FDA승인된 약물로 구성된 서브-네트워크를 분석하여 유사한 생리활성 효과를 가지는 약물 클러스터를 이끌어 냈으며, 이 네트워크 모듈 분석을 통해 신약 재창출의 실현 가능성을 제시하였다.",
		"KEYWORD": null
	},
	{
		"ID": 813,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인천대학교 경영대학원",
		"TITLE": "클라우드 컴퓨팅 환경에서의 기업 응용 시스템 분석 및 설계에 관한 연구 =(A)study on analysis and design for enterprise system applications in cloud computing environment ",
		"AUTHOR": "최만규",
		"REGION": "인천",
		"PROFESSOR": "지도교수:김준우",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "Gartner, the prestigious research and advisory firm in IT sector, voted cloud computing for one of the “Top 10 Strategic Technology” in 2010. This report says that the companies to plan building new information systems should consider the cloud computing architecure because it has the profound effect on the increasing the innovation as well as reducing the risk of the companies. Under the rapid changing circumstance, most of companies consider adopting cloud computing seriously. Moreover, the emergence of big data, green IT and mobile industrial market also tends to make the cloud computing spreading more. Under this circumstance, this research consists of the following three purposes. Firstly, this explains the definition, the characteristics, the key technologies and the general considerations of the cloud computing necessary when introduced. Secondly, the standards for cloud computing system implementation were proposed and tested by the system experts. And with these standards, the suitable applications for cloud computing could be selected. Thirdly, this research shows two design schemes such as the existing way (in datacenter of the company) and the cloud computing way with these standards, and explains the pros and cons of each design. This research could show the guideline to the executives, the staffs and persons in charge for adopting cloud computing.",
		"KEYWORD": "클라우드 컴퓨팅"
	},
	{
		"ID": 814,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "소셜 네트워크 분석을 활용한 온라인 쇼핑몰 평가방법론 ",
		"AUTHOR": "안석모",
		"REGION": "서울",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수:홍준석 참고문헌 : p.41-43",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "현대 사회는 정보통신기술이 발달함에 따라 전자상거래가 급속도로 발전하게 되었고 이에 따라 소비자들이 전자상거래를 적극적으로 활용할 수 있는 온라인 쇼핑몰 시장의 규모 역시 커졌다고 할 수 있다. 이러한 기하급수적으로 증가하고 있는 온라인 쇼핑몰 시장의 규모에 따라 온라인 쇼핑몰 시장을 평가하기 위한 방법도 여러 가지 방법이 있을 수 있다. 매출액을 기준으로 평가하는 방법, 소비자들의 만족도를 설문을 통하여 평가하는 방법, 온라인 쇼핑몰의 접속 횟수를 이용하여 평가하는 방법 등 다양한 방안이 제시되고 있다. 하지만 기술적인 방법을 이용한 온라인 쇼핑몰을 평가의 도구는 전무한 실정이다. 본 연구에서는 온라인 쇼핑몰을 평가하기 위한 방법으로 소셜 네트워크 분석을 이용하여 온라인 쇼핑몰을 평가하기로 하였다. 소셜 네트워크란 ‘사람들이 연결되어 있는 관계망‘이며, 소셜 네트워크 분석은 수학의 그래프이론에 따라 연결 구조와 연결 강도 등을 바탕으로 사용자의 영향력을 측정하는 기법이라고 할 수 있다. 즉, 온라인 쇼핑몰 시장을 소셜 네트워크 분석을 한다는 것은 온라인 쇼핑몰 시장의 네트워크를 구축하고 각각의 쇼핑몰들이 네트워크 내에서 어떤 영향력을 구사하고 있는지를 분석하는 것이라고 할 수 있다. 온라인 쇼핑몰 시장을 소셜 네트워크 분석을 활용하는 방법으로는 포스트를 검색하여 두 개의 쇼핑몰 시장이 동시에 출현하면 빈도를 증가시키고 출현하지 않으면 빈도를 증가시키지 않는 방법으로 모든 온라인 쇼핑몰 시장을 모두 검색하여 빈도를 바탕으로 매트릭스를 구성하고, 이 구성된 매트릭스를 소셜 네트워크 분석을 통하여 온라인 쇼핑몰 시장의 네트워크를 구축한다. 구축된 온라인 쇼핑몰 시장의 네트워크를 중심성 분석을 통하여 각각의 쇼핑몰에 대한 중심성 값을 바탕으로 온라인 쇼핑몰을 평가하였을 때 어떤 결과가 나오는지 분석하고자 한다. 본 연구 방법을 통해서 소셜 네트워크 분석을 활용한 온라인 쇼핑몰 평가의 방법을 제시하고, 이 평가 방법을 바탕으로 온라인 쇼핑몰 시장을 평가하였을 때 어떤 결과가 나타나는지를 연구하여 보았다.",
		"KEYWORD": "소셜 네트워크,온라인쇼핑몰 평가방법"
	},
	{
		"ID": 815,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2012",
		"UNIVERSITY": "목원대학교 대학원",
		"TITLE": "지속가능 미래형 스마트교육 시스템 개발 및 적용에 관한 연구 ",
		"AUTHOR": "박지현",
		"REGION": "대전",
		"PROFESSOR": "",
		"STORE_LOCATION": "목원대학교 도서관",
		"ABSTRACT": "스마트교육은 ‘우리 주변에 존재하는 다양한 기기 및 도구들을 효율적으로 활용하여 모든 사람들이 교육 수요자의 요구와 수준·흥미를 고려한 수준별 맞춤형 교육과 질 높은 교육의 혜택을 받을 수 있으며, 이를 통해 지속적으로 미래와 사회 변혁을 위해 필요한 가치, 행동, 삶의 방식을 배움으로써 행복한 사회를 지향하는 교육’이라고 정의할 수 있다. 그러나 현재 추진하고 있는 스마트교육은 내용보다는 외형적인 면에 초점을 두고 실행하는 경향이 있어 우려된다. 스마트 교육은 연구의 부족으로 방향을 정확하게 정립하지 못하고, 통합적 접근방식도 미흡한 실정이다. 또한 스마트교육 교수·학습 모델이나 모형의 개발이 미흡하고, 정책결정자나 교사·학생·학부모 등의 마인드 부족, 시장중심의 스마트기기 도입, 스마트교육에 적합한 시스템 및 교수·학습 자료의 부족, 스마트기기 보급에 따른 학교 운영비의 부족 등 많은 문제점들이 산적해 있으며, 교육기관이 스마트기기의 전시장, 전문성 업체들의 각축장으로 변모하고 있다는 우려를 낳고 있는 형편이다. 이러한 문제점을 해결하여 스마트교육이 학교현장을 이끌어 갈 수 있도록 서비스의 방향을 정립하고 이에 적합한 시스템을 구축하여 교수·학습 모형을 제시함으로써 학교교육과정 전반에 스마트교육이 접목되어야 할 필요성이 제기되고 있다. 지금까지의 학교교육에서는 현재의 스마트교육뿐만 아니라 과거의 이러닝, 유러닝도 도구중심으로 발전하여 교육목표 달성을 위한 교육내용과 방법 및 모델 개발에는 미흡하였기에 교육의 본질을 달성하는 데는 한계가 있었다. 교육은 단발성이나 외형적인 면에 치우치거나 현재 나타난 내용을 봉합하거나 비전만 제시해서는 안 될 것이다. 또한 대부분의 정책결정자나 교사 및 학부모, 학생들이 스마트교육을 도구중심으로 생각하고 있는 것을 활용이나 서비스 중심이라는 것으로 인식 전환을 유도하고 이미 익숙한 시스템이나 도구들을 스마트교육 환경에 적합하도록 지속적으로 활용하면서 학생들과의 다양한 상호작용을 통한 교수·학습 방법을 다양하게 개발하고 학습공간을 확대하면서 필요성을 인식시키는 것이 중요하다. 본 논문은 지속적이고 일관성이 있으며, 가능성 있는 비전을 제시할 수 있도록 스마트교육의 방안을 제시하고자 다음과 같이 연구하였다. 첫째, 공교육에서의 이러닝의 현황 및 실태에서는 LMS/LCMS의 개념과 구축 실태를 파악하고, 국가주도 이러닝과 포탈업체의 이러닝 현황을 분석하였다. 둘째, 지속가능 미래형 스마트교육 서비스 방안을 제시하고자 스마트교육을 위한 요구사항 분석, 스마트교육 교수·학습서비스 방안, 스마트 학력누적관리서비스 방안, 스마트 화상강의 및 실시간 강의 서비스의 방안을 연구하였다. 셋째, 지속가능 미래형 스마트교육 교수·학습 모델에서는 지속가능 미래형 스마트교육 교수·학습 모델 요구분석, 지속가능 미래형 스마트교육 교수·학습 방향과 지속가능 미래형 스마트교육 교수·학습 모델을 제안하였다. 넷째, 지속가능 미래형 스마트교육 시스템 설계 및 구축 방안에서는 지속가능 미래형 스마트교육 시스템 요구사항 분석, 지속가능 미래형 스마트교육 시스템 설계 방안, 지속가능 미래형 스마트교육 시스템 구축 방안을 제안하고, 빅데이터 지원을 위한 스마트교육 시스템 설계안을 제안하였다. 이러한 제안들을 통해 스마트교육이 아날로그적 감성을 바탕으로 디지털적 창의력과 사고력을 신장시켜 미래 글로벌 역량을 갖춘 인재 개발로 이끌어 사람중심의 교육으로 이끌고자 하였다.",
		"KEYWORD": "ESD,smart education,smart learning,smart s-t model,스마트교육,스마트교육 교수.학습 모델,스마트교육 교수.학습 모형,스마트교육 서비스,스마트교육 시스템,지속발전가능교육"
	},
	{
		"ID": 816,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "홍익대학교 산업미술대학원",
		"TITLE": "소셜 네트워크 서비스 상에서의 인간관계를 표현한 인포그래픽 사례 고찰 =(A)study on infographic cases of human relations in social network ",
		"AUTHOR": "고성주",
		"REGION": "서울",
		"PROFESSOR": "국, 영문초록수록 지도교수: 이나미 참고문헌(p. 111-113)수록",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "The change in the media environment now forms new relationships, and the use of infographic has increased to maintain social relationships stably and to exchange information through relationships with SNS. And as a means of mutual communication, the width of using infographic is spreading more and more. In this paper, by analyzing the infographic cases that expressed the human relationship in the SNS environment, I will examine the necessity and importance of infographic between the formation of relationship and the effective communication. The specific objectives of this study are as follows. The infographic is intended to be able to grasp the digital relationships which are complex and subtle at a glance, to be provided to visualize and simplify. By expressing a large amount of information overflowing on a daily basis visually clear and concise, SNS infographics shape the information clear and meaningful. Looking for examples of such infographic, I reflect on the meaning of “weak ties” and try to look at the visualization representation of digital relationship. This study was carried out through literature study, case analysis and discussion. In chapter 2, I talked about what has been claimed in the paper “The Strength of Weak Ties” sociologist Mark Granovetter wrote in 1969. When people look for jobs, when people meet the new information, when people start a new business and when people touch the latest trends, he insisted close weak social ties are more important than strong relationship. And the weak ties play a critical role when you are trying to communicate with the outside world. He also insisted weak link is the bridge to the outside world. In addition, it has been presented to the opinions of such as the type and concept of infographics for the purpose of effective communication through theoretical considerations on information design. In chapter 1, through the theory of “The Strength of Weak Ties” and with the development of recent media, I knew the human relations are changing. And I also knew the new digital relationships by computers and digital media are making new digital relationships being formed. Digital relationship lead to the sustainable development of the media, as a result, communication between people has become flexible and smooth. And I explained that the mutual exchange is changing the concept and scope of human relations to be extended. Today digital relationships mean to maintain social relationships stably via the social network, make friends of different groups and exchange information. In other words, people have entered into relations independently with various groups. In order for the message is transferred from one group to another, meaning the fact that weak ties that connect the groups must pass through the human. Again, people who diffuse ideas and information are ones who belong to the weak ties. Since people related separately to each other, in order to communicate information more people to know, ordinary people must provide it. In chapters 2 and 3, through the analysis of the trend of infographic, diversity of information and big data, there is that everyone can be subject of information and the source of information on the social network. The chapter 4 is focused on case analysis. By the use of SNS infographic cases which derived by the analysis of the situation of chapters 2, 3, 4 and theoretical considerations of the chapter 1, I examined the way of visualizing the digital relationship. Conclusions of this study are as follows. First, rather than general communication relationship, SNS users produce an interactive relationship with posts and replies, information and business contacts, or search and links. And they share knowledge and information through this relationship. Second, it was found that social networking service companies analyze the characteristic and tendency of the users and notify them to related companies or utilize them as a marketing tool, which lead to strengthen the capacity of enterprises. It means paradigm shift from share and experience-centered relationship to need-centered relationship. These changes found not only in enterprises but also in SNS users. Third, if the person, concept and organizations are well organized and expressed by infographic, the relationship which plays important role in organization and industry will be understood and communicated easily and clearly. Infographics are great tool for story-telling. I found that good information and visual elements which are expressed well in infographic make people focus on the contents much easier. Infographic gives a significant impact on the relationship formation by making readers feel the importance of information emotionally. Thus, in this study I’ve learned that inforgraphic can provide the context for interconnecting the huge groups of common interests, finding new way of trouble shooting and opening the door of innovation. When you visualize the business model and characteristics of the company, the framework of the relationship is provided. In such a case, rather than representing a simple meaning, infographic is a decision-making tool, and can be a powerful means of communication.",
		"KEYWORD": null
	},
	{
		"ID": 817,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "R언어 기반의 빅 테이터 프로파일링에 관한 통계적 분석 연구 =Big data profiling statistical analysis based on the R language ",
		"AUTHOR": "장원중",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 818,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "산업보안 거버넌스를 위한 사물인터넷 관리 시스템 연구 =Research on IoT management system for industrial security governance ",
		"AUTHOR": "최명인",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박세현",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 논문에서는, 정보보호와 산업보안의 명확한 개념 및 범위의 확립과 다양해지는 산업자산 침해에 대응하기 위해 다각적인 방법으로 거버넌스 체계를 분석하였다. 또한 최적 환경의 산업설비를 조직원들에게 제공하기 위한 산업체 설비 환경에서 센서기반의 사물인터넷 시스템을 제시 하였다. 산업보안 거버넌스 빅데이터 트리는 산업보안 침해에 영향을 미치는 모든 요소들의 관계를 정의한다. 인간행위적 관점에서 산업보안을 정의하고, 산업보안에 영향을 미치는 요소들 간의 유기적 연계성을 바탕으로 하였다. 산업체 설비 환경 관리 센서기반 사물인터넷 시스템을 위해 환경 정보를 수집할 수 있는 Interactive Control Monitoring System (ICMS)라는 센서 모듈을 설계하였다. IoT 기술 기반의 테스트베드 구축 및 자체 실험결과 제안하는 시스템의 효율성을 확인할 수 있었다. 본 논문에서 수행한 산업보안 거버넌스 체계 분석 및 IoT 기반의 시스템 연구는 전 세계적인 IoT 환경에서의 산업보안에 있어 중요한 연구이며, 추후 연구가 확장이 되어 다양한 산업환경 적용에 기여할 수 있을 것으로 기대된다.",
		"KEYWORD": null
	},
	{
		"ID": 819,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "Data management and analysis inside SSDs =SSD 내에서의 데이터 관리 및 분석 ",
		"AUTHOR": "배덕호",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김상욱 국문요지, Astract 수록 참고문헌 : p. 101-110",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근, 인터넷 비즈니스의 증가, 이메일의 보편화, 스마트 단말의 보급, 다양한 소셜 네트워크 서비스들의 등장으로 인해, 생성되는 데이터양이 폭발적으로 증가하고 있다. 이러한 대용량의 빅 데이터를 효율적으로 다루기 위해 높은 I/O 대역폭, 낮은 access latency, 저전력 등의 특성을 가진 solid state disk (SSD)가 하드 디스크를 대체하는 차세대 저장장치로 각광받고 있다. SSD의 등장은 대용량 데이터 관리와 분석을 위한 데이터베이스와 데이터 마이닝 기술들에 새로운 도전 과제들을 야기한다. 특히, 본 학위 논문에서는 SSD 내에서의 데이터 관리 및 분석 방안에 대해 다룬다. 첫 번째로 플래시 메모리 환경을 위한 새로운 레코드 관리 방법을 제안한다. 먼저, 플래시 메모리의 특성이 클러스터링 방법과 논 클러스터링 방법에 미치는 영향을 분석한다. 이를 통해 디스크 환경과는 달리 플래시 메모리 환경에서는 논 클러스터링 방법이 더 적합하다는 것을 보인다. 더 나아가, 논 클러스터링 방법을 플래시 메모리 환경에 그대로 적용했을 때 발생하는 문제점에 대해 분석하고, 이를 바탕으로 플래시 메모리 환경을 위한 효율적인 레코드 관리 방법을 제안한다. 제안하는 방법은 논 클러스터링 방법에 기반을 두고 있으며, 삽입되는 레코드들을 동일한 페이지에 단 한 번의 쓰기 연산으로 저장할 수 있게 한다. 본 학위 논문에서는 이러한 레코드 관리 기법을 그룹쓰기라 부른다. 또한, 그룹쓰기를 효과적으로 지원하기 위한 그룹쓰기를 위한 전용 버퍼와 빈 공간이 존재하는 페이지들을 관리하는 메인 메모리 리스트를 제안한다. 끝으로 본 학위 논문에서는 제안된 기법의 성능 개선 효과를 정량적으로 검증하기 위하여 다양한 실험을 수행한다. 두 번째로 플래시 메모리 환경을 위한 컨테이너 구조를 제안한다. 먼저, 플래시 메모리 환경이 기존의 슬롯 페이지 기반 레코드 관리 방법에 미치는 영향을 분석하고, 기존의 슬롯 페이지 구조를 그대로 플래시 메모리에 적용하였을 때의 문제점을 지적한다. 이를 기반으로 플래시 메모리 환경을 위한 효율적인 레코드 관리 구조인 컨테이너 구조를 제안한다. 더 나아가, 컨테이너 구조를 기반으로 하는 효율적인 레코드 관리 방법을 제안한다. 제안하는 방법은 컨테이너 구조를 이용하여 레코드 삽입, 삭제, 수정 연산을 수행함으로써 덮어쓰기 연산을 효율적으로 수행할 수 있으며, 이로 인해 소거 연산을 크게 줄일 수 있다. 세 번째로 대용량의 데이터 마이닝을 위한 지능형 SSD를 소개한다. 먼저, 내부에서 데이터를 효율적으로 처리하기 위해 지능형 SSD가 가져야 할 구조적 특징에 대해 논의하고, 이를 통해, 데이터 마이닝 알고리즘들의 지능형 SSD에서의 수행 적합성을 보인다. 더 나아가, 지능형 SSD에서 데이터 마이닝 알고리즘들을 효율적으로 수행하기 위한 전략들을 제안하고, 지능형 SSD 내에서 데이터 마이닝 알고리즘들을 수행할 때 공통적으로 나타나는 요소 비용들을 분석한다. 끝으로, 비용 모델 수립을 통해 지능형 SSD를 위한 데이터 마이닝 알고리즘들의 효용성을 보인다. 네 번째로 지능형 SSD 내에서 외부 정렬을 효율적으로 수행하기 위한 방안을 제안한다. 먼저, 런 파일 병합을 위한 divide and conquer 전략을 도입한 기본 방안을 제안한다. 더 나아가, 기본 전략의 문제점을 분석하고, 이를 해결하는 발전된 방안을 제안한다. 끝으로, 비용 모델 수립을 통해 ISSD를 위한 데이터 마이닝 알고리즘들의 효용성을 보인다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 820,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "급변하는 기업환경에 효과적으로 적응하는 OLAP 프레임워크 연구 ",
		"AUTHOR": "이현석",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 논문은 저작권법에 의해 보호받습니다 지도교수:최종무 참고문헌 : 25장.",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "현재 우리는 빅데이터의 시대에 살고 있다. 사용자는 웹 페이지 클릭만으로 매일 엄청난 데이터를 만들어내고 있고, 기업은 경영과 제조 공정에서 많은 양의 데이터를 발생시킨다. 데이터가 증가함에 따라, 기업은 신속하고 정확하게 가치 있는 정보를 만드는 것은 기업간 경쟁우위를 확보하기 위해서 필수 요소가 되었다. 이러한 요구사항을 충족시키기 위해서 다차원 데이터베이스 개념과 이것을 기반으로 시작된 온라인 분석 프로세싱 (OLAP : On-Line Analytic Processing) 을 이용하여 많은 기업은 BI(Business Intelligence) 시스템을 도입하였다. BI 시스템은 비즈니스 환경의 변화 속에서 정확한 분석을 제공하기 위한 필수 요소이고 미래의 방향을 예측하여 다양한 비즈니스 의사결정과정에서 도움을 준다. 하지만 기존의 OLAP 시스템은 단점을 가지고 있다. 기업에서 본격적으로 도입한 지 10년 전에는 하드웨어에서 성능 면에서 제한적이었다. 그렇기 때문에 기존의 OLAP 시스템은 제한적인 하드웨어를 사용하여 효율적인 성능을 내는 것이 관건이었다. 이를 달성하기 위해서 기존 시스템은 원천 데이터와 사실 테이블 사이에서 차원 테이블을 사용하게 된다. 이는 DW (Data Warehoues) 최적화 구성으로 사용자가 원하는 관점의 차원 테이블을 사용하여 원천 데이터를 정제하여 사실 테이블을 구성하는 것이다. 그리고 정제된 데이터로 Cube를 구성하는 것이다. 즉 신속하게 분석 결과에 접근할 수 있도록 Cube를 만드는 과정에서 원천 데이터를 분리시키는 것이다. 그러나 이러한 최적화는 역효과를 가져왔다. 새로운 형태의 데이터를 추가하거나 사용자가 새로운 관점에서 데이터를 분석하기를 원할 때 기존 방식은 차원 테이블부터 재구성해야 하므로 수정을 위해서는 많은 공수가 필요하다. 이 논문에서는 이런 단점을 극복하기 위해서 원천 데이터를 바로 사실 테이블로 구성하는 새로운 OLAP 시스템을 제안한다. 이 제안은 많은 Core와 거대한 DRAM 크기, 새로운 타입의 기억장치(예를 들어 SSDs), 빠른 네트워크와 같이 현재의 하드웨어 변화가 있어 가능하다. 이러한 하드웨어의 변화는 아무런 성능 저하 없이 원천 데이터를 직접 분석이 가능하도록 하였다. 이 제안에서는 사용자 요구사항 정의, 원천 데이터의 인터페이스, Cube 생성, 장표 생성 등의 단계를 포함하여 구성하였다. 개발자의 공수와 필요한 하드웨어의 사양을 기반으로 이번 제안을 평가하였다. 평가 결과, 제안한 방식이 유연성과 개발 공수 면에서 여러 장점을 가진다는 것을 알 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 821,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "웹 사이트간 연결 관계를 이용한 유해사이트 판별 방법 =Methods for discriminating harmful web sites using link relations between web sites ",
		"AUTHOR": "신정훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이상준",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "Wide availability of mobile devices such as smart phones and development in wireless communication technology has made the internet ubiquitous. Such technological advancement has made accessing and sharing information fast and easy. Sharing information has made significant contribution to today`s world. Nonetheless, easy access to the internet and rapid spread of information do have some negative consequences. The biggest problem with the internet is that it exposes people to harmful contents. There are many web sites that contain harmful information such as illegal gambling, violence, suicide. Access to such information especially by children or teenagers is a big social issue. Therefore, the government maintains and blocks access to a list of harmful web sites through monitoring and reporting. In order for a web site to be blocked, it has to be first determined whether the web site concerned does indeed contain harmful information. There are two ways to make such decision: manual examination and automated searching for certain texts, videos, or sounds. Manual examination is the most reliable method but is costly and requires a lot of time. In case of automated decision making based on content search, it not only requires a lot of time and resources but also is not as reliable as manual examination so that the web site might have be examined again by humans Therefore, there is a strong need for a decision-making method that is capable of processing large amounts of data on the internet. In this dissertation, a new method for determining a harmful web site based on the relationships between web sites. It is different from the existing method which analyzes the contents within a web site. The proposed method exploits the characteristics of the web which is that web sites of similar topics are linked by hyperlinks. In order to test and evaluate the proposed method, a system that creates a list of harmful web sites was designed and implemented. The implemented system uses an existing list of harmful web sites to extract hyperlinks or URL(Uniform Resource Locator)s of other web sites. The extracted hyperlinks are used to create a Directed Graph and the system looks for any cycles within the graph. If one of the web sites in the cycle is a harmful web site, then all of the web sites in the cycle are determined harmful. The proposed method uses only the relationships between harmful web sites to distinguish other harmful web sites so that it is greatly advantageous in covering the unlimited information available on the internet.",
		"KEYWORD": null
	},
	{
		"ID": 822,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "기계 학습을 이용한 변동성 매매 전략에 관한 연구 =A study on volatility trading strategy using machine learning ",
		"AUTHOR": "라윤선",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김선웅 참고문헌: p. 23-25",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "기계학습(Machine Learning)은 인공 지능의 한 분야로, 테이터를 이용하여 기계를 학습시켜 기계 스스로가 데이터 분석 및 예측을 하게 만드는 것과 관련한 컴퓨터 과학의 한 영역을 일컫는다. 그중에서 SVM(Support Vector Machine)은 주로 분류와 회귀 분석을 목적으로 사용되는 모델이다. 어느 두 집단에 속한 데이터들에 대한 정보를 얻었을 때, SVM 모델은 주어진 데이터 집합을 통해 얻어낸 초평면을 바탕으로 하여 새로운 데이터가 어느 집단에 속할지를 판단해준다. 최근 들어서 많은 금융전문가는 기계학습과 막대한 데이터가 존재하는 금융 분야와의 접목 가능성을 보며 기계학습에 집중하고 있다. 그러면서 각 금융사는 고도화된 알고리즘과 빅데이터를 통해 여러 금융업무 수행이 가능한 로봇(Robot)과 투자전문가(Advisor)의 합성어인 로보어드바이저(Robo-Advisor) 서비스를 발 빠르게 제공하기 시작했다. 로보어드바이저의 주요 업무는 투자자의 개인적인 투자 성향을 기반으로 투자자의 투자에 대해 자문하고 포트폴리오를 자동으로 관리해주는 서비스를 제공하는 것이다. 따라서 현재의 금융 동향을 고려하여 본 연구에서는 기계학습 방법의 하나인 SVM 모델을 이용하여 한국형 변동성 지수인 VKOSPI를 예측하고 이를 실제 옵션 매매에 적용하여 매매성과를 올리는 방법에 대해 제안하고자 한다. VKOSPI는 KOSPI200을 기초자산으로 하는 옵션 가격을 토대로 KOSPI200 지수의 향후 변동성을 측정한 지수로서, 미국의 S&P500 옵션 가격을 토대로 산출하는 VIX지수와 유사하다. 한국거래소(KRX)는 실시간으로 VKOSPI 지수를 발표하고 있다. VKOSPI는 흔히 말하는 변동성과 같고 VKOSPI는 금융파생상품의 한 종류인 옵션의 가격에 영향을 미친다. 일반적으로 VKOSPI 값은 옵션의 종류와 관계없이 옵션 가격과 정비례하는 특성이 있다. 변동성이 상승하면 그만큼 만기시점에서의 옵션의 행사 가능성이 커지기 때문에 옵션의 프리미엄이 높아진다. 그러므로 VKOSPI의 정확한 예측은 옵션 매매에서의 수익을 낼 수 있는 중요한 요소 중 하나이다. 본 연구에서는 VKOSPI의 정확한 예측이 실제 옵션 매매에서 큰 수익이 가능하다는 것을 실제 옵션 데이터를 통해 검증하였다. 지금까지 기계학습을 기반으로 한 VKOSPI의 예측을 다룬 연구는 없었다. 본 연구에서는 SVM을 통해 일 중의 VKOSPI를 예측하였고, 예측 정확도는 평균 57.83%였다. 또한, 예측 내용을 바탕으로 옵션 매매에 대한 적용 가능 여부를 실험하였다. 그 결과, 포지션 진입 횟수는 평균 43.2회로써 벤치마크(100회) 대비 절반 이하로 줄어들었다. 적은 거래 횟수는 거래의 효율성을 나타내주는 지표이다. 게다가 매매 성과도 벤치마크에 대비하여 상당히 높아진 것을 실험을 통해 증명하였다.",
		"KEYWORD": null
	},
	{
		"ID": 823,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "인터넷 정보수집을 통한 독립적 개체간의 관계성 도출기법 =(A)study of independent object-relationship derivation technique through the information retrieval ",
		"AUTHOR": "김재중",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": "감성분석기,비정형정보,오피니언마이닝,정형정보,텍스트마이닝,형태소분석"
	},
	{
		"ID": 824,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한남대학교 대학원",
		"TITLE": "개인화 추천 서비스를 위한 카산드라 기반 모바일 어플리케이션 설계 =Design of mobile application based on Cassandra for personalized recommendation service ",
		"AUTHOR": "김난주",
		"REGION": "대전",
		"PROFESSOR": "한남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 최의인 참고문헌: p. 43-46",
		"STORE_LOCATION": "한남대학교 도서관",
		"ABSTRACT": "모바일 네트워크 및 디바이스의 발전으로 스마트폰 보급이 확산되고, 스마트폰 사용자가 증가함에 따라 수 많은 콘텐츠와 다양한 부가서비스들도 증가하고 있다. 따라서 사용자는 원하는 정보를 언제 어디서나 사용자가 선호하는 시점에 제공받기를 원하고 있다. 즉, 사용자가 선호하는 콘텐츠나 상품, 정보들을 적절하게 추천하는 시스템에 대한 관심이 증가하고, 이를 활용한 다양한 개인화 맞춤 서비스가 이루어지고 있다. 개인화 서비스는 사용자의 현재 상황, 행동, 성향, 선호도 등의 정보를 이용하여 사용자 프로파일을 분석하여 사용자 요청에 부응하는 서비스를 제공해야 한다. 현재 개인화 추천 서비스는 단순 사용자 위치정보나 과거 이력을 바탕으로 사용자 중심의 서비스를 제공하고 있다. 따라서 사용자의 상황을 이용하여 사용자의 상황을 정확히 파악, 그에 따른 서비스를 제공해주는 상황인지 서비스가 필요하다. 최근 개인화 추천 서비스는 소셜 미디어 및 다양한 정보들로 인하여 저장 및 분석할 데이터가 많아짐에 따라 빅데이터 기술에 대한 관심이 증가하고 있다. 다양한 정보들을 저장하고, 이를 바탕으로 개인 맞춤형 데이터를 추출하기 위하여 빅데이터 분석 기법을 사용하며, 특히 비정형 데이터 및 실시간 분석에 탁월한 NoSQL 분석 모델을 사용한다. 본 논문에서는 상황인식 기술과 카산드라를 이용하여 사용자 개인화 추천 서비스를 구현 하였다. 사용자 개인화 추천 서비스를 위하여 상황정보 모델링을 통해 상황을 정의 하였으며, 상황 추론을 위하여 추론엔진을 사용하였다. 또한, 사용자 프로파일을 사용하여 사용자 선호도 기반 서비스가 가능하도록 하였고, 프로토타입의 구현을 통하여 테스트를 하였다.",
		"KEYWORD": null
	},
	{
		"ID": 825,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "SNS 데이터를 활용한 국내 대학 인식 파악 및 선호도 분석 =(An)awareness identification and preference analysis for domestic university using SNS data ",
		"AUTHOR": "양민혁",
		"REGION": "충청북도",
		"PROFESSOR": "충북대학교 논문은 저작권에 의해 보호됩니다 지도교수:조완섭 참고문헌 : p.46-48",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "Recently the number of smartphone users is rapidly increasing through the expansion of the prevalence of smartphones. Accordingly, smartphones have become necessities for maintaining social relationships. In addition, data traffic has been exponentially increasing due to the increase in the utilization of smartphones. Smartphones became the primary means of communicating with others, and Social Network Service (SNS) based on the smartphones is also rapidly developing. In this study, SNS Big Data has been collected from Twitter and analyzed in order to identify the issues and preferences of the domestic universities. The data has been collected over 6 weeks using university name, its synonyms, and university-related keywords. We performed the multi- dimensional analysis on the collected data after loading them into the Hadoop-based data warehousing packages Hive. We then performed statistical analysis and visualization using RHive. As a result, we were able to evaluate the awareness and the sentiments of domestic universities from the Tweet data.",
		"KEYWORD": null
	},
	{
		"ID": 826,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "건축물 에너지효율개선제도에 관한 행정법적 연구 =A study on the building energy efficiency improvement system from the administrative law perspectives ",
		"AUTHOR": "김미영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이종영",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "지구환경 문제의 해결을 위한 온실가스 감축을 위한 노력의 일환으로 건축물의 에너지 효율을 개선하는 것의 의의는 크다. 건물은 전체 온실가스 배출량의 25% 이상을 차지하고 있으며 향후 건물부문의 온실가스 배출량이 국가 전체 배출량의 50%에 이를 전망이기 때문이다. 또한 4차 산업혁명의 시대를 맞아 제조업 등 기존 산업에 의한 온실가스 배출량은 줄어들고 기술·지식 산업의 증대로 건물 이용이 많아지게 됨에 따라서 건물로 인하여 발생하는 배출량이 늘어날 전망이어서 건축물 에너지효율개선제도에 관한 연구를 통하여 해당 제도에 대한 법적인 쟁점과 그에 대한 개정안이 필요한 경우 그 안을 제시하여 해당 제도의 안정적인 시행에 이바지하고자 하는 것이 본 논문이 추구하는 바이다. 주요 인증제도를 살펴보기에 앞서 건축물 에너지효율개선 제도에 관한 에너지법적 측면에서의 필요성을 고찰하고 본 제도에 대한 헌법적 정당성, 제도의 필요성과 한계점, 국내법 체계와 주요 국가들의 정책 등을 분석한다. 본 연구에서는 건축물에너지효율개선제도의 주요 인증제도인 녹색건축인증제도, 건축물에너지효율등급인증제도, 제로에너지빌딩인증제도에 관하여 연구하였으며 각제도의 의의, 도입배경, 외국의 사례, 규정, 현행법령상 건축물 에너지효율등급 인증제도의 문제점 분석과 법제개선방안 등 주요 쟁점 등을 분석하였다. 특히 2017년 1월 20일부터 건물 부분의 에너지절약 및 국가 온실가스 감축목표 달성을 위한 제로에너지건축물인증제가 시행되었는데 이 제도는 2020년부터 공공부문을 시작으로 2025년에는 민간부문까지 단계적으로 제로에너지건축을 의무화하기 위한 핵심제도가 될 전망이다. 그러나 ‘의무’의 시행을 앞두고도 의무화 규정이 없다는 것은 바람직하지 못하며 의무화 규정은 그 위반 시 벌칙 등을 부과할 수 있으므로 규칙 등에 개정하는 것 보다는 상위법인 녹색건축물 조성 지원법에 규정하는 것을 제안하며 이에 대한 개정안을 제시하였다. 또한 제로에너지빌딩은 IoT, ICT와 건축 기술의 융합으로 실현이 가능하며 해당 인증의 요건에 필수적인 건물에너지관리시스템(BEMS) 기술의 경우 시스템에 사용되는 센서가 에너지 사용자의 생활패턴을 수집하면서 사용자의 에너지 사용 흐름에 대한 빅데이터 (Big Data)가 수집되는데 이 경우 우리나라의 개인정보보호법에서 빅데이터를 수집할 수 있는지가 문제된다. 이에 따라 우리나라 개인정보보호법에 대한 분석을 통하여 빅데이터를 활용하면서도 개인정보를 보호할 수 있는 방안에 대한 개정안을 제시하였다. 건축물 에너지 효율 개선 제도의 안정적이고 발전적인 시행을 위하여서는 직접적으로 적용되는 법률뿐만 아니라 제도의 정착을 위한 기술의 발전을 위하여서는 개인정보보호법에 대한 개정도 필요하다. 이에 따라 해당 기술이 안정적으로 발전할 수 있도록 법적인 측면에서 다각도로 분석하는 것이 필요하고 그 방향에 맞는 개정이 이루어져야 우리나라도 제4차 산업혁명의 흐름을 이끌 수 있는 주요국가가 될 수 있을 것이다. 이상의 내용을 통하여 본 논문은 건축물 에너지효율개선제도의 발전과 안정적인 시행에 이바지하고자 한다.",
		"KEYWORD": null
	},
	{
		"ID": 827,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "피크요금제를 고려한 건축물 전력소비량의 저비용 예측방안에 관한 연구 =Research on low cost prediction method of building electric consumption considering critical peak pricing ",
		"AUTHOR": "왕승현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김주형 권두 국문요지, 권말 Abstract 수록 부록 수록 참고문헌: p. 21-24",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "현재 국내에서 시행되고 있는 피크요금제에 의한 기본요금 산정은 당월의 15분 평균 전력 소비량 중 가장 높은 전력소비량을 기준으로 계산되며, 특히, 7, 8, 9, 12, 1, 2월의 경우, 전력사용량이 단 한번이라도 기존의 전력소비량을 초과한다면 초과된 전력소비량에 해당하는 기본요금을 1년 동안 지속적으로 부담해야 한다. 따라서, 피크요금제를 고려해 15분내의 예측주기로 건축물의 전력소비량을 예측하는 것이 필요하다. 전력소비량을 원하는 주기로 예측을 하기 위해서는 계측기를 이용해 해당주기의 관련데이터를 수집해야한다. 하지만 계측기 설치의 높은 비용은 수요자에게 경제적 부담감을 주기 때문에(박병철, 2013, 이성인, 2014), 피크요금제 대응에 어려움을 준다. 따라서, 별도의 계측기를 설치하지 않고 데이터를 수집 할 수 있는 방안이 필요하다. 이에 본 연구에서는 피크요금제를 고려한 건축물 전력소비량 예측 시 데이터 수집 비용에 대한 수요자의 경제적 부담감을 줄이기 위해 정부에서 제공하는 공공 빅 데이터인 외부 기온, 외부 습도, 풍속, 전력소비량 데이터를 사용하였다. 또한, 예측정확도를 향상하기 위해 비선형패턴의 데이터를 고려함으로써 높은 예측 성능을 가지고 있는 SVR과 SVR의 세 파라미터의 최적의 조합을 도출 할 수 있는 GA를 결합한 GA-SVR을 사용하였다. 그 결과, CV(RMSE)값은 14.17%로 나타났으며, 이는 한국에너지공단에서 허용하는 오차허용범위인 ±30%이내이다. 따라서, 공공 빅 데이터와 GA-SVR을 이용한 본 연구의 예측모델은 피크전력 소비량 예측에 활용할 수 있을 것이다.",
		"KEYWORD": "건축공학"
	},
	{
		"ID": 828,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "경북대학교 산업대학원",
		"TITLE": "비정형 데이터를 위한 효율적인 데이터 수집 시스템의 구축방안 ",
		"AUTHOR": "서동찬",
		"REGION": "대구",
		"PROFESSOR": "지도교수: 김승호 참고문헌: p. 44",
		"STORE_LOCATION": "경북대학교 중앙도서관",
		"ABSTRACT": "The development of communication technologies and mobile devices anytime, anywhere information can produce. Structured / unstructured data are being produced in large quantities due to the development of computers and smart phones and social network service. Big data processing technology is attracting attention, a variety of techniques have been developed. This paper proposes an architecture for big data processing technology in a small environment, database environment that can increase the production of unstructured data, processing, storage, sharing efficiency.",
		"KEYWORD": "비정형데이터,자료수집,자료취합"
	},
	{
		"ID": 829,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 부동산융합대학원",
		"TITLE": "시계열모형을 이용한 프랜차이즈 커피전문점 매출 추정에 관한 연구 =(A)study on estimating sales of franchise coffee shops using time series models ",
		"AUTHOR": "경은희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최창규 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 65-68",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "프랜차이즈 커피전문점 두 곳의 일별 매출자료를 이용하여 최적의 매출 예측모형을 설정하고, 유사한 형태의 커피전문점에 단기적인 매출예측에 필요한 기초정보를 제시.",
		"KEYWORD": "부동산"
	},
	{
		"ID": 830,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한국교원대학교 대학원",
		"TITLE": "창의적 문제해결력 증진을 위한 퍼즐활용 교육의 효과 ",
		"AUTHOR": "최지은",
		"REGION": "충청북도",
		"PROFESSOR": "한국교원대학교 논문은 저작권에 의해 보호받습니다. 지도교수 : 김성식 심사위원 : 이태욱, 김영식, 김성식 참고문헌 : pp.26-28",
		"STORE_LOCATION": "한국교원대학교 도서관",
		"ABSTRACT": "본 연구의 목적은 창의적 문제해결력 증진을 위한 퍼즐활용 교육을 하여 그 교육적 효과를 확인하기 위한 것이다. 연구 목적을 달성하기 위해 퍼즐의 어떤 특성이 창의적 문제해결력을 높일 수 있는지 분석하여 정규 수업 시간에 적용할 수 있는 퍼즐 문제를 개발 및 선정하였다. 해당 퍼즐 문제를 고등학교 1학년 학생들에게 7주간 7차시에 걸쳐 적용한 결과, 본 연구에서 개발 및 선정한 퍼즐을 활용한 수업을 실시한 집단이 전통적 수업을 실시한 집단에 비해 창의적 문제해결력 향상에 있어 유의하게 높은 결과를 나타내었다. 본 연구 결과 퍼즐활용 교육이 학습자의 창의적 문제해결력 향상에 긍정적인 영향을 미친다는 점을 확인하였다.",
		"KEYWORD": "정보,창의적 문제해결,퍼즐활용교육"
	},
	{
		"ID": 831,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "(A) semantic-based category recommendation system exploiting big data processing technologies ",
		"AUTHOR": "Jae-IkKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 832,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "NAND 플래시 메모리 기반의 하이브리드 파일시스템 설계 및 구현 ",
		"AUTHOR": "신현주",
		"REGION": "서울",
		"PROFESSOR": "지도교수:노재춘",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "‘빅 데이터(Big Data)’ 시대로 진입하면서 대용량, 고속의 저장장치와 그 저장장치를 더욱 효율적으로 활용할 수 있도록 하는 고성능 파일시스템의 필요성이 증가하고 있다. NAND 플래시 메모리를 기반으로 하는 SSD(Solid State Disk/Drive)가 많은 멀티미디어 기기에 사용되며 차세대 스토리지로 떠오르고 있지만, 대용량 시스템에서는 SSD를 사용하기 위해서는 같은 용량의 HDD에 비해 비용 부담이 크기 때문에 활용도가 낮은 편이다. 본 논문에서는 대용량 시스템에서 SSD의 사용 부담을 덜고, HDD만으로 구성된 파일시스템보다 높은 성능을 보이기 위해 EXT4 파일시스템 기반에서 SSD, HDD의 특성을 함께 활용하는 하이브리드 파일시스템인 HUSH(Hybrid Union of SSD and HDD) 파일시스템을 설계하고 구축하였다. HUSH는 크기가 작고 분산 저장되는 메타데이터는 SSD에, 크기가 크고 연속적으로 저장되는 일반 데이터는 HDD에 저장함으로써 SSD와 HDD를 함께 사용하기 위한 효율성을 높였다. 앞으로 HDD에서 SSD로 변화하는 스토리지 시장의 흐름에 따라 대용량 시스템에서 이러한 하이브리드 파일시스템을 다양하게 응용할 수 있을 것이다.",
		"KEYWORD": "EXT4,NAND Flash,SSD,대용량 스토리지,파일시스템"
	},
	{
		"ID": 833,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "수원대학교 공학대학원",
		"TITLE": "국방정보체계내 클라우드 컴퓨팅 보안정책 ",
		"AUTHOR": "강상태",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 고승철",
		"STORE_LOCATION": "수원대학교 도서관",
		"ABSTRACT": "Along with the growth of cloud computing service environment, development of related technology continues. Yet, due to inherent vulnerabilities of the cloud environment, controversy over security persists. Recently, as new security technology compatible with the cloud environment is developed, cloud computing service is gradually expanding its reach, despite the security issue. In defense field, the cloud concept is applied to establishing a defense integrated data center in order to economize and efficiently utilize information resources. In this process, reviewing security issues raised during the development of civilian cloud would be meaningful in solving security issues when applying cloud to the defense field. The study aims to anticipate security vulnerabilities when applying cloud to the defense field by reviewing the security controversy and cases of cloud computing service and to provide technical measures to overcome security issues that Big-Data analysis, as a new convergence and integration security technology, could be very effective. In particular, the study suggested behavior-based security control as an appropriate security technology in private cloud used by multiple accessors, since it identifies abnormal behavior by comprehensively analyzing each log, as well as anticipating possible situations. I expect that this study can contribute to continuous development of highly secured security technology convenient to both service providers and service users, as well as to protection of major defense information by achieving fundamental intent of defense information by minimizing security vulnerabilities and guaranteeing security while operating the defense cloud.",
		"KEYWORD": null
	},
	{
		"ID": 834,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한국외국어대학교 대학원",
		"TITLE": "기계학습 기반 단기가격 및 추이 예측 모델링에 관한 연구 =(A)study on predicting short-term price & trend based on machine-learning modeling ",
		"AUTHOR": "김준석",
		"REGION": "서울",
		"PROFESSOR": "한국외대 논문은 저작권에 의해 보호받습니다. 지도교수: 최대우 참고문헌 : p. 34",
		"STORE_LOCATION": "한국외국어대학교 글로벌캠퍼스 도서관,한국외국어대학교 서울캠퍼스 도서관",
		"ABSTRACT": "기계학습 기반 단기가격 및 추이 예측 모델링에 관한 연구 빅데이터(Big data) 시대가 되면서 예측의 중요성은 더욱 높아지고 있다. 다양한 경제지표와 원자재 가격 등은 급격하게 변화하기 때문에 이를 미리 인지하는 일은 더욱 중요해지고 있다. 본 연구에서는 기계학습을 이용하여 기존의 가격 예측 모델을 개선하고, 나아가 상승과 하락을 예측하는 방법을 시도하였다. 예측모형의 타당성과 유연성을 확인하기 위하여, 긴 기간과 다양한 데이터의 예측을 수행하였다. 그 결과로 빅데이터와 기계학습을 통해, 충분한 데이터와 예측모델링을 통해, 예측이 가능하다는 것을 알 수 있었다.",
		"KEYWORD": "Deep learning,Random forest,SAX"
	},
	{
		"ID": 835,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "이화여자대학교 대학원",
		"TITLE": "전자문서 기반 법률콘텐츠 구조화 :온라인 행정심판에의 활용 ",
		"AUTHOR": "배유진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최승원 참고문헌: p. 150-157",
		"STORE_LOCATION": "이화여자대학교 도서관",
		"ABSTRACT": "Government 3.0 is a government administrative center of the national center of individuals by changing the paradigm. This is linked to system which is open, sharing of public information, and sharing information of inter-agency, customized ??service for each targeted citizen. Development, sharing, communication and cooperation is the core value of this era, being oriented by Government 3.0. The key is content and services. Access to these contents is a vast multimedia content. In other words, practical use will be possible, through a systematic analysis of big data and record search as well as a simple accumulation. Thus, the government`s direction can take an advantage of the efficient co-operation of contents various types that is conventional structured data is not being limited to. And unstructured content is not a way which is simply giving and receiving, as structured to unstructured content. In other words, unstructured contents which are including orthopedic items, the parallel formulation of the atypical, can be switched through. Structuralization is formalized the unstructured contents and is to organize typed data. In particular, Legal contests can also sort of big data such as various laws, legal knowledge, including the literature material law or the law of life related with political, economic, social and cultural areas. So, if the law is structured content, in addition to simple ordinance search, it can give easy access to legal issues related to people`s daily life, laws and regulations, decision, precedent, people in the eye. At the same time, judicial officer and lawyers who help professional judgment and decision-making can search for and utilization exactly, contents related variety of major topics. ? Also, these knowledge and experiences will be able to go towards knowledge advancement, is reflected in knowledge system again through a feedback reflux process. Structuralization of knowledge should be based under electronic documents. In particular, it is easy to combine with separate Data and view, N-dimensional structure is possible, and should be based document SOAXML with standardization, automation features. The practical use of Legal contents are applied the principle of structured in the online administrative appeal. In addition, by making this web form, try to implement and empirical approach has been attempted. And it has raised the issue appears through structured and ongoing online hub of administrative appeals system. Salient issues are illegal and unfair criteria, the nature of the principle of proportionality, the problem of autonomy in relation, amendment issues can be raised as online. As for this issue, it is needed to emphasize for empirical and normative approaches.",
		"KEYWORD": null
	},
	{
		"ID": 836,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "스마트정부 시대의 공공정보 개방 인식에 관한 실증적 연구 =(An)empirical study on the recognition of public information openness in the smart government era ",
		"AUTHOR": "한용희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현성",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "최근의 사회는 정보통신기술의 급격한 발전 과정에서 과거와 비교할 수 없을 정도로 많은 데이터가 생성되고 있으며 그것의 처리를 필요로 하고 있다. 특히 스마트기기 기반의 서비스 확산으로 인한 정부의 행정혁신, 기업의 경영혁신, 신규 경쟁력 강화 등은 사회전반에 걸쳐 큰 변혁을 가져오고 있으며 이러한 시대상을 스마트시대라고 표현할 수 있다. 이런 스마트시대를 맞이하여 새롭게 떠오르고 있는 논제로 공공정보 활용에 관한 논의가 꾸준히 이어지고 있다. 국가와 정부가 갖고 있는 공공정보를 공공부문은 물론 민간부문에서 적극적으로 활용함으로써 공공부문의 비효율성과 비합리성을 극복함과 동시에 민간부문에서 새로운 경제성장 동력으로 활용하는 방안 등이 본격적으로 도입되기 시작한 것이다. 이미 우리에 앞서 미국과 EU, 영국, 호주 등의 선진국들이 공공정보의 민간개방 및 활용을 위한 법제도를 준비하고 시행하는 노력을 통해 스마트시대의 새로운 사회동력으로 활용하고 있는 상황이다. 공공정보를 확보하는 있는 주체는 정부이며 그것을 활용할 수 있도록 변환하고 민간에게 제공하는 임무를 수행해야 하는 주체 역시 정부이다. 특히 2013년 10월 31일부터 시행되는 ‘공공데이터의 제공 및 이용활성화에 관한 법률’에 맞추어 공공정보 개방 및 활용을 위해 일선에서 노력해야 할 공무원들이 어떻게 준비하고 있으며 어떠한 문제점 등을 인식하고 있는지 파악해야 할 필요성이 있을 것이다. 현재 공공정보 개방 및 활용에 대한 연구가 절대적으로 부족한 상황이며 특히 일선 공무원들을 대상으로 한 실증적인 연구가 필요하다는 사실은 명확하다. 따라서 본 연구의 목적은 실증적인 분석을 통하여 공공정보 개방 및 활용을 활성화시키기 위한 방안을 모색해 보고자 하는 것이다. 본 연구는 총 5개의 장으로 구성되어 있다. 제1장은 서론으로 연구의 배경 및 목적, 연구의 범위 및 방법을 제시하고 있으며, 제2장은 이론적 고찰로 공공정보에 대한 이론적 논의와 웹 3.0시대에서의 공공정보 개방에 관한 내용을 담고 있으며 공공정보의 개방 및 활용에 관한 선행연구를 비판적으로 검토해보고 있다. 제3장은 연구의 설계로 연구의 분석틀, 연구의 변수의 조작적 정의, 측정지표의 선정, 자료수집 방법 및 분석방법, 측정변수의 신뢰도와 타당도 검정을 포함하고 있다. 제4장은 실증분석으로 공공정보 개방에 관한 공무원들의 인식에 영향을 미치는 요인에 대한 분석을 위한 설문조사 내용을 담고 있다. 설문조사를 통해 획득한 자료를 바탕으로 기술통계, 집단간 차이분석, 상관관계분석, 다중회귀분석을 실시하여 분석결과를 제시하였다. 마지막으로 제5장은 연구의 결론으로 연구내용을 요약하며 연구의 시사점 및 향후 연구의 방향을 제시하고 있다. 본 연구에서는 문헌조사 및 선행연구를 바탕으로 독립변수로 기술적 요인, 법·제도적 요인, 조직행태적 요인을 선정하였고 종속변수로는 공무원의 공공정보 개방 인식을 선정하였다. 이를 바탕으로 서울시와 안산시의 기초자치단체 공무원들을 대상으로 한 설문조사를 실시하였다. 설문조사 결과를 분석하여 다음과 같은 내용을 확인 할 수 있었다. 첫째, 기술적 요인에서 공공정보의 기술표준화 정도는 개방 인식에 영향을 미치지 못했으며 공공정보의 상호연동성이 정(+)의 영향을 미치는 것을 확인 할 수 있었다. 이는 공공정보 개방을 위한 기술적인 토대가 이미 어느 정도 구축되었으며 이제는 그것을 실제로 활용해야 하는 단계에 이르렀음을 의미한다고 볼 수 있겠다. 둘째, 법·제도적 요인은 공공정보 개방 인식에 영향을 미치지 못하는 것으로 나타났다. 이 역시 기술적 요인과 마찬가지로 ‘공공데이터의 제공 및 이용활성화에 관한 법률’이 시행되는 등 그 기초적인 토대가 이미 완성되었음을 의미한다고 볼 수 있을 것이다. 셋째, 현재 공공정보 개방에 가장 큰 영향을 미치는 것이 조직행태적 요인임을 확인 할 수 있었다. 특히 공공정보 개방을 위한 담당인력의 충분한 확보가 개방인식에 정(+)의 영향을 미치며 공공정보 개방과 관련된 교육을 받을수록 개방인식에 정(+)의 영향을 미치는 것을 확인 할 수 있었다. 따라서 기존에 구축된 기술적 요인과 법·제도적 요인을 아우르는 인프라를 형성하고 어떻게 활용 할 것인지와 그것을 위한 교육 등이 필요한 단계에 도달했다는 것을 확인 할 수 있었다. 본 연구는 문헌조사 및 선행연구 분석을 통해 선별한 요인들을 중심으로 설문조사 결과를 확인하여 실증적으로 분석하고 그것의 의미를 확인했다는 점에서 연구의 의의가 있다고 하겠다. 앞으로 성공적인 공공정보 개방 및 활용을 위해서는 공공기관간의 공공정보 상호연동성을 높이고, 공공정보 개방 담당인력을 충분한 확보하며 그와 관련된 교육훈련이 꾸준히 이루어져야 할 것이다.",
		"KEYWORD": "공공정보 개방 및 활용,교육,담당인력,상호연동성,조직행태적 요인"
	},
	{
		"ID": 837,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 정보·지식재산대학원",
		"TITLE": "딥러닝을 활용한 자율주행 자동차의 사회적 딜레마 해결 방안 =Social dilemma solution of the autonomous car take advantage of the deep learning ",
		"AUTHOR": "정완",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수: 양재수 참고문헌: 35 장",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "자율주행 자동차에 필요한 기반 기술의 발전으로 인하여, 자율주행 자동차는 더 이상 공상과학 소설에 나오는 이야기가 아닌 현실에 가까워지고 있다. 자율주행 자동차에서의 대표적인 기술에는 상황을 인지하기 위한 이미지 처리, 각종 센서, 대용량 데이터 처리 기법 등이 있다. 이중에서도 핵심 기술은 순간 마다 빠르게 변화하는 상황에 대응하기 위한 데이터 처리 기법이라고 할 수 있겠다. 과거에도 기계 학습 등에 필요한 알고리즘으로 인공 신경망 기술이 발표되었으나, 방대한 학습 데이터 처리에 소요시간이 길어지는 문제로 실용화 되지 못하였다. 하지만 컴퓨터 연산 속도의 발달로 인하여 빅데이터 처리 기술이 발전하고 인공 신경망을 발전시킨 심층 신경망, 즉 딥러닝이 등장하면서 이에 관한 많은 문제점들이 해결되고 실용화가 대두되게 되었다. 빠른 기계적 발전과 달리 전통적인 사회적 규범 및 합의는 아직 기술의 속도를 따라 가지 못하고 있다. 자율 주행 중 돌발 상황 발생 시 인명과 재산의 보호의 기준을 어떻게 두어야 하는지에 대한 사회적 딜레마는 자율 주행의 상용화 이전에 꼭 해결되어야 할 문제 일 것 이다. 이에 본 논문에서는 자율 주행 돌발 상황에 대한 판단을 기계적 판단에 전적으로 의지 하지 않고 사회적 윤리, 합의 그리고 개인에 대한 데이터를 딥러닝의 학습데이터로 활용하여 보다 보편타당에 가까운 선택을 할 수 있도록 하는 것을 목표로 한다.",
		"KEYWORD": null
	},
	{
		"ID": 838,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "Word2Vec을 이용한 위키피디아 텍스트 데이터 분석 시스템 구현 =Implementation for Wikipedia text data analysis system using word2vec ",
		"AUTHOR": "김윤덕",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 최용락 참고문헌: p. 27-28",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근, 머신 러닝에 대한 관심이 증가하고 있다 . 빅데이터 시대의 도래와 더불어, 컴퓨팅 성능은 좋아졌으며 컴퓨팅 자원을 합리적인 가격에 갖출 수 있게 되면서, 머신 러닝은 각종 연구, 사업 영역에서 폭 넓게 주목을 받고 있다. AI(Artificial Intelligence)의 한 분야인 자연어 처리(NLP: Natural Language Processing)또한 그런 흐름의 영향을 받은 분야 중의 하나다. 자연어 처리는 컴퓨터가 사람의 언어를 이해할 수 있도록 하는 방법을 연구하는 하나의 분야로써 사람이 직접 작성한 규칙을 기반으로 사람의 언어를 해석하려는 고전적인 방식부터, 통계적 언어 모델(Statistical Language Model)이 도입되고, 머신 러닝이 적용되면서 점차 발전해 왔다. 이러한 연구들은 인공신경망을 적용한 NNLM(Feedforward Neural Net Language Model), RNNLM(Recurrent Neural Net Language Model) 방식이 등장하면서, 큰 성능 향상을 가져왔다. 최근에는 word2vec 방식이 등장하면서, 기존 인공신경망 방식들에 비해 효율성을 높였다. 위키피디아는 전 세계인이 협력하여 작성하고, 유지하는 방대한 지식 스키마이다. 따라서 이 텍스트 데이터 셋을 분석하여, 각 단어들의 상관관계를 분석하는 것은 유의미한 작업이 될 것이다. 그러나 이러한 작업들이 실제로 이뤄지고 있으나, 비교적 최신 알고리즘인 word2vec의 위키피디아 데이터 셋에 대한 적용되는 사례는 많지 않다. 따라서, 본 논문에서는 데이터를 분석하기 위한 word2vec 라이브러리, 모듈 사이의 통신을 위한 Django 프레임워크, 단어 사이의 유사성을 시각화 하여 보여주기 위한 D3.js를 이용하여 효율적으로 위키피디아 데이터 셋을 분석하고, 해당 데이터 셋의 단어들이 서로 얼마나 상관성을 갖고 있는지 보여줄 수 있는 애플리케이션을 구현한다.",
		"KEYWORD": "NLP,wikipedia,word2vec,인공신경망,자연어처리"
	},
	{
		"ID": 839,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "GPU기반의 보안 로그와 이벤트 고속필터링기법에 대한 실증적 연구 =(An)empirical study of the high-speed filtering techniques for security logs and events based on GPU ",
		"AUTHOR": "안혜선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "컴퓨터와 인터넷의 확산으로 2011년 한해에만 1.8ZB(제타바이트)의 데이터를 생산하는 등의 데이터 홍수와 폭증으로 빅 데이터가 특정분야에 국한되지 않는 이슈로 등장하였으며 이중 가장 대표적인 로그 데이터 분야에서는 전자기록 증거 및 분석에 대한 중요성이 매우 높아져 정규화 또는 축약의 처리과정 없이 원본 로그 그대로의 수집과 저장이 중요한 요소가 되었다. 통합보안관리솔루션(ESM)과 보안 정보와 이벤트 관리시스템(SIEM)은 상호 연관관계 분석 및 필터링 수행을 위해 관계형 DB에 입력하고 색인화 또는 조회에 필요한 시간만큼 지연이 발생하는 구조로 데이터의 건수가 많거나 크기가 커지면 처리 시간이 급격히 증가하여 대규모 데이터 수집과 실시간 조회, 분석이 필요한 보안정책 위반사건에 적합하지 않은 구조이다. 본 논문에서는 고비용 시스템 업데이트를 하지 않고서도 증가하는 보안 로그와 이벤트를 실시간 분석 및 처리하고자 GPU(Graphic Processing Unit)기반의 고속필터링기법을 연구하였다. GPU의 각 스레드에서 Brute Force String Matching 알고리즘을 응용한 필터링 알고리즘을 동시에 수행한 결과 CPU(Central Processing Unit)만을 이용한 기존 필터링 수행시간에 비해 평균 약 3000배 이상 빠른 측정 결과를 보였으나 이는 GPU 공유 메모리 할당문제를 해결하지 못하여 최대 수행 가능한 30 라인씩 나누어 반복 수행한 결과이다.",
		"KEYWORD": null
	},
	{
		"ID": 840,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "데이터의 시각화를 통한 현시대상의 기록과 표현 =(The)expression of the modern age through `visualization of database` ",
		"AUTHOR": "김해리",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임영길 국·영문초록수록 참고문헌: 장 44-46",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "Times constantly change, develop and evolve. With the development of the Internet, the amount of data created by each individual is beyond our imagination and now we are about to enter the era of big data. These data have begun to penetrate the field of art in addition to medical, science and industrial fields and it is no exaggeration to say that we spend every minute of our life with data. For me as a researcher, I attach significance to recording how the present age and people living in it look like through data visualization. My work includes reflection and expression of the lives of numerous people living in various spaces in modern society. I watch and interpret from an observer’s point of view ordinary objects we often regard as meaningless in our daily routine and visualize them on a screen using an individual material,“heat.”I personally refer to a work produced this way as“heat detection”and I focus on dealing with screen printing works (2013-2015). First of all, by reviewing the previous cases of data visualization art, the possibility and worth as“record”will be assessed and a theoretical foundation will be established and possibilities will be sought concerning the methods of screen printing through data visualization. Like this, even though the works have been produced based on my subjective interpretations, I am expecting the viewers would feel empathy with them because we are living in the same age. Considering I began with great passion to produce works reflecting the present age with a portrayal of the space and people of the present time and make them become records to share with our later generations, I hope that my works would serve as a foundation for producing more developed and forward-looking works with boundless places as the background.",
		"KEYWORD": null
	},
	{
		"ID": 841,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "원격 백업 구축 및 우선순위 기반 스케줄링 =Design and implement of remote backup and priority based scheduling ",
		"AUTHOR": "황한태",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조인휘 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 40-41",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 데이터를 이용하는 분야가 폭발적으로 증가함에 따라서 데이터를 생산 수집 가공에 비즈니스 생태계가 형성되고 있다. 이런 상황에서 빅데이터 뿐만 아니라 RDBMS의 데이터의 중요도도 같이 증가하고 있어 해당 데이터의 손실 방지뿐만 아니라 복구에 소요되는 시간도 점차 중요해 지고 있다. 본 논문에서 제안하는 원격 백업 구축 및 우선순위 기반 스케줄링은 Python과 MySQL을 이용해서 구현되었다. 또한 MySQL의 스케줄링에 필요한 메타 정보를 저장하기 위해서 사용되었다. 본 연구에서 제안하는 원격백업 구축은 하나의 네트워크 대역에 구축하여 백업으로 인한 서비스 영향을 최소한으로 줄였다. 또한 우선 순위 기반은 백업 완료 시간 및 과거 3일치의 백업 성공 여부에 가중치를 두어서 우선순위를 결정하는 스케줄링이다. 기존에 사용하던 랜덤 알고리즘은 3일 연속 실패 서버가 총 493대이며 우선순위 기반 알고리즘은 8대이다. 우선순위 기반 알고리즘 실패하는 8대는 물리적으로 백업이 불가능한 서버들이다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 842,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한국외국어대학교 대학원",
		"TITLE": "Genetic 알고리즘 기반 최적 k-익명화 탐색에 관한 연구 =Study on exploring k-anonymity based on genetic algorithms ",
		"AUTHOR": "황명식",
		"REGION": "서울",
		"PROFESSOR": "한국외대 논문은 저작권에 의해 보호받습니다. 지도교수: 최대우 참고문헌 : p.26",
		"STORE_LOCATION": "한국외국어대학교 글로벌캠퍼스 도서관,한국외국어대학교 서울캠퍼스 도서관",
		"ABSTRACT": "Genetic 알고리즘 기반 최적 k-익명화 탐색에 관한 연구 빅데이터에 대한 관심이 높아지면서 데이터 개방의 필요성이 대두 되고있다. 때문에 데이터 개방과 개인정보보호를 동시에 고려하는 Privacy Preserving Data Mining이라는 익명화 방법이 연구되고 있다. 본 연구에서는 익명화 방법중 하나인 k-anonymity를 사용하여 개인정보는 보호하며 데이터의 손실을 줄이는 최적의 방법을 Genetic Algorithm을 적용한 탐색 방법을 제안하였다. Genetic Algorithm을 적용한 탐색은 과거 시도보다 최적의 익명화 데이터를 3배 정도 빠르게 탐색하는 성능을 보였다.",
		"KEYWORD": "Gentic algorithm,k-anonymity,Privacy Preserving Data Mining,일반화 계층구조"
	},
	{
		"ID": 843,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "서울벤처대학원대학교",
		"TITLE": "은행지점의 입지 및 점포특성이 매출에 미치는 영향에 관한 연구 :(An)empirical study on the effect of locational and store characteristics of bank branch on the sales :분당 및 판교신도시를 중심으로 =a case of Bundang and Pangyo new city area ",
		"AUTHOR": "이정대",
		"REGION": "서울",
		"PROFESSOR": "",
		"STORE_LOCATION": "서울벤처대학원대학교 중앙도서관",
		"ABSTRACT": "논 문 개 요 최근 은행들이 경쟁력 강화를 위해 지점 축소 또는 재배치를 진행하고 있다. 그러나 은행은 점포를 통한 대면채널이 영업활동에 매우 중요한 역할을 담당하고 있어 지점 축소를 쉽게 결정할 수 없다. 이에 본 연구는 은행지점의 입지 및 점포특성이 매출에 미치는 영향을 분석하여 향후 은행지점의 출점 및 폐점전략에 필요한 기초자료를 제시하는데 목적이 있다. 이를 위하여 분당신도시 및 판교신도시 지역에서 2012년 현재 영업 중인 138개 은행지점에 대한 매출 관련 빅데이터(Bigdata)를 기초자료로 활용하였다. 빅데이터(Bigdata)를 통해 구득한 은행지점의 매출을 종속변수로 하고, 종속변수에 영향을 주는 변수들을 독립변수로 구성하였다. 독립변수는 인구요인(주민등록인구수, 전철이용객수), 부동산요인(소재지 용도지역, 자가점포여부), 접근요인(대형쇼핑시설거리, 주민센터 거리, 전철역 거리), 물리적 요인(전용면적), 업무요인(영업기간, 근무인원, 복합금융여부) 등 5개 요인 11개 독립변수로 구분하였다. 독립변수는 분당 및 판교지역에서 근무하는 은행직원들을 대상으로 FGI 조사를 실시하여 현장의 심층적인 의견을 청취하였으며, 그 결과 은행지점의 특성을 크게 입지특성과 점포특성으로 구분하여 다중회귀분석을 위한 변수를 1차 구성하였다. 이후 이론 및 선행연구 고찰을 병행하여 최종 독립변수를 선정하였다. 이렇게 구성된 변수는 다중회귀모형을 통해 종속변수와 독립변수들 간의 회귀식을 추정하고, 추정된 회귀식을 이용하여 매출에 미치는 영향관계를 실증 분석하였다. 또한 세분화가 필요한 독립변수에 대하여 종속변수 분산분석(ANOVA)을 실시하여 분석대상을 세분화하였다. 분산분석 결과 도출된 각각의 독립변수는 다중회귀모형으로 다시 실증분석 하였다. 이러한 과정을 통해 각각의 독립변수가 종속변수인 은행지점의 매출에 영향을 미치는 한계효용점을 도출하고, 은행지점의 운영에 필요한 전략적 포지션(position)과 정책적 함의를 제시할 수 있었다. 특히 은행지점의 매출은 단순하게 유동인구가 많은 지역보다는 경제활동이 활발하게 이루어지는 상업지역에서 긍정적인 결과를 얻을 수 있음을 확인 할 수 있었다. 또 임차보다는 자가소유 형태의 은행지점 매출이 높은 것으로 나타났다. 아울러 은행지점과 전철역까지의 거리는 50m까지가 최대 한계효용점으로 확인되었으며, 경제활동인구는 많고 유동인구는 적을수록 은행지점의 매출에 도움이 되는 것으로 나타났다. 무엇보다 은행지점이 안정적인 매출을 확보하기 위해서는 출점 후 3년 정도의 정착기간이 필요한 데, 출점 3년 이내인 ‘신설지점’은 지하철역에 가까운 점포가 매출증대에 유리하고, 3년 이상 된 ‘기존지점’은 상업지역이면서 근무인원이 많은 지점이 매출 증대에 유리한 것으로 나타났다. 또 은행지점의 전용면적이 증가하면 근무인원도 함께 증가하는 상관관계를 확인할 수 있었다. 은행지점의 업무유형은 개인금융과 기업금융을 동시에 유치하는 복합금융이 매출에 긍정적인 영향을 미치고, 매출을 구성하는 총수신과 총대출은 모두 영업손익에 긍정적인 영향을 미치는 것으로 나타났다. 본 연구의 결과는 향후 은행지점의 출점 및 폐점전략의 기초자료로 활용될 수 있다는데 그 의의가 있다. 특히 은행지점의 매출에 영향을 미치는 다양한 변수를 도출하고 이를 계량화하였다는 데에서 그 의미가 크다. 그러나 본 연구는 공간적으로 분당 및 판교신도시만을 대상으로 하고 있기 때문에 연구모형과 결과를 기존도시 또는 타 지역에 그대로 적용하는 것에는 한계가 있다. 따라서 향후 다른 지역에 대해서도 분석을 수행함으로써 폭넓은 점포효율화 전략을 수행할 수 있는 기초자료를 만들 수 있을 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 844,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한국외국어대학교 국제지역대학원",
		"TITLE": "위험사회에서 소셜미디어의 효용성에 대한 연구: `세월호` 사건에 대한 인터넷 뉴스와 트위터의 비교를 중심으로 ",
		"AUTHOR": "김신구",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 845,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "Cloud-based e-discovery system for implementing the public service of digital investigation =디지털 수사의 공공 서비스 실현을 위한 클라우드 기반 전자증거개시 시스템 ",
		"AUTHOR": "TaerimLee",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 846,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 비즈니스IT전문대학원",
		"TITLE": "사이트 포트폴리오 구성을 위한 사용자 관점의 웹사이트 클러스터링 =User perspective website clustering for site portfolio construction ",
		"AUTHOR": "김민규",
		"REGION": "",
		"PROFESSOR": "지도교수: 김남규 참고문헌: p. 32-36",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "많은 사용자들이 인터넷을 통해 정보검색, 쇼핑, 커뮤니티 참여 등의 일상 생활을 영위하고 있으며, 이들 인터넷 사용자들로부터 수익을 창출하기 위한 웹사이트들의 경쟁은 점점 치열해지고 있다. 각 사이트의 운영자 및 마케팅 담당자들은 경쟁 우위를 차지하기 위해 다양한 전략을 수립하고 있으며, 이 과정에서 타 사이트와의 제휴가 이루어지는 경우도 비일비재하다. 이는 타 사이트와의 제휴를 통해 타사의 고객 정보를 부분적으로 공유할 수 있을 뿐 아니라 포인트 공유, 상호 추천 등 보다 다양한 전략의 운용이 가능하기 때문이다. 제휴를 통해 긍정적인 성과를 거두기 위해서는 현재 자사의 고객은 아니지만 미래의 자사 고객이 될 수 있는 잠재 고객을 다수 확보하고 있는 타 사이트를 제휴 대상으로 선정하는 것이 매우 중요하다. 하지만 많은 사이트 중 이와 같이 자사에 도움이 되는 제휴 대상 사이트를 식별하는 것은 쉬운 일이 아니다. 따라서 본 논문에서는 방문 고객의 유사성 관점에서 사이트 클러스터링을 수행하고, 이에 근거하여 유사 고객 군을 공유하고 있는 제휴 사이트 대상을 식별할 수 있는 방안을 제시한다. 또한 제안 방법론의 실무 적용 가능성을 평가하기 위해, 웹사이트 150,295개에 대한 패널 5,000명의 실제 방문 기록 약 1억 4천만 건에 대해 실험을 수행하고 그 결과를 제시한다.",
		"KEYWORD": null
	},
	{
		"ID": 847,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한양대학교 경영대학원",
		"TITLE": "기업의 SNS 노출이 주가에 영향을 미치는가 =Do the firm`s exposures to SNS affect their stock prices in Korea? :한국의 트위터와 블로그를 중심으로 ",
		"AUTHOR": "김태환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이상용 권두에 국문요지, 권말에 Abstract 수록 참고문헌: p. 41-43",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "주가의 변동에 대한 예측은 경제 분야뿐만 아니라 수학, 통계, 전산 분야에 걸쳐 오랜 기간 매우 중요한 연구과제로 인식되어 왔으며 학계에서뿐 아니라 실무에서도 높은 관심거리가 되어 왔다. 본 연구의 목적은 주식시장에 상장되어 있는 기업이 SNS을 통해 많은 사람들에게 회자 되고 있다면, 이것이 기업 주가에 얼마나 영향을 주는지에 대해 확인해 보고자 하는 것이다. 본 연구의 데이터는 2012년 5월 25일부터 9월 1일까지 100일간의 252개 상장기업의 주가데이터와 KRX100지수, SNS 상에 노출된 빈도수, 긍정어 수, 부정어 수를 수집하였으며 대상기업의 데이터를 3개의 카테고리로 구성하여 (IT/비 IT, 대기업/중소기업, 코스피/코스닥), 회귀분석과 Granger Causality 분석을 통해 주가 예측에 대한 인과관계를 알아보았다. 분석결과 SNS상에서 특정 기업의 노출 빈도가 많을수록 해당 기업의 주가는 긍정적인 상관관계로 나타났고, 부정적 표현 보다는 긍정적 표현의 기업이 주가에 영향을 미치는 것으로 나타났다. 결론적으로, 비록 경제학적 관점에 국한되기는 하지만 SNS 공간에서 어떤 한 기업이 많이 노출된다는 것은 그 만큼 그 기업의 가치가 높아진다는 것을 의미하며 그 기업에 대한 부정적 표현보다는 긍정적 표현이 그 기업 가치를 조금 더 적절하게 반영한다고 할 수 있다. 또한, 이러한 효과는 비 IT 기업 보다 IT기업이 대기업 보다는 중소기업이 더 큰 것으로 나타났다.",
		"KEYWORD": "경영전략"
	},
	{
		"ID": 848,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "딥러닝 기법에 기반한 인터넷 상점 클릭스트림 데이터를 통한 구매 예측 =Purchase prediction through clickstream data of internet stores based on deep learning technique ",
		"AUTHOR": "김기태",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김종우 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 48-52",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 빅 데이터가 이슈가 되면서 데이터들을 어떻게 분석할 것인지가 이슈가 되고 있다. 이 중 딥러닝(Deep Learning)이라 불리는 심층신경망 기법들이 이미지 인식이나 음성 인식에서 뛰어난 성능을 보여 주목을 받고 있는데, 이는 기존 기법들이 구현하기 어려웠던 사람 얼굴과 같은 고차원적인 특징을 추출하는 것에서 강점을 가지고 있기 때문이다. 다만 지금까지 딥러닝에 관한 연구들은 대부분 컴퓨터 분야에서 딥러닝의 성능을 높이거나 더 빠르게 훈련할 수 있는지에 맞춰져 있었다. 본 연구는 이러한 딥러닝의 강점을 이미지나 음성 데이터 외에도 비즈니스 데이터를 분석하는데 활용한다면 좋은 성과를 보일 수 있을 것이라 생각하였다. 이를 확인해 보기 위하여 한 인터넷 서점의 클릭스트림 데이터를 사용해 고객의 구매를 예측하는 모형들을 만들고 그 성능을 비교해 보기로 하였다. 실험을 위해 딥러닝 기법 중 DBM을 기반으로 한 구매 예측 모형들과, 성능 비교를 위한 나이브 베이지안(Naive Bayesian) 분류법을 기반으로 한 구매 예측 모형들을 작성하였다. 두 종류의 모형들의 예측 성능을 비교할 때에는 정밀도와 재현율을 동시에 고려할 수 있는 F1-score를 사용하였다. 실험 결과, 딥러닝을 기반으로 한 예측 모형이 나이브 베이지안 분류법을 기반으로 한 모형에 비해 더 좋은 예측 성능을 보여준 것을 확인하였다. 이를 통해 비즈니스 데이터를 분석할 때에 딥러닝 기법을 활용한다면 더 좋은 결과를 보일 수 있을 것이란 가능성을 볼 수 있었다. 그리고 위 실험에서 가장 좋은 성능을 보인 딥러닝 예측 모형을 하나 선택하여, 해당 모형이 학습한 구매자들의 페이지 이동 경로 특징을 시각화하여 분석하였다. 그 결과 구매자들은 검색 페이지와 홍보 페이지, 검색 페이지와 장바구니 페이지 사이를 왕복한다는 특징과, 계정 페이지에서 장바구니 페이지로 이동한다는 특징을 가지고 있다는 것을 확인할 수 있었다.",
		"KEYWORD": "전자상거래"
	},
	{
		"ID": 849,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "남서울대학교 대학원",
		"TITLE": "연속수치지도와 공간통계를 이용한 범죄발생취약지역 분석 ",
		"AUTHOR": "박진이",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 김의명",
		"STORE_LOCATION": "남서울대학교 도서관",
		"ABSTRACT": "In modern society, crime in urban area is said to be one of serious social problems. According to crime statistics, crimes occurred at road, residential areas and sex establishments in order. Status information related to crime in domestic has been provided for user in the form of statistics which does not have location information. So user cannot recognize the exact place of crime occurrence. Also, crime related location information has been provided to concerned agency in the form of hot spots that have been interpolated. As a result, it is difficult to derive information of crime prevention because there is not enough accuracy about information of crime occurrence place. In this study suggested methodology of extraction of crime vulnerable areas using spatial information, statistics information and public information that has characteristics of spatial. Through this study will provide appropriate information of individuals crime prevention information and will solve anxiety of social problems from women, children and the infirm who are socially disadvantaged. Methodology of extraction of crime vulnerable areas consisted of three stages. The first stage used spatial information like road-center line layer and building layer of digital map. The second stage used statistics information like estimated income and population socially disadvantaged. The third stage extracted final crime vulnerable areas using public information like CCTV location information with outcome data of first stage and second stage. Methodology of extraction of crime vulnerable areas analysed two study areas that are many population movement of urban. Also, this methodology verified with analysis of quantitative and qualitative using crime occurrence information of safe map that services the National Disaster Management Institute. As a result, methodology of extraction of crime vulnerable areas and analysis of quantitative coincided each other by about 76.89% and they have high accuracy. And result of analysis about crime vulnerable areas based on grid can provide exact information more than existing information of crime statistics about near by area of administration border area and narrow area. Also this methodology will provide efficient management and efficient work from local government officials through combination of extracted crime vulnerable areas and road name address.",
		"KEYWORD": null
	},
	{
		"ID": 850,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서강대학교 경영전문대학원",
		"TITLE": "서비스의 개인화 정도와 정보 프라이버시 염려가 인지된 서비스 가치에 미치는 영향 :개인화된 모바일 서비스 중심으로 ",
		"AUTHOR": "김기수",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김명석 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Being personalization of service increase benefit of not only customer but also service provider like win-win situation. The benefit of personalization is in doubt because information privacy concern. According to privacy calculus model, when customer was called to ask to provide personal information from service provider, they conduct risk-benefit analysis. In this study, benefit was defined as perceived level of personalization and risk was defined as information privacy concern. Perceived Personalization was measured by Carol and Michale(1987)’s model. Perceived personalization was divided 2 dimensions ? usability, information. Perceived risk was measured by IUIPC model by Malhotra et al.(2004). 221 samples were collected. I analyzed data with AMOS 20.0 and SPSS 19.0. According to the result of research, information privacy concern and perceived level of personalization decide value of service quality. We also learn privacy concern is more effective than perceived level of personalization when deciding value of service quality.",
		"KEYWORD": null
	},
	{
		"ID": 851,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "효과적인 전자증거개시 처리를 위한 질의 추천 시스템 ",
		"AUTHOR": "이헌민",
		"REGION": "부산",
		"PROFESSOR": "지도교수:신상욱 참고문헌",
		"STORE_LOCATION": "부경대학교 도서관",
		"ABSTRACT": "In order to effectively respond to the future litigation and to win a case, the most important task is to secure the highly relevant evidence produced by the proper search and review in respect of litigation issues during a whole e-Discovery procedure. At this point, the role of search is to reduce the amounts of document which should be additionally reviewed as potential evidence, so the poor search result caused by the use of wrong keywords can bring unexpected time and cost problems. These keywords, in general, are selected by analysis about the content of complaint or related documents at the beginning stage of e-Discovery and this stage is called ECA(Early Case Assessment) in EDRM(Electronic Discovery Reference Model). Ultimately, the success of e-Discovery depends very much on how well the participants performed essential tasks of ECA, but it has mostly depended on the ability of specific human like lawyer because existing e-Discovery solutions did not support this kind of function in priority. This thesis, therefore, suggests the machine learning based litigation preparing method for effective early case assessment on e-Discovery procedure. The suggested method extracts and collects the meaningful information from the complaints and related documents which were retained by the litigant. This information can be used for identifying the main issues of litigation, discussion in meet-and-confer session, creating a request for production, or writing another related complaint. Also, special experiment and evaluation result using the real complaint introduced by TREC Legal Track will be described for analyzing the availability of this method.",
		"KEYWORD": null
	},
	{
		"ID": 852,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "부경대학교 대학원",
		"TITLE": "인더스트리4.0 기반 사이버 물리 시스템과 생산관리시스템간의 미들웨어 구축을 통한 수평적 통합에 관한 연구 ",
		"AUTHOR": "김대근",
		"REGION": "부산",
		"PROFESSOR": "지도교수:박만곤 참고문헌",
		"STORE_LOCATION": "부경대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 853,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서울시립대학교 과학기술대학원",
		"TITLE": "하둡 클러스터에서 GPU를 이용한 이미지 객체 검출의 가속 =Accelerating image object detection using GPU on Hadoop cluster ",
		"AUTHOR": "김명배",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이영민",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "현 시대에서 CCTV로 얻어지는 영상데이터는 날로 증가하여 빅데이터의 중요한 부분을 차지하고 있으며, 많은 영역에서 이용되고 있다. 영상데이터에서 원하는 특징 점을 검출하는데 효율적인 처리가 가능한 SURF 알고리즘은 OpenCV에서 API를 지원하고 있으며 여러 분야에서 응용되고 있다. 영상데이터 처리를 위해서는 많은 계산시간이 소요되므로 이를 개선하기 위하여 GPU을 이용한 처리가 연구되고 있으며 OpenCV에서는 CUDA로 구현된 GPU SURF 알고리즘을 지원하고 있다. 본 논문은 CUDA를 이용한 GPU 가속 SURF 알고리즘에 병렬분산처리 시스템인 하둡을 연결하여 개선된 결과를 얻고자 하였다. OpenCV로 구현된 CPU SURF와 GPU SURF에 Hadoop Pipe를 이용해 하둡과 연결하고 노드의 수를 증가시키면서 특징 점을 검출하는 실험을 하였다. Single mode CPU SURF에 대해 GPU SURF는 검출 속도가 1.4배 빠른 것을 확인하였고 하둡 노드수의 증가에 따라 최대 10.3배까지 속도가 빨라지는 것을 확인하였다.",
		"KEYWORD": "GPU,하둡"
	},
	{
		"ID": 854,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "한양대학교 이노베이션대학원",
		"TITLE": "방송콘텐츠 서비스 전략에 관한 연구 :(A)study on the strategy of future content & services for EBS :EBS 지식채널e를 중심으로 =based on success factors of EBS 지식채널e ",
		"AUTHOR": "유남이",
		"REGION": "서울",
		"PROFESSOR": "국문요지: p. vii-viii Abstract: p. 141-143 설명적 각주 수록 부록: 1. 지식채널e 프로그램 개요, 2. 역대 프로그램 제작진 현황, 3. EBS콘텐츠 가격결정 원칙 외. 지도교수: 김용범 참고문헌: p. 107-109 서지적 각주 수록",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 TV 및 방송 분야에는 많은 변화가 일어나고 있다. 미디어기술의 발달에 따른 스마트화가 진행되고 있고 유통 채널의 다변화에 따른 N스크린적 소비가 보편화되고 있다. 이러한 미디어 컨버전스는 세계적인 추세로, 여러 미디어소비 행태 조사 등을 통해 볼 때 웹 및 모바일, 디지털 미디어 활용시간이나 데이터 사용량이 지속적으로 증가될 것으로 예측되고 있다. 국내의 미디어 산업은 글로벌 거대 기업의 온라인 플랫폼 전략으로 위기에 처해 있고, 전자출판시장까지도 애플의 아이북스, 아마존의 킨들과 같은 해외의 디지털기술 표준과 디지털콘텐츠에 잠식될 위기에 처해 있다. 또한, 소비자들의 스마트 기기의 활용은 웹서핑, 동영상콘텐츠, 게임 등 주로 오락 위주로 편중되어 있어 고품질의 콘텐츠 제공 환경 조성을 위한 적극적인 대처와 지식콘텐츠에 대한 새로운 필요성이 대두되고 있는 시점이다. 본 논문은 이러한 급변하는 미디어 기술과 사회변화에 적극 대처하기 위하여 새로운 콘텐츠의 기획, 제작, 서비스를 어떻게 구현해가야 할 것인가에 대한 문제를 EBS의 ‘지식채널e’ 프로그램을 중심으로 분석하였다. 지금까지의 지식채널e에 대한 연구는 저널리즘 관점, 학교 현장에서의 교과지도, 독서지도 등의 분야에서 수사학이나 교육적 활용 방안에 대한 연구로 집중되어 왔다. 이러한 기존의 연구의 한계를 넘어서 본 연구는 다음과 같은 연구를 수행하였다. 첫째, 지식채널e의 대중적 호응, 작품성, 교육성, 공익성 등의 원동력은 무엇인지에 대한 분석을 통해 지식채널e의 특성과 성공 요인을 분석하고 둘째, 사회 환경 변화, 미디어 환경 변화를 고려한 어떻게 새로운 미디어 전략을 펼칠 것인지에 대한 대안 제시이다. 지식채널e의 특성과 성공요인 분석에서는 첫째, 연도별 국내 일평균 매체 소비시간 변화-한국방송광고공사의 MCR, 감성사회 진입에 따른 가치추구 변화, 네티즌의 공유와 참여, 그리고 자기학습 확대와 자발적 확산 등 사회적 변화와 소비자의 욕구 변화를 분석하고 둘째, 콘텐츠 기획, 제작, 서비스 측면에서는 지식채널e의 주요한 특성 즉 짧은 분량 특성을 활용한 반복노출 효과, 여백과 결핍의 공감코드, 더 많은 사람들에게 가치를 공유하기 위한 인터넷 무료 정책 등을 다루었으며 셋째, 콘텐츠의 서사구조 및 감성적 스토리텔링 측면에서는 서사구조의 완결성, 영상콘텐츠의 미학을 통해 서사구조 전략과 지식채널e의 구성의 묘미를 파악하고, 출판물로 장르전환 시 각 출판물의 서사구조와 기획 전략을 비교해 봄으로써 매체별 콘텐츠 기획의 특성과 고려 사항을 살펴보았다. 새로운 미디어 전략 수립을 위한 대안 제시의 측면에서는 첫째, 방송콘텐츠가 나아갈 서비스의 지향점을 제시하고 둘째, 미디어 교육의 확대 방안을 제시하였으며 셋째, 클립콘텐츠에 스토리텔링을 접목한 웹과 모바일 기반의 인터렉티브형 서비스, 콘텐츠 플랫폼 운영 등의 전략 방안을 제안하였다. 이러한 분석과 대안 제시를 통해 본 연구는 미디어 환경 변화와 사용자의 욕구 변화에 적극적으로 부응하고 이에 대처하기 위하여 콘텐츠 플랫폼을 구축하고 지원하는 일은 글로벌 콘텐츠 경쟁력을 확보하는 일과 함께 미디어 유통전략 뿐만 아니라 문화전략 측면에서도 매우 중요한 일임을 강조하였다.",
		"KEYWORD": "미디어"
	},
	{
		"ID": 855,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "MySQL/PostgreSQL/ 상에서 TPC-C 워크로드를 이용한 분산파일 시스템 성능비교 =(The)performance study of distribute file systems using MySQL/PostgreSQL/ with TPC-C ",
		"AUTHOR": "김영롱",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 차재혁 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 49-50",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "오늘날 다양한 정보 채널의 등장과 스마트폰 단말 등으로 인해 데이터의 크기가 기하급수적으로 증가를 하고 있다. 특히 스마트폰과 SNS(social network service)의 등장과 발달로 이러한 증가를 더 확산시키고 있다. 이런 대규모의 데이터를 빅데이터(Bigdata)라고 부른다. 일반적으로 많은 사용자가 사용하는 데이터를 보다 쉽게 관리하기 위하여 데이터베이스 시스템(DBMS)을 사용한다. 현재 범용적으로 많이 사용되고 있는 데이터베이스 시스템으로는 관계형 데이터베이스 시스템(RDBMS)이다. 기존의 관계형 데이터베이스의 서버 처리방식은 스케일업(Scale-up) 방식으로 스토리지 노드에 스토리지 디바이스(Storage device)를 추가하거나 자체노드 성능을 높여 처리 하는 방식이다. 그러나 스케일업의 한계는 스토리지 노드에 한정된 용량확장과 비용이 많이 든다는 점에 있다. 이러한 한정된 용량확장과 비용을 해결하기 위해서는 스케잇아웃(Scale-out)을 이용할 필요가 있다. 스케일아웃은 노드자체의 성능을 높이기보다 새로운 노드를 추가하여 분산된 서버처리를 하는 방식이다. 그래서 스케일아웃과 확장성(Scalability)을 이용하는 분산파일시스템을 가지고 관계형 데이터베이스를 사용하였을 때 각 각 어떤 성능이 측정되는지 테스트를 진행하였다. 본 논문에서는 관계형 데이터베이스로 현재 오픈소스로 많이 이용하는 Mysql, PostgreSQL를 사용하였고 분산파일시스템은 많은 기업에서 연구가 활발히 진행되고 있는 Ceph, Swift, GlusterFS 을 사용하였다. 성능분석은 리눅스에서 지원하는 툴로 IOstat, Perf 및 트랜잭션 성능평가 의원회(TPC)에서 발표한 데이터베이스 벤치마크 모델 중 하나인 TPC-C를 사용하였다. 벤치마크 툴로는 오픈소스로 사용할 수 있는 HammerDB를 활용하여 각 각의 분산파일시스템의 tmp(Transaction per minute) 값으로 성능을 측정하였다. 성능분석을 통해 각 분산파일 시스템에서의 Read, Write 요청값의 비교결과를 나타낼 것이다. 그리고 분산파일시스템의 확성(scalability)에 따른 TPM 값과 관계형 데이터베이스가 각 각의 분산파일시스템 환경에서 어떤 성능결과를 나타내는지 보여 줄 것이다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 856,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "맵리듀스와 지역민감해싱을 이용한 근사 근접 이웃 처리 =Processing approximate nearest neighbor using MapReduce and locality sensitive hashing ",
		"AUTHOR": "윤기영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박호현",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "맵리듀스 환경에서 보다 빠른 Approximate Nearest Neighbor(ANN) 를 수행하려면 맵단계에서 리듀스단계로 넘어가는 데이터를 최소화하는 것이 중요하다. 따라서 불필요한 데이터의 생성 및 전송을 막아야 한다. 본 논문은 Entropy Locality Sensitive Hashing(ELSH)과 블룸필터를 이용하여 맵리듀스 환경에서 ANN을 제안한다. ELSH는 공간복잡도가 Basic LSH(BLSH)보다 낮으며 블룸필터는 쿼리와 관계없는 데이터들을 제거해 네트워크 비용을 감소시킨다. 실험결과 블룸필터를 이용하는 것이 블룸필터를 이용하지 않는 방법보다 3배 이상의 성능차이를 가져오며 같은 재현율을 가질때 ELSH가 BLSH보다 약 40%의 속도향상을 가져왔다. 그리고 제안방법은 재현율이 0.99일때 선형검색에 비해 쿼리가 1k일때는 약 10배, 10k일때는 60배의 성능효과를 낸다. 본 논문에서 제안하는 방법은 고차원의 빅데이터에서 ANN 수행시 빠른 수행결과와 높은 재현율을 동시에 만족한다.",
		"KEYWORD": null
	},
	{
		"ID": 857,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 대학원",
		"TITLE": "Scale-up 서버에서의 도커 컨테이너를 이용한 아파치 스파크 시스템 확장성 개선 =Docker container-based scalable partitioning for apache spark scale-up server scalability ",
		"AUTHOR": "전진우",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 임성수 Docker Container-based Scalable Partitioning for Apache Spark Scale-up Server Scalability 참고문헌 : p.31",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "기존의 빅데이터(BigData) 플랫폼에서는 분산 처리 환경(scale-out)을 기반으로 한 하둡(Hadoop)과 스파크(Spark)와 같은 분산 처리 프레임워크가 많이 사용되어 왔다. 하지만 최근 기술이 발달하여 매니코어(Many-core) 기술과 같은 고성능 컴퓨팅 서버가 보편화됨에 따라 여러 대의 서버로 구성된 분산 처리 환경 대신 한 대의 고성능 컴퓨터 환경(scale-up)에서 분산 처리 프레임워크를 구축하여 빅데이터를 처리하는 시도가 가능해졌다. 따라서 이러한 방법이 현실화되기 위해서는 코어 수 증가에 따른 성능 확장성(scalability)이 확보되어야 한다. 본 논문에서는 하둡 파일 시스템(HDFS)과 아파치 스파크(Apache Spark) 시스템을 120 코어로 구성된 단일 scale-up 서버에 구성하고, 스파크 성능을 측정하는 벤치마크의 워크로드 4가지로 코어수를 바꿔가며 성능을 측정하였다. 코어 수가 늘어남에 따라 성능이 더 잘나오는 것을 기대했지만, 일정 코어수가 늘어나자 성능이 점점 떨어지는 확장성 문제를 발견하였다. 확장성 문제의 원인으로는 스파크가 사용하는 자바 가상 머신의 GC(Garbage Collection)에 의한 오버헤드, scale-up 서버의 NUMA(Non Un -iform Memory Access) 메모리 구조에 따른 메모리 접근 지연(Memory Access Latency) 시간 문제, 공유 메모리 시스템(Shared Memory System)의 환경 때문에 발생하는 확장성 저해 요소가 있음을 분석하였다. 이러한 확장성 문제를 해결하기 위해 리눅스의 도커 컨테이너를 이용하여 scale-up 서버를 파티셔닝(partitioning)하여 하나의 서버를 분산 시스템(Distributed System)처럼 구성하는 방법을 제안하였다. 본 논문에서는 시스템의 효율적인 파티셔닝을 결정해주는 도커(Docker) 컨테이너(Container) 기반 프레임워크(Decision Engine)의 디자인을 제안하며, 파티셔닝 기법의 가능성을 확인하기 위해 15코어 또는 30코어 단위로 여러 개의 컨테이너를 설정하여 파티셔닝을 수동으로 수행했을 때의 성능을 측정하였다. 그 결과 4개의 스파크 벤치마크 워크로드에 대해 파티셔닝을 하기 전보다 확장성이 개선된 것을 확인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 858,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "대전대학교 대학원",
		"TITLE": "하둡 기반의 정규식을 이용한 효율적인 보안로그분석 시스템 ",
		"AUTHOR": "이종윤",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 이봉환",
		"STORE_LOCATION": "대전대학교 도서관",
		"ABSTRACT": "Logs generated from a variety of IT devices are useful and important data which can be used to trace events in the system. It is needed to construct an integrated log management system which provides an appropriate security policy in order to predict security risk and enhance security of the institution. Normally the integrated log management system requires tremendous amount of time to store and process large amounts of log data. In this thesis, we designed and implemented a Hadoop-based log analysis system by using distributed database model which can store large amount of data and reduce analysis time by automating log collecting procedure. In the proposed system, we use the HBase in order to store a large amount of data efficiently in the scale-out fashion and propose an easy data storing scheme for analysing data using a Hadoop-based regular expression, which results in improving data processing speed compared to the existing system. In conclusion, the Hadoop-based security log management system can store and process a large amount of security log data and provides better performance in throughput, response time, data expandability than the existing system which determines the malicious attack on the basis of the security policy.",
		"KEYWORD": "ESM,로그분석시스템,클라우드 컴퓨팅,하둡"
	},
	{
		"ID": 859,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "기능분석을 통한 Big data 수집 대상 도출 방법 연구 =(A)study on the methods of big data acquisition via function analysis ",
		"AUTHOR": "송규석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 양승민",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "",
		"KEYWORD": "big data,도출,분류,수집"
	},
	{
		"ID": 860,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "영상 매칭의 속도와 정확성 최적화를 위한 특징자 기반 알고리즘의 연구 =A study of descriptor-based image matching algorithm for optimizing speed and accuracy ",
		"AUTHOR": "김진혁",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다 지도교수:김현진 참고문헌 : 42-43 장",
		"STORE_LOCATION": "단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "Due to the easiness of multimedia data creation and development of cloud services, the number of images to be stored and classified is increasing, which requires Big data analysis. Therefore, techniques using Big data image analysis are continuously being studied. The technique about searching objects in each image can be key to improving the quality of the big data image analysis. Considering the requirement of invariant characteristics in images the feature-based searching technology has several advantages. In the feature-based searching technology, objects can be detected using intuitive features such as lines and colors. In addition, it is possible to extract features that are invariant to the rotation and size of target images. In this paper, object retrieval methods through robust features in images is proposed using the vector and binary features. In the proposed technique using vector features, with the extracted features based on the existing method, the optimized fast and accurate image matching is focused. The vector features are extracted by using the SURF (Speed-Up Robust Features) algorithm. In addition, the proposed matching method adopted the Euclidean distance calculation, where the proposed method decides whether the Euclidean distance is to be calculated using the directionality of the descriptor or not. Therefore, unlike conventional methods, the complexity of the Euclidean distance calculations can be grealty reduced. Among the matching features by Euclidean distance calculation, the proposed method filters the features that are not actually used in the image matching. By filtering redundant features, the accuracy in the image matching can be improved. On the other hand, in the proposed method using the object retrieval method using binary features, the binary features are extracted by using the ORB (Oriented FAST and Rotated BRIEF) algorithm. Then, the proposed matching method adopts the Hamming distance calculation method. Before calculating the Hamming distance, the feature is decided whether to be used in the matching or not. By reducing the number of Hamming distance calculations and redundant features. The matching speed and accuracy can be enhanced. Experiments are performed using the vector and binary features. Considering the experimental results, it is concluded that the improvements in speed and accuracy between the conventional methods and the proposed Image matching methods can be shown.",
		"KEYWORD": null
	},
	{
		"ID": 861,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "자동차 부품 산업의 부도 위험 수준 예측 사례연구 =Case study for bankruptcy risk level forecasting of automobile parts industry ",
		"AUTHOR": "안병건",
		"REGION": "서울",
		"PROFESSOR": "권두에 국문요지, 권말에 Abstract 수록 지도교수: 한현수 참고문헌: p. 18-19",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "거시지표의 거동이 개별산업의 부도율 변동과 어떠한 연관이 있는지를 살펴보고자 하였다. Porter의 5가지 경쟁요인(공급 위험, 경쟁자 위험, 수요 위험, 신규진입자 위험, 대체재 위험)에 기반 하였으며 이중 공급사슬위험과 관련된 공급위험과 수요위험에 범위를 한정하고, 각 산업별 전 후방 산업과 관련된 거시지표의 수집 및 분석을 틍해 산업 단위의 위험수준 예측이 가능한지에 대한 초기 시도라는 데 의의를 두었다.",
		"KEYWORD": "경영정보"
	},
	{
		"ID": 862,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "연계분석 기법을 활용한 Malware 탐지/대응 기법 =The malware detection/response techniques using connection analysis ",
		"AUTHOR": "오상우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박재표",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "Malware에 의한 피해가 꾸준히 늘어나고 있는 추세이며 셀 수 없을 정도로 감염 경로는 확산되고 있다. 보안솔루션을 우회하는 다양한 기법들이 생겨나고 있고 신종 Malware가 지금도 개발되고 유포되고 있는 실정이다. 나날이 늘어나고 있는 수많은 Malware들을 이제는 사람이 대처하기 힘든 현실에 놓인 상황이다. 이러한 상황 속에서 여전히 우리는 보안솔루션에 의존하고 현재 시스템에만 의존하고 있다. 제로데이나 APT 공격 등에 대응하기 위해서는 지속적인 관심과 연구가 필요하며 현재의 시스템에 안주하지 않고 계속 개선시켜 나가야만 한다. 본 논문은 기존보다 효율적인 탐지 체계를 만들고 빠르고 신속한 대처를 위한 Malware 탐지/대응 기법에 대한 연구를 진행한다. 연계 이벤트 분석 기반의 연구를 진행하였으며 Malware 파일 자체의 분석 기법이 아닌 탐지/대응 체계에 대한 기법을 제안하였고 이를 통해서 기존 시스템보다 효율적인 탐지/대응이 가능한 시스템임을 확인할 수 있다. Malware 정보들과 감염 행위들을 연계 분석하여 기존에 탐지할 수 없었던 체계를 좀 더 강화하고 개선하는 기법을 제안하였고 해당 기법을 통하여 조금 더 고도화된 탐지와 빠른 대응이 가능해짐으로써 위험을 최소화 할 수 있다. 향후 빅데이터 기반의 더욱 정밀하고 고도화된 체계를 만들기 위해 꾸준히 연구할 계획이며 앞으로도 Malware뿐만 아니라 대한민국 보안을 위해 지속적인 연구와 관심을 가지고 꾸준히 노력 하려고 한다.",
		"KEYWORD": "Malware,보안"
	},
	{
		"ID": 863,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "전남대학교 대학원",
		"TITLE": "TV토론회에서 트위터의 이슈 생성 행태 연구 :제18대 대통령 선거 TV토론회를 중심으로 ",
		"AUTHOR": "한창진",
		"REGION": "광주",
		"PROFESSOR": "지도교수: 김경수 참고문헌 : p. 43-45",
		"STORE_LOCATION": "전남대학교 도서관(여수캠퍼스),전남대학교 중앙도서관",
		"ABSTRACT": "제18대 대통령선거 TV토론회는 SNS 중 트위터의 참여가 많았다. 매스미디어에서 미디어앱 2.0을 거쳐 SNS와 결합한 소셜미디어시대가 도래하면서 변화가 시작된 것이다. 트위터리안들이 후보의 발언을 듣고 인터넷이나 스마트폰을 이용하여 검색과 트윗, 리트윗을 하면서 자연스럽게 정책 이슈를 생성하였다. 트윗 이슈 생성 행태를 보면 트윗 수가 최고인 이슈는 발언 즉시 만들어졌다. 트윗한 내용 중에는 진보성향의 트윗이 많았고, 네거티브적인 내용은 핵심키워드를 자주 거론하지 않아도 트윗 이슈가 되었다. 인기 리트윗은 이슈와 상관없이 토론회 과정을 평가하는 형식이었다. 이렇게 트위터가 TV 보완재가 되어 트위터 여론을 만들고 선거 의제가 되었다. SNS 트위터가 TV토론회와 결합하면서 유권자들의 투표 참여율이 높아졌고, 직접 민주주의 실현 계기가 되었다. 앞으로 TV토론회를 진행하면서 실시간 트위터의 트윗 이슈 생성 실태를 TV 화면에 자막으로 표시한다면 TV토론회가 이슈 중심 토론회가 될 것으로 전망된다.",
		"KEYWORD": "소셜미디어"
	},
	{
		"ID": 864,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "연세대학교 정보대학원",
		"TITLE": "페이스북 마케팅 활용 방안에 대한 연구 :페이스북 `좋아요` 기능과 인구통계학적 정보 추출 ",
		"AUTHOR": "유성종",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이준기",
		"STORE_LOCATION": "연세대학교 원주캠퍼스 학술정보원,연세대학교 학술정보원",
		"ABSTRACT": "Custom marketing is one of the core methods in strategic marketing. With Big Data analysis, companies become capable of segmenting customers with details. Although Big Data analysis has great potentials in many fields, massive amount of data is required. In order to meet this requirement, companies attract customers with special events, such as giving free samples or trial opportunity. However, since customer privacy has become a critical issue, instead of helping companies, people start erasing their personal information and filing false data on the internet. Even though there are some limitations on collecting customer data, social network sites are one of the most well-known data pools in the world. Our study use Facebook as a prime social network site and its key feature called ‘Likes’ as a data set to predict user`s basic demography, such as age, sex, and educational background. To make an accurate analysis for the study, ‘Likes’ data has been processed by using singular value decomposition (SVD) for dimensionality reduction. With the machine learning technique randomForest, the result shows that sex has 88.66%, age has 77.91%, and educational background has 56.96% accuracy rate. From this study, we expect to provide a useful and efficient guideline for companies who are suffering to make an accurate customer analysis.",
		"KEYWORD": "big data analytics,data mining,likes,machine learning,random forest,SNS,social network services,기계학습,데이터 마이닝,랜덤포레스트,빅데이터 분석,소셜네트워크 서비스,좋아요"
	},
	{
		"ID": 865,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "전남대학교 대학원",
		"TITLE": "개인정보권의 침해에 대한 사법적 구제 ",
		"AUTHOR": "오대한",
		"REGION": "광주",
		"PROFESSOR": "지도교수: 송오식",
		"STORE_LOCATION": "전남대학교 중앙도서관",
		"ABSTRACT": "정보화 사회에서 정보는 중요한 가치를 지닌 자원이다. IT산업은 꾸준히 발달중이며, 빅데이터, 클라우드 컴퓨팅, 사물인터넷 등 새로운 유형의 기술들이 끊임없이 생성되고 있다. 정보를 기반으로 하는 신기술들의 발전은 정보에 대한 수요를 비약적으로 증가시킬 뿐 아니라 정보에 대한 개인의 권리 침해문제를 야기하기도 한다. 특히 개인정보는 개인의 통제, 기업의 이익 확보, 단체의 목적 달성 등의 대상이 되는 개인에 대한 정보이므로 그 중요성이 특히 크며, 침해가 빈번하다. 개인정보권이란 개인정보가 언제 누구에게 어느 범위까지 알려지고 이용되도록 할 것인지를 정보주체 스스로 결정할 수 있는 권리로서, 재산권적 성격을 지니는 동시에 헌법 제17조와 제10조에 근거한 인격권적 성격을 지닌 권리이다. 개인정보의 가치가 커질수록 개인정보권의 침해는 증가한다. 따라서 그에 따른 침해구제가 중요하다. 개인정보권의 침해 구제를 위해서는 먼저 침해의 대상인 개인정보에 대한 개념 정의가 필요한데, 이는 개인정보의 개념을 어떻게 볼 것이냐에 따라 그 보호범위가 달라질 수 있기 때문이다. 특히 작금의 빅데이터, 사물인터넷 등 정보기반의 신기술의 발달로 개인정보의 개념도 기술발달에 맞추어 대응하여야한다. 또한 개인정보권의 내용과 침해 유형에 대한 분석 역시 필요하다. 개인정보권의 내용은 정보주체의 사용·수익·제공권과 동의권, 관리참여권, 잊혀질 권리 등이 있다. 그리고 침해 유형은 침해 주체, 침해 객체인 개인정보의 유형, 개인정보 처리 행위의 단계, 개인정보권의 내용에 따라 분류할 수 있다. 개인정보권 침해의 사법적 구제수단에는 사전적 구제수단으로 금지청구권을 피보전권리로 하는 개인정보침해금지가처분과 간접강제가 있으며, 사후적 구제수단으로는 손해배상청구가 있다. 이중에서 주로 문제가 되는 것이 손해배상청구인데, 개인정보권은 그 특성상 과실판단 기준, 손해의 발생 여부와 위자료 산정에 관한 쟁점이 특히 문제가 된다. 이에 대해서는 본 논문에서는 판례의 경향을 고찰함과 동시에 판단 기준 및 대안을 제시하였다. 또한 개인정보권 침해의 특성상 침해, 손해, 인과관계 등의 증명이 어려운 점 때문에 증명책임을 어떻게 볼 것인지에 대한 점, 피해가 소액이며 피해자가 다수인 경우가 빈번하여 단체 소송 및 집단 소송 등의 필요성이 존재하는 점 등을 어떻게 규율할지 문제되는 바 이에 대해서는 법률 개정의 필요하다. 아울러 개인정보권의 침해 구제의 실효성 확보를 위하여 기존에 여러 법제로 산재해 있던 개인정보 관련 특별법들을 개인정보보호법으로 통합하고, 법정 손해배상, 징벌적 손해배상, 책임보험 제도 등이 개인정보보호법으로 편입 되어야 한다. 정보통신 환경은 빠르게 변화하고 있고, 이에 따른 개인정보권의 침해 범위 역시 확산되고 있다. 개인정보권은 일반적인 인격권의 침해와 다른 특성을 지니고 있다. 따라서 침해 구제도 개인정보권의 구조와 특성에 맞게 고려될 필요가 있다. 아울러 정보화 사회에서 개인정보는 중요한 가치로서 보호해야할 존재임과 동시에 효율적으로 이용하여 관련 산업의 발전을 꾀해야 하는 자원이므로 그 구제에 있어서 보호와 이용 간의 균형이 필요하다. 본 논문에서는 이러한 개인정보권 침해의 특성을 분석하고, 관련 법률 및 판례의 경향을 고찰하였으며, 이에 따른 기준을 제안함과 동시에 대안 및 법률의 개정방향에 대해서 제시함으로써 개인정보권의 침해에 대한 사법적 구제에 대해 연구하였다.",
		"KEYWORD": "개인정보권,사법적 구제,손해배상,침해"
	},
	{
		"ID": 866,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "공주대학교 대학원",
		"TITLE": "클라우드 컴퓨팅에서 OAuth를 사용한 권한위임 사용자 인증 시스템 =(A)delegator for authentication management system using OAuth in cloud computing environment ",
		"AUTHOR": "문정경",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 김황래 참고문헌: 108-113장",
		"STORE_LOCATION": "공주대학교 도서관",
		"ABSTRACT": "This thesis designed and implemented the certification system that can overcome the vulnerability of virtualization. It can decrease information disclosure and service failure resulted in the centralization of information in cloud computing environment. In this thesis, built several university library database in cloud environment and we proposed authentication protocol based on OAuth 1.0 protocol that is standard authentication protocol for secure user authentication and service authentication. Additionally, we made access control to BRS system using privilege method. OAuth 1.0 protocol cannot support many characteristics of cloud computing environment that consumer and service provider can be changed from time to time. And if consumer and service provider increase, certificate information increases exponentially. To overcome the restriction, this thesis proposed the privilege management infrastructure between the consumer and service provider. This is independent agent and manages the certificate information. ADAMS mean A Delegator for Authentication Management System using OAuth in Cloud Computing Environment. and delegator is a independent between consumer and service provider. The delegator agent placed in the web-proxy server or in the PMI system that is one of the consumer and service provider. Therefore, this system increased reliability and security, simplified the authentication procedures compared to the OAuth 1.0.",
		"KEYWORD": null
	},
	{
		"ID": 867,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "동국대학교 국제정보대학원",
		"TITLE": "사설 클라우드 환경에서의 기업 포렌식 조사기법 연구 =(A)study on investigation methodology of private cloud environment ",
		"AUTHOR": "신승목",
		"REGION": "서울",
		"PROFESSOR": "동국대학교 논문은 저작권법에 의해 보호받습니다. 지도교수:김대형",
		"STORE_LOCATION": "동국대학교 중앙도서관",
		"ABSTRACT": "2000년도 초반부터 국내수사기관에서는 디지털포렌식 기법을 적용하여 디지털 증거를 법정에서 간접증거로 활용하기 시작하였다. 이러한 디지털증거에 대한 수사 활용은 전세계적인 추세이며, 향후 민간분야의 디지털포렌식을 활용한 디지털증거 확보 및 법적 대응을 위한 시장 활성화가 예상된다. IT 기술의 빠른 발전은 디지털포렌식 기법에도 많은 변화를 가져오고 있어, 컴퓨터 하드디스크 이외에도 휴대폰, 스마트폰, 네트워크 연결 스토리지, 가상화데스크탑 인터페이스, PMP, 내비게이션 등 다양한 디지털 저장매체들에서 증거를 확보하는 시대로 발전하고 있다. 이러한 다양한 디지털 저장매체의 출현 및 용량의 기하급수적인 발전은 기존의 디지털포렌식 서비스 기법의 발전을 요구하고 있다. 최근 각 수사시관 및 사법수사기관들의 디지털포렌식센터 설립 및 시스템 구축은 이러한 IT 기술의 발전에 대응하여 신속하고 효율적인 디지털포렌식 수사기법을 개발하고 실무에 적용하기 위한 시도로 볼 수 있다. 최근의 빈번한 개인정보 유출사고로 인해 법률적으로 망분리가 의무화됨에 따라서, 디지털포렌식 분석 기법의 변화의 필요성은 빠르게 요구되고 있다. 기업의 망분리 환경에서 상시적인 전산 감사 및 퇴직자 발생 시 디지털 증거를 획득하고 보존 및 분석하는 방법이 법이나 제도적으로 명확하지 않으며, 이미 디지털 포렌식 전용 하드웨어 복제기나 분석용 소프트웨어를 구축하고 있는 기업들도 망분리 환경에서 이러한 솔루션들을 활용하지 못하고 있는 실정이다. 이에 본 연구에서는 망분리 환경 특히, 가상화데스크탑 및 네트워크 연결 스토리지를 기반으로 한 환경에서 상시 감사 및 퇴직자 발생 시 포렌식 조사를 어떻게 수행해야 하는지에 대한 기법을 제시한다. 디지털 증거 분석자의 관점에서 망분리 환경에서의 증거 수집 및 분석 기법을 연구에 보고 이에 대한 발전방향을 모색하여 기업의 정보 유출사고를 예방하고 유출 사고 시 빠른 증거 수집 및 분석을 수행하는 조사 기법을 연구하여 기업의 효과적인 디지털포렌식 도입기반을 마련하고자 한다.",
		"KEYWORD": "가상화데스크탑,클라우드,포렌식"
	},
	{
		"ID": 868,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "Selective regulation of micro-RNAs in breast cancer ",
		"AUTHOR": "You-KyungSon",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 869,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "고려대학교 공학대학원",
		"TITLE": "고객의 평가를 이용한 어플리케이션 스토어의 컨텐츠 추천시스템 제안 ",
		"AUTHOR": "서대평",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최린 참고문헌: 장 41",
		"STORE_LOCATION": "고려대학교 과학도서관,고려대학교 도서관,고려대학교 세종학술정보원",
		"ABSTRACT": "특정 상품이나 컨텐츠 등에 대해 고객으로부터 생성되는 수많은 데이터 중 성별, 나이, 지역과 같은 기본적인 고객정보 외에도 구매 전후에 일어나는 행위(User Behavior)를 기반으로 특정 타켓群에게 수익을 내려는 스토어 서비스 및 포탈 서비스들이 증가하고 있다. 이러한 사용자 행위 중 정성적인 데이터 형태로 남겨지는 고객의 평가는 그 동안 분석의 어려움과 비정형성을 이유로 비즈니스분야에서 활용되지 않았다. 그러나 고객의 평가는 상품이나 컨텐츠에 대해 품질이 높을 때와 낮을 때, 호감도와 비호감도에 따라 내용이 달라지게 되며, 다른 고객에게 상품에 대한 유효성과 신뢰성 판단 기준을 제공할 수 있다. 그만큼 고객의 평가는 고객간 의견을 확인하는 중요한 수단이다. 본 논문에서는 최근 업계의 화두인 빅데이터 분석의 일환으로 어플리케이션 또는 컨텐츠로부터 추출된 고객의 평가(반응)를 분석하여 긍정적인 어휘와 부정적인 어휘 그리고 강조 어휘를 도출하여 호감도 및 평가가 높은 어플리케이션 또는 컨텐츠를 다른 고객에게 추천하는 시스템 모델을 제안하고 설계하고자 한다. 이러한 제안을 위하여 데이터 분석 기법 중 텍스트마이닝 기술을 이용하여 고객의 평가를 보다 효율적이고 효과적으로 분석할 수 있도록 구문 패턴 (syntactic patterns) 분석의 개념을 도입하였다. 제안하는 방법론은 텍스트마이닝 중 구문 추출(Phrase extraction)을 통하여 특정 문장에 대한 범주화 및 정보추출 기법의 사용을 포함하고 있다. 특히, 통계적으로 보다 견고한 분석결과를 도출할 수 있도록 전통적 통계분석기법중의 하나인 교차분석방법을 제안하는 방법론에 포함하였다. 마지막으로 제안한 방법론의 타당성을 검증하기 위하여 특정 어플리케이션 스토어의 컨텐츠를 선정하여 고객의 평가를 분석하고 그 결과를 통해 시스템을 검증 하였다.",
		"KEYWORD": "어플리케이션 스토어"
	},
	{
		"ID": 870,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "가상화 환경에서의 공간 최적화를 위한 블록 단위 데이터 중복 제거 시스템 =Block-layered data deduplication for space optimization in virtualized environment ",
		"AUTHOR": "김현지",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 노재춘",
		"STORE_LOCATION": "세종대학교 도서관",
		"ABSTRACT": "최근 들어, 빅데이터와 사물인터넷의 발달로 인해 발생하는 데이터의 양이 폭발적으로 증가하고 있다. 수십 년간 사용된 HDD는 기계적인 구조의 특성 때문에 처리 속도의 발전이 한계에 이르면서, 빠른 입출력 및 저 전력 등의 다양한 장점을 가지고 있는 SSD로 대체되고 있다. 하지만, SSD의 경우 단위 용량 당 높은 가격으로 인해, SSD로만 대용량 저장 장치를 구성하기에 한계가 있다. 또한, 클라우드 컴퓨팅과 서버 가상화 기술의 발달로 가상 머신의 이용이 보편화 되었고, 이로 인해 가상 머신 이미지들의 중복 데이터가 증가하였다. 이를 해결하기 위해 본 연구에서는 가상화 환경에서 공간 최적화를 위한 블록 단위 데이터 중복 제거 기능을 제공한다. 앞으로 HDD에서 SSD로 대체되어가는 IT 인프라 상황에 맞추어 이와 같은 중복 제거 시스템은 대용량 시스템에서 필수적인 요소가 될 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 871,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "아주대학교 대학원",
		"TITLE": "데이터 마이닝 기법을 이용한 직업성 근골격계 질환 예측 모델 개발 =Development of the prediction model for musculoskeletal disorders using data mining methods ",
		"AUTHOR": "윤정민",
		"REGION": "경기도",
		"PROFESSOR": "아주대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박범 참고문헌: p.157-165",
		"STORE_LOCATION": "아주대학교 도서관",
		"ABSTRACT": "직업성 근골격계 질환은 전 세계적으로 매우 중요한 산업 안전보건 문제로 인식되고 있으며, 한국의 경우 2013년 기준 전체 직업 관련성 질환자의 약 71.4%가 근골격계 질환인 것으로 나타났다. 직업성 근골격계 질환의 경우 작업자의 업무 능력을 감소시키는 것은 물론 지속적인 관리가 필요하기 때문에 이에 따른 경제적 손실 또한 매우 크다. 따라서 국가와 기업, 연구기관 등에서는 직업성 근골격계 질환에 영향을 미치는 유해위험요인을 도출하고, 이를 통해 정확한 원인을 규명하기 위한 다양한 연구들을 수행하고 있다. 본 연구에서는 작업장에서 복합적으로 작용하는 다양한 작업 환경 요인들이 직업성 근골격계 질환의 발생에 영향을 미치는 주요 유해위험요인을 도출하고, 각 요인 수준에 따른 직업성 근골격계 질환의 발생 예측 모델을 제안하였다. 분석 대상은 산업안전보건연구원에서 실시한 근로환경조사 응답자 50,032명의 데이터 중 임금근로자 34,788명을 대상으로 진행하였으며, 다시 전체 근로자, 사무직 근로자, 생산직 근로자로 구분하여 세부 분석을 실시하였다. 또한 기존 연구에서 주로 사용하는 로지스틱 회귀분석 외에 의사결정나무, 인공신경망 등 데이터마이닝 기법을 활용한 모델을 추가 제안하고, 각 모델의 정확도와 신뢰도를 비교 검증하였다. 직업성 상지 질환은 목, 어깨, 팔, 손 등의 신체 부위에서 발생하는 근골격계 질환으로, 상지 부위의 반복적인 작업에 노출될 위험이 많은 생산직 근로자는 물론 사무직 근로자에게서도 다수 발생되는 것으로 알려졌다. 분석 결과에 의하면 전체 근로자의 직업성 상지 질환에 가장 많이 영향을 미치는 요인은 작업 환경 요인으로 나타났으며, 특히 근골격계 부담 요인의 영향력이 매우 높은 것을 알 수 있었다. 사무직 근로자의 경우에도 근골격계 부담 요인의 영향력이 높게 나타났으며, 이외에 업무요구도, 고객 상대, 직장 내 인간관계에서 오는 스트레스도 주요 요인으로 도출되었다. 생산직 근로자는 근골격계 부담 요인 외에 화학물 노출과 같은 물리적 작업 환경 요인과 건강이나 안전에 위협을 주는 작업, 업무 스트레스 등의 영향을 많이 받는 것으로 나타났다. 직업성 요통은 업무 중 허리에 과도한 힘을 받아 발생한 급성 및 만성 통증을 의미하며, 34,788명의 임금근로자 중 10% 수준인 3,435명이 요통을 앓고 있다고 응답하였다. 전체 근로자, 사무직 근로자, 생산직 근로자 등 모든 그룹에서 잘못된 자세나 반복적인 동작 등의 근골격계 부담 요인이 주요 요인으로 나타났다. 사무직 근로자의 경우에는 근골격계 부담 요인 외에 고객 상대나 컴퓨터 작업 시간이 길어질수록 발생 확률이 증가하였으며, 생산직 근로자의 경우에는 주당 근무시간, 업무요구도, 결근일 수 등의 중요도가 높았다. 직업성 하지 질환은 해당 부위의 반복적인 작업 동작으로 인해 극히 미세한 근육이나 조직의 손상이 누적되어 나타나는 기능적 장애를 의미하며, 직업이나 컴퓨터 작업, 인터넷/이메일 사용, 반복적인 동작 등이 기본적인 주요 유해위험요인으로 나타났다. 사무직 근로자의 경우 화가 난 고객을 상대하거나 언어폭력, 감정을 숨기고 일해야 하는 경우 발생하는 업무 스트레스 등 사회 심리적 요인이 매우 중요하게 나타났으며, 생산직 근로자의 경우에는 분진, 고온, 소음 등 물리적 작업 환경 요인도 높은 영향력을 보였다. 이번 연구를 통해 기존의 통계적 기법에 기반한 연구 방식에서 벗어나 데이터마이닝 기법을 활용한 빅데이터 기반의 근골격계 질환 발생 확률 예측 모델을 제안하였으며, 이를 통하여 다양한 유해위험요인들이 복합적으로 작용하는 실제 작업 환경을 어느 정도 반영하는 계기가 될 것으로 생각된다. 또한 다양한 작업 환경 조건에서 발생하는 직업성 근골격계 질환의 주요 유해위험요인과 그 영향력을 사전에 파악하고 이를 통해 예방하는데 크게 기여할 것으로 기대하며, 본 연구를 개선 보완하기 위한 추가 연구를 지속적으로 수행할 예정이다.",
		"KEYWORD": "데이터 마이닝,예측 모델,직업성 근골격계 질환"
	},
	{
		"ID": 872,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "심층신경망의 효과적인 초기화를 위한 분할 훈련 및 병합 기법에 관한 연구 ",
		"AUTHOR": "안홍섭",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:이상민 참고문헌 : p.106-113",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "최근 기계 학습 (machine learning)에서 가장 활발한 연구는 심층신경망 (deep neural network, DNN)을 이용한 딥러닝 (deep learning) 분야에서 이루어지고 있다. 일반적으로 심층신경망이란 인공신경망 (artificial neural network, ANN)의 한 종류인 다층 퍼셉트론 (multi-layer perceptrons, MLPs)이 두 개 이상의 은닉층 (hidden layer)으로 구성되어 있는 경우를 의미한다. 이미 오래전 여러 가지 한계로 인해 관련 연구가 거의 이루어지지 않았던 심층신경망이 다시 한 번 주목 받게 된 이유는 빅 데이터 (big-data)의 등장과 하드웨어의 발전 그리고 여러 알고리즘이 제안되었기 때문이다. 본 논문에서는 DNN 파라미터의 효과적인 초기화를 위한 DBN (deep belief network)과 유전알고리즘 (genetic algorithm, GA)기반의 새로운 사전학습 (pre-training) 알고리즘을 제안한다. 제안된 알고리즘은 크게 세 가지 과정으로 구성되어 있다. 먼저 학습 데이터를 분할 (split)하여 DBN을 사용하여 학습 시킨다. 다음으로 학습된 두 신경망의 각 층의 가중치 행렬과 바이어스 벡터를 하나의 행렬로 구성하고 이 행렬의 각 행을 염색체 (chromosome)로 사용한다. 각 층의 염색체는 유전알고리즘의 교차, 변이, 선택 연산을 사용하여 하나의 신경망으로 병합 (merge)되고 이를 신경망의 초기 파라미터 값으로 사용한다. 마지막으로 초기화된 신경망을 역전파 알고리즘을 사용하여 미세조정 (fine-tuning)한다. 제안된 알고리즘은 SM-DBN (split and merge DBN)이라고 하며 신경망 파라미터의 효과적인 초기화를 통해 패턴 인식 능력을 향상시키고 re-training에 대한 새로운 접근 방법을 제안하는 것을 목적으로 한다. 제안된 SM-DBN의 성능은 이미지와 음향 데이터를 사용하여 검증되었다. 이미지 데이터에 대해서는 필기체 숫자 이미지를 60,000개의 학습 데이터 세트와 10,000개의 테스트 데이터 세트로 구성한 MNIST (mixed National Institute of Standards and Technology) 데이터베이스를 사용하였고 여러 가지 상황에서의 패턴 인식 능력을 측정하여 성능을 검증하였다. 음향 데이터에 대해서는 SM-DBN을 디지털 보청기의 핵심 알고리즘에 적용시킨 후 그 성능을 측정하여 검증하였다. 이미지 데이터를 사용한 SM-DBN의 성능 검증을 위해 다양한 신경망에서 패턴 인식 성능 측정과 re-training 상황에서의 성능 측정 그리고 SM-DBN의 강인성을 측정하는 실험을 진행하였다. 먼저 서로 다른 네 개의 구조를 갖는 신경망에서 SM-DBN의 패턴 인식 성능을 측정하고 기존 DBN과 비교하는 실험을 진행하였다. 실험 결과 모든 신경망의 학습과 테스트 곡선에서 SM-DBN은 DBN 보다 낮은 초기 오차율을 가지고 빠르게 수렴하였으며 반복 시행 횟수의 증가에도 역전되지 않는 경향을 보였다. 100번째 반복 시행 횟수에서 오차율를 측정한 결과 SM-DBN은 DBN 보다 평균 8.43%의 성능 향상을 보였다. 다음으로 이미 학습된 신경망에 클래스를 추가하는 상황을 가정하여 re-training 성능을 측정하였다. 실험은 0과 1의 클래스 추가와 8과 9의 클래스를 추가하는 두 가지 상황을 가정하여 진행하였다. 실험 결과 기존 데이터에 대한 RBM (restricted Boltzmann machine) 사전학습 과정 없이 기존 DBN에 비해 각각 평균 11.31%와 10.98%의 성능 향상을 가지고 클래스를 추가할 수 있었다. 마지막으로 은닉층에 많은 뉴런의 수를 갖는 신경망을 사용하여 SM-DBN의 강인성을 평가하였다. 앞선 실험에서 사용한 세 가지 상황에서의 실험 결과 기존 DBN에 비해 각각 0.76%, 4.58% 8.40%의 성능 향상을 보였다. 제안된 SM-DBN의 음성 데이터에 대한 검증을 위해 디지털 보청기의 음성 검출 알고리즘과 음향 피드백 제거 알고리즘에 적용하여 성능을 평가하였다. 먼저 음성 검출기는 백색, babble, 사무실 잡음이 각각 0, 5, 10, 15dB SNR을 가지는 상황에서 성능을 평가하였다. 실험 결과 DBN은 기존 음성 검출 알고리즘에 비해 우수한 음성 검출 결과를 보였으며 SM-DBN은 DBN에 비해 각각의 상황에서 평균 2.46%, 3.2%, 3.56%의 성능 향상을 보였다. 다음으로 SM-DBN을 디지털 보청기의 음향 피드백 제거 알고리즘에 적용하여 성능을 평가하였다. 성능 비교를 위해 VS-APA (variable step-size affine projection algorithm), GSAP (global speech absence probability), DBN 기반의 피드백 제거 알고리즘을 사용하였으며 불일치도 (misalignment)를 살펴보고 다양한 투사 차수 (projection order)에서 PESQ (perceptual evaluation of speech quality), LLR (log-likelihood ratio)의 성능을 비교하였다. 실험 결과 모든 상황에서 SM-DBN의 불일치도가 가장 낮았으며 PESQ 평가에서는 평균 6.66%, 3.32%, 0.7%의 성능 향상을 보였고 LLR 평가에서는 평균 34.60%, 16.37%, 5.8%의 성능 향상을 보였다.",
		"KEYWORD": null
	},
	{
		"ID": 873,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "부산대학교 대학원",
		"TITLE": "SNS 기반 소통을 통한 학교폭력 예측 지원 앱 설계의 핵심 원리 탐색 ",
		"AUTHOR": "임유미",
		"REGION": "부산",
		"PROFESSOR": "지도교수: 김영환 부록: 1.대상별 예방 프로그램 분석결과 외수록 참고문헌: p. 147-155",
		"STORE_LOCATION": "부산대학교 중앙도서관",
		"ABSTRACT": "This study aims to search for core principles in designing applications which support to predict and prevent school violences before it happens. 1. What are the problems presented in previous researches on prediction or prevention of school violence? 2. What are the problems presented in a need analysis which was conducted on prediction or prevention of school violence targeting teachers and parents? 3. What are the problems presented in in-depth interviews which was conducted on prediction or prevention of school violence targeting teachers and parents? 4. What are the core principles for designing applications to support for predicting and preventing school violence based on the results for research questions 1 to 3? This study developed core principles for application design based on the results from previous research analysis, need analysis, in-depth interviews and expert interviews. The research researches can be suggested as follows. Core principles for a smart-based support system to predict and prevent school violence is “to support teachers and parents to communicate closely and properly so that students have more trust”. Based on this core principles, more specified principles are as follows. Mid to long term, key principles of the first is spread and stages of preparation for a communication for you to the principle of prevention and prediction, “Mid-and long-term preparedness” any easier as you well. Second, ‘Communication together“, This means communications about causes and results for school violence are not limited to students but expand to parents, teachers and experts together. Third, ‘Diagnosis based on community character’. It needs to link researches with practices based on diagnosis on community character. Fourth, ‘Ownership mind for school violence’. It is not only students but also parents and teachers that do major parts in school violence. Therefore the participation from teachers and parents are essential. Fifth, ‘Spread of communications’. Communications need to be spread not only school classes but community with relationships. Suggestions in this study can be summarized as follows: First, as this study produced design principles for a support system to predict and prevent school violence based on the results from research analysis, need analysis and in-depth interviews, those principles need to be developed more in formative researches with field appication in the futuer studies. Second, this study has limit in searching for designing principles in developing application for prediction and prevention of school violence based on SNS communications. Therefore, it can be suggested develop specific application system development and its implication in a follow-up study. Third, the researches on school violence in linkage with SNS and communications has started recently. In this meaning, studies on problems and improvements in communications and relationships in aspect with school violence need to be conducted more in the future. Four, It needs to develop assessment items for communications between teachers and parents in order to enable them to do check themselves.",
		"KEYWORD": "앱설계,학교폭력"
	},
	{
		"ID": 874,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서경대학교 대학원",
		"TITLE": "군집분석을 이용한 기후요인에 따른 강수지역 구분에 관한 연구 =(A)study on the regional classification of precipitation by climate factors using cluster analysis ",
		"AUTHOR": "김훈범",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 안재현",
		"STORE_LOCATION": "서경대학교 중앙도서관",
		"ABSTRACT": "국내의 경우 국토면적에 비해 지형이 다양하여 강수지역에 대한 구분을 정확히 할 수 없다. 여러 연구에서는 이러한 상황에 도움을 주기 위하여 국내 강수지역을 다양한 시도를 통해 구분한 바 있다. 하지만 2000년 대 이후 강우는 지역적, 게릴라성 호우가 많이 출연하고 있는 추세이며, 예측하기 힘든 패턴을 보이는 강우가 늘어나고 있다. 이러한 강우는 예상치 못한 기간, 예상치 못한 지역에서 나타나기도 한다. 강수지역의 변화 및 국내 강수지역구분을 정의하기 위하여 국내에서도 강수지역구분에 관한 많은 연구들이 진행되어 왔으며, 문영수(1990)가 처음으로 강수지역을 구분하기 위하여 계층적 군집분석 방법인 Ward 방법을 사용하여 국내 강수지역을 크게 8개 지역 작게 24개 지역으로 구분하였다. 이후 박정규와 이승만(1993), 문영수와 김희종(2001), 김웅태 등(2000), 이영섭 등(2012)은 연평균 강우량, 월평균 강우량과 계층적 군집분석 방법인 Ward 방법을 이용하여 국내 강수지역을 구분하였다. 하지만 이러한 선행연구들은 연평균 강우, 월평균 강우 등을 사용하여 극치에 대한 부분이 고려되지 않았다. 또한 계층적 군집분석 방법은 Ward 방법은 동시에 여러 개의 인자를 군집화 할 수 없으며 데이터가 크면 분석하기 힘들다는 단점이 있다. 본 연구에서는 국내 강수지역을 구분하기 위하여 일단위 데이터를 사용하여 빅데이터 분석을 하였으며, 강우이외의 요인이 강수지역 구분에 미치는 영향을 확인하기 위하여 강우량 자료 이외에도 일 평균기온, 일 평균상대습도, 자료를 동시에 K-means 군집분석으로 분석하였다. 강우만을 가지고 군집화한 결과 선행 연구들과 큰 차이가 없음을 확인하였고, 요인이 추가됨에 따라 군집화의 결과가 다른 양상을 띄는 것으로 확인되었다. 본 연구를 통해 기후요인 및 강수량을 군집화하여 강수지역을 정확하게 구분하여 풍수해 피해를 줄이는데 이바지 하고, 예상치 못한 지역에 극심한 강우가 내리는 것에 대한 효율적인 대비를 할 수 있는 자료를 제공할 수 있을 것으로 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 875,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 예술대학원",
		"TITLE": "공공도서관 지식정보플랫폼 이용자 추이분석 =Analysis on fluctuation of the user of knowledge information platform at public library ",
		"AUTHOR": "장선미",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 권병웅 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "이 연구는 지식정보사회라고 일컬어지는 현대사회에서 공공도서관이 지식정보플랫폼으로서 어떠한 역할을 수행하고 있는지 알아보고, 변화하는 수요자의 정보요구에 맞추어 어떤 정보서비스를 제공해야하는지 그 방안을 제시하는데 목적이 있다. 이론적 고찰에서는 정보에 대한 여러 학자들의 정의를 바탕으로 정보가 주는 가치 활동에 대해 살펴보았다. 정보란, 지각된 데이터로 사회변화를 촉진하는 재화로써 특히 과거 농업사회, 산업사회보다 현재 지식정보사회에서 그 가치가 더욱 증대된다. 이러한 정보제공 기능 이외에도 도서관은 교육시설, 문화활동 및 평생교육의 장려 등 많은 기능을 수행하고 있으나, 결국 지식기반사회에서 도서관의 가장 중요한 기능은 ‘지식의 축적과 정보의 공유를 목적으로 하는 지식정보플랫폼’으로 규정된다. 이에 공공도서관의 정보플랫폼 이용 실태를 살펴보고 정보서비스의 고도화를 위하여 A지역도서관을 대상으로 한 이용자 만족도 조사를 바탕으로 발전방안을 찾고자 하였다. 분석의 틀로는 도서관 소장자료, 도서관 정보접근 및 접근성, 도서관 이용환경에 대한 평가로 나누어 각각의 만족도를 파악하고 2010년, 2012년, 2013년의 이용자 추이를 분석하였다. 이를 통해 도서관에 대한 정보접근 및 접근성이 높을수록 이용자 만족도는 상승하는 것을 알 수 있었다. 이를 충족시키기 위해서 장서량의 증가와 신간도서의 유입이 요구되지만 제한된 예산으로 지속적으로 상승하는 이용자의 요구를 만족시킬 수는 없을 것이다. 이에 따른 정보서비스 고도화 방안으로 첫째, 디지털시대의 이해를 기반으로 시행할 수 있는 데이터 큐레이션 서비스 둘째, 이용자에게 최적화된 서비스를 제공할 수 있는 빅데이터 활용 셋째, 도서관간 협력체계 구축을 통한 다양한 이용자 서비스 충족, 마지막으로 기존의 도서관이 시행 중인 문화서비스의 개선을 제시하였다. 특히 지역도서관이 갖는 강점인 근접성을 기반으로 하여 지역사회의 특성과 요구가 반영된 정보서비스를 제공한다면 지역문화교류의 플랫폼으로 기능하게 될 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 876,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "근본 원인 분석(RCA)를 위한 시프트 비교와 자동 대상 선정 기법 =Shift comparison and automatic selection of comparable target for root cause analysis(RCA) ",
		"AUTHOR": "김철",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 조인휘 권두 국문요지, 권말 Astract 수록 참고문헌 : p. 23",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "현재(2013년)의 IT환경은 클라우드, 빅데이터와 같은 가상화, 대용량 분산환경의 발전으로 복잡도는 높아지고 인프라는 증가하여, IT 자원 관리에서 장애에 대한 신속한 진단과 해결이 점점 어려워지고 있습니다. 본 논문은 이와 같은 문제를 좀더 쉽게 해결 하고자 근본 원인 분석 기술을 이용하여 장애에 대한 신속한 진단과 해결을 위한 근본 원인 분석 도구를 제안합니다. 이 분석기는 수치기반의 데이터에서 지표 간의 정확한 상호 연관성을 탐지하기 위해 데이터의 오차와 누락을 방지하는 두 가지 기술을 제안 합니다. 첫 번째는 탐지 대상에 대한 능동적인 수집 방법입니다. 능동적인 탐지 대상 수집은 분석과정의 일관성과 대상의 누락 방지를 보장 할 수 있습니다. 두 번째는 상관성 분석에서 타임프레임의 오차를 회피 할 수 있는 방법을 제시 하였습니다. 위에서 언급한 두 가지 제안 기술을 통해 우리는 오차를 회피하고, 누락을 방지 하여 단순 분석보다 높은 상관성을 탐지 하였으며, 부가적으로 효과적인 근본 원인 분석을 지원 할 수 있는 Data Visualization[8]을 제공 할 수 있었습니다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 877,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "자기주도 학습을 위한 블록형 한글 학습 모듈 개발 :Developing a Korean language-learning module using block-type pieces to help self-directed learning ",
		"AUTHOR": "김보성",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박종일 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 50-52",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "과학 기술력이 증가함에 따라서 ICT(Information & Communication Technology)산업 내에서도 유아를 위한 교육 프로그램이 활발히 개발되어지고 있다. 또한 많은 교육자들에 의해서 ICT를 활용한 교육이 유아에게 긍정적인 영향을 끼친다는 검증이 이뤄지고 있다. 유아교육에 있어서 가장 중요한 부분은 유아가 교육에 대한 집중력을 올리기 위해서 흥미를 유발시킬 수 있는 특징이 있어야한다. 유아에게 한글을 교육하는 기존 방식은 학습지, 낱말카드, 어플리케이션 그리고 미디어를 이용한다. 하지만 학습지와 낱말카드는 다양한 교육콘텐츠를 제공할 수 없기 때문에 유아가 쉽게 흥미를 잃을 가능성이 있다. 또한 계속적으로 새로운 학습지와 낱말카드를 구입하는 것은 경제적으로 낭비이다. 그리고 어플리케이션을 이용한 교육은 정해진 규칙과 주어진 목적이 명확하기 때문에 창의성을 키우기에 어려움이 있다. 마지막으로 미디어는 눈으로만 보는 교육방식이기 때문에 촉각적인 교육이 결여되어 있다. 따라서 본 논문에서는 기존의 교육방식의 장점은 살리고 각각의 단점을 보완한 블록형 한글학습 모듈 시스템에 대해 제안한다. 유아가 한글의 가획과 합성 원리에 대한 지식이 증가할수록 글자에 대한 이해도가 높아진다. 이러한 이유로 블록놀이를 통해 글자를 배울 수 있도록 설계하였다. 블록을 인식하기 위해서 Matrix 구조로 44×28의 근접센서를 배치하였다. 인식된 Binary 이미지는 빅 데이터 기반으로 Template Matching을 통해 글자 데이터로 변환한다. 그리고 최종적인 데이터에 맞는 소리가 나오게 된다. 이러한 단계를 통해 유아가 블록을 조합하여 만든 형태가 올바른 글자인지를 아닌지를 인식하게 되고 해당 글자가 어떠한 발음인지를 배우게 된다. 또한 제안한 시스템에 낱말카드와 어플리케이션에 대한 기능을 추가하여 다양한 콘텐츠를 제공하고 유아의 흥미를 지속적으로 유발시킬 수 있도록 하였다. 이와 같이 유아에게 교육에 대한 지속적인 흥미유발 및 시각적, 청각적, 촉각적인 감각을 활성화 시키고 블록놀이라는 창의성을 키울 수 있는 교육을 통해 기존의 교육 방식을 보완한 시스템을 제안한다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 878,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Essays on internet policy :인터넷 정책 연구 :backbone interconnection and broadband access technology development =백본망 간 상호접속제도 및 엑세스망 기술정책 제언 ",
		"AUTHOR": "Choi,SunMe",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 879,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "상명대학교 문화기술대학원",
		"TITLE": "한국 대중음악산업현황 분석을 통한 대중음악시장 발전방안 =Method of development for popular music industry through analysis of status quo Korean popular music industry ",
		"AUTHOR": "백종현",
		"REGION": "서울",
		"PROFESSOR": "상명대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 조남규 참고문헌: p. 84-86",
		"STORE_LOCATION": "상명대학교 서울캠퍼스 도서관,상명대학교 천안학술정보관",
		"ABSTRACT": "본 연구는 국내 대중음악산업의 흐름을 파악하고 향후 대중음악산업의 발전적 방향에 대해 모색하는데 목적을 두고 있다. 이를 위해 미국과 일본의 대중음악산업의 현황과 성공사례를 토대로 S.W.O.T 분석을 통해 국내 대중음악산업이 앞으로 나아가야 할 방향을 모색하였다. 본 연구에서 사용된 수치와 데이터들은 약 5년간의 한국콘텐츠진흥원의 자료들을 활용하여 대중음악산업의 흐름을 파악과 연구를 위해 재구성하여 사용하였다. 특히 아직까지 다른 대중산업의 영역과 달리 대중음악산업의 연구가 미비하여 가장 최근의 현황과 이슈들을 파악하기 위해 관련된 기사들을 인용하였다. 이에 대중음악시장 발전방안을 위한 본 연구의 결론은 다음과 같다. 첫째, 빅 데이터 기술 활용에 관한 연구가 필요하다. 현재 온라인상에 널리 퍼져있는 많은 정보들을 취합하여 소비자 개개인의 음악적 취향에 관련된 니즈(Needs)를 분석하고 다가올 음악의 유행에 관해 예측 할 수 있게 도와준다. 이러한 정보를 토대로 각각에 부합하는 홍보 전략을 수립할 수 있는 등, 앞으로 빅 데이터를 활용할 수 있는 기술은 대중음악산업 발전전략에 반드시 필요할 것이다. 둘째, 공연산업과의 연계를 들 수 있다. 이는 현재 온라인 중심의 대중음악산업이 성장의 한계를 맞고 있다는 지속적인 의견들이 제기되고 있다. 디지털 산업으로의 음악시장의 변화는 음원중심의 작곡가와 작사가 등의 창작자와 음원을 제공하는 대기업의 플랫폼 영역 중심으로 변화하였다. 그러나 현재 K-Pop의 한류가 가수 중심의 실연자들의 영역으로 효과가 확장되면서 공연산업과의 연계 또는 다양한 OSMU 중심의 이동이 필요한 시기가 도래하였다. 셋째, 온라인 음악시장의 가격정책의 변화가 필요하다. 현재 대기업 중심의 온라인 음악유통업 중심의 수익분배구조에 관한 문제에 있다. 현재에 관행처럼 이루어지고 있는 분배구조와 음원판매가격은 창작자와 실연자들에게 여전히 불합리한 여건을 조성하고 있다. 이러한 문제는 국내 대중음악산업이 질적인 발전을 이루는데 있어 창작욕구를 저해하는 요소로 작용하기에 가격정책에 대한 움직임이 반드시 수반되어야 할 것으로 보인다. 넷째, 퍼블리시티권의 인정 등 지적 재산권의 확대로, 이는 국내 대중음악산업이 복합적인 구조로 변모해가는 과정에서 개선되어야 할 문제들로 생각할 수 있다. 이미 미국과 유럽 등지에서 이를 적극적으로 인정하고 관련법규와 사례들을 통해 보호하는 추세이다. 이와 관련한 분쟁들로부터 예술가들의 권익을 보호하는 움직임이 활발하게 이루어지고 있다. 이와 같이 앞으로의 문화예술관련 산업이 계속적으로 구조화 체계화됨에 따라 지적 재산권과 계약에 대한 문제가 지속적으로 나타날 것이다. 국내에서도 이와 같은 지적 재산권에 관한 분쟁들이 일어나고 있어 적극적으로 대응하기 위한 노력을 하고 있다. 따라서 대중음악산업의 궁극적인 발전을 위해서는 대중음악산업에 대한 전반적인 정책적 확장은 물론 정확한 법령이나 기준들이 바로 서야 할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 880,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "한국 ICT기업의 금융업 진출 (핀테크) 발전방안 연구 :(A)study on ICT companies` penetration into financial service (Fintech) in South Korea :미국 중국과의 대표 사례 비교분석을 중심으로 =focusing on the comparison analysis of U.S. and China cases ",
		"AUTHOR": "申海蘭",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 881,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "소비자 개인정보보호에 관한 연구 :온라인 사례를 중심으로 ",
		"AUTHOR": "김진경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 유진수 참고문헌: p. 73-76",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "개인정보의 보호가 과거에는 사생활 보호의 권리로서 소극적 권리인 개인 프라이버시 측면의 인격권에 초점이 맞추어져 있었다면, 빅 데이터(big data) 시대가 오면서 점차 그 범위가 변화·확대되고 있다. 사회변화에 따라 개인정보의 범위가 확대되었음에도 불구하고 아직까지는 확대된 개인정보에 대한 논의가 적절하게 이뤄지지 않고 있으며, 그에 따라 보호도 미흡한 실정이다. 미국과 EU를 비롯한 국가에서는 이러한 현실에 맞춰 새로 법을 제정비하고 있는 과정에 있으나, 국내에는 정보통신망법과 개인정보보호법, 위치정보보호법 등의 법률이 이미 제정되어 있어 다른 국가보다 개인정보보호에 앞장서고 있는 면모를 확인 할 수 있다. 그럼에도 불구하고 현실적인 부분에 있어서 개인정보보호가 적절하게 이루어지고 있지 않는 것을 발견 할 수 있다. 이에 본 논문에서는 이러한 부분에 있어 문제점을 발견하고 이를 개선하기 위한 정책적 시사점을 도출하고자 하였다. 사례를 통해서 본 소비자 개인정보를 강화하기 위한 방향으로는 첫째 현행 법률이 보호하는 개인정보의 법위에 대한 새로운 논의가 필요하고, 둘째 기업 인수 합병 시 발생할 수 있는 개인정보 통합에 따른 정보 집중에 관한 법률적 보안책이 마련되어야 하며, 셋째 현행법의 적극적인 집행과 넷째, 법을 위반에 대해 엄중한 처벌이 필요하다. 여기에서 더 나아가 개인정보수집에 관한 동의를 얻는 부분에 있어서는 개별 사항별로 동의를 받는 방안에 대한 검토와 국외에서 서비스를 제공하는 업체에 대해 국내법 적용에 관한 문제를 해결함으로써 국내의 개인정보보호를 좀 더 강화 할 수 있다. 적절한 규제를 통해 소비자의 개인정보보호가 강화 된다면 시장의 신뢰를 통해 거래가 활성화 될 것이고, 바람직한 시장 형성은 빅 데이터를 활용한 사회적 효율성을 증가 시킬 수 있기에 개인정보보호의 강화가 필요하다.",
		"KEYWORD": null
	},
	{
		"ID": 882,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "어플라이언스 시스템의 혁신특성과 품질이 채택의도에 미치는 영향 =(A)study on the effect of innovation characteristics and quality of appliance systems on intention to adopt ",
		"AUTHOR": "유응준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최정일",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "In the information overflow represented by big data, the importance of a new computing system combining software with hardware as infrastructure for fast data processing and decision making has been increasing day by day. Nonetheless, there has not been a full-scale study on the acceptance of computer appliance systems. In order to examine the acceptance factors of such a computer appliance system, this study intended to grasp the level of effects innovative features and quality of the appliance system has on organizational performance, and ultimately analyze the willingness of the IT staff to adopt an appliance system. The study used three models an innovation diffusion model for innovative features, an IS performance model for quality factors, and an UTAUT model. It was then conducted using reliability and cost as externally independent variables based on previous studies on appliance systems. For this study, a survey was conducted on 350 vendors’ clients and partners who currently use an appliance system. The survey was then analyzed and showed quality factors such as technical advantages, facilitation and trial ability, organizational performance expectations all had an effect. In case of checking what was for uniqueness, it was shown that facilitation, which might be considered to be the base/basic condition of accepting a system or not, had a negative (-) effect. Along with this, when an appliance system is adopted, it was shown that cost and reliability emphasized by a vendor did not produce any significant effects on organizational performance expectations. Through additional analysis, it was made clear that organizational performance expectations partially mediated between the innovative features and intention to adopt, and between the quality and adoption. And through the test for difference between groups, it was shown that the experience of use and status within the organization had a slight effect on the intention of adoption to some extent. This study is significant as it is the first to combine such models as IDT, ISS, and UTAUT with a new external variable. It illustrated how variables had an effect on the adoption of an appliance system, and suggests practically ways of applying the findings to sales, support, and development strategies within companies implementing such systems.",
		"KEYWORD": null
	},
	{
		"ID": 883,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "Apache Spark 기반 실시간 안드로이드 악성코드탐지시스템 설계 및 구현 =Design and implementation of Android malware detection systems in real-time based on Apache Spark ",
		"AUTHOR": "임다운",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박제원 참고문헌: p. 32-34",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 모바일 디바이스를 통해 다양한 서비스들이 제공되면서 악의적인 행위를 하는 애플리케이션인 악성코드를 통한 모바일 보안 위협이 증가하고 있다. 공격자들은 악성코드를 통해 사용자의 재산과 직결되는 중요한 금융정보를 중간에서 탈취하거나 랜섬웨어를 이용하여 사용자의 디바이스를 인질로 삼고 있다. 이러한 피해를 줄이기 위해 다양한 연구가 활발히 진행되고 있으며, 특히 빅데이터 환경에서 기계학습 기법을 적용한 악성코드 탐지에 관한 연구가 주목 받고 있다. 하지만 빅데이터 처리의 패러다임이 배치처리에서 실시간 처리로 변화하는 가운데, 이를 악성코드 탐지분야에 적용하는 관련 연구 기술은 부족한 실정이다. 본 논문에서는 Apache Spark를 이용하여 스트리밍 데이터를 분석하는 실시간 안드로이드 악성코드탐지시스템을 제안한다. 그리고 이를 실제로 구현해보고 탐지 성능을 측정하여 시스템의 실효성을 검증하고자 한다.",
		"KEYWORD": "Android Malware Detection Systems,Apache Spark,K-Means,Real-Time Detection,Streaming data analysis"
	},
	{
		"ID": 884,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "하둡 기반 강화학습 알고리즘 =Reinforcement learning algorithm based on Hadoop platform ",
		"AUTHOR": "김진욱",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정기철",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "오늘날의 인공지능은 많은 상태공간에서 최적의 수를 찾아내기 위해 다양한 알고리즘을 사용한다. 하지만 대부분은 현재 상황에서 가장 손해가 적은 탐색을 하는 임기응변식이다. 상태공간이 넓어지면 탐색의 넓이가 넓어지므로 계산량이 늘어나게 되어 대응속도가 느려진다. 본 논문에서는 이러한 인공지능의 한계를 개선하고자, 빅데이터 분산처리시스템에서 강화학습을 이용한 인공지능을 제안한다. 학습은 미지의 환경에서 학습하는 강화학습의 temporal difference 알고리즘을 사용하는데, 처음 학습시간은 오래 걸리지만 수렴이 가능하고 꾸준한 학습이 가능하다. 또한, 어떠한 분야에도 적용할 수 있는 조사되지 않은 영역과 이미 아는 지식을 결합한다는 장점이 있다. 강화학습의 결과 데이터는 하둡시스템에 분산 저장되어 빠르게 처리할 수 있으므로, 추후 많은 상태공간을 갖는 인공지능분야에서도 활용될 수 있다. 실험은 보드게임인 오목에서 최소-최대 게임 트리를 사용한 인공지능과 제안한 알고리즘의 대결로 진행하며, 그 확장 가능성을 연구한다.",
		"KEYWORD": null
	},
	{
		"ID": 885,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Data-driven approach for traffic state prediction with state transition analysis =데이터 기반 교통상태 전이 분석 및 예측 방법론 연구 ",
		"AUTHOR": "Simonoh",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 886,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 자동차산업대학원",
		"TITLE": "GIS 및 C-ITS 기반 자율주행차량의 실시간 최적경로계획과 교통신호 판단 연구 =Research for real-time optimal path planning and traffic signal judgement of autonomous vehicles based on GIS and C-ITS ",
		"AUTHOR": "이동훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 김정하 Research for real-time optimal path planning and traffic signal judgement of autonomous vehicles based on GIS and C-ITS 참고문헌 : p.70",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "자율주행차란 운전자의 개입 없이 주변 환경을 인식하고, 주행 상황을 판단하여, 차량을 제어함으로써 목적지까지 자동으로 주행하는 자동차를 말한다. 이러한 자율주행 자동차는 교통사고를 줄이고, 탑승자의 편의를 증대시키며, 연료를 절감하고, 교통 효율성을 높이게 된다. 기존 자율주행차의 경로 데이터는 경유점(Waypoint)을 참조점으로 지나가는 방식이며, 출발점과 도착점을 알고 있는 상태에서 GPS를 통한 위치 갱신으로 경유점 부근을 지나는 경로추종으로 단 방향적인 경로 데이터 형태로 전 구간 또는 분할 구간으로 단순화 되어 있다. 하지만, 자율 주행시 분할 구간이 길어지면 오차범위가 커져 안정적인 경로 보정이 다시 필요하게 되어 효율성과 안전성이 저하되는 문제점이 발생한다. 본 연구에서 제시하는 자율주행을 위한 방법으로 기존 전역경로와 지역경로의 데이터 처리 방식에 지리정보시스템(GIS : Geographic Information System)과 지능형교통체계(ITS : Intelligent Transport System)를 활용하여 실시간 경로 계획을 생성하고, 융합을 통한 효율성을 높이는데 있다. 기존 자율주행 시스템에 맵기반 실시간 도로·교통정보를 반영하여 경로 데이터를 차량에 제공 한다. 국가교통정보센터에서 제공하는 지능형교통체계(ITS)를 한 단계 더 발전시켜 양방향 통신을 기반으로 한 차세대 협력·지능형교통체계(C-ITS : Cooperative Intelligent Transport System)와 지리정보시스템(GIS)의 구간별 도로교통정보를 활용하면 최적의 구간별 경로계획, 인지, 제어에 활용할 수 있다. 실시간 도로교통상황에 따른 정보는 사고, 정체, 공사 등 각종 교통정보와 날씨나 환경에 따른 도로 상태를 데이터로 만들어지고, 이러한 데이터에서 자율주행차에 필요한 메타데이터(Meta Data)로 생성하여 모아지면 빅 데이터(BIG Data)가 형성되어 예측 및 추정까지 가능한 시스템으로 발전될 수 있다. 이러한 데이터는 경로계획, 환경인지, 차량제어 등 자율주행 시스템에 최적의 효율적인 정보를 제공하며, 동시에 얻게 된다. 이것은 실시간 도로·교통정보가 되며, 노변기지국(RSU : Road Side Unit)에서 WAVE(Wireless Access in Vehicular Environment)통신을 통하여 자율주행 차량의 단말기(OBU : On Board Unit)에 정확하고 안정적이며, 효율적인 정보를 제공 할 수 있고 받을 수 있다. 위 내용을 바탕으로 본 연구는 자율주행차의 기본주행에 필요한 경로계획을 실시간 도로·교통정보를 기반으로 생성하고, 정확한 측정을 기반으로 하는 각종 센서들의 오류를 대체 할 수 있는 활용 방법을 제안한다.",
		"KEYWORD": null
	},
	{
		"ID": 887,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "SDN/OpenFlow 환경에서 대역폭 DDoS 공격 제어 방법에 관한 연구 :(A)study on mitigating bandwidth consumption DDoS attack with SDN/OpenFlow :회선 제어를 통한 서비스 손실 감소 =reduce service loss using internet line control ",
		"AUTHOR": "임동호",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수 : 양재수 참고문헌 : 28장",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "현재 스마트 폰의 보급과 더불어 인터넷의 트래픽이 급격하게 증가함에 따라 데이터의 효율적인 활용을 위한 빅데이터(Big Data) 기술이 탄생하고, 언제 어디서나 데이터를 접근하기 위한 클라우드(Cloud) 기술이 탄생하였다. 이런 기술들을 활용하여 서비스를 제공하는 사업자(Internet Service Provider)는 폭발적으로 증가하는 데이터를 처리하기 위한 네트워크 환경의 변화의 필요성이 대두되어 왔다. 이런 변화에 대응하여 해당 데이터를 전송하기 위한 인터페이스는 100Gbps 까지 개발이 되어 상용화가 되어있으며, 점점 늘어나는 서버를 효율적으로 활용하기 위해 서버 가상화(Server Virtualization)의 보급이 급격하게 증가하고 있다. 하지만 네트워크 환경은 장비 제조사의 의존성과 폐쇄성에 의해 이런 변화의 물결에 빠르게 따라가지 못하고 있다. 데이터의 급격한 증가로 인하여 네트워크는 한정된 자원 속에서 데이터의 우선순위(Quality of Service)를 정해 중요성이 높은 데이터를 먼저 전송하여 서비스의 품질을 향상시키는 동시에, 가상화의 도입으로 해당 가상 시스템마다 네트워크를 분리(Virtual LAN)하여 관리하는 어려움이 증가하고 있다. 또한, 네트워크 구성의 필수 요소인 라우터(Router), 스위치(Switch)는 장비 제조사의 폐쇄성과 의존성에 의해 기존에 네트워크 인프라가 구축이 되어 있는 경우에는 새로운 장비 제조사의 제품과 호환성 문제가 발생 될 수 있으며, 관리 명령어의 차이로 인해 유지보수에 추가적인 인력이 필요로 함에 따라 비용 및 장애가 발생 시 원인 파악 및 해결하는 시간이 증가 한다. 게다가 장비는 하드웨어와 소프트웨어의 비용이 포함이 되어 있어 사용하지 않는 불필요한 기능으로 인해 불필요한 지출이 추가적으로 발생 될 수 있다. 이런 관리의 복잡성과 불필요한 비용 절감 및 제조사의 종속성과 폐쇄성에서 벗어나 사업 환경에 맞는 네트워크 환경을 구축하기 위해 SDN/OpenFlow가 화두로 떠오르게 되었다. 각 장비마다 접속을 위한 보안 정책 및 패킷에 대해 우선순위를 정하던 방식에서 중앙 컨트롤러에서 전체 단말을 관리함으로써 관리 비용을 줄일 수 있으며, 표준화된 프로토콜을 통해 장비간의 통신의 호환성을 보장 받을 수 있으며, 장비의 불필요한 기능을 줄임으로써 비용을 절감 할 수 있다. 본 논문에서는 SDN/OpenFlow를 통한 네트워크 환경 구축과 대역폭 DDoS(Distributed Denial of Service)[8] 공격으로 인하여 서비스 영향을 나타내고, 기존에는 적절한 대응 방법 없이 수동으로 대처하여 발생하는 서비스 손실을 제안하는 방법을 통해 최소화하는 것을 검증 할 수 있었다.",
		"KEYWORD": null
	},
	{
		"ID": 888,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "정보시각화에서 시각적 장식 요소의 유무가 수용자 정보처리 유형별 미치는 영향 =(The)effect of visual embellishment on user information processing type in the information visualization ",
		"AUTHOR": "유두호",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 윤재영 부록: 설문지 참고문헌: 장 74-77",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "현대는 기술의 발달과 사회적 변화로 인한 데이터의 급격한 증가로 빅데이터 시대를 맞이하였다. 그 관점에서 우리는 더욱 많은 데이터 및 정보의 굴레에서 살아가게 되며, 그 정보 중에는 우리에게 시각적으로 바로 인지되는 것이 있는가 하면 과학 및 사회 분야의 총체적인 데이터처럼 해석을 해야 하는 것도 있다. 이러한 사회적 상황은 빅데이터 혹은 정보를 표현하는 방식인 정보시각화에 대한 관심으로 이어지고 있다. 그리고 해당 연구 분야 중에서 일부 단체와 연구자들은 양적 정보 시각화, 즉 차트 디자인에서 차트의 불필요한 시각적 요소, 데이터를 이해하는 데 꼭 필요하지 않은 시각적 장식들을 줄여야 한다고 말한다. 반면에 일부 인포그래픽 관련 디자이너들은 표현된 데이터를 자세하게 포장하고 정보에 대한 시각적 장식을 정보시각화에서 추가로 정교화 하기도 하는데, 이러한 상황이 발생하면서 시각적 장식이 정말로 수용자의 이해에 이롭지 못한지, 그리고 다른 이점들은 무엇인지에 대한 질문들을 시작으로 세부 연구들이 진행 중에 있다. 그 맥락에서 본 연구는 정보 시각화에서 시각적 장식의 유무(有無)가 수용자 정보처리 유형별 태도에 미치는 영향이며 선행연구에서 진행되지 않은 인지욕구와 감정강도에 따른 수용자의 정보처리 4유형별 영향의 차이를 밝히는데 중심을 두었다. 본 연구는 실험에 앞서 정보시각화의 개념과 유형 및 비주얼 표현 양식을 이해하고 정보시각화 분야에서 정보를 표현하는 그래프 이외에 시각적 장식에 관한 사례와 그에 따른 선행 연구 및 논쟁의 측면, 그리고 수용자의 인지욕구와 감정강도에 따른 정보처리 4유형에 관한 이론적 배경을 고찰하였다. 그리고 본 실험에서는 양적 정보시각화의 대표적 유형인 막대, 선, 원 다이어그램 그래프를 기준으로 현재 인터넷상에서 시각적 장식이 포함된 정보시각화의 실제 사례들을 선출하였으며 비교를 위해 선행연구를 바탕으로 시각적 장식의 요소를 모두 제거한 유형을 제작하여 원본과 비교 분석 할 수 있도록 하였다. 본 실험은 설문조사로 진행되었는데 첫 번째로 인지욕구 및 감정강도에 따른 수용자 유형분석, 두 번째로 정보시각화 유형 비교 분석은 신뢰도, 유용성, 선호도의 총 3가지로 이루어졌으며 분석 방법으로는 SPSS ver12.0을 사용하여 통계적 자료처리를 실시하였다. 연구결과, 수용자 유형에서 시각적 장식이 없는 유형에 전체적으로 긍정적이었던 인지적 정보처리자를 제외한 3가지 수용자 유형에서는 유용성, 선호도에서 시각적 장식이 있는 정보시각화 유형에 긍정적인 것으로 나타났으며, 복합적, 감정적 정보처리자의 경우 신뢰성 측면에서는 시각적 장식 유,무 비교에서 차이가 미비한 것으로 나타났다. 이러한 결과는 정보시각화에서 메시지 유형의 변화가 수용자의 인지 욕구와 감정 강도에 따른 유형별 수용 태도에 대한 차이가 있다는 것을 나타내고 있다. 따라서 정보시각화를 진행하는 경우, 기존의 주요 제작 가이드라인이었던 정보의 목적과 내용전달, 설계에 덧붙여 본 연구의 결과를 바탕으로 정보를 수용하는 사람들의 유형이나 특성 또한 고려된다면 보다 효과적인 정보시각화 를 이루어 낼 수 있을 것이라 생각한다.",
		"KEYWORD": null
	},
	{
		"ID": 889,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "상지대학교 대학원",
		"TITLE": "연관 상황 모델과 유사도 군집 분석을 이용한 마이닝 기반의 헬스케어 추천 방법 =Mining-based healthcare recommendation method using associative context model and similarity clustering analysis ",
		"AUTHOR": "정호일",
		"REGION": "강원도",
		"PROFESSOR": "지도교수: 정경용",
		"STORE_LOCATION": "상지대학교 학술정보원",
		"ABSTRACT": "As the development of information technology reaches its peak, convergence technology is being used in all fields. The data and information that have been scattered as documents in each existing field are now digitized and constructed as a system. In response to these social changes, humans are studying information filtering methods to obtain more useful information in a wide variety of information. In the medical health industry, most of the medical information is used as they are applied to the efficient health management and u-health care. Recently, as interest in healthcare has increased due to population aging and chronic diseases, healthcare recommendation methods based on IT convergence technology have been developed, and healthcare recommendation services using the Internet or mobile have been developed. Currently, the healthcare recommendation service that is being researched and developed is the recommendation service of diet management, exercise, and chronic disease management focused on self-health management. However, these services consist of comprehensive content and contents that do not take into account the environment and personal health status according to the characteristics of person the service targets, and it is difficult to maintain consistent and efficient health management because the prescription is made only by the measurement result of the temporary measurement result. Therefore, in order to recommend appropriate and proper healthcare services to users, personalized context information that can be acquired in daily life should be provided. In addition, a context model is needed that complies with medical criteria in the healthcare characteristics and reflects the information and characteristics required for healthcare service recommendations and furthermore, personalized health care services customized for persons should be recommended through analysis of existing big data scattered related to healthcare. Personalized healthcare recommendation services should provide services and items that are well suited to appropriate circumstances and situation of use. The existing healthcare recommendation method does not reflect the context information according to the user`s environment or characteristics because the recommendation is made with the information inputted by the user and the application user record, and the recommendation is made using the data extracted from the static model. This has the problem that the accuracy of forecasting is low due to sparsity and initial evaluation problems in health care recommendation. Therefore, in this paper proposes a mining-based healthcare recommendation method using associative context model and similarity clustering analysis. The proposed method classifies and defines the context information in order to analyze the user`s situation in daily life, and models the context information by using the ontology technique which can display the user`s situation efficiently. In addition, it uses FP-tree mining to discover potential associations between contextual information and develops context-based modeling to find useful information that is not revealed potentially from user context information. It is possible to overcome the drawbacks of unidirectional focused reasoning of existing context modeling. In order to provide more accurate and appropriate healthcare recommendation to users, it analyzes the similarity of existing chronic disease patient Big Data by using Tanimoto coefficient based on the attribute data of HDSS, applies the Fast-Apriori algorithm to produce relevant user cluster based on similarity. It derives the similarity weight value based on the attribute data of the chronic patients through the similarity based association user group and applies it to the health care recommendation to improve the accuracy of recommendation. The accuracy of healthcare recommendation is improved when users who have basic information with high similarity are grouped. Therefore, for the user cluster with high similarity, the healthcare related factor data should be subject to the significance verification analysis and the user cluster with high similarity should be created to improve the health care recommendation accuracy. In addition, the proposed method is based on static data of {related user - items} extracted through mining and {User-item} merging matrix from inference rules of association context model through associative context model to recommend a healthcare service to the user, thereby improving the problem of the existing recommendation method. In order to verify the validity of the proposed method, the performance evaluation was performed by applying the mining - based healthcare recommendation method to the set of dietary nutrition items of the chronic ill patients using the associative context model and similarity cluster analysis. It developed a healthcare mobile service application through the proposed method and evaluated the accuracy of the prediction through the recommendation method and the comparative experiment. As a result of the evaluation, it is confirmed that the performance of the recommendation through the proposed method is about 16.5% better than the conventional method.",
		"KEYWORD": "군집 분석,데이터 마이닝,헬스케어"
	},
	{
		"ID": 890,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "하둡에서의 RBAC를 활용한 접근제어 프레임워크 설계 =(A)design of access control frameworks using RBAC in Hadoop ",
		"AUTHOR": "김보선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박재표",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 빅 데이터에 대한 관심이 높아짐에 따라 처리 기술에 대한 논의가 핫 이슈로 떠오르고 있다. 그 중 하둡(Hadoop)은 빅 데이터를 처리하는 대표적인 분산처리 기술로 가장 널리 쓰이나 시스템 내 데이터 파일에 대한 접근 권한설정 및 제어 기술의 부재로 취약점을 가지고 있다. 따라서 본 논문에서는 이러한 취약점을 해결하기 위하여 RBAC를 활용한 접근제어 프레임워크를 제안하였다. 접근제어 프레임워크는 네임노드 내에 관리자 메타데이터 관리 모듈과 접근관리 모듈로 구성하고 운영체제상의 사용자 인증은 기존과 같이 제공하였다. 접근제어를 위한 보안레벨은 그룹(G), 사용자(U), 역할(R)로 구성하였으며, 보안레벨에 따라 접근 허용 여부가 결정된다. 특히 역할(R)에 따라 접근이 허용되더라도 사용자에게 가능한 읽기(R), 쓰기(W), 삭제(D)의 작업 범위를 차등 부여함으로써 보다 세밀한 접근제어 및 안전성을 보장하도록 하였다. 관리자와 소유자의 역할을 별도로 두어 권한 오용에 따른 정보 유출을 방지함으로써 안정적인 제어정책을 갖추도록 하였다.",
		"KEYWORD": "big-data,hadoop,RBAC,role-based access control,빅데이터,역할기반 접근제어,하둡"
	},
	{
		"ID": 891,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "중앙대학교 예술대학원",
		"TITLE": "여성 화장품의 웹 사이트 디자인에 관한 연구 :Research on website design of female cosmetics : focused on the UX design for Taobao online shopping site ",
		"AUTHOR": "왕동",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 서혜옥 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "현재, 세계적으로 20억 명 이상이 인터넷을 이용하는 것으로 추정되고 있다. 또한, 개인용 컴퓨터 외에도 휴대전화, TV 등 다양한 기기들이 인터넷 접속 기능을 속속 갖추고 있으며, 제3 세계를 중심으로 한 IT 기기 보급률 역시 꾸준히 증가하고 있어 인터넷 사용자 증가 추세는 앞으로도 계속 이어질 것으로 보인다. 이러한 새로운 경제의 시대에서 살아남기 위해서는 디지털 마케팅의 개념과 전략으로 급변하는 마케팅 환경의 변화에 적응이 필요하다. 웹 사이트는 고객과의 커뮤니케이션이 가능하여 기업정보 전달과 판매의 매체로 자리 잡아 웹 디자인의 중요성은 날로 부각되고 있다. 최근 인터넷 전자상거래 초기 시절 22%에 미치지 못하던 여성 소비 고객들이 68% 이상을 차지할 정도로 비중이 높아졌다. 하지만 중국 온라인 화장품 회사의 사례를 조사한 결과 이용자 경험 디자인은 아직까지도 여성소비자들을 만족시키지 못함을 알 수 있었다. 이 논문은 UX 디자인 중심으로 여성 화장품 웹 사이트 디자인에 관하여 연구를 진행하였다. 연구 목표는 화장품 웹 사이트에서 여성을 위한 UX 디자인 필요한 이유를 밝히고, 고려해야하는 조형구성 요소들을 개선해 디자인하는 것이다. 본 논문은 웹 사이트 디자인의 조형적 구성요소를 중점으로 연구하여 웹 디자인 시 UX 디자인 중심으로 고려해야 할 6가지 원칙을 발견하였다. 첫째, 전체적으로 보면, 이 웹 페이지 레이아웃은 여성 상품을 여성화하게의 사고방식과 달리 고객 피드백과 데이터 수집과 분석을 통하여 맞춤형 조정을 하였다. 이어서 웹 사이트의 조작 체험감을 줄이고 쇼핑 체험을 강조하게 만들어냈다. 둘째, 여성 소비자들이 구매하면서 가진 심리를 분석하고 총괄을 한 다음에, 이 웹 사이트는 설계하면서 일반적인 디자인 풍격으로 하지 않았고, 여성 소비자들의 구매 욕심을 끌어낼 수 있는 색채와 이미지를 사용하여 여성 소비자들의 주의력을 최대한 쇼핑에 둘 수 있게 만들었다. 셋째, 웹 페이지의 논리가 분명하고 순서가 명확하다. 여성 소비자들은 짧은 시간 안에 자기가 원하는 제품을 찾아낼 수 있다. 이어서 편리하게 조작하고 시간도 낭비하지 않는다. 소비자들이 구매 욕망이 제일 강하는 시간에 상품을 바로 구매하게 한다. 넷째, 웹 사이트는 사용자들의 열람 습관, 쇼핑 경력, 개인 피부 타입 특징 등의 분석을 통하여 소비자들에게 합리적인 구매 추천을 해준다. 이어서 사용자들이 합리적인 소비 결정을 낼 수 있게 도와주며, 사용자들에게 맞춤화 쇼핑 체험을 제공하여 여성 소비자들이 서비스의 핵심을 만들어 냈다. 다섯째, 웹 사이트는 빅데이터(Big data)와 인공 지능 기술을 결합하고, 사용자가 감독하는 각도, 그리고 제품 공정의 측면에서 웹 사이트에서 판매하는 상품의 정보 진실성과 유효성을 보증하였다. 이런 측면에서 보면, 사용자가 웹 사이트에 대한 신뢰도가 높여주었다는 것이다. 여섯째, 웹 사이트는 즉시 통신 시스템과 제품 정보 발포 시스템을 완선하였다. 사용자들이 언제 어디서나 자기가 관심이 가진 상품에 대해 알아 볼 수 있고, 지향이 서로 맞는 친구들도 사귈 수 있다. 이어서 쇼핑과 사교가 서로 결합하는 전자 상거래 시스템을 탄생할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 892,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "Development of tunnel facilities maintenance and management system based on life cycle cost analysis =생애주기비용분석(LCCA)기반 터널부속시설물 유지관리시스템 개발 ",
		"AUTHOR": "이유희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 서종원 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 75-76",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "전 국토의 도시화가 가속화에 됨에 따라 도로망이 확대되고, 이에 따라 교량 및 터널의 수가 급증하고 있다. 통계청에 따르면, 지난 10년 간 국내의 전체 터널 개수는 817개소(2005년)에서 1,944개소(2015년)으로 237%나 증가하였고, 터널의 길이 역시 551km(2005년)에서 1,418km(2015)로 257% 가량 증가하였다. 이러한 터널의 증가는 자연 환경 파괴 최소화, 도로 이용자 안전등을 목적으로 한 도로의 선형설계를 주요 원인으로 들 수 있다. 따라서 증가한 터널의 구조적 안전성과 경제성 확보를 위하여 전문적이고 체계적인 유지관리 단계의 관리가 필요하다. 이미 선진국에서는 터널의 유지관리를 시설물의 운용의 시작부터 해체/폐기까지 이르는 모든 과정, 즉 생애주기(Life-Cycle)관리를 통해 시스템화하여 시설물의 성능을 일정하게 유지하게 함과 동시에 경제적 투자를 효과적으로 제어할 수 있는 기술력을 갖추고 있다. 본 연구의 목적은 터널 내에서도 수선/교체 주기가 잦고 끊임없이 에너지를 소모하는 부속시설물을 대상으로 하여 생애주기비용분석(LCCA)기반의 터널 유지관리시스템을 개발하는 것이다. 확장성과 호환성이 높은 LCC방법론을 정의하고 모델을 개발함으로써 분석대상의 추가가 용이하도록 설계 및 개발을 목표로 하였다. 본 연구를 통하여, 터널 부속시설물의 유지관리 이력 데이터를 축적할 수 있어, 장기적으로 자산관리를 수행하기 위한 빅데이터로 활용이 가능하다. 뿐만 아니라, LCC 분석 모델을 통해 현재상태의 시설물과 기타 품명의 설계안을 비교함으로써, 장기적인 관점에서 유지관리 비용을 손쉽게 비교할 수 있고, 장기적으로 국가적 예산절감에 도움을 줄 수 있다. 또한, 비용중심의 단/장기 유지관리 계획을 수립하는 데에 있어, 국가재정에 맞는 예산분배를 수행함으로써, 터널의 상태 및 관리의 중요도를 고려한 시설물 성능관리를 수행할 수 있는 기틀을 마련하였다.",
		"KEYWORD": "토목공학"
	},
	{
		"ID": 893,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "배재대학교 대학원",
		"TITLE": "SaaS 클라우드시스템에서 개방형 인증 프로토콜을 활용한 효율적인 응용소프트웨어 접근통제 방안 =(An)efficient access control mechanism for application software using the OAuth in the SaaS cloud system ",
		"AUTHOR": "김선주",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 조인준 참고문헌 : p. 73-76",
		"STORE_LOCATION": "배재대학교 도서관",
		"ABSTRACT": "최근들어 다양한 모바일 기기를 지원하는 클라우드 서비스가 발전하고 있다. 이를 위해 가상화, 프로비저닝, 빅데이터 처리 등의 다양한 기술이 제안되고 있다. 그러나, 이러한 기술에도 불구하고 보안사고가 지속적으로 발생하고 있다. 이로 인해 주요 데이터의 외부 노출을 꺼리는 기업들은 가상화 소프트웨어를 이용하여 직접 사설 클라우드 서비스를 구축하고 있다. 이러한 사설 클라우드 서비스 구조는 몇가지 문제점이 있다. 첫째, 서버에 동일한 종류의 게스트 운영체제를 중복 설치로 인해 서버의 리소스 낭비를 초래한다. 둘째, 응용 소프트웨어를 사용하기 위해서는 반복적인 사용자 로그인 과정이 필요하다. 셋째, 원격 데스크톱 소프트웨어를 설치하고, 이를 통해서만 접속이 가능하다. 마지막으로, 반복적인 사용자 로그인 과정을 줄이기 위해 일부 업체에서는 단일인증시스템을 추가적으로 구축하기도 한다. 따라서, 본 논문에서는 SaaS 클라우드시스템에서 개방형 인증프로토콜(OAuth Protcol)을 활용하여 효율적으로 응용 소프트웨어의 접근통제 방안(ACMOS: Access Control Mechanism of application software using the Oauth in the Saas cloud system)을 제안한다. ACMOS는 시스템 리소스를 절감하고, 원격 데스크톱 프로그램의 설치 없이 웹을 통해서 소프트웨어를 사용할 수 있도록 제안하였다. 이를 위해 ACMOS는 동일한 종류의 게스트 운영체제와 응용 소프트웨어는 하나의 게스트 운영체제에 통합 설치하였다. 그리고, 웹을 통해 응용 소프트웨어를 실행 할 수 있고, 보안토큰을 활용한 개방형 인증 프로토콜을 사용하여 반복적인 사용자 로그인 과정을 줄이도록 설계하였다. ACMOS를 정보보호제품에 대한 공통평가기준 및 공통평가방법론에 정의한 방법에 따라 ACMOS에 대한 공격 성공 가능성을 조사해본 결과 보증등급 EAL4에서 충분히 안전함을 확인할 수 있었다. 본 논문에서는 제안한 ACMOS의 타당성과 현실성을 검토하기 위해 다음과 같은 연구를 하였다. 첫째, 클라우드 서비스 개요와 개방형 인증프로토콜을 비롯한 클라우드 서비스 관련 주요기술과 사고 사례를 정리하였다. 둘째, 기존 방식의 문제점을 보완하기 위해 ACMOS를 설계 및 구현하였다. 그리고, ACMOS의 기능 및 성능을 검증하기 위해 시뮬레이션 환경을 정의하고, 3가지 시나리오에 따라 제안시스템을 분석하였다. 마지막으로, 본 연구를 통해 파악된 주요 사항을 정리하고, 향후 이루어져야 할 연구분야를 정리하면서 본 논문을 마무리 하였다.",
		"KEYWORD": "OAuth,SaaS,개발형인증프로토콜,응용소프트웨어,클라우드"
	},
	{
		"ID": 894,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 광고홍보대학원",
		"TITLE": "정보 수용자의 개인적 특성에 따른 인포그래픽의 인지도 차이 =(The)difference of infographic perception depending on the individual characteristics of information consumers ",
		"AUTHOR": "김주연",
		"REGION": "서울",
		"PROFESSOR": "부록: 설문지 국·영문초록수록 지도교수: 성열홍 참고문헌: 장 90-94",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "빅데이터 시대, 활발한 SNS 환경, 화면 크기와 모양이 다양한 디바이스의 등장, 공공 데이터에 대한 중요성 인식 확산 등의 시대적 분위기로 인해 빠르고 효과적인 정보디자인에 대한 요구가 더욱 커진 상황이다. 이에 복잡한 정보를 효과적이고 직관적으로 전달하기 위한 인포그래픽의 활용이 증대되고 있다. 인포그래픽이 인지도에 긍정적인 영향을 끼치는 것으로 이미 많은 연구를 통해 나타났지만, 모두 동일 수준으로 정보를 받아들이는 것은 아닐 것이다. 본 논문을 통하여 저자는 수용자를 몇 가지 방식으로 구분하여 인지도에 차이가 없는지를 고찰해 보고자 하였다. 정보 수용자들의 개인특성에 따른 인지도 차이를 살펴보는 것은 최근의 추세와 발맞춘 맞춤형 인포그래픽의 유형을 제시하고 인포그래픽 사용 비중 등을 파악할 수 있을 것으로 기대되기 때문이다. 정보디자인이라는 시각정보를 수용함에 있어 1차적으로 관련이 있는 인간의 뇌유형별 인지도의 차이를 우선 살펴보고, 성별, 연령별에 따른 차이가 있는지를 고찰하였다. 먼저 뇌유형별 정보 인식의 차이를 알아보기 위해 뇌분할 이론을 고찰하고, 인포그래픽을 통한 정보 파악의 정확도와 속도를 테스트할 수 있는 설문을 통해 뇌유형별, 연령별, 성별 인지도에 관해서도 연구하였다. 결론적으로 이미지 정보처리와 관련이 있는 뇌로 알려진 우뇌형이 좌뇌형보다 이미지를 더욱 잘 파악하였고, 성별 간에는 유의한 차이가 없었으며, 연령별로는 나이가 어릴수록 인포그래픽에 대한 인지도가 높았다. 단순한 지지와 기각 이외에 연령별로 지지와 기각이 차이가나는 등 더 자세한 분석을 살펴보는 것은 앞으로의 인포그래픽 활용에 대한 차후 연구 과제를 제공하고 있다.",
		"KEYWORD": null
	},
	{
		"ID": 895,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "디자인주도 IP 융복합을 통한 국가 R＆D 기술시각화 예측모형 연구 =(A)study on predictive model of visualization technology in national research ＆ development by design initiative intellectual property convergence ",
		"AUTHOR": "한소영",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 부록: 1. IP 융복합 특허전략수용도(KPI) 적용항목 및 가중치, 2. 전문가 대상 : 심층인터뷰 3. 델파이 SPSS프로세싱 데이터 지도교수: 김주연 참고문헌: p. 188-193",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "The purpose of this research is to propose a national research and development(R&D) plan through the examination of prior applications of design and intellectual property(IP) and methodologies of design-driven IP convergence in the changing market. A total of 100 empirical studies will help detect the relationship of IP and design in national R&D; here, the importance of design-driven IP convergence will be emphasized. With this, this study will make use of patents, which are formalized large-scale data that includes roughly 80% of all aspects of technology as “Technical Reports.” This data can be used for entering a new market and for protecting an existing market through IP. By utilizing this information from the perspective of design and by building a strong binomial model (BM)?based IP portfolio, a predicted model of technological visualization will be proposed. Design-driven IP convergence could also be applied in private R & D fields. Furthermore, disruptive ideas, IPs, BMs, and infrastructures could be formed at the limits of technology, which will then contribute to national competitiveness. Under the scope of its research background, this study detected the relationship between IP convergence application and design-driven application through a structural formula. In addition, the degree of application and evaluation of the predicted model was studied through interviewing a focus group made up of professionals. The research results revealed that the IP extraction progress depended on number of patents > number of BM patents > number of copyrights > number of design rights, respectively. IP convergence is the most influential variable, but it was confirmed that a design-driven application was affective enough to lead the progress. In addition, in interviews of professionals regarding this matter, it was said that these research results were worthy of the next model of IP-R&D and will be used as a tool to seize the future market as its application and influence on national R&D businesses and private R&D industries are significantly high. However, examinations of case studies showed different results depending on each stage of R&D. In particular, the dynamics of IP extraction was different when approaching the market between government and private R&D cases. Therefore, the need to separate the research for each stage was brought up. In addition, there is also a need to expand the range of interviewees for the interview of professionals. Thus, the need to construct a more competitive methodology through studying existing and new IP convergence businesses was proposed as the next research project.",
		"KEYWORD": null
	},
	{
		"ID": 896,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "테크놀로지의 진화와 확장에 따른 `반응형 아이덴티티 디자인` 연구 =(A)study of `responsive identity design` by the revolution and expansion of technology ",
		"AUTHOR": "김거수",
		"REGION": "서울",
		"PROFESSOR": "국ㆍ영문초록 수록 지도교수:장동련 참고문헌 (p.171-177) 포함",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "‘반응형 아이덴티티 디자인(Responsive Identity Design)’은 테크놀로지의 진화와 확장에 의해 변화된 환경에서 전개되는 진화된 아이덴티티 디자인을 의미한다. 이 연구는 급변하는 테크놀로지 환경을 통해 앞으로 전개될 ‘반응형 아이덴티티 디자인`의 역할과 형태에 대한 논리적 근거를 구성하고 ‘반응형 아이덴티티 디자인`의 준비를 위한 선험적 차원에서 진행되었다. “고정된 아이덴티티가 능사는 아니다”라는 생각을 오랫동안 해 온 ‘스테판 사그마이스터(Stefan Sagmeister)`의 사고와 같이 진화된 아이덴티티 디자인은 ‘참여(Participation)`의 사회문화 환경 속에서 ‘플렉서블 아이덴티티 디자인(Flexible identity design)`을 넘어 결국 ‘제너레이티브 로고(Generative Logo)`와 같은 ‘참여 아이덴티티 디자인`의 실현을 이루었다. 이와 같이 급격히 진화하고 발전하는 테크놀로지와 사회 환경에서의 아이덴티티 디자인은 새로운 방법과 기능을 지닌 진화된 형식의 아이덴티티 디자인이 되어야 한다는 논리를 연구자는 귀납적으로 추론해 볼 수 있었다. 미디어 환경의 변화, 사회의 변화, 테크놀로지 생태계의 변화가 모두 이루어지고 ‘반응형 메커니즘(Responsive mechanism)`의 확산에 대한 전조(前兆)가 글로벌 곳곳에서 발생하고 있다. 참여와 개인화 사회로 인해 나타난 반응성, ‘맥락적 정보(Contextual information)’, ‘증강현실(Augmented Reality)`, ‘입체 공간 디스플레이’와 ‘소셜 네트워크 서비스’의 인프라는 ‘매체의 효율적 등장’과 ‘사회화’의 등식을 구성하는 데 길지 않은 시간을 필요로 했다. ‘반응형 웹디자인(Responsive Web Design)`, ‘시맨틱 웹(Semantic Web)’과 ‘빅데이터(Big Data)`와 ‘클라우드 컴퓨팅(Cloud Computing)`, ‘N스크린`과 같은 테크놀로지는 ‘반응형 아이덴티티 디자인`의 등장 배경을 논리적으로 설명해 주고 있다. 연구자는 이러한 시기와 환경에서 ‘반응형 아이덴티티 디자인`을 연구하여 그 개념적 정의를 규정하고 핵심적 특징에 대한 유형화를 이루었다. 유형화의 논리적 개연성을 위하여 연구자는 ‘칼 포퍼(Karl Popper)`의 ‘Three Worlds`에 등장하는 ‘World 2`, ‘World 3`의 ‘주체적 특성(Subjective properties)’과 ‘객체적 특성(Objective properties)`에 대한 인식적 접목을 유도했다. 그리고 ‘반응형 아이덴티티 디자인`을 구성하고 있는 다섯 가지 중요한 특징들이라고 할 수 있는, ‘일관성(Consistence)`, ‘가변성(Flexibility)`, ‘공간성(Extensity)`, ‘맥락성(Contextuality)`, ‘강도성(Intensity)`을 규정함으로써 연구자는 ‘반응형 아이덴티티 디자인`의 더욱 견고한 개념을 정립하고자 했다. 또한 연구자는 현상적 관점에서의 반응 아이덴티티 디자인의 전조를 ‘글로벌화에 반응한 국내 아이덴티티 사례`, ‘사업 다각화에 반응한 글로벌 아이덴티티 사례`, ‘시대적 트렌드에 반응한 이벤트 아이덴티티 사례`, ‘미디어 변천에 반응한 IT 테크놀로지 아이덴티티 사례`로 구분한 사례 연구를 진행하였다. 이러한 사례 연구는 최근 10년간 나타나고 있는 아이덴티티 디자인의 변화와 움직임, 그리고 방향 분석에 대한 중요한 원천이 되었다. 이러한 현상은 연구자로 하여금 ‘반응형`이라는 사회 현상적 키워드를 도출하게 했다. 그리고 결국 이를 ‘반응형 아이덴티티 디자인’으로의 진화를 위한 의미 있는 현재의 연구 대상이 되게 했다. 이러한 연구는 앞으로 등장하게 될 미래 테크놀로지의 확장된 사회문화 환경에서 ‘반응형 아이덴티티 디자인’으로의 진화를 위한 의미 있는 과정과 사회현상이 되었다고 할 수 있었다.",
		"KEYWORD": null
	},
	{
		"ID": 897,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "극좌표계 텍스트 배치를 위한 CSS3 확장사양 설계 및 전처리기 구현 =CSS3 extension for polar-coordinate text layout and its preprocessor ",
		"AUTHOR": "심승민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 임순범 참고문헌: p. 92-95",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "우리는 주변의 로고, 포스터, 접시 등에서 글자를 원형에 맞추어 배치한 사례를 종종 볼 수 있다. 또한, 최근 스마트워치 등 원형 기기들이 출시되고, 빅데이터 시대의 도래로 데이터 시각화 분야가 주목받으면서 글자의 원형 배치에 대한 요구가 증가하고 있다. 하지만 웹에서는 글자를 원형 또는 부채꼴로 배치하는 방법을 따로 지원하지 않아 작성하기에 복잡하며, 현재까지 표현 가능한 범위가 제한적이다. 이에 따라 웹상에서 글자를 원형 또는 부채꼴에 맞추어 배치하는 모든 경우를 지원하고, 기존의 방법보다 더 간결하고 효율적으로 작성할 수 있는 방법을 제공할 필요가 있다. 본 연구는 브라우저 기반의 웹 환경에서 CSS 스타일시트와 HTML로 표현되어 있는 웹페이지 내의 글자를 원이나 부채꼴의 중심을 기준으로 하는 극좌표계로 배치할 수 있도록 CSS3 사양을 확장한다. 또한, 확장 CSS3 사양으로 작성한 콘텐츠가 기존 브라우저에서 표현될 수 있도록 전처리기를 구현한다. 그 후, 본 연구에서 제안한 방법을 사용하면 웹상에서 글자를 극좌표계로 표현하는 데 제한이 없으며, 간결한 방법을 통해 효율적으로 작성할 수 있음을 증명하기 위해 문서 작성 프로그램인 파워포인트와 글자의 원형 배치를 지원하는 자바스크립트 라이브러리인 CssWarp.js로 동일한 샘플 콘텐츠를 작성하여 결과를 비교ㆍ분석하였다. 본 연구에서 제안한 확장 CSS3 사양이 표준 모듈로 채택될 것을 기대해본다. W3C 표준이 된다면 사용자는 특정 라이브러리를 찾아다니거나 복잡한 코드를 작성하는 데 시간을 낭비할 필요가 없다. 마지막으로, 본 연구가 직교좌표계를 가정하는 웹에서 극좌표계의 패러다임을 열 수 있는 기점이 되었으면 한다.",
		"KEYWORD": null
	},
	{
		"ID": 898,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "동방문화대학원대학교",
		"TITLE": "『周易』과 色彩心理를 통한 憂患의 내재적 극복 연구 =Study to overcome internal anxiety through book of changes and color psychology ",
		"AUTHOR": "연덕희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤무학",
		"STORE_LOCATION": "동방문화대학원대학교 도서관",
		"ABSTRACT": "The government’s anti-suicide policy appears to be focused on providing ‘external support’. This policy direction is oriented to identifying cause of pain that triggers suicide, selecting parties vulnerable to such pain and inviting outside parties (nation·professional institutions·experts) to manage and counter the situation. Being such, all humans and human affairs fall into the policy and those declining counseling or monitoring may not benefit much from the policy. In short, it is not a fundamental solution. This study specifies causes of suicide pointed out by today’s men and women as extreme outcome of misfortune (pain or unhappiness) and discusses ways to cope with one’s misfortune within oneself by focusing on human heart and mind that experience such unwanted feeling. The ancient people believed innate and external environment including misfortune is determined by god’s luck (the divine will). Correlating meaning of ‘luck (the divine will)’ as the ancient people understand and ‘misfortune’ by today’s men and women leads to the conclusion that judgment about whether one feels ‘happiness’ or ‘misfortune’ is not based on the environmental good or bad luck one experiences. Rather, it is made or even changes depending on how one understands, accepts oneself and the surrounding environment and how one takes reasonable ‘action’. Understanding of luck held by the ancient people evolved from a one-sided relationship of ‘god → human’. It started to divide god from humans under the condition of unity from the Zhou Dynasties and later to ‘god ? humans’ as the concept spread from god to humans. This is when ‘anxiety of consciousness’ by Confucianism revealed itself. ‘Anxiety of consciousness’ indicates the strong determination to face one’s innate and external environment with an initiative and reflective way. One must have an understanding of ‘oneself’ and the ‘subject’ to overcome if he/she is to cope with the misfortune with a strong initiative and reflective manner, which this study defined as ‘luck’ in the contemporary meaning. Ancient people relied on ‘fortune telling’ to know of their luck but it is not easily accessible and hard to grasp by today’s men and women, particularly Westerners. Ancient people relied on ‘fortune telling’ to know of their luck but it is not easily accessible or comprehensible by today’s men and women, particularly by those in the West. Aware of such limitations, this study searched for a new tool that accounts for all cultural differences between East and West, and age or gender differences. As a starter, the study selected ‘fortune telling’ in the ancient age, ‘psychological counseling’ in the modern age and today’s ‘Big data’ as the key system used to predict the unknown and know of one’s luck. Close comparison and analysis of communication process by the different system indicated that all of them go through ‘human→ object→ visualization→ analysis·interpretation. ‘Color’ is suggested as a common tool to know of one’s luck. Color is a natural phenomenon that is hardly affected by individual characteristics and cultural traits. Color is used in today’s world to figure out dormant conditions of body and mind, and to seek balance. This so-called ‘color psychology’ takes the same communication process of ‘human → object→ visualization→ analysis·interpretation observed in fortune telling · psychological counseling · Big data. It also signals that color of one’s choice can be used for fortune telling(know ordering).",
		"KEYWORD": "색채심리,우환의식,자살,지명,커뮤니케이션,행복"
	},
	{
		"ID": 899,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "로지스틱 회귀모형과 랜덤포레스트를 혼합한 변수선택법에 기반하여 의사결정나무를 이용한 외래 관광객 만족도 분석 =An analysis on foreign tourists satisfaction using dicision tree based on a combination of logistic regression model and random forest ",
		"AUTHOR": "오세웅",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 차경준 권두 국문요지, 권말 Abstract 수록 부록 수록 참고문헌: p. 50-52",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "본 연구는 2013년1월부터 2015년 12월까지 3년 동안 국내여행을 한 외래 관광객을 조사대상으로 한국문화체육관광부에서 발표한 ‘외래 관광객 실태조사’ 설문지 데이터를 활용하여 외래 관광객의 만족도를 확인하고 매우 만족한 집단의 특징을 파악하고자 한다. 분석모형은 의사결정나무의 CART, CHAID, CTree 알고리즘 중 가장 높게 분류되는 모델을 사용하였다. 그 결과 CART 알고리즘이 가장 잘 분류되었다. 목표변수는 만족도로 지정하였고, 만족도가 매우 높은 외국인 관광객들의 특징을 잡아내기 위해 의사결정나무의 CART 모델을 사용하였다. 과적합을 막기 위해 변수들을 선택하는 방법은 데이터 마이닝 기법 중 로지스틱 회귀모형, 의사결정나무(C4.5), 랜덤포레스트, 인공신경망, 로지스틱 회귀모형과 랜덤포레스트를 혼합한 모델을 사용하여, 정확도와 민감도가 가장 높은 방법을 사용하였다. 그 결과 로지스틱 회귀모형과 랜덤포레스트를 혼합하여 사용하면 조사연도, 연령, 거주국, 활동내역의 변수를 선택하게 되고, 이 선택 된 변수들로 더 높은 민감도를 보였다. 기존에 주로 사용되고 있는 변수선택 방법들을 혼합하여 변수선택을 하였고 외래 관광객 데이터를 분석할 때에는 이 혼합방법을 이용하는 변수를 선택하는 것이 좋은 성능을 나타낸다. 본 연구로 빅데이터를 연구함에 있어 좋은 예측력과 분류 특징을 잡아내는 분류 모델을 만들었고, 연구의 결과는 향후 외국인 관광객 유치를 위한 효과적인 마케팅전략 수립 시 기초 자료로 활용이 가능할 것이라고 사료 된다.",
		"KEYWORD": "통계학"
	},
	{
		"ID": 900,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2012",
		"UNIVERSITY": "명지대학교 대학원",
		"TITLE": "정보시스템 기반의 행정프로세스 혁신모형(X-LERD) 개발 연구 ",
		"AUTHOR": "김숙희",
		"REGION": "서울",
		"PROFESSOR": "명지대학교 논문은 저작권에 의해 보호받습니다. 지도교수 : 정윤수. 참고문헌 : p.140-144.",
		"STORE_LOCATION": "명지대학교 도서관(서울)",
		"ABSTRACT": "Korea’s e-Government system is the best in the world, as confirmed by various reputable international organizations. For example, the UN-DESA(Department of Economic and Social Affairs), has rated the system as No. 1 in the world, in both 2010 and 2012. Regardless of this remarkable achievement, aspects of the system such as government efficiency, business transparency, and services to citizen, have not reached the aspirational levels. This study therefore attempts to investigate why such a notable e-government system in Korea, has not led to improved outcomes for the benefit of the nation and its society. The study also suggests some feasible solutions for the issues identified. The operating principle of outcomes was adopted for this research in order to clarify the deficiencies identified, and find the rationale for explaining why Korea’s e-government system is not sustainable, and has not led to expected outcomes. The result of the study indicates that an invalid worldview on both process and service management is the source of the problem. The Business Process Reengineering(BPR) framework was used to analyze the problems in the process management practices. While the concepts underlying BPR may not be the most suitable from the perspective of process management, it was the most feasible option available at the time of this study. With regard to the worldview of service management, a comparison was made to explain any differences between existing goods-dominant logic and newly emerging service-dominant logic. After that an in-depth discussion was made to explain why goods-dominant logic on services is no longer workable and why service-dominant logic is needed for successful informatization of public administration. The study explained how service-dominant logic with a new worldview can be projected in the administration and its information systems. The necessity of applying the concept of process as a means to convert abstractions of service-dominant logic into practices was also discussed. An information system-based administrative process innovation model(X-LERD) as an effective solution to the causes of the identified problems was presented, and the core ideas behind it were discussed. It is the core idea of X-LERD that the performance of administrative process can be significantly improved simply by applying information systems without its physical reorganization, and, extending the process to include people as its important part as suggested by the service-dominant logic. The study therefore gives a detailed explanation about why the process extension should inevitably include people as a key component in the administrative process, together with its accompanying process transformations like logical integration, enhancing, reverse flow, and decomposition. The benefits of each type of process transformation were conceptually discussed as well. Finally, the validity of the administrative process innovation model(X-LERD) which was the core framework used for this study, was explored. A few of the typical real-world cases were selected to explain how and where, the ideas of X-LERD are being applied. An analysis was then made to assess the magnitude of X-LERD`s contributions and implications to process improvement in two dimensions: increase in information processing capacity and reduction of information processing demand are discussed.",
		"KEYWORD": "행정프로세스"
	},
	{
		"ID": 901,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "Technique for concurrent processing graph structure and transaction using topic maps and cassandra =토픽맵과 카산드라를 이용한 그래프 구조와 트랜잭션 동시 처리 기법 ",
		"AUTHOR": "JaehyunShin",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 902,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "Selective regulation of epithelial-mesenchymal transition (EMT) using micro-RNAs in breast disease ",
		"AUTHOR": "Min-JiKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 903,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "전주대학교 대학원",
		"TITLE": "Big data mining and validation study of microRNAs as a potential target for colon cancer prevention ",
		"AUTHOR": "Jin-WookKang",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 904,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "충남대학교 대학원",
		"TITLE": "Real-time multicasting for multiple sensors and actuators in internet of things =사물 인터넷에서 다수의 센서와 구동기를 위한 실시간 멀티캐스트 프로토콜 ",
		"AUTHOR": "HosungPark",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 905,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "홍익대학교 산업미술대학원",
		"TITLE": "수용자 개인적 특성에 따른 정보격차와 인포그래픽 이해도에 관한 연구 :(A)study on understanding of infographic and digital divide according to user`s individual features :공공 인포그래픽을 중심으로 =around public infographic ",
		"AUTHOR": "이경은",
		"REGION": "서울",
		"PROFESSOR": "국ㆍ영문초록 수록 부록 :1, 설문지. 지도교수:최광 참고문헌 (p.111-114) 포함",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "정보가 기하급수적으로 증가하는 빅데이터 시대가 도래하고 정부 3.0이 등장하면서 공공정보 공개의 필요성이 대두하였다. 그러나 정보 매체에 접근하기 어렵거나 이용할 수 없는 정보 취약계층은 자연히 정보사회에서 낙오될 수밖에 없다. 정보의 접근성을 높이기 위해 단순히 디지털 미디어를 보급하는 양적인 접근보다는 정보의 질적인 접근이 필요하다. 최근 정부에서는 공공정보를 공개하고 전달하는 수단으로 인포그래픽을 주목하고 있다. 이에 본 연구에서는 정보를 시각화하는 인포그래픽을 통해 정부가 정책을 전달하는 과정에서 나타나는 정보격차를 극복하고, 국민 누구나 쉽게 공공정보를 이해할 수 있는 방안을 모색하고자 연구를 시작하였다. 이를 위한 연구문제는 다음과 같다. 첫째, 수용자의 개인적 특성인 성별, 연령별, 사회 · 경제적 지위에 따라 정보격차는 있을 것인가? 둘째, 수용자의 개인적 특성에 따라 인포그래픽에 대한 이해도에 차이가 있을 것인가? 2차 자료 조사로는 문헌과 인터넷을 통해 인포그래픽, 정보격차 관련 이론과 사례를 조사하였다. 1차 자료 조사인 실증 연구에서는 수용자의 개인적 특성을 성별, 연령별, 사회 · 경제적 지위별로 분류한 뒤, 공공 인포그래픽을 선별하여 온 · 오프라인 설문조사를 통해 정보격차와 인포그래픽 이해도를 측정하였다. 연구 샘플은 중앙선거관리위원회에서 발행한 투표절차에 관한 공공 인포그래픽으로 선정하였다. 조사 대상은 서울 · 경기 지역의 일반 성인남녀 270명을 대상으로 17세에서 50대 이상까지 성별, 연령별, 사회 · 경제적 지위별 표본구성을 하였다. 그 중 247명의 유효한 응답을 바탕으로 결과를 추출하였다. 설문조사의 연구 결과 첫째, 성별에 따른 정보격차는 접근격차, 활용격차, 수용격차 모두 차이를 보이지 않았으며, 연령이 높을수록 정보격차가 크게 나타났다. 사회 · 경제적 지위를 판단하기 위하여 학력, 직업, 직급, 소득을 변인으로 채택하였다. 사회 · 경제적 지위는 학력이 낮을수록, 직업의 사회적 지위가 낮을수록, 소득이 낮을수록 정보격차가 크게 나타났다. 반면에 직급의 분류는 무의미한 결과가 도출되었다. 둘째, 정보격차와 마찬가지로 성별에 따른 인포그래픽 이해도의 차이는 유의미한 차이를 보이지 않았다. 연령이 낮을수록 인포그래픽 이해도의 차이가 높게 나타났다. 사회 · 경제적 지위에 따른 이해도의 차이는 학력이 높을수록, 직업의 사회적 지위가 높을수록 이해도가 높게 나타났다. 반면에 소득에 따른 인포그래픽 이해도는 차이를 보이지 않았다. 이 같은 조사결과는 본 연구의 가설과 일치하였으며, 정보격차 이론을 증명하고 있다. 인포그래픽이 세대와 학력, 사회적 지위를 막론하고 공통 시각 언어로써 정보를 전달하고 이해하기 쉽게 직관적으로 표현하는 수단이라는 것이 본 연구를 통해서 다시 한번 검증되었다. 인포그래픽은 시각적으로 정보를 쉽고 빠르게 이해할 수 있기 때문에 정보 취약계층도 정보를 받아들이는 데 있어서 텍스트 정보보다 공유와 소통이 쉬울 것이다. 앞으로 인포그래픽의 공유와 소통, 시각 언어적 특성을 공공정보에 맞게 보완하여 정부의 정책에 모든 국민이 공감할 수 있는 새로운 대안 매체가 되기를 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 906,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "메이크업 시뮬레이션 서비스 시스템의 개발과 이용자 만족도 =(A)study on the development of a make up simulation service system and user satisfaction ",
		"AUTHOR": "송연비",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박명희",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "사회적 성취감과 경제력 향상, 자기계발 등으로 여성의 사회적 진출이 높아지고 자연스럽게 메이크업에 대한 관심과 활용이 가속화되는 상황에서 여성들이 빠르고 편리하게 완성도가 높은 메이크업 서비스를 이용하고자 하는 것은 자명한 추세이다. 그러나 메이크업 아티스트들의 부족에 비해 고객의 요구가 커지고 있어 이에 대한 대책으로 메이크업 서비스가 중요하다고 인지하였다. 국내에서 진행되고 있는 메이크업 서비스과정을 살펴 본 결과 고객니즈 파악을 위한 도구로 인쇄물형태가 있었으나 실재 현장에서 사용하지 않고 있음이 파악 되었다. 메이크업 전에 고객의 니즈 사항을 번거로운 인쇄물보다는 메이크업시술자인 메이크업 아티스트와 원하는 메이크업의 결과물을 얻기 위한 쉽고, 빠르며 재미를 주는 메이크업 서비스가 필요하였다. 메이크업 서비스에 체험마케팅과 C. R. M(Customer Relationship Management:고객관계관리)마케팅을 연계한 메이크업 시뮬레이션 시스템을 개발하여 I. M. R(Individual Make-up Recipe)서비스라 명명하고 빅 데이터 활용 및 시스템 이용자의 만족도를 살펴보기 위하여 본 연구를 진행 하였다. 메이크업 시뮬레이션 서비스 시스템은 IT에 기반을 두어 국내 화장품 브랜드의 제품 특성을 반영해 개발하고자 하였고, 이를 위해 고객과 시술자인 메이크업 아티스트를 대상으로 사전 수요도 조사를 실시하였다. 메이크업 시뮬레이션 시스템 개발에는 국내 각 업체의 메이크업과 서비스 차트를 참고 하였고, 태블릿 PC를 통한 시뮬레이션으로 완성하여 고객 접근성을 대폭 높였다. 메이크업 시뮬레이션 서비스 시스템을 개발하여 시범 운영 후 이의 이용자를 고객과 시술자인 메이크업 아티스트로 나누어 시스템 만족도를 분석 하였다. 이용자 만족도는 설문조사를 통해 진행 하였으며 결과는 다음과 같다. 첫째, 메이크업 시뮬레이션 체험 서비스인 I. M. R(Individual Make-up Recipe) 시스템을 구축하여 이용자의 시스템에 대한 니즈 파악 및 만족도를 파악할 수 있었다. 연구대상자 중 고객에서 실재 메이크업 시술을 받은 사람은 20대와 30대가 주대상자로 젊은 층의 체험 마케팅 참여가 매우 높았다. 고객이 시뮬레이션 시스템 이용 후 가장 만족한 사항은 5점 척도 중 ‘메이크업 시술 전 원하는 스타일을 아티스트에게 보여줄 수 있는 점’ 4.34로 가장 높았고, 시스템에 대한 고객 흥미도는 평균 4.19이며 시스템 만족도는 평균 4.25로 흥미도보다 만족도가 높게 나타났다. 시뮬레이션 시스템의 이용 전에 느끼는 고객 기대감이 고객 만족도에 영향을 미쳤고, 고객 흥미도가 평균보다 높은 그룹과 낮은 그룹 간에도 고객 만족도에 유의한 결과로 나타났다. 둘째, 시뮬레이션 시스템 이용 후 시술자인 메이크업 아티스트의 만족도는 고객 만족도가 높을수록 메이크업 아티스트의 만족도도 높게 나타났으며, 특히 고객 흥미도에 따라 메이크업 아티스트 만족도가 크게 영향을 받는 것으로 분석 되었다. 메이크업 아티스트의 시스템 만족도는 5점 척도 중 평균 4.24로 고객 만족도 평균 4.25와 유사한 수준의 만족도를 보였다. 메이크업 아티스트가 가장 만족한 세부 항목은 ‘메이크업에 대한 고객 니즈를 파악할 수 있는 점’과 ‘메이크업의 다양한 이미지를 간접 경험함’ 순으로 높게 나왔고, 고객이 가장 만족한 ‘메이크업 시술 전 원하는 스타일을 아티스트에게 보여줄 수 있는 점’과 비교할 때에 고객과 메이크업 아티스트 그룹 모두 양자 간의 적극적인 커뮤니케이션에 가장 만족하는 것으로 분석할 수 있다. 셋째, 시스템 이용 고객의 제품 구매 행태에 대한 분석에서 제품 구매도는 높게 나타났으며, 구매액은 ‘2-3만원’대가 높게 나타났다. 고객의 메이크업 선호에는 ‘메이크업을 배우기 위해’로 가장 높은 답변으로 나타났고, 고객이 좋아하는 메이크업 이미지는 ‘내추럴 & 투명 메이크업’, 선호하는 컬러는 ‘브라운 & 오렌지’로 나타나 전반적으로 자연스럽고 편안한 메이크업을 선호하는 것으로 나타났다. 향후, 고객과 메이크업 아티스트와의 감성 친화적 양방향 커뮤니케이션 효율도를 높일 뿐만 아니라 커뮤니케이션 활용부분에 있어, 고객의 니즈와 트렌드 파악을 통한 메이크업 서비스의 균질화와 정량화한 빅데이터를 실현시킬 수 있다. 이에 본 논문은 다국어 서비스를 통한 국가 간? 지역 간? 편차를 극복한 마케팅 전략을 세우고 신제품 개발 등에 활용하여 글로벌한 경쟁력을 높이는데 기여할 수 있다. 넷째, 축적된 데이터를 통한 국가별, 인종별, 시기별, 선호 이미지별 마케팅 전략을 세우고 신제품 개발 등에 활용하여 고객 만족도를 높일 수 있고, 메이크업 니즈와 트렌드 파악 및 빅 데이터를 통한 자료의 정량적 활용과 감성 친화적 양방향 커뮤니케이션 모델로 성장할 수 있는 점이 본 시스템 개발의 의의라 할 수 있다.",
		"KEYWORD": "가상현실 체험,고객 선호 컬러,고객선호 메이크업,메이크업 서비스,메이크업 시뮬레이션 시스템"
	},
	{
		"ID": 907,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "상명대학교 대학원",
		"TITLE": "대학도서관 업무의 시대별 변천에 따른 특성 연구 =(A)study on the characteristics of jobs in academic libraries according to different generations ",
		"AUTHOR": "조철현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 노동조",
		"STORE_LOCATION": "상명대학교 서울캠퍼스 도서관,상명대학교 천안학술정보관",
		"ABSTRACT": "본 연구는 웹의 진화에 따른 도서관의 대응을 도서관1.0, 도서관2.0, 도서관3.0으로 시대 구분하여 대학도서관 업무의 변화를 알아보고, 나아가 시대별 변화에 따른 업무의 특성을 제시하고자 하였다. 이를 위한 연구방법 및 자료수집은 3단계로 진행하였다. 1단계는 대학도서관 시대구분과 직무분석 관련 문헌을 분석하였고, 2단계는 대학도서관 업무모형을 도출하기 위하여 국내 및 미국 대학도서관 직무분석을 실시하였으며, 3단계는 대학도서관 전문가 집단을 대상으로 델파이 조사를 실시하여 대학도서관 시대별 업무모형 개발 및 직무의 특성을 분석하였다. 델파이 조사는 3차례에 걸쳐 실시하였으며, 제1차 델파이 조사는 대학도서관 전문가 30명을 대상으로 이루어졌다. 제2차 델파이 조사는 제1차 델파이 조사 응답자인 25명을 대상으로 실시하여 대학도서관의 시대별 업무를 도출하였다. 제3차 델파이 조사는 제2차 델파이 조사에 응답한 25명을 대상으로 실시하여 대학도서관의 시대별 업무 특성을 측정하였으며, 통계 검증을 위하여 SAS Ver 9.3으로 대응 t-검정을 실시하였다. 본 연구의 결과를 요약하면 다음과 같다. 첫째, 대학도서관 업무를 직무영역별로 크게 경영관리, 장서개발 및 관리, 자료조직, 이용서비스, 정보시스템 구축 및 관리의 5개로 구분하였으며, 도서관1.0 시대에서 시작하여 도서관3.0 시대로 계속 이어지는 업무 169개, 도서관2.0 시대에서 시작하여 도서관3.0 시대로 이어지는 업무 58개, 도서관1.0 시대에서 시작하여 도서관2.0 시대로 이어지는 업무 3개, 도서관1.0 시대에만 존재한 업무 3개, 도서관2.0 시대에만 존재한 업무 1개, 도서관3.0 시대에 새로이 생성된 업무 25개 등으로 도서관 시대에 따라 변화가 있는 것으로 나타났다. 특히, 도서관1.0 시대에서 시작하여 도서관3.0 시대로 계속 이어지는 업무는 대학도서관의 기본적인 업무로 판단된다. 둘째, 도서관3.0 시대에 새로이 생성된 업무는 1)경영관리의 경우, 경영혁신, 이용자 참여 계획 등 총 6개 업무이고, 2)장서개발 및 관리는 디지털 자원에 대한 장서 개발정책 수립, 지역사회 요구분석 등 총 8개 업무이며, 3)자료조직은 전자자료 오리지널 편목, 전자자료 카피 편목 등 총 3개 업무로 나타났고, 4)이용서비스는 서비스자문위원회 운영, 원거리이용자서비스 지원 기획 등 총 6개 업무이며, 마지막으로 5)정보시스템 구축 및 관리는 각종 전산기기 통합관리, 각종 애플리케이션 개발 및 관리의 총 2개로 나타났다. 이러한 도서관3.0 시대에 생성된 업무는 향후 대학도서관 업무를 예측하는 중요한 역할을 한다. 셋째, 5개 직무영역의 세부적인 부분을 포괄하는 전체적인 특성을 살펴보면, 먼저 경영관리의 경우, 중요도, 난이도, 빈도 모두가 시대별로 유의미하게 상승하는 것으로 나타났다. 이러한 원인은, 도서관1.0 시대에는 경영관리 방식이 일방적 하향식이었고, 도서관2.0 시대에는 양방향 의사소통 구조로 상향식 체제가 도입되었으며, 도서관3.0 시대에는 정보통신 기술 변화에 대응하며, 빅 테이터를 활용한 경영관리가 도입되기 때문이다. 다음으로 장서개발 및 관리의 경우, 중요도, 난이도, 빈도 모두가 도서관2.0 시대에서 도서관3.0 시대로만 유의미하게 상승하는 것으로 나타났다. 이러한 원인은, 도서관 1.0 시대에는 자관 중심의 일방적인 장서 개발이 이루어졌고, 도서관2.0 시대에는 전자자료, 오픈 액세스 콘텐츠 자료 개발이 이루어졌으며, 도서관3.0 시대에는 특성화된 자료 구성, 웹사이트 콘텐츠 자료 개발이 필요하기 때문이다. 이어서 자료조직의 경우, 중요도는 도서관1.0 시대에서 도서관2.0 시대로 유의미하게 하락하고, 빈도는 시대별로 유의미하게 하락하며, 난이도는 시대별로 유의미한 변화가 없는 것으로 나타났다. 이러한 원인은, 도서관1.0 시대에는 자관의 특성에 맞는 자료조직 체계를 운영하였고, 도서관2.0 시대에는 자료조직 업무의 아웃소싱이 진행되었으며, 도서관3.0 시대에는 FRBR 개념의 RDA 적용으로 전문가 수준의 사서가 필요하지만 업무의 아웃소싱 등으로 도서관2.0 시대와 구체적인 변화가 없기 때문이다. 그리고 이용서비스의 경우, 중요도는 시대별로 유의미하게 상승하며, 난이도는 도서관1.0 시대에서 도서관2.0 시대로만 유의미하게 상승하는 것으로 나타났다. 빈도는 시대별로 유의미하게 변화하지 않는 것으로 나타났다. 이러한 이유는 도서관1.0 시대의 경우, 소장자료를 중심으로 이용자에게 서비스를 제공하였고, 도서관2.0 시대는 학문 분야별 주제전문서비스 및 전자정보 자료 교육 등이 도입되었으며, 도서관3.0 시대는 이용자와 항상 연결을 유지하는 시스템을 개발하여 이용자가 시스템에서 즉석으로 도움을 받을 수 있어야 하기 때문이다. 마지막으로 정보시스템 구축 및 관리의 경우, 중요도 및 빈도는 시대별로 유의미하게 상승하며, 난이도는 시대별로 유의미하게 변화하지 않는 것으로 나타났다. 이러한 이유는, 도서관1.0 시대에는 클라이언트/서버 형태의 자관 독자적인 정보시스템을 구축하였고, 도서관2.0 시대에는 정보통신 기술을 기반으로 양방향 소통 시스템이 구축되었으며, 도서관3.0 시대에는 스마트 기기 이용 극대화, LOD 정보시스템, 기계와 사람이 소통하는 시스템 등이 이루어지기 때문이다. 본 연구의 결과로 도서관 3.0 시대를 맞이하여 대학도서관에서 대비 및 준비해야 할 사항을 제언하면, 첫째, 경영관리의 경우, 도서관 운영에 있어 이용자 참여 확대를 강화해야 하며, 특히 국내외 타 도서관 변화를 지속적으로 파악해야 한다. 둘째, 장서개발 및 관리의 경우, 오픈 액세스, 빅 테이터를 활용한 장서 개발 등이 될 수 있는 사서의 자질이 요구된다. 특히 자료 소장공간을 해결하기 위하여 대학도서관 간 공동자료 소장공간을 마련해야 한다. 셋째, 자료조직의 경우, FRBR 개념의 RDA를 적용할 수 있는 자료조직 시스템 도입을 위한 제도를 마련해야 한다. 넷째, 이용서비스의 경우, 도서관과 이용자 간에 상시 연결을 유지할 수 있는 시스템이 개발되어야 하며, 이용교육은 개인별 맞춤 교육 형태로 이루어져야 한다. 다섯째, 정보시스템 구축 및 활용의 경우, 스마트 기기 이용 극대화 및 기계와 사람이 소통하는 지능적이고 스마트한 도서관 시스템을 구현해야 하고, 사서와 시스템 전문가 간에 긴밀한 협업이 이루어져야 하며, 지속적으로 최신의 기술을 도서관 시스템에 도입하여야 한다.",
		"KEYWORD": null
	},
	{
		"ID": 908,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "유아용품 시장의 소비가치에 관한 기호학적 연구 ",
		"AUTHOR": "염동윤",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:백승국 참고문헌 : p.124-133",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "유아용품 시장은 다른 제품들과는 달리 실제로 사용하는 유아들을 대신하여 실질적인 구매행위를 부모가 담당한다. 유아용품을 기획하고 마케팅하기 위해서는 제품을 실제로 사용하는 유아의 선호나 유아의 정신적, 육체적 성장에 대한 고려도 필요하지만, 실질적인 소비를 수행하는 부모에 대한 분석이 필수적이다. 그런데도 유아용품에 대한 국내 연구들의 경우 부모와 부모의 소비가치에 관한 연구가 미비한 수준이었다. 국내 유아용품 시장은 저출산으로 인해 인구가 감소했지만, 시장 전체적으로는 양적인 성장이 이뤄지고 있다. 자녀의 수가 적어진 대신 한 명의 아이에 더욱 적극적으로 투자하는 부모들이 등장하였기 때문이다. 유아용품 시장의 변화와 성장에 맞춘 제품 기획 및 마케팅 방식을 수립하기 위해서는 유아용품을 둘러싼 소비가치를 파악해야 하며, 이중 구매행위에 직접 연관되는 부모의 소비가치를 파악하는 것은 매우 중요하다. 본 연구에서는 유아용품 시장의 미디어 담론 변화를 분석하여 유아용품 시장에서 부모의 소비가치를 파악해 보고자 하였다. 이를 위해 유아용품 시장을 구성하는 다양한 제품군들을 3가지로 분류하고, 대표성을 지니는 유아 가구, 가족캠핑용품, 유아 전동차의 세 가지 사례를 꼽아 집중적으로 분석하였다. 2000년부터 2016년에 걸쳐 진행된 유아 가구, 가족캠핑용품, 유아 전동차에 대한 대중매체의 보도기사를 근거이론과 그레마스의 서사 기호학 분석 방법론을 이용하여 분석하였다. 실용적, 합리적 소비가치와 특별함을 추구하는 프리미엄 가치의 대립이 반복되는 가운데, 유아 가구, 가족캠핑 용품, 유아 전동차 시장에 등장한 프랜디의 개념은 현시점에서 핵심적인 역할을 수행한다. 그러나 본 연구에서는 프랜디 개념 자체가 하나의 핵심적인 소비가치가 될 수는 없을 것으로 분석되었다. 향후 유아용품 시장에서는 프랜디의 개념보다 유아용품 제품 자체의 속성과 실용성, 합리적 소비를 강조하는 미니멀리즘적 소비형태가 핵심적 소비가치로 부상하리라 판단하였다. 본 연구는 유아용품 시장의 미디어 담론에 집중해 소비시장 전체적 소비가치를 탐구하는데 집중하여, 개별적 소비자들의 반응에 대한 분석이 이뤄지지 못한 한계점이 존재한다. 그러나 본 연구에서 시도한 유아용품 시장에서 부모의 소비가치에 대한 분석은 향후 유아용품 시장에 관한 기획 및 마케팅 연구에서의 외연적 범위를 확장하는데 의미가 있을 것이다. 또한 본 연구에서 사용한 근거이론과 서사 기호학 방법론을 이용한 접근방식이 빅데이터를 인문학적인 방법론으로 활용하고, 해석할 수 있는 실마리가 되기를 바란다.",
		"KEYWORD": "가족캠핑용품,근거이론,기호 사각형,미니멀리즘,미디어 담론,서사 기호학,소비가치,유아 가구,유아 전동차,유아용품 시장,프랜디,프리미엄"
	},
	{
		"ID": 909,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "국민대학교 디자인대학원",
		"TITLE": "뉴실버세대의 웰니스 라이프스타일을 위한 웨어러블 디바이스 UX Design :(A)study on wearable devices UX design for the wellness-lifestyle of new silver generation :스마트워치의 헬스 케어 서비스를 중심으로 =focusing on the smart-watch health care service ",
		"AUTHOR": "김지혜",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 장중식 참고문헌: p. 89-91",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 910,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "SNS 해시태그 사용 :SNS hashtag tracking :글로벌 패션브랜드의 인스타그램 사례분석을 중심으로 =global fashion brands` use of Instagram ",
		"AUTHOR": "이윤아",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이규혜 권두 국문요지, 권말 Abstract 수록 부록 수록 참고문헌: p. 59-65",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "이미지 기반 SNS인 인스타그램의 가입자 수가 급증하면서 많은 기업과 브랜드에서 인스타그램의 해시태그 기능에 주목하며 다양한 인스타그램 마케팅을 실시하고 있다. 특히 해시태그는 최신 트렌드와 이슈, 소비자들의 관심사 등을 쉽게 파악할 수 있게 하며, SNS 사용자들은 자신의 패션스타일, 일상 또는 관심사를 공유하는 과정에서 해시태그를 통해 해당 제품의 이름 또는 브랜드를 언급하게 된다. 즉, 기업이나 브랜드에서 직접적인 마케팅을 진행하지 않더라도 SNS 사용자들의 해시태그 사용에 따라 간접적으로 기업이나 브랜드 또는 제품을 자연스럽게 노출시킬 수도 있는 것이다. 이에 본 연구에서는 인스타그램에서 패션브랜드의 브랜드해시태그(#브랜드명)의 이용현황에 대해 알아보았다. 첫째, 브랜드해시태그가 사용된 총 게시물의 수에 대해 알아보고 게시물의 좋아요 수와 사용자의 팔로워 수 사이의 상관관계, 그리고 팔로워 수에 따른 평균 좋아요 수에 대해 알아보았다. 둘째, 사용자의 성별, 브랜드해시태그가 사용된 지역(나라)과 날짜에 따른 브랜드해시태그의 이용현황에 대해 알아보았다. 즉, 브랜드해시태그 별로 조사기간 중의 브랜드해시태그가 포함된 총 게시물의 수를 분석하여 사용자의 특성에 따른 이용의 차이를 알아보았으며, 특정 이슈가 있는 날짜에 브랜드해시태그 이용의 변화가 있는지 알아보았다. 셋째, 브랜드해시태그가 사용된 게시물에 함께 사용된 연관 해시태그에 대해 알아보았고, 브랜드자산의 요소에 따라 분류하여 각 브랜드의 자산가치에 대해 알아보았다. 연구의 실증적 분석을 위해 Assetize 사의 유료 Hashtag Tracking 프로그램인 Keyhole을 사용하여 브랜드해시태그에 대한 빅데이터 자료를 수집하였다. 해당 프로그램을 이용하여 조사기간 중의 브랜드해시태그를 포함한 총 게시물의 수, 날짜와 시간대별 브랜드해시태그 포함 게시물의 수, 남녀 사용자별 브랜드해시태그 포함 게시물 수, 국가별 브랜드해시태그 포함 게시물 수, 브랜드해시태그를 포함하여 게시물을 올린 사용자들 중 파워유저들(influencer)의 팔로워 수와 그들이 올린 게시물의 좋아요 수, 조사대상 브랜드해시태그와 함께 게시물에 가장 자주 사용된 연관 해시태그 등의 자료를 수집하였다. 수집된 자료를 바탕으로 분석에는 기술적 분석과 통계분석을 실시하였으며, MAC용 스프레드시트 프로그램인 Numbers를 활용하여 이용현황에 대해 분석하였고 통계 프로그램인 SPSS Statistics 22.0을 활용하여 상관관계분석을 하였다. 위와 같은 분석을 통해 얻은 결과를 요약하면 다음과 같다. 첫째, 브랜드해시태가 포함된 게시물의 좋아요 수와 해당 게시물을 업로드한 사용자의 팔로워 수 사이에 유의한 상관관계가 있었다. 둘째, 브랜드에 따라 브랜드해시태그 이용에 남녀의 차이가 있었으며, 사용자들의 관여도가 더 높은 브랜드군에서 브랜드해시태그 사용의 빈도가 더 높게 나타났다. 스포츠브랜드의 경우에만 남성 사용자의 비율이 높게 나타났으며, 이는 성별에 따른 의복관여도에 따라 브랜드해시태그의 사용에 차이가 있음을 보여준다. 셋째, 국가별로 브랜드 선호도에 따라 브랜드해시태그의 사용에도 차이가 있는지 알아 본 결과, 매장 수 또는 브랜드 선호도에 따라 브랜드해시태그의 빈도에 차이가 있었다. 넷째, 일부 브랜드군에서 날짜별 이용현황에 차이가 나타났다. 스포츠브랜드 군의 경우에는 브랜드해시태그 사용빈도에 차이가 거의 없었던 반면, SPA브랜드군 중 H&M의 경우 럭셔리브랜드와의 콜라보레이션 컬렉션 런칭 및 발매일에 브랜드해시태그 사용이 급증하였고 이를 통해 브랜드해시태그가 구전효과가 있음을 알 수 있었다. 또한, 럭셔리브랜드군의 경우는 사회적인 이슈에 영향을 많이 받는 것으로 나타났으며, 러시아 여객기 폭파, 파리테러가 있었던 시기에 브랜드해시태그의 사용이 감소하였다. 다섯째, 브랜드해시태그와 함께 게시물에 사용된 연관 해시태그를 통해 브랜드이미지를 파악할 수 있었으며, 브랜드자산 요소에 따른 분류를 통해 각 브랜드들의 브랜드자산가치를 파악할 수 있었다. 이상의 결과를 통해 인스타그램에서 브랜드해시태그의 사용은 사용자의 브랜드 선호도 또는 의복관여도에 따라 차이가 있으며, 브랜드해시태그를 통해 브랜드이미지 파악이 가능하다는 것을 알 수 있었다. 본 연구는 인스타그램에서의 패션브랜드 해시태그 이용현황에 대해 알아보았으며, 사용자들의 특성이나 브랜드선호도, 또는 사회적인 이슈 등에 따른 해시태그 사용의 차이와 브랜드이미지에 대해 알 수 있었다. 본 연구는 사용자들의 특성에 따른 브랜드해시태그 이용현황을 통해 기업이나 브랜드에서 해시태그를 마케팅의 도구로 활용할 때의 타겟 소비자 또는 마케팅 방법을 구축하는 데에 기초적인 자료를 제시한다. 또한, 브랜드해시태그의 구전효과 및 마케팅 효과에 대한 다양한 시사점을 제공한다.",
		"KEYWORD": "마케팅"
	},
	{
		"ID": 911,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "PPGIS를 이용한 주민참여형 도시 유산관광 정보체계 구축 :Establishment of urban heritage tourism information system using public participation GIS :서울시 종로구 세종마을을 대상으로 =focused on the Sejong village in Seoul city ",
		"AUTHOR": "김학중",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김남조",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 관광의 지속가능성을 위해 주민참여가 강조되고 있다. 본 연구는 서울시 종로구 세종마을을 대상으로 선정하여, 유산자원을 보전?활용할 수 있는 ‘유산관광’과 ‘주민참여형 관광’의 중요성을 논하였다. 또한 그 구체적인 실행방안으로 PPGIS를 적용하고자 했다. PPGIS(Public Participatory Geography Information System)는 대상지역 이해관계자들의 참여를 유도할 수 있는 방안으로, 누구나 정보를 입력하고 공유할 수 있는 특징이 있다. 최근 정보통신기술 발달 및 스마트폰 대중화로 언제 어디서나 인터넷 사용이 가능해지면서 그 활용가능성은 더욱 증가하고 있다. 이미 여러 분야에서 활용되고 있으며, 관광분야의 연구가 필요한 시점이다. 본 연구에서는 관련 문헌과 SNS 빅 데이터 분석 결과를 매핑하여 PPGIS 정보체계를 구축하였다. 다음, 이해관계자 인터뷰를 실시하여 그 가능성을 논하였다. PPGIS 정보체계는 다양한 관광정보를 표현할 수 있으며, 실제 관광활동에도 유용하게 쓰일 것이란 결과를 얻을 수 있었다. 단, 정보의 품질 및 신뢰성이 보장되고 인식이 확대되어야 그 가치를 발휘할 수 있을 것이다. 본 연구는 최근 주목받고 있는 SNS 기반의 PPGIS 정보체계 구축을 통해 공공참여의 중요성을 강조하였으며, 관광분야에 활용하고자 한 선구적 연구로 의의를 지니고 있다.",
		"KEYWORD": "PPGIS,관광정보체계,유산관광,주민참여"
	},
	{
		"ID": 912,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "개인신용정보 제도에 관한 법적 연구 =(A)legal study on personal credit information system ",
		"AUTHOR": "이정민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 高東源 참고문헌: p. 138-146",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "개인신용정보 유출사태가 지속적으로 발생하면서 개인신용정보가 다양한 방법으로 불법 사용되고 있고 이로 인해 개인의 정신적 피해 및 금전적 손해가 증가하고 있다. 개인신용정보는 「신용정보의 이용 및 보호에 관한 법률」뿐만 아니라 「개인정보보호법」, 「정보통신망 이용촉진 및 정보보호 등에 관한 법률」, 「위치정보의 보호 및 이용 등에 관한 법률」, 「전자금융거래법」 및 「전자서명법」 등 다양한 법률에 그 내용이 관련되어 중첩되는 부분들이 많고 소관 부처가 다양하여 통합적인 대책이 어려운 상황이다. 이번 연구를 통해서 현재 금융기관 사이에 가장 큰 화제로 부각 받고 있는 개인신용정보에 대하여 의의와 법제 소개 등을 통해 문제점을 살피고, 개인신용정보 법제 정부개정안에 관련된 논의도 다루어 개인신용정보 법제의 해결방안을 연구하고자 한다. 현재 개인신용정보는 많은 언론에서도 큰 관심거리로 작용하고 있기 때문에 개인신용정보 관련 기사들을 통해서 개인신용정보의 유출상황과 논의 상황을 제시한다. 또한 각 법률에서 제시하는 개인신용정보의 의미를 구분하고 「신용정보의 이용 및 보호에 관한 법률」에 초점을 맞추어 유관 법률에 개인신용정보 법제 내용을 소개할 것이다. 또한 외국의 개인신용정보법제가 어떻게 운영되고 관리되고 있는지를 분석하여 국내의 개인신용정보법제와 비교하여 문제점을 검토하고 개선방향을 모색하고자 한다. 개인신용정보는 신용도에 관련된 정보뿐만 아니라 개인식별정보를 포함하고 있기 때문에 다중 적용될 수 있는 법들이 존재한다. 그러나 상충되는 규정들을 단일화하는 것은 매우 어렵기 때문에 현 정부개정안처럼 신용정보법제가 이 법률들보다 우선적용될 수 있는 특별법으로서의 지위가 되어야 한다. 나아가 가공정보 등 추가적으로 개인신용정보가 될 수 있는 부분들을 포함하여 보다 폭넓게 개인신용정보의 범위를 정할 필요가 있다. 또한 하나의 종합신용정보집중기관을 설립하는 것보다는 신용정보집중기관 내에 독자적인 신용정보관리위원회를 설치하여 취급정보의 최소화나 신용정보회사로의 정보제공 제한 등을 통해 공적 기능을 단계적으로 강화해야할 것이다. 마지막으로 금융회사들이 신용정보 제공·이용에 대한 책임을 갖도록 법적인 제재 조치가 마련되어야할 것이다. 현 정부개정안처럼 과징금, 과태료 및 징벌적 손해배상 체제를 넘어 신용정보법제에 한하여 집단소송을 수행할 수 있도록 하고 자진신고제 혹은 모범 금융기업 인증제도를 도입하여 자율규제 환경을 조성해나갈 필요가 있다. 추가적으로 수범자들의 법 인지수준을 신장시키기 위해 ‘개인신용정보 지침’을 만드는 것이 부차적인 대안이라고 생각한다. 빅데이터 산업의 성장에 따라 빠르게 변화하는 정보환경 속에서 신용정보법이 특별법으로서 올바르게 유지될 수 있도록 정기적으로 입법영향을 분석·평가하여 환경에 대응할 수 있도록 해야한다. 주제어 : 개인신용정보, 신용정보관리위원회, 모범 금융기업 인증제도, 집단소송, 개인신용정보 지침",
		"KEYWORD": "개인신용정보"
	},
	{
		"ID": 913,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "한세대학교 대학원",
		"TITLE": "물리적 센서와 상태전이형 유동 프로파일을 이용한 이상징후 탐지 매커니즘의 설계 =(A)design for anomaly detection with finite automata dynamic profile ",
		"AUTHOR": "김진경",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 신승중",
		"STORE_LOCATION": "한세대학교 도서관",
		"ABSTRACT": "현재 육·해·공·우주를 넘어 제5의 영역이라 불리는 사이버공간 상에서 보이지 않는 치열한 전쟁이 일어나고 있다. 지난 3.20 금융기관 전산망 장애사태와 6.25 정부기관 해킹 사건에서 보듯이 사이버 공격은 개인, 기업의 피해를 넘어 심각한 사회문제로 대두되고 나아가 국가 간의 분쟁을 유발시키기도 한다. 따라서 사이버 공격의 이상징후에 대하여 최단시간에 탐지하고 대응하는 기술뿐만 아니라 사전에 인지할 수 있는 기술이 필요하다. 사이버 공격은 IT기술의 발전과 함께 나날이 지능화 되어가고 있어 이러한 이상징후를 탐지할 수 있는 기술의 고도화가 필요하다. 따라서 본 연구는 클라우드 및 빅데이터 등 다양한 환경에서 대용량 보안이벤트 수집·처리·분석과 장기간·이기종 보안이벤트 상관분석을 수행하였고, 악성코드 프로파일링 및 행위분석을 통해 악성코드를 신속하게 탐지할 수 있도록 하였다. 또한 물리적 오류 징후 상관분석, 공격특징 정보추출, 이벤트 상관분석 등을 통해 정확하고 신속한 악성코드 분석을 수행하였다. 그리고 기존의 보안장비인 방화벽, 침입탐지장비 등 물리적 센서들과 연계한 차별화된 메커니즘을 설계하여 사이버 공격의 이상징후를 파악, 사전에 악의적이고 무차별적인 사이버 공격에 대응할 수 있도록 하였다.",
		"KEYWORD": "물리적센서,상태전이,오토마타,유동프로파일,이상징후"
	},
	{
		"ID": 914,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울시립대학교 도시과학대학원",
		"TITLE": "소방성능 향상을 위한 자동제어 적용방안에 관한 연구 =A study on the application of automatic control for improving firefighting performance ",
		"AUTHOR": "박나미",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤명오",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "It is difficult to start and suppress fires of loft buildings which increase in the modern society and there are various constraint conditions in escaping from the fires. Accordingly, the reliability of fire extinguishing facilities and fire-prevention system is very important. The fire extinguishing facility is put into operation in an initial fire and the fire-prevention system is employed as the most important part in evacuation. Due to characteristics that such the fire extinguishing facilities are not used normally but used only in case of fire, consistent maintenance of a fire extinguishing facility normal state and a preparation plan in case the fire extinguishing facility fails to reach and perform a target function may be a touchstone that tests the reliability. When installing and managing the fire extinguishing facility, the reliability securing means that the fire extinguishing facility performs an optimized function corresponding to the current fire after a fire is early sensed, so that belongings and damage of human life can be minimized. According to the current fire system, a facility object is determined based on fire-extinguishing-related regulations and only minimum functions required by technique standard are secured and installed. Because of that, the reliability of the fire-extinguishing facility becomes very low in case of fire. If the operation of only one related-device or instrument fails, fire response is likely to become difficult. In case a skyscraper large architecture and a basement-connected building, which have a high fire risk, are used in a preset scale or more and for a specific purpose, facilities and functions proper to building characteristics are additionally provided to enhance fire-extinguishing performance based on performance based design confirmation & evaluation and disaster impact assessment for the reliability of fire-extinguishing facility. The facility added based on the performance based design is likely to have an aspect of an architecture owner’s cost increase and a problem of double installation with another field. Accordingly, safety is enhanced by linkage with other facilities or improving the performance of the fire-extinguishing facility. However, such a method is exclusively performed because of theoretical validity and technical verification. An automatic control method is very useful among methods configured to enhancing performance by improving such the reliability of the fire-extinguishing facility. The automatic control method reflects the changing stream of times of the fourth industrial revolution which processes information on various topics, using information communication technology development and intelligent IoT big data, and is able to be applied to the fire-extinguishing facilities. However, there are many limitations to apply the automatic control method to the fire-extinguishing facilities and field. The fire-extinguishing system lacks internal power for overcoming such limitations. The present thesis proposes the necessity of the automatic control based on a fire-extinguishing facility control status analysis and suggests foundation furtherance required to introduce the automatic control and policy-level plan by analyzing the current fire-extinguishing field environment. The automatic control foundation furtherance is promoted as a technical foundation for realizing the automatic control, following some plans. However, a main dispute is to apply the automatic control to a field and it is another matter in the current fire-extinguishing system. Accordingly, the present thesis suggests a policy for applying the automatic control to the current condition by analyzing the current fire-extinguishing system. The automatic control of the fire-extinguishing facility is performed by the automatic control foundation furtherance and the policy realization, so that the reliability of the fire-extinguishing facility may be secured and the paradigm of the changing society may be accepted. Accordingly, the fire-extinguishing industry is expected to be growing together with the other fields.",
		"KEYWORD": "성능점수제,성능정량화,소방설비제어,자동제어,화재대응결과보고서"
	},
	{
		"ID": 915,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "SPA매장 파사드 디자인의 브랜드 표현수단에 관한 연구 :(A)study on the brand representation using facade design of SPA fashion store :Joe Fresh 플래그십 스토어 디자인 =Joe Fresh flagship store design ",
		"AUTHOR": "백성주",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 우승현 참고문헌: 장 87-89",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "오늘날 생활하는 환경 어느 곳에서나 웹을 통한 구매와 결재가 가능해진 상업 환경에서 살고 있다. 이에 패션 브랜드는 빅데이터를 이용한 시장과 소비자에 대한 분석과 이해를 바탕으로 지속적인 발전을 거쳐 유형적, 무형적으로 브랜드의 영향력 안에서 생활 하고 있다. 브랜드는 기업과 소비자 간의 커뮤니케이션 방식으로 브랜드의 시각적 이미지를 도구로 삼고 있다. 소비자의 매장 내에 체류하는 시간을 연장시켜 이미지 또한 판매하는 개념이다. 기업은 소비자에게 브랜드의 이념과 이미지를 일체감을 조성하여 판매전략 뿐만 아니라 새로운 환경 여건을 반영한 매장을 선보이고 있다. 이에 발맞추어 단순히 상품을 판매하는 범위를 넘어선 글로벌 기업의 매장은 브랜드 정체성을 반영한 공간 마케팅으로 접근할 필요가 있다. 갈수록 심화되는 경기 침체 속에서 유행에 민감한 소비자는 저렴한 가격과 우수한 품질을 모두 요구하며 보다 합리적인 구매를 선택한다. 이러한 구매 환경에 맞춰 기업은 리테일의 유통부터 생산까지 책임지고 생산하는 SPA의 다른 판매 개념을 도입한다. 이에 본 연구는 세계 패션시장에서 입지를 굳히고 있는 SPA매장을 중심으로 소비자가 가장 먼저 경험하게 되는 매장의 파사드 디자인을 이용한 브랜드 표현이 브랜드 정체성 확립과 브랜드의 인지에 어떠한 영향을 미치고 매장의 디자인 마케팅 접근 방법에 대한 기반을 연구한다. 조사한 자료를 토대로 브랜드 고유의 디자인 철학이 없는 Joe Fresh 매장을 선택하여 설계 프로젝트를 진행하며 기존 브랜드를 변화하는 패션 시장에서 소비자에게 브랜드의 고유의 아이덴티티를 유지하며 환경에 맞춰 브랜드의 이미지와 가치를 극대화 할 수 있도록 계획한다. 위의 이론과 계획을 바탕으로 SPA브랜드의 매장 디자인의 완성도를 높이고 갈수록 치열해지는 패션 시장에서 경쟁력을 높일 수 있는 마케팅 전략의 수립에 토대가 될 것으로 기대된다.",
		"KEYWORD": null
	},
	{
		"ID": 916,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "금오공과대학교 대학원",
		"TITLE": "UWB 레이더 기술 기반의 비접촉 생체신호 검출 센서 개발을 통한 생체신호 및 수면환경 분석 시스템 개발에 관한 연구 ",
		"AUTHOR": "조중길",
		"REGION": "경상북도",
		"PROFESSOR": "지도교수: 이종환",
		"STORE_LOCATION": "금오공과대학교 도서관",
		"ABSTRACT": "최근 들어 모바일 기술 및 ICT 분야의 급속한 기술 발전, 다양하고 폭 넓은 기술간의 경계가 허물어져 상호 교류 가능한 디지털 융복합 기술의 혁명이 여러 산업 분야에서 활발히 개발되며 상용화되고 있다. 의료 분야에서도 소위 유헬스(U-health)라는 영역에 대한 새로운 개발 및 시도들이 활발하게 진행되고 있다. 최근에는 인구 노령화, 만성 퇴행성 질환 및 의료비 증가 등의 사회 환경 변화에 따라 ‘치료 중심의 의학’ 보다 ‘예방 중심의 의학’의 중요성이 부각되면서 개인이나 가정에서도 쉽게 인간의 건강 상태를 측정하여 적절한 건강 서비스를 제공 받는 형태의 서비스 요구가 증대하고 있다. 인간의 건강 관점에서 사람은 일생의 1/3을 수면 상태로 보내기에 수면의 품질은 일생에 있어서 매우 중요한 역할을 한다. 또한 수면 품질은 각종 안전사고의 원인이 되며, 정서장애, 사회적응 장애 및 생활의 불만족 및 만성 질환들을 유발하거나 악화시킬 수 있는 요인이기도 하다. 수면의 품질을 측정해서 정량화하여 개선하기 위한 기술이나 서비스는 현재 제공되어 있으나, 이 방식은 피험자 인체에 접촉식 센서를 부착하는 방식이며, 수면 클리닉을 갖춘 병원에서만 가능하다는 공간 제약성과 1회 진단 비용이 고가라는 단점이 있다. 또한, 생체 신호를 감지하기 위해 사용하는 센서는 신체 접촉식이기에 피험자에게 불쾌감 및 불편함을 유발하고 결국에는 수면의 품질 측정 데이터에 대한 부정확성을 야기할 수 도 있다는 문제가 있다. 본 논문은 이러한 문제점을 해결하기 위해 생체신호 검출 센서를 비접촉식으로 하는 것을 목표로 NCB(non-contact biosensor, 비접촉식 생체신호 검출 센서)를 개발하고 UWB(ultra wide band, 초광대역) 신호를 이용하는 수면 코칭 시스템을 연구하고 개발하여 상용화를 위한 인프라를 확보하는 것이다. 이를 위해, 본 논문에서는 다음과 같은 연구를 진행하고자 한다. 먼저, NCB 센서를 개발하고, 조도, 온도, 습도, 노이즈 센서가 탑재된 수면 코칭 디바이스에 대해서 연구한다. 이 디바이스를 위한 클라우드 서버 및 모바일 애플리케이션을 개발하며, UWB용 고성능 레이다 안테나 및 수면분석 알고리즘에 대해서도 연구하고 개발한다. 본 연구를 통해서, 병원에서의 접촉식 수면 클리닉 시스템을 피험자의 불편함이나 거부감이 없는 무자각 상태에서의 비접촉식 수면 클리닉 시스템으로유도하여 더욱 신뢰성 높은 데이터를 획득할 수 있고, 홈케어 시스템 구축 관점에서 각 가정별로 구축이 될 경우, 획득된 개인의 수면 관련 빅데이터는 질병 예방 중심의 의학 발달에도 기여가 가능하여 다양한 서비스 모델 창출의 기회를 제공할 수 도 있다. 또한 생체신호 측정 기술과 네트워크 시스템을 통해 상호 연결되는 또 다른 스마트 디바이스들과의 연결은 다양한 분야에 응용이 가능하여 개인별 맞춤형 스마트 홈 시스템 구축 관점에서 인간의 삶을 윤택하게 해 줄 것이라 사료된다.",
		"KEYWORD": "NCB,UWB,생체신호,수면코칭"
	},
	{
		"ID": 917,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "홍익대학교 광고홍보대학원",
		"TITLE": "인포그래픽(infographics)을 활용한 광고가 광고태도에 미치는 영향 ",
		"AUTHOR": "최근혜",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 장동련, 서구원 국, 영문초록수록 부록: 조사설문지 참고문헌(p. 49-55)수록",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "빅 데이터(Big Data) 시대에 거대한 양의 소비자 정보를 효과적으로 표현할 수 있는 방법으로서 인포그래픽(infographics)이 미디어의 주목을 받고 있다. 인포그래픽이 커뮤니케이션 수단으로서 민간기업, 정부기관 및 공공기관 등 다양한 조직 사이에 빠르게 확산되고 있는 반면, 학문적인 연구는 매우 미흡한 수준이다. 선행연구들은 대부분 인포그래픽의 제작 기법과 구성요소들, 가독성 등에 집중하고 있으며, 인포그래픽의 커뮤니케이션 효과에 대한 연구는 찾아보기 힘든 실정이다. 따라서 본 연구는 인포그래픽을 활용한 기업의 커뮤니케이션 수단이 주목도, 정보검색, 이해 용이성에 미치는 영향에 차이를 나타내고 있는가를 분석하였으며, 인포그래픽을 활용한 커뮤니케이션의 효과에 제품관여도가 어떤 영향력을 미치는지 탐색하였다. 본 연구는 인포그래픽 광고와 텍스트 광고 두 개의 광고 자극물을 제작하여, 수도권에 거주하고 있는 총 238명의 일반인을 대상으로 소비자 인식을 조사하였다. 수집된 자료는 SPSS/Win 18.0을 이용하여 t-Test, 분산분석(ANOVA), 및 회귀분석에 활용되었다. 연구결과, 인포그래픽 광고와 텍스트 광고가 소비자의 인식에 차이점이 있는 것으로 나타났다. 구체적으로 인포그래픽 광고가 텍스트 광고보다 소비자의 주목도, 정보검색, 이해 용이성에서 높게 나타났다. 또한 주목도, 정보검색, 이해 용이성이 광고태도에 긍정적(+)영향을 주는 것으로 나타났다. 결국 광고에 인포그래픽을 적용하였을 때, 광고에 대핸 주목도, 정보검색, 이해 용이성을 제고하여 궁극적으로 광고태도를 높여준다는 것을 알 수 있다. 본 연구결과는 이론적으로는 광고의 설득커뮤니케이션이론을 확장하며 실무적으로는 인포그래픽을 기업의 새로운 커뮤니케이션 도구로 활용하는 데 유용한 시사점을 제공해 준다. 본 연구는 광고 커뮤니케이션 영역에서 실증적 연구를 통해 지식을 확장한다는 데에 의의가 있다.",
		"KEYWORD": null
	},
	{
		"ID": 918,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "ERP와 PLM 시스템의 효과적인 통합 연계 모델에 대한 연구 =(A)study on the efficient integrated model for ERP and PLM system ",
		"AUTHOR": "이규환",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수:박규식 참고문헌 : 47장.",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "현대 사회의 제조업계 및 유통업계에서 네트워크 및 빅데이터 관리에 대한 기술이 발전하면서 협업(Collaboration)의 중요성이 부각되고 있다. IT환경의 기술이 점차 확대됨에 따라 제조업계에서는 기존의 전사적 자원관리 시스템인 ERP(Enterprise Resource Planning)과 현재 제조업에서 각광 받고 있는 기술인 제품주기관리(PLM:Product LifecycleManagement)와의 통합에 관련된 부분에 초점이 맞추어져 있다. 즉 제조업체의 핵심역량을 이루는 제품의 기획·설계·생산·AS·폐기 등 제품의 전체 라이프사이클의 디지털데이터를 각 업무부문간 공유하고 협업함으로써 효율을 극대화하는 데 그 목적이 있다. 우선, 어떻게 해야 ERP를 성공적으로 구축하고 기업의 경쟁력을 획기적으로 끌어올릴 수 있을 것인가를 고민하기 전에, 왜 많은 기업들이 ERP를 도입하면서 난관에 봉착하게 되고 극단적으로는 오랜 노력과 시간, 자금, 인력을 투입하고도 그에 상응하는 효과를 보지 못하고 실패하게 되는지 그 요인들을 짚어보자. 대부분의 실패하는 기업에서 공통적으로 도출되고 있는 요소들은 우리도 당할 수 있는 함정일 수가 있기 때문이며, 이를 통해 사전에 이 함정들을 피해 갈 수 있는 대비책을 마련하기 위해서라도 ERP도입을 고려하는 모든 기업들이 한번쯤 신중히 판단해 보아야 하는 부분이라고 할 수 있다. 본 논문에서는 지속되는 불황속에 원가절감이라는 목표를 가지고 비용을 절약하고, 품질이 떨어지고, 디자인이 평범하게 변해가는 사회에서 원가와 회계 실시간으로 매출데이타를 관리 할 수 있는 ERP 시스템으로 재고와 매출을 정확하게 일치시키고, PLM시스템의 도면관리를 통하여 제품의 개발속도 향상 및 비용절감으로 고객에 빠르게 대응 할 수 있는 전략을 제시하고자 하며, ERP 와 PLM시스템의 통합방법을 하기 위한 개선과제들과 CAD Data관리를 통한 INTERFACE 프로그램을 활용하여 Data Migration 및 기업의 표준화를 통하여 프로세스 정립을 하고, 추진목표, 전략, 조직의 구성을 통한 전사적 관점에서의 프로젝트 추진을 통하여 효과적인 통합 연계 모델을 연구하고자 한다.",
		"KEYWORD": "ERP,PLM"
	},
	{
		"ID": 919,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "하이브리드 네트워크에서 링크 비용 기반 빠른 합의 알고리즘 =(A)fast consensus algorithm using link cost in hybrid networks ",
		"AUTHOR": "임헌규",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박성용",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "New IT trends, such as cloud services and big data, constantly change incredibly fast. On the other hand, the fundamental flow that penetrates these trends has changed little. Today, with an increasing number of data and the growing importance of availability and scalability, the majority of services are designed and produced based on distributed processing models. Additionally, it is very difficult to synchronize each distributed processing model, where sites are regionally isolated and different processes participate. Therefore, most asynchronous distributed processing systems adopt asynchronous models rather than synchronous models. Asynchronous models characteristically display higher availability and scalability rates. Thus it is possible for asynchronous models to provide services with better solubility and expandability. Regarding such asynchronous distributed processing models, process consensus issues are considered to be a fundamental problem in the construction of a reliable distributed processing system based on distributed processing models. There are different solutions to the problems of consensus according to service environments such as centralized and decentralized, and hypotheses. This thesis expands a consensus algorithm adopting a decentralized rotating cooperator paradigm, and proposes an algorithm that will optimize link-transmission costs in region-based, prompt intermediary processes to participate in the consensus procedure, and ultimately induce a fast-speed process consensus.",
		"KEYWORD": "분산처리"
	},
	{
		"ID": 920,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "동의대학교 경영대학원",
		"TITLE": "금융산업 활성화를 위한 핀테크의 활용방안에 관한 연구 ",
		"AUTHOR": "곽현주",
		"REGION": "부산",
		"PROFESSOR": "동의대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박영배 참고문헌: p. 39-40",
		"STORE_LOCATION": "동의대학교 중앙도서관",
		"ABSTRACT": "핀테크는 금융과 기술을 결합한 용어로 글로벌 ICT 기업이 폭넓은 사용자 기반을 바탕으로 송금, 결제, 대출, 자산관리 등 각종 금융서비스를 결합하여 제공하는 새로운유형의 금융서비스를 말한다. 핀테크의 등장은 스마트폰 이용의 보편화로 소비자의 소비행태가 모바일 중심으로 변화하고 있고, 빅데이터 분석 등으로 소비자에게 맞춤형 금융서비스가 가능해진 것을 의미한다. 핀테크는 전자상거래와 금융서비스가 새롭게 만나면서 자연스럽게 생겨나는 현상이다. 핀테크는 기술을 핵심 요소로 하는 금융서비스 혁신으로 파괴적 혁신이라는 특징을 지닌다. 즉, 핀테크 기업은 기존 금융서비스의 전달체계를 와해시키거나 대체할 수 있는 파괴자의 속성을 가지고 있다는 것이다. 우리나라는 미국이나 영국보다 핀테크 산업이 늦게 발전하고 있다 그 이유는 신용카드 결제의 편리함 때문이다. 2014년 세계 100대 핀테크기업 중 우리나라 기업은 하나도 없다. 그러나 핀테크 확산은 거스를 수 없는 사회현상이다. 알리페이, 페이팔 등은 이미 국내에서 금융서비스를 제공하고 있고, 애플, 구글 등도 국내 금융시장에 참여할려고 하고 있다. 따라서 국내에서 핀테크를 통한 금융혁신이 늦어질 경우 해외핀테크 기업에 금융시장 및 고객을 내줄 가능성이 높다. 정부는 올해 들어 창조경제의 일환으로 ‘핀테크 육성’을 금융개혁의 핵심이슈로 선정하고 개혁을 추진 중에 있다. 정부는 핀테크 창업을 통해서 다양한 일자리 창출 청년문제 등 일자리문제를 해소하고, 중위험/중금리 사업모델인 인터넷전문은행의 선정, 각종 규제의개선 등으로 우리경제가 저성장의 늪에서 벗어나 재도약하는 발판의 역할을 할것이라 기대하고 있다. 본 논문에서는 핀테크의 개념, 발전 배경과 주요 기업의 혁신 사례를 통해 핀테크의 트렌드를 살펴보고, 핀테크에 따른 미래 금융의 혁신 모습을 분석한 후 우리나라의 핀테크 현실을 바탕으로 정책적 시사점을 제시하고 그 시사점을 발판삼아 좀더 나은 금융혁신을 이루기를 기대해보고 핀테크를 기반으로 거듭나 세계적인 금융회사로 나아가는 기업이 나오길 희망한다.",
		"KEYWORD": null
	},
	{
		"ID": 921,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "성균관대학교 정보통신대학원",
		"TITLE": "APT 보안장비 기능 분석을 통한 보안SLA 지표 분류기준 연구 =A study on security SLA`s indicator classification criteria based on the analysis of APT security equipment functions ",
		"AUTHOR": "이승엽",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 원동호 참고문헌: p. 31-32",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "오늘날 정보화의 발달로 각종 산업분야에서 인터넷과 정보기술에 대한 활용도 및 의존도가 급속도로 높아졌다. 이러한 환경변화에 따라 서비스의 편의성 및 안전성에 대한 사용자의 요구수준도 점점 증가하고 있다. 이에 따라 기업은 빅데이터, 인공지능, IoT 등 최신 IT신기술을 기존 서비스와 융합하여 고부가 혹은 신규 가치 창출을 도모하고 있다. 그러나 IT신기술 발달과 활용성이 높아짐에 비례하여 지능적이고 지속적인 복합적 특성을 가진 사이버 공격은 날로 증가되어 사회전반에 막대한 경제적 손실을 낳고 있는 실정이다. 이에 따라 기업은 각종 보안시스템을 도입하여 운영하고 있으나, 타 분야에 비해 보안서비스 관련 서비스수준협약은 기준 및 적용방안이 미흡하여 수준 높은 보안서비스에 한계가 있다. 특히, 지능형 지속위협 공격은 3.20 사이버테러, 소니픽쳐스 해킹, 한수원 협력업체 해킹, 농협 해킹 등 정부기관과 금융기관, 언론사 등이 주요 공격 대상으로 경제적으로 막대한 피해를 초래함에 따라 이에 대한 대응체계가 국가적인 측면에서 시급한 상황이다. 본 논문은 APT 보안장비의 기능을 분석하여 공통보안기능과 개별보안기능을 분류하고, 이를 통해 보안서비스의 안전성을 확보하기 위한 보안SLA 지표 및 적용방안을 제안한다. 이를 통해 단순 일차원적인 운영에서 벗어나 APT 보안장비에 적용 가능한 서비스 수준협약이 가능할 것이다. 주제어 : 서비스수준협약 , 보안SLA , 지능형 지속위협 공격 , APT 보안장비 , 사이버테러",
		"KEYWORD": "APT 보안장비,보안SLA,사이버테러,서비스수준협약,지능형 지속위협 공격"
	},
	{
		"ID": 922,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "타문화에 대한 호감도, 국가이미지, 브랜드자산 및 제품구매의도간의 관계에 관한 연구 :중국문화를 중심으로 ",
		"AUTHOR": "양뤼",
		"REGION": "서울",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 윤성준 참고문헌 : p. 83-105",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "21세기에 진입하면서 문명은 급속도로 발전해왔다. 과학기술이 발전하면서 국가, 지역 그리고 각 민족사이의 커뮤니케이션이 더 쉬워졌고, 빈번해졌다. 이에 따라 글로벌이라는 개념이 나타나게 되었다. 이것은 전세계적으로 새로운 경쟁의 시대가 도래했음을 의미하는 것이다. 단, 위험과 계획은 항상 동시에 나타난다. 중국의 경우, 전인들의 노력 덕분에 다시 세계 경제를 이끄는 경제 대국으로써의 입지를 되찾게 된다. 2010년도에는 일본을 추월하면서 세계 두 번째 경제 대국이 되었고, 현재까지 세계에서 가장 많은 제품을 생산하는 나라로써 매우 중요한 위치를 차지하고 있다. 중국은 생산과 경제를 강조하기 시작하면서 풍부한 중국 내 천연 자원과 인력자원을 바탕으로 노동집약형 일차 제품 생산가공 산업에 집중한다. 그리고 이는 많은 소비자들이 중국산 제품은 낮은 기술력으로 마늘어진 거칠고 저렴한 일차 생산 제품이라는 인식을 갖게 하는 계기가 된다. 하지만 중국은 급격하게 진행되는 노령화로 인해 노동인구가 감소하고 인건비가 상승할 것으로 예상되는 만큼. 노동집약적 일차 제품 생산 산업에서 기술집약적 산업으로의 전환이 필요한 상황이다. 독일의 ‘공업 4.0’ 책을 참고하여 중국 정부는 2015년 5월 8일, <중국제조2025>계획을 출범하였다. 향후 10년 동안 제조 강국으로써 중국의 활동 방향에 대한 내용이 담긴 이 계획의 발표로, 중국 정책의 변화와 중국 제품의 변화가 소비자에게 얼마나 빨리 어떠한 영향을 미칠 것인가가 중국 경제를 연구하는 연구자들에게 중요한 이슈가 되고 있다. 문화산업 분야에서 경영전략을 어떻게 사용해야하는가에 대한 문제도 마찬가지다. ‘인터넷 시대’와 ‘빅 데이터 시대’가 도래함에 따라, 사람들은 여러 매체를 통해 자국의 문화를 전파하고 있다. 중국은 역사적으로 수 천년동안 GDP 1위의 경제 대국으로써 화려한 문화적 기반 역시 가지고 있다. 때문에 이러한 훌륭한 문화와 현대문명을 융합한다면 사람들이 가지고 있는 중국에 대한 이미지를 바꿀 수 있다고 본다. 앞에서 논의한 바와 같이, 본 연구의 목적은 한국 소비자를 대상으로 중국 문화가 외국 소비자들이 갖는 중국 및 중국제품에 대한 이미지에 어떠한 영향을 미치는가를 규명하는데 있다. 또한, 중국 문화의 후광효과가 한국 소비자들의 중국 제품 구매에 어떠한 영향을 미치는지도 확인한다. 본 연구에서는 먼저 ‘문화적 거리감’이 ‘중국문화에 대한 호감도’와 ‘중국 국가이미지’ 사이에 조절효과를 가져오는지에 대해 조사한다. 그 다음에 ‘중국문화에 대한 호감도’가 ‘중국제품 구매의도’ 및 ‘중국제품 브랜드 자산’에 어떤 영향을 미칠 것인지 살펴본다. 동시에 ‘중국 국가이미지’와 ‘중국제품 브랜드자산’이 ‘중국문화에 대한 호감도’ 및 ‘중국제품 구매의도’ 사이에 매개효과로서 작용하는지에 대해 연구한다. 마지막으로, 문화후광효과를 기반으로 ‘중국제품 브랜드자산’이 ‘중국 국가이미지’ 및 ‘중국제품 구매의도’의 사이의 매개효과가 되는지 조사한다. 분석결과를 보면 조절변수 ‘문화적 거리감’의 하위변수인 ‘세계시민주의’는 정(+)의 조절영향을 미치는 것으로 나타났고 나머지 하위변수인 ‘자국중심주의’는 정(+)의 조절영향을 미치지 않는 것으로 나타났다. 그리고 ‘중국 국가이미지’가 매개변수로 들어갔을 때, 하위변수인 ‘국민이미지’는 정(+)의 매개영향을 미치는 것으로 나타난 반면, ‘전체적 국가이미지’는 정(+)의 매개영향을 미치지 않는 것으로 나타났다. 또한 분석결과를 보면, ‘중국제품 브랜드자산’이 매개변수로 들어갔을 때 그 하위변수인 ‘제품이미지’가 ‘중국 국가이미지’ 및 ‘중국제품 구매의도’ 사이에 정(+)의 매개영향을 미치는 것으로 나타났고, 또 다른 하위변수 ‘지각된 품질’은 유의한 매개 영향을 미치지는 않은 것으로 나타났다. 앞의 논의를 종합해보면, 문화에 대한 호감도는 중국과 중국제품에 정(+)의 영향을 미치며, 문화후광효과는 직접적 혹은 간접적으로 외국소비자들의 중국제품구매의도에 정(+)의 영향을 주고 있음을 알 수 있다.",
		"KEYWORD": "구매의도,국가이미지,문화호감도,브랜드 자산,소비자 특성"
	},
	{
		"ID": 923,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 대학원",
		"TITLE": "국내 설상스포츠의 비교우위종목 탐색 =(A)study on the comparative advantage in Korea snowsports ",
		"AUTHOR": "이지만",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신승호 국문 또는 영문 초록 수록 참고문헌: p. 127-133",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "이 연구는 국내 설상스포츠의 비교우위 종목을 찾아내는 연구이다. 연구를 수행함으로서, 현재 동계 스포츠의 양 축을 이루고 있는 빙상종목과의 불균형을 해소하고, 더불어 국내 설상 스포츠의 지속 가능한 발전을 이루고자 하는데 그 목적이 있다. 연구의 목적을 달성하기 위해 설상스포츠 종목에 대한 기본적인 이해를 각종 문헌을 통해 설명하였으며, 올림픽의 주요 종목으로 이루어지고 있는 설상종목을 9개 종목으로 구성하여 자료포락 분석을 실시하였다. 자료포락 분석에 사용된 자료는, 정부의 정보공개 정책에 따라, 공개되고 있는 대한체육회 산하 가맹 경기단체의 경영공시 자료를 참고 하였다. 이를 통해 연간 설상 종목별 운영비용과 선수 및 코치 인원, 그리고 종목별 경기장 건설비를 투입요소로, 2014년 소치 동계 올림픽에서의 종목별 최고 성적을 산출요소로 선정하였다. 이 중 투입요소인 경기장 건설비용을 ‘Case1’ 에서는 제외하였으며, ‘Case2’ 에서는 경기장 건설비를 포함하고 또한 선수 및 코치 인원을 국가대표와 그 코치 수로 변경하여 각각 대입하였다. 다음으로 빅 데이터(Big data)분석의 가장 기초로 활용될 수 있는 웹 마이닝(Web Mining) 기법을 통해 웹상에 나타나는 설상 종목별 검색어를 페이지 검색 기준으로 추출하여 종목별 환경 분석을 실시하였다. 이를 통해 나타난 결과는 다음과 같다. 국내 설상종목의 환경은 설상 종목의 모두를 운영하기에는 제한적인 환경으로 나타났으며, 특히 설상종목 운영에 필수 요소인 적설량이 부족한 것으로 나타났다. 하지만 “프리스타일스키” “회전스키” “스노우보드” 등의 종목을 운영함에 있어서는, 현재 설상스포츠 시설 그대로의 활용이 가능한 것으로 나타났다. 경기장 건설비용을 투입요소에서 제외시킨 DEA 분석 결과 국내 설상스포츠 중 효율적이며 비교우위가 있는 종목은 “프리스타일 스키”와 “스키점프”로 나타났으며, 다음으로 “스노우보드”, “회전스키” 가 발전 가능성이 있는 종목으로 나타났다. 경기장 건설비용을 투입요소에 대입시킨 DEA분석에서도 가장 비교우위에 있는 효율적 종목은 “프리스타일 스키”로 나타났으며, 다음으로 “스노우보드”와 “회전스키”가 발전 가능성이 있는 종목으로 나타났다. “스키 점프”의 경우 경기장 건설비용을 대입한 DEA분석 결과에서는 비효율적인 종목으로 나타났다.",
		"KEYWORD": null
	},
	{
		"ID": 924,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "랜덤포레스트를 이용한 변수 선택 ",
		"AUTHOR": "권안나",
		"REGION": "인천",
		"PROFESSOR": "지도교수:박헌진 인하대학교 논문은 저작권에 의해 보호받습니다. 참고문헌 : p.28",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "본 연구에서는 데이터 마이닝이나 빅데이터에서 이슈가 되고 있는 변수선택 문제를 해결하기 위한 다양한 방법을 비교 연구하였다. 지금까지 주로 연구에서 사용하는 변수 선택 방법에는 상관분석, R-Square, Adjust R-Square, stepwise 등 회귀분석 기법을 이용한 방법과 의사결정나무와 의사결정나무에 앙상블 기법을 적용한 Bagging, Bumping 등의 방법이 알려져 있다. 이들 방법과 더불어 의사결정나무 개념을 적용하여 발전된 랜덤 포레스트의 방법을 이용하여 변수를 선택하는 방법을 제시하고자 한다. 기존의 방법들과 랜덤 포레스트의 결과를 비교하기 위하여 프리드만(1984)의 모형, 장영재(2008)의 모형, 기타 모형을 이용한 시뮬레이션 자료를 생성하고, 결과를 비교한다. 그 결과, 랜덤 포레스트는 다른 방법들에 비해 주변수를 선택하는 기능은 약하지만 noise 변수를 걸러내는 데에는 효과를 나타낸다. 다음으로는 Cellulose 용해에 영향을 주는 최적 용매를 랜덤포레스트를 이용하여 선택하고, 선택된 변수를 이용하여 모형에 적합하여 예측한 결과와 전체 변수를 이용하여 예측한 결과를 비교한다. 비교 결과, 랜덤 포레스트를 이용하여 선택한 변수를 모형에 적합했을 때가 전체 변수를 이용한 모형보다 성능이 더 좋게 나타난다. 또한 bagging, 랜덤 포레스트, 회귀분석으로 선택된 변수들을 이용하여 MARS 분석을 실시하고, 전체 변수를 이용하여 분석한 결과와 비교한 결과, 선택된 변수들을 가지고 분석한 모형의 성능이 더 좋게 나타난다.",
		"KEYWORD": "bagging,데이터마이닝,랜덤포레스트,변수선택"
	},
	{
		"ID": 925,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "退溪의 理發氣隨 情學 硏究 =(A)study on Toegye`s science of feelings based upon `The Principle Issues and the Material Forces Follow` ",
		"AUTHOR": "김성실",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이기동 참고문헌: p. 225-240",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "본 논문은 퇴계가 이해하는 감정이 바로 ‘理發氣隋’의 구조를 가지고 있으며, 理發氣隋 情學이라고 말하게 될 때에 理發氣隋 情學이 무엇이고 어떤 특성이 있으며 오늘날 어떤 의의를 지니는가에 대해 고찰하였다. ‘理發氣隨’라는 말은 본래 퇴계와 고봉의 사단칠정논변에서 최초 언급된 것으로, ‘四端은 理가 발해서 氣가 따르는 것이며, 七情은 氣가 발해서 理가 타는 것이다’는 퇴계의 말에서 비롯된 개념어이다. 오늘날의 퇴계학 연구의 대부분이 퇴계는 사칠논변에서 `理發`과 `氣發`을 둘 다 인정한 互發論者라고 이해하고 있지만, 본 논문에서는 퇴계가 오직 `理發氣隨`만을 인정하였음을 밝히고, `理發氣隋`라는 개념이 단순히 사칠논변에서 감정을 이해하는 방식의 차원을 넘어서 퇴계학 전반을 가로지르는 핵심개념임을 밝히고자 하였다. 따라서 본 논문은 理發氣隋 情學의 ‘土臺’, ‘特性’, ‘意義’의 구성을 통해 퇴계의 理發氣隋 情學을 고찰하였다. 먼저 제1장 서론에서는 왜 본 논문을 작성하게 되었는가에 대한 문제제기와 함께 본 논문의 연구목표와 연구방법을 기술하였다. 제2장 본론에서는 ‘情學’과 ‘理發氣隨’라는 용어가 비전공자뿐만 아니라 전공자에게 있어서도 낯선 개념이기 때문에 퇴계학의 흐름을 분석하고 왜 退溪情學인지, 情學은 어떤 의미를 지니는지에 대해 『四書』와 『退溪集』을 중심으로 그 근거를 살펴보고자 하였다. 제3장에서는 理發氣隨 情學의 특성을 ‘純善無惡’, ‘自然原則’, ‘共感’, ‘永遠無限’의 크게 4가지로 정의하였다. ‘純善無惡’에서는 善惡의 개념에 대한 검토를 통해 氣와 感情이 有善惡의 근거가 되는 기존의 관점을 비판하고 퇴계의 입장을 분석하였다. 그리하여 감정이 有善惡이 아니라 性發爲情의 情이므로 다 좋을 수밖에 없는 감정의 진실을 밝히고 있다. ‘自然原則’에서는 理發氣隋 情學이라는 말 자체가 必然과 因果임을 밝히고자 하였으며 퇴계가 이해하는 ‘所以然’과 ‘所當然’의 관계 이해 등을 통해 분석하였다. ‘共感’은 감정이라는 것이 누구나 가지고 있는 보편적인 것이지만 동시에 나에게만 있는 고유한 것이기 때문에 그것을 올바로 이해하는 것이 바로 理發氣隋 情學임을 밝히고자 하였다. ‘永遠無限’은 감정의 주체는 영원무한한 ‘나’ 자신이라는 것을 깨닫고 ‘나’에 대한 올바른 이해를 추구하는 것이 理發氣隋 情學의 특성임을 밝히고자 하였다. 제4장에서는 理發氣隨 情學이 현대사회에 어떠한 의의를 지니는가를 크게 4가지로 요약하여 보았다. 첫째, 나는 사랑[仁]으로 이미 완전한 존재임을 아는 것, 둘째, 개인[私]과 공동체[公]는 이미 하나임을 아는 것, 셋째, 앎과 믿음은 불가분의 관계임을 아는 것, 넷째, 나는 욕망의 주체[理欲]임을 아는 것의 4가지 의의를 지니고 있음을 밝혔다. 마지막 제5장 결론에서는 각 장의 내용을 요약ㆍ정리하고, 理發氣隨 情學의 전체적인 특성과 의의 및 향후 발전과제 등에 대해 요약ㆍ정리하였다. 우리는 늘 배우면 즐겁고 기쁘다. 만일 화가 나거나 슬픈 때가 있다면 그때야 말로 우리가 즐겁게 배울 때이다. 다 좋을 뿐인데 그렇지 않다고 느끼는 것은 왜 그런지를 이제 잘 알아보라는 감정의 지시이기 때문이다. 그런 의미에서 理發氣隨 情學은 좋은 것을 좋다고 하고 싫은 것을 싫다고 말하는 단 한번도 틀린 적이 없는 과학(Science)이다. 이제 이러한 理發氣隨 情學의 특성을 다양한 분야에 구체적으로 확인해 나간다면, 있는 것은 다 좋다는 것을 확인하는 기쁨의 학문, 기쁨의 세상이 될 것이다.",
		"KEYWORD": "四七論辨,感情,理發氣隋,純善無惡,退溪"
	},
	{
		"ID": 926,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "세종대학교 대학원",
		"TITLE": "인터넷 포털의 6C 전략과 이용자 만족도에 관한 연구 :Study on Internet portal`s 6C strategy and satisfaction of user : focused on Tencent and Naver ",
		"AUTHOR": "MaWei",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 927,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울대학교 대학원",
		"TITLE": "사물인터넷 이용자의 개인정보 보호에 관한 공법적 연구 :개인정보의 효용 및 보안 리스크를 고려하여 ",
		"AUTHOR": "권은정",
		"REGION": "서울",
		"PROFESSOR": "참고문헌 수록",
		"STORE_LOCATION": "서울대학교 중앙도서관",
		"ABSTRACT": "인터넷이 주도해온 정보화 시대는 한 세대를 지나 다음 세대의 진화된 통신 인프라, 소위 ‘사물인터넷’에 주목하고 있다. 사물인터넷은 무수한 센서, 클라우드, 빅데이터 등의 정보기술이 결합되어 유기적인 통신 생태계를 형성하게 되는데, 특히 개인정보를 적극 활용하여 맞춤형 생활 편의를 제공하는 서비스가 주를 이룬다. 문제는, 개인정보의 이용가치가 증가할수록 개인정보의 유통량도 급증하여 정보 침해의 위협이 크게 상승할 우려가 있다는 것이다. 즉, 사물인터넷의 본질인 연결성과 결합성으로 인해 사물인터넷 이용환경 자체가 개인정보 리스크 내지 보안 리스크를 안을 수밖에 없다. 따라서 사물인터넷 이용자의 개인정보에 대한 규율은 ‘리스크 행정’의 관점에서 설명될 수 있고, 그 법적 규율의 토대로서 관련된 보호법익과 이해관계를 재고할 필요가 있다. 종래 개인정보 규율은 국내외를 불문하고 정보주체의 인격적 가치에 중점을 두고 개인정보자기결정권을 보호하는 것에 주력하였다. 하지만 (1) 식별가능성 또는 결합용이성 있는 개인의 정보에 대하여 (2) 정보주체의 동의를 받아 수집, 이용, 제공하여야 하며 (3) 침해사고에 대해서는 정신적 손해배상을 하여야 한다는 세 가지 측면의 주된 규율은 사물인터넷에서 자동 수집되어 이용되는 개인정보의 속성과는 괴리가 있다. 이를 극복하기 위해 EU, 미국, 일본 등은 부분적인 입법과 유연한 해석을 동원하여 새로운 통신환경을 법영역으로 포섭하는 노력을 기울여왔다. 이 논문은 사물인터넷의 순기능을 지지하는 입장에서, 프라이버시와 같은 인격권뿐만 아니라 개인정보의 경제적?사회적 효용까지 확보하고 보안 리스크를 실효적으로 낮출 수 있는 공법상 규율 방안을 제안한다. 개인정보의 보호필요성을 결정하고 책임을 합리적으로 귀속시키려면 법률 차원에서 명확한 기준을 설정하는 것이 중요한 바, 첫 단추가 되는 개인정보 분류기준으로서 센서, 기기 등 보안기술 단위가 유용하게 적용될 수 있다. 나아가 개인정보의 속성 및 이용 행태는 4단계의 규제를 정하는 기준이 된다. 끝으로 공정한 책임 분배를 위해 경제적 수익과 공공성을 고려하여 행정제재 및 배상책임을 인정해야 할 것이다. 새로운 정보 패러다임의 잠재력을 확보할 수 있도록 명확한 입법을 통한 개인정보 규율의 쇄신을 서둘러야 할 때이다.",
		"KEYWORD": "개인정보,개인정보보호법,개인정보자기결정권,리스크 행정,사물인터넷,프라이버시"
	},
	{
		"ID": 928,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인천대학교 동북아물류대학원",
		"TITLE": "DEA모델을 이용한 국내 및 해외 유통기업의 운영형태별 효율성분석에 관한 연구 =A study on operational efficiency analysis of local & foreign retail providers with business types by using DEA model ",
		"AUTHOR": "오병주",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 송상화",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "과거 유통업은 제조업의 종속되어 있는 구조에서 현재 유통업이 제조업을 주도하고 있다. 장기간의 세계경기불황 등으로 인한 제로성장시대에서도 유통업은 IT기술의 발전으로 온라인 기반 유통업체가 성장을 이끌고 있다. 공유경제, 빅데이터, O2O, 위치기반서비스 등의 기술은 유통업체에 서비스 혁신을 일으키고 있으며 성장의 기폭제 역할을 하고 있다. 국내 유통기업은 글로벌 유통업체에 비해 규모도 작고 역사도 매우 짧은 편으로 아직도 많은 개선이 필요하다. Deloitte에서 선정한 Top 250기업 중 해외 16개 기업과 Ceoscore.com에서 선정한 국내 11개 기업을 선정하여 2013년부터 2015년도 3개년도 재무제표를 토대로 DEA효율성 분석과 Cash Operating Cycle 분석을 실시하였다. 글로벌 유통업체와 국내 유통업체의 효율성 비교를 통한 국내 업체의 효율성 증대방안과 유통업에서의 무형자산의 중요성 및 운영 형태별 특이점을 분석하였다. 투입요소로는 영업비용과 총자산을 산출요소로는 매출액과 영업이익을 선정하였다. 이에 따라 산출된 결과를 해외기업과 국내기업으로, 무형자산비율이 높은 기업과 낮은 기업으로 분류하여 비교 분석하였다. 또한 운영형태별 특이점도 분석하였다. DEA의 CCR 수치와 Cash Operating Cycle, ROA도 고려하여 분석한 결과는 다음과 같다. 첫째, 해외기업의 CCR 평균은 94.7%로 국내기업 89.0% 대비 대체적으로 효율적으로 운영되고 있으나, 영업이익률은 국내기업이 오히려 양호한 것으로 나타났다. 총자산 이익률인 ROA는 해외기업이 국내기업 대비 6.2% 높게 나타났다. 무형자산 비율은 해외기업이 53.6% 대비 국내기업은 2.8%로 해외기업이 무형자산투자에 많은 노력을 기울이는 것으로 조사되었다. 둘째, 무형자산비율이 조사대상기업 평균이 32.9%이며 그 평균 이상의 기업과 이하의 기업을 비교분석하였다. 무형자산과 DEA 효율성 측면에서는 거의 차이가 없는 결과가 나왔고 무형자산가치가 평균 이하인 기업이 영업이익률 측면에서는 오히려 0.8% 높게 나타났다. 반면 ROA는 무형자산가치가 평균이상인 기업이 7.4% 높게 분석되었다. ROA와 무형자산비율은 양의 상관관계가 있는 것으로 나타났으며, 이를 많이 벗어나는 기업들은 지역, 제품, 유통채널에 특화되어 있거나 경쟁열세에 있는 기업으로 해석할 수 있다. 셋째, 운영형태별 분석결과 e-Retailer가 CCR은 74.8% 낮은 편이나 영업이익률은 13.5%로 높은 편이고 Department store의 CCR은 94.2%로 평균 수준이나 재고일수, 매입채무일수는 매우 높은 수준이다. 운영형태별 ROA와 무형자산비율도 양의 상관관계가 있는 것으로 분석되었으며, 무형자산의 중요성이 유통업에서도 적용됨을 알 수 있다.",
		"KEYWORD": "DEA,무형자산,유통기업,효율성"
	},
	{
		"ID": 929,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성균관대학교 정보통신대학원",
		"TITLE": "GRC에서 APT攻擊의 效果的인 對應方案에 관한 硏究 =(A)study on the effective countermeasures against APT attacks in GRC ",
		"AUTHOR": "박정준",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 원동호 참고문헌: p. 69-71",
		"STORE_LOCATION": "성균관대학교 중앙학술정보관",
		"ABSTRACT": "스마트 디바이스(smart device)의 기하급수적인 확산과 더불어 IT환경의 빅뱅(big bang)현상은 다양한 기술들이 융합되고, SNS의 활성화로 이어지면서 공격자 입장에서는 필요한 정보를 획득하는데 매우 유리한 환경으로 변화되고 있어서 그 위협이 더욱 거세지고 있다. 특히, 공격의 목적이 경제적이거나, 정치적인 특정 목표를 대상으로 조직적이면서, 지속적으로 치밀한 전략을 바탕으로 진행되는, 이른바 “지능형 지속 위협” (이후 APT)에 대한 피해사례가 증가하고 있고, 다양한 공격 기법들이 융합된 형태를 갖추면서 대응하기가 더욱 어려워지고 있다. 이러한 위협에 따라 보안 업계는 그동안 다양한 솔루션들 예컨대, UTM, IPS, 웹방화벽, DDoS전용장비와 최근에 APT방어 솔루션에서 빅데이터(big data) 기반의 융합관제 서비스에 이르기까지 APT공격을 방어하기 위한 노력이 계속되고 있다. 그럼에도 불구하고, APT공격은 제로데이(zero-day)악성코드, 스피어피싱(spear phishing) 등 더욱 진화된 형태로 이어지고 있어서, 기업의 이미지에 치명적인 영향을 줄 뿐 아니라, 국가 사회적인 문제로 그 심각성이 날로 증가되고 있는 실정이다. 이러한 현상의 원인에는 APT공격에 대한 대응방안이 단편적인 기술적, 관리적인 측면에 의존하는 경향이 매우 크고, 공격의 특성에 따른 전반적인 보안 프레임웍을 수립하고 개선해 나가는 방식이 아닌, 보안 이슈가 발생할 때 마다 새로운 솔루션을 도입하고 문제점을 보완하는 수동적인 관리체계가 반복되고 있는데 그 원인을 찾을 수 있다. 따라서, 본 논문에서는 APT공격 대응에 있어서 무엇이 문제이고, 이를 극복하기 위한 근본적인 접근방안을 GRC에서 살펴보고, APT공격 대응 방안을 재정립함으로써, 보다 효과적인 방어체계를 수립하고 보완해 나갈 수 있는 방안을 제시해 보고자 한다.",
		"KEYWORD": "APT,Compliance,Governance,GRC,Risk Management"
	},
	{
		"ID": 930,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한양대학교 공공정책대학원",
		"TITLE": "不動産價格公示制度의 改善方案에 관한 硏究 :(A)study on the improvement of the official announced real estate price system :政府3.0 導入을 中心으로 =focusing on the introduction of government policy 3.0 ",
		"AUTHOR": "박정민",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최호근 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 114-121",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 정부 및 공공기관은 정부3.0 이라는 정부운영 패러다임이 화두이다. 정부는 부의 양극화, 고용률 정체, 저성장 경제 침체기 등 당면한 정부운영의 한계를 극복하고자 정부3.0 이라는 새로운 정부운영 패러다임 제시로 변화를 이끌어 가고 있다. 이에 본 연구는 해마다 약 1,300억원 가량의 국가예산이 투입되는 부동산가격공시제도에 대해 정부3.0 기반 추진과정에서 제기될 문제점들에 대한 개선방안을 제시하는 것이 목적이다. 따라서 정부3.0에 대한 정확한 개념을 고찰하고, 정부3.0 기반하의 부동산가격공시제도의 법제적, 행정조직적, 정보시스템적 측면에 대한 현황을 조사?분석하여 다음과 같은 문제점을 도출할 수 있었다. 첫째, 정부3.0 도입에 따른 부동산가격공시제도상의 법제적 미흡이다. 우선 부동산가격공시법상의 정부3.0을 적용할 수 있는 법규가 미흡했으며, 개방·공유·소통의 권리구제 제도 운영이 미비한 것으로 분석되었다. 둘째, 정부3.0 기반 부동산가격공시제도 운영 및 조직의 비체계성이다. 현재 부동산가격공시 대상별 행정조직간의 협력적 체계가 미흡하고 부동산가격공시 담당인력의 정부3.0 추진 전문성 부족이 분석되었다. 셋째, 부동산가격공시제도의 통일된 정보화 운영체계 미흡이다. 공시정보와 유사정보간의 융합을 위한 표준정보화가 미진하고, 이원화된 부동산가격공시시스템 운영에 따른 비효율성이 분석되었다. 이상과 같은 문제점을 바탕으로, 본 연구는 정부3.0 기반하의 부동산가격공시제도에 대한 합리적이고 실질적인 개선을 위해 다음과 같은 방안을 제시하였다. 첫째, 부동산가격공시법 하에서 정보수집, 등록, 관리, 이ㆍ활용 등과 관련한 규정 및 지침 등의 신설, 가칭『공개 부동산공시 법정』제도와 같은 정부3.0적용을 위한 부동산가격공시제도의 법제적 개선이 필요하다. 둘째, 경제 활성화 및 가격공시정보의 개방을 위한 민간?정부 협업 전담기관의 신설, 부동산가격공시 담당인력의 채용시험과목 조정, 공간정보기술 교육과 연수강화로 전문성 강화등 정부3.0 기반 부동산가격공시제도 운영 및 조직의 체계화가 필요하다. 셋째, 빅데이터(Big Data)활용을 위한 공시·유사정보의 표준 정보화, 빅데이터 기반의 일원화된 부동산가격공시 시스템 구축등 정부3.0 기반의 통합 부동산가격공시 정보화 운영체계 강화가 필요하다. 본 연구는 한정된 선행연구 결과물을 대상으로 문헌적 연구 방법을 통해 현황을 분석하고 도출된 문제점에 대한 개선방안을 제시하였으나 후속 연구에서는 정부3.0 기반하의 부동산가격공시제도가 시행된 결과를 바탕으로 실증분석의 객관성 및 타당성을 확보할 수 있는 다양한 유형의 선행연구물과 사례를 분석할 필요가 있을 것으로 본다. 이상으로 본 연구가 향후 정부3.0이 진화되어 실현될 정부4.0, 정부5.0등 미래 정부운영패러다임의 기반이 되며, 효율적인 국가운영과 국민 행복이 선 순환하는 새로운 패러다임 시대를 이룩하는데 조금이나마 도움이 되길 기대한다.",
		"KEYWORD": "부동산"
	},
	{
		"ID": 931,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "(A) preliminary study on school meal system ",
		"AUTHOR": "JaeYeonKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 932,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "인지컴퓨팅 융합 헬스케어 정보서비스 수용요인에 관한 연구 =(A)study on the acceptance factors of healthcare information services converged with cognitive computing ",
		"AUTHOR": "배영우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 신용태",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "헬스케어 산업은 질병의 치료에서 예방을 위한 건강관리로 그 무게 중심이 변화하고 있다. 이 변화를 견인하고 있는 것은 인구의 고령화, 의료 기술과 정보통신 기술의 발전이다. 그중에서도 유헬스, 원격의료, 건강관리 서비스 등은 국내 시범서비스 사업을 통해 기술적인 유효성을 검증하고 있다. 하지만 서비스의 효과성 측면에서는 사회적 동의를 얻지 못하고 있다. 반면에 미국을 비롯한 해외에서는 정보통신기술과 융합한 서비스의 헬스케어 분야 이용이 보편적이다. 인간과 언어를 통해 자연스럽게 소통하는 인지컴퓨팅은 헬스케어 지식을 활용한 서비스 혁신의 가능성이 높다. 미국의 암센터를 중심으로 암 전문의사의 환자진단을 지원하는 분야에 이미 적용되고 있다. 특히 인지컴퓨팅으로 인한 사용자경험 혁신은 헬스케어 정보서비스와 융합하여 일반인의 평소 건강관리 효과를 높일 것으로 예상된다. 이는 치료에서 예방으로 전환되는 산업적 변화에 부합되는 중요한 기술이 될 가능성이 높다. 본 연구에서는 인지컴퓨팅과 헬스케어 정보서비스를 융합한 서비스 개념과 모델을 확립하고 일반인을 대상으로 이 융합서비스에 대한 수용요인을 연구하여 규명하였다. 이를 위해 기술수용모델과 선행연구에 대한 고찰을 통해 이론적 배경을 기술하고 연구 모델을 설계하였다. 건강관여, 기술혁신성, 서비스품질, 사회적영향, 개인화를 독립변수로, 매개변수는 인지된 유용성, 인지된 이용용이성을 그리고 종속변수는 이용의도를 제시하였다. 일반인을 대상으로 온라인 설문조사를 실시하고, 탐색적 요인분석과 신뢰도 분석으로 8개의 요인을 채택하였다. 구조방정식 모델을 이용해 확인적 요인분석과 타당성 검증을 완료하였다. 가설검증을 위해 경로분석을 시행하여 변수 간 인과관계를 규명하여 수정가설 1개를 포함한 총 10개의 가설이 모두 채택되었다. 또한 남녀 성별로 서비스 수용에 영향을 미치는 요인이 다름을 검증하였다. 본 연구 결과의 시사점은 다음 네 가지로 요약된다. 첫째, 응답자의 과반수가 건강관리 서비스를 선호하므로 이 분야에 초점을 둔 초기 서비스 개발이 필요하다. 둘째, 신뢰성이 매우 중요한 수용요인이므로 서비스에 대한 신뢰를 높이는 것이 가장 우선되어야 한다. 셋째, 세분 집단별 수용요인을 분석할 후속연구가 필요하다. 넷째, 융합서비스에 적합한 서비스품질 차원을 규명하는 연구가 필요하다. 본 연구는 일반인들을 위한 서비스 개발 및 제공을 위해 우선적으로 고려해야할 사용자의 수용요인을 규명하였다. 성공적인 융합 서비스의 디자인과 사용자 이용을 높이기 위해 향후 실제적인 서비스에 대한 다양한 수용요인을 검증하는 후속연구가 진행되어야 할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 933,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숙명여자대학교 대학원",
		"TITLE": "주성분을 이용한 고빈도 다변량 금융시계열 변동성 분석 =High-frequency multivariate volatility for financial time series using principal component ",
		"AUTHOR": "진민경",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 황선영 참고문헌: p. 44-46",
		"STORE_LOCATION": "숙명여자대학교 도서관",
		"ABSTRACT": "This thesis is concerned with multivariate volatility based on high frequency financial time series. PCA (principal component analysis) is employed to achieve a dimension reduction in multivariate volatility. Various multivariate realized volatilities (RV) are calculated from high frequency data and the optimal RV is suggested using PCA. Specifically, various RVs are compared in harmony with exiting daily volatilities such as Choleski, EWMA and BEKK after utilizing PCA. Real data illustration is made via recent high frequency stock prices of KOSPI 200, Samsung Electronics and Hyundai motor company.",
		"KEYWORD": null
	},
	{
		"ID": 934,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "(A)boosting method for metamodel generation based on large data ",
		"AUTHOR": "Hyuk-HoKwon",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 935,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "건국대학교 대학원",
		"TITLE": "혁신활동이 공기업의 혁신성과에 미치는 영향에 관한 실증분석 :(An)empirical analysis about the public enterprise`s innovation performances affected by innovation activities :SMRT의 혁신활동을 중심으로 =based on the innovation activities of SMRT ",
		"AUTHOR": "김병선",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박선영",
		"STORE_LOCATION": "건국대학교 상허기념도서관",
		"ABSTRACT": "The main purpose of this research is to analyze SMRT`s innovation performance empirically based on the innovation activities, and in the viewpoint of management of technology, to propose improving results for the public organization`s innovation performance. For this reason, as theoretical backgrounds, the author utilized the definition of innovation and the 4 major types innovation of Oslo Manual. In the base of the definition of STEPI about innovation activity, the author carried out studies on advanced research. To analyze SMRT`s innovation performance empirically, conducted reliability test, correlation test, multiple regression analysis on 271 samples those are replied from the staffs of SMRT. The empirical analysis showed the several crucial results. First, as a degree of utilization of SMRT`s internal innovation performance on the innovation activities, the innovation activities give partially positive influence to SMRT`s innovation performance. If the innovation performances of SMRT‘s innovation activities are divided in two of financially or non-financially. 1) financial innovation performances showed statistically significant results in service cost saving or revenue increasing(2/5), labor costs etc. cost saving(3/5), operation revenue increasing(2/7). 2) non-financial innovation performances showed statistically sig- nificant results in service quality improvement(3/5), service produc- tivity increasing(2/5), process management environment & safety improvement(2/5), department communication increasing(3/5), organi- zation management environment & safety improvement(4/5), SMRT‘s brand recognition(2/7), customer satisfaction increasing(3/7). Second, in the case of innovation developments with outside organiz- ations, degrees of collaboration with the innovation partners don`t give us strong positive influence to SMRT`s innovation performance. If the innovation performances of SMRT‘s innovation activities are divided in two, financially or non-financially. 1) financial innovation performances showed significant results statistically in service cost saving or revenue increasing(1/5), labor costs etc. cost saving(2/5), operation revenue increasing(1/5). 2) non-financial innovation performances showed significant results statistically in service quality improvement(1/5), service productivity increasing(1/5), process management environment & safety improve- ment(1/5), department communication increasing(2/5), organization ma- nagement environment & safety improvement(1/5), SMRT‘s brand re- cognition(1/5), customer satisfaction increasing(1/5). Third, the general characteristics of SMRT`s staffs are expected to be affected to the innovation performances, but they don`t affect to the innovation performances. 1) financial innovation performances showed significant results statistically in service cost saving or revenue increasing(2/8), labor costs etc. cost saving(2/8), operation revenue increasing(1/8). 2) non-financial innovation performances showed significant results statistically in service quality improvement(1/8), service productivity increasing(3/8), process management environment & safety impro- vement(2/8), department communication increasing(1/8), organization management environment & safety improvement(0/8), SMRT‘s brand recognition(2/8), customer satisfaction increasing(1/8). The results gives the author some lessons. 1) the author gives the necessity about the ‘technology sharing system’ and ‘communication system’ for the SMRT`s innovation per- formance. 2) the author gives the necessity about the building of ‘a value-oriented share value as a organization culture`. 3) the author gives the necessity of political supporting about the building of big-data. Based on the research lessons, as a result of this research, the author showed the process of raising of the public enterprise`s innovation performances, that is reflected the specificity to operate social infrastructure as a public enterprise and the reality to be required innovative change. The process of raising of the public enterprise`s innovation performances can be expressed to build the ‘technology sharing system’, the ‘communication system’ and ‘a value-oriented share value as a organization culture`. In the viewpoint of management of technology, not only private enterprise but also public enterprise`s innovation performance researches are required widely. Keyword : public organization, innovation activity, service innovation, process innovation, organizational innovation, marketing innovationn",
		"KEYWORD": null
	},
	{
		"ID": 936,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "Reduction of power consumption for pipelined deep packet inspection on FPGA ",
		"AUTHOR": "김한수",
		"REGION": "대한민국",
		"PROFESSOR": "Includes bibliographical references.",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "우리가 사용하고 있는 인터넷 및 네트워크 환경은 우리의 삶에 많은 풍요로움을 제공해 주었지만, 우리의 행복과 안전을 위협하는 많은 위험요소도 가져다 주고 있다. 이러한 문제를 해결하기 위해, DPI (deep packet inspection, 심층 패킷 검사. Snort [2] 등)가 바이러스, 악성코드 및 디도스 공격 등의 위험에 가장 효과적으로 대응하는 기술 중의 하나로 자리매김하게 되었다. 검색의 속도, 정확성 및 문자열 패턴을 저장하는데 필요한 공간의 확보와 더불어, 검색을 수행하는데 소모되는 전력 또한 DPI 시스템의 중요한 문제가 되고 있다. DPI 시스템에 쓰이는 파이프라인형 AC-DFA (Aho-Corasick deterministic finite automaton) 구조에서, 효율적으로 전력 소모를 줄이는 방법들을 제안하였다. 이는 메모리 접근 횟수가 전력 소모에 가장 큰 영향을 끼친다는 것과, 파이프라인형 AC-DFA의 스테이지 사용 횟수가 뒤쪽 스테이지로 갈수록 급격하게 감소한다는 관찰결과에 따른 것이다. 먼저, 파이프라인형 AC-DFA의 스테이지에 할당된 stride를 각 스테이지별로 다르게 하여 전력 소모를 최소화하도록 설정하였고, 문자열의 검색에 이진 검색 기법을 적용하였다. 이러한 방법으로, 최신 DPI 시스템에 비해 약 34%의 전력 소모를 절감할 수 있었다. 또한, 사용되지 않는 스테이지의 동작 클럭을 감소시켜 불필요하게 소모되는 전력을 줄였다. 이러한 방법으로, 최신 DPI 시스템에 비해 약 13%의 전력 절감 효과를 가져왔다. 이러한 두 가지 방법을 모두 사용하여 DPI 시스템을 구현하였고, 최신 DPI 기술들과 전력 소모를 비교하였다. 전력 소모 추정의 오차를 최소화하기 위하여, 실제 구현에 쓰이는 하드웨어 정보들을 알맞게 적용하였다. 그 결과로, 최신 DPI 기술들보다 최대 35%의 전력 소모 절감 효과를 가져오게 되었다. 제안한 방법들은 빅 데이터(big data)의 정보 검색에서부터 디지털 포렌식에 이르기까지, 파이프라인형 DPI 구조 및 다중 패턴 문자열 검색의 어떤 응용에도 손쉽게 적용될 수 있을 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 937,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "국민대학교 테크노디자인전문대학원",
		"TITLE": "A.I. 아바타를 활용한 개인맞춤형 건강관리 콘텐츠디자인에 관한 연구 :A study of A.I. avatar for personalized healthcare contents design : a case study of PHAVATAR app developing ",
		"AUTHOR": "김태원",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 전승규 참고문헌 : p. 112-114",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "현재 전 세계는 디지털 혁명을 기반으로 21세기 시작과 더불어 제4차 산업혁명의 거센 변화의 맞이하고 있다. 제4차 산업혁명은 인공지능과 로봇기술의 확산과 더불어 기존 산업분야의 지각변동과 정보서비스 환경에도 큰 변화가 예상되고 있다. 빅데이터를 비롯한 현재의 정보서비스 환경에서 사용자들이 직면하고 있는 문제점들은 데이터양이 너무 많다는 점과 데이터의 유의미성을 도출하기 위해서는 별도의 전문적 지식을 필요로 하는 경우가 많다는 점 그리고 사용자의 상황에 따라 데이터가 가지는 의미가 유동적일 수 있다는 점 등이다. 또한 경제수준의 상승과 삶의 질에 관한 관심이 높아지면서 헬스케어 역시 정보서비스와 더불어 ‘개인 맞춤형 서비스’의 필요성이 대두되고 있는 상황이다. 개인 맞춤형 서비스는 고객의 만족도를 높이는 목적과 더불어 개인의 특성의 반영을 통해 오차범위를 좁힘으로써 데이터의 정확도를 높이는 역할도 가능하기 때문에 다양한 측면에서 그 필요성은 높아지고 있다. 이러한 환경변화에 부합하는 콘텐츠와 서비스를 제공하기 위해서 고려될 수 있는 방안 가운데 하나는 비트세계에서 사용자를 대신할 수 있는 구체적 대상을 만드는 것이고 이러한 대상으로 아바타(avatar)의 활용 가능성을 고찰하는 것이 본 논문의 목적 가운데 하나이다. 본 논문을 통해 아바타가 활용되어지기 위해서는 지금까지 활용되어온 아바타 개념 전환의 필요성에 관해서도 고찰코자 한다. 과거에 디지털 환경에서 생성된 아바타는 허구의 존재였다. 이러한 아바타는 디지털 환경에서 사용자를 대신하긴 하였지만 개발자가 기획한 허구의 세계에 사용자가 몰입할 수 있도록(immersible) 도와주는 개체로써 활용되는 것이 주된 역할이었다. 과거의 허구적 존재로서 아바타가 헬스케어라는 사용자에게 건강 더 나아가 생명과 관련된 정보를 전달하는 개체로 활용되어지기 위해서는 개념 전환의 필요성이 예상되며, 객관적인 정보를 기반으로 실질적인 사용자 편의 제공을 위한 구체적 기능성 부여의 가능성을 검토하였다. 본 논문은 내용적으로 크게 두 부분으로 구성되어 있다. 2장부터 4장은 이론적 논의에 해당하는 부분으로 제5장의 Phavatar 디자인 적용에 활용할 개념과 관련 분야의 현황 등의 문헌연구를 통해 디자인 방향성 및 방법론 도출이다. 이를 위해 2장은 인터페이스 관련 개념 및 기술, 3장은 인터페이스 디자인 방법론, 4장은 통합적 정보 표현수단으로써의 가능성을 검토하기 위한 이론적 논의를 담고 있다. 세부적인 각장의 구성내용은 다음과 같다. 2장 인터페이스 관련 기술 및 개념은 컴퓨터의 개발 목적과 배경에 해당하는 내용으로 만능기계인 컴퓨터의 개발 의도와 활용 방향성 그리고 인터페이스 관련 기술 및 개념 부분은 1990년대 후반 니콜라스 니그로폰테 교수의 초기 컴퓨터 관련 기술 및 개념을 바탕으로 현재의 기술 현황을 추가하여 정리하는 과정을 통해 현재 사용자중심의 인터페이스 구축을 위한 연구들이 1990년대 제시된 방향성의 연장선상에 있음이 확인되었고 세부적으로는 사용자와 컴퓨터간의 커뮤니케이션 채널의 필요성과 이를 중복 사용하는 중복인터페이스를 구축함으로써 보다 정확한 컴퓨터의 사용자 인식이 가능함을 확인하였다. 또한 인공지능을 도입한 지능 인터페이스에 관한 요구가 예견되었으며, 이것을 구체화하는 방법론으로 디지털 대행자의 도입이 하나의 대안으로 제시되었다. 이러한 내용들을 제시를 통해 아바타를 매개한 인터페이스 구축의 타당성에 관한 객관화를 시도하였다. 인터페이스 디자인의 방향성을 도출하기 위해 인터페이스 분야의 두 거장, 도널드 노먼과 존 마에다의 비슷한 시기에 출간된 인터페이스와 관련된 저서인 ‘심플은 답이 아니다’와 ‘단순함의 법칙’을 기준으로 저자들의 다른 저서와 영상자료들의 교차 검토를 과정을 통해 사용자들이 단순하지만 다양한 기능의 운용이 가능한 직관적 인터페이스의 요구를 확인하였고 이를 위한 통합 매개체의 도입이 하나의 대안으로 제시될 수 있음이 파악되었다. 4장은 정보표현 수단으로써 아바타의 타당성을 검토하기 위해 정보환경의 변화와 현재의 IoT환경에 관한 조망, 그리고 아바타와 관련된 내용의 검토를 아바타 활용에 따른 기대 효과를 도출하였다. 앞의 문헌 연구를 통해 도출된 방향성과 방법론을 반영한 디자인 사례를 제시하였으며 그 개발과정을 기술하기 위해 먼저 대상이 되는 건강관련 내용의 제시, 사용자의 건강관련 데이터 수집과 관련 장치 현황, 헬스케어 앱 분석을 위해 추가 개발된 알고리즘 소개, 데이터 수집 절차 및 방법, 주요화면 소개 등을 제시하였다. 건강관련 내용을 독립된 장으로 다루지 않고 개발과정에 포함시킨 이유는 아바타를 활용한 인터페이스가 사용자의 건강정보에만 적합한 것으로 논의되는 오류를 막기 위한 의도된 구성이었다. 결론으로 현재 구글, 페이스북, 트윗터 등의 인터넷 서비스 업체간 사용자의 통합 계정 서비스는 각 서비스 업체별로 분절되어 있는 사용자 정보의 통합 정보 파급력을 반증하는 업계동향으로 파악되며 이러한 움직임은 급속도로 확산되고 있다. 사용자 정보의 통합을 통한 가장 큰 수혜자가 사용자가 되어야 한다는 점에서 아바타는 비트세계에 서비스 업체들을 기준으로 흩어져 있는 사용자 정보가 통합될 수 있는 환경을 제공하는 대안으로 활용되어질 수 있을 것이다. 또한 아바타를 활용한 인터페이스는 사용자에게 친근하고 직관적 활용이 가능한 보다 진보된 형태의 사용자중심 인터페이스를 제공할 수 있을 것이다. 본 논문을 통해 마련된 아바타를 활용한 인터페이스 구축의 방안을 토대로 다양한 분야의 전문가들과 협업을 통해 이를 실현하는 노력을 이어가고자 한다. 그리고 본 논문을 통해 제시되고 있는 바와 같이 추상적인 비전을 구체화하여 각 분야의 전문가들이 협업할 수 있는 토대를 마련하여 노력을 결집시키는 역할이 현재에 전문분야별로 세분화되어있는 환경에서 그 필요성 점점 더 부각될 것으로 판단되며 제4차 산업혁명은 전문분야들의 재조합과 통합의 완결된 모습으로 마무리될 것이다. 그 변화의 중심에서 디자이너들이 역할 할 수 있기를 희망한다.",
		"KEYWORD": null
	},
	{
		"ID": 938,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "Hierarchical parameter analysis of PCB manufacturing processes using data mining technologies =데이터 마이닝 기법을 이용한 PCB 제조공정의 계층적 요인 분석 방법론 ",
		"AUTHOR": "HyunSikSim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 939,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "블록체인 기술 수용의도에 영향을 미치는 요인에 관한 연구 =A study on factors affecting the intention to accept blockchain technology ",
		"AUTHOR": "김정석",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 김광용 참고문헌: p. 87-101",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "In a hyper-connected society, intelligence networks create new values in all aspects of society and the recent advances in artificial intelligence(AI), Internet of Things(IoT), big data and emerging convergence technologies show that we are at the doorsteps of entering such a society. A bitcoin-based technology named blockchain is garnering attention in various industries as a cost-effective measure in strengthening security and a reliable technology medium. Blockchain technology will play a critical role in the Fourth Industrial Revolution, and IT technology is expected to bring fundamental changes. Most of the current studies focus on the state of blockchain technology and their types, examples, and future aspects while offering few if none in systematic studies of its technologic acceptability. Therefore, the present study focuses on the characteristics of blockchain technology and the effects of the intention to accept its technology in an empirical manner. The aspects of the technology are organized by researching blockchain technology and theories of technology acceptability and previous studies were used as guidelines to create the research model and propose the hypothesis. The research model is based on UTAUT with a set-up of 5 factors (security, availability, reliability, diversity, and economic efficiency) for performance expectancy and effort expectancy. For empirical analysis, a survey was conducted on 283 IT workers in Korea, and SPSS and AMOS were used as the analytical tools. To examine the hypothesis structural equation modeling was used performance expectancy was influenced by security, reliability, diversity, and economic efficiency while effort expectancy was influenced by reliability and economic efficiency. Performance expectancy, social influence, facilitating conditions affect the intention to accept. Innovativeness of an organization and control effects are influenced as well. The present study aims to provide practical guidance as supplementary research in utilizing blockchain technology, and the limitations of the study and future research possibilities are discussed as well.",
		"KEYWORD": "Blockchain,기술수용,블록체인"
	},
	{
		"ID": 940,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 기업경영대학원",
		"TITLE": "SNS와 스토리텔링 감성 마케팅의 융합방안에 관한 연구 =(A)study on the convergence of SNS and storytelling emotional marketing ",
		"AUTHOR": "성준모",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이성욱 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 57-58",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "국문요지 스마트폰이 일상화되어 소셜미디어를 통한 기업체 마케팅이 격화되고 있는 상황에서 스토리텔링 기법을 통한 감성 마케팅은 소비자의 마음을 먼저 이해하는 것에서 출발한다. SNS 연구들은 아직까지 마케팅 커뮤니케이션 효과 측면 에서의 연구 이슈들을 벗어나지 못하고 있으며, 이에 서비스, 특히 융합 서비스 활용 도구로써 기업 발전을 위한 활용방안이 필요한 시점이다. 진정한 스토리텔링 감성 마케팅이 되기 위해서는 고객을 참여시켜 보편화시키고 상호교환하면서 재창조할 수 있는 환경을 만드는 것이 중요하다. 그러한 SNS와 스토리텔링 감성 마케팅의 성공적 융합을 통한 사례로 우루사와 박카스에 대해 연구하였다. 본 연구의 목적은 스토리텔링을 통한 감성적 이야기 자체로도 소비자에게 흥미와 관심을 끌고, SNS를 통한 피드백과 함께 감성 측정툴 개발의 필요성도 증가할 것이 예측됨에 따라 SNS와 스토리텔링 감성 마케팅의 핵심요소와 형태를 정의하고, 이를 기반으로 사례분석을 통해 융합 방안을 제시하는 것이다. 이야기를 가지고 사람의 감성을 사로잡을 수 있는 마케팅을 하는 것이 최근 업계의 흐름이다. 또한 이는 모두 스토리텔링을 기반으로 한다는 점은 소비자의 감성을 자극하는 요소로 그 효과가 높았기 때문이라 할 수 있다. 이에 따라 스토리텔링을 기반으로 한 감성 마케팅의 활용 방법에 대해 연구해 보고 그 융합방안을 제시하면 다음과 같다. 첫 번째로 보다 빠른 감성 피드백과 함께 소비자의 감성을 미리 예측하고 계량화할 수 있는 툴을 개발하는 것이 필요하다. 두 번째로 감성 ICT 산업 아이템 중 모바일 기기의 SNS와 연계되어 체험 및 사용자 편의성을 중심으로 인간의 감성을 인지하여 피드백 해 주는 개인감성 맞춤형 스토리텔링 마케팅 융합 방안이 필요하다. 세 번째로 감성마케팅 실행의 전단계로써 빅데이터와 SNS 데이터의 융합 분석이 필요하다. 본 연구의 한계점으로는 특정 기간 내에 연구를 끝내야 하는 시간적 제약과 문헌위주로 자료를 수집할 수밖에 없었던 상황으로 인하여 본 연구의 결과를 일반화하는 데는 약간의 한계가 있을 수 있다. 따라서 앞으로는 이러한 점을 충분히 고려하여 연구를 진행하여야 할 것이다.",
		"KEYWORD": "마케팅"
	},
	{
		"ID": 941,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "홍익대학교 국제디자인전문대학원",
		"TITLE": "여가만족도 향상을 위한 가상현실게임과 u-Healthcare 기반의 피트니스 서비스 제안 ",
		"AUTHOR": "배장은",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 김승인 참고문헌(p. 63-71)수록 서지적각주수록",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "In modern society, the meaning of leisure is much beyond than a concept of resting time, it`s more about achieving self-development and self-realization by creative and productive activities. Therefore, it is comprehensible that satisfaction which comes from the leisure activities is directly connected to the individual`s happiness. However South Korea is one of the countries which has the longest working and studying hours among OECD member countries and leisure activity time is relatively very short, so it`s easy to encounter Koreans who spend their time doing inactive activities such as watching TV. Thus these restrictions of leisure activities seem to have relevance to low happiness level in Korea. To let people feel more satisfied and happy from leisure activities, social system has to be changed to allow more time for leisure activity and to provide more opportunities to enjoy various leisure activities should be provided by extending infrastructure for leisure activities. This study aims to develop new leisure activity service to improve leisure satisfaction of customers considering Korean social property and various age groups, by a service design methodology; ‘Double Diamond Model’. First step of this study which called discovering step, by analyzing Korean`s leisure activities it was shown that most of the Korean`s leisure activities were such as watching tv, surfing internet or playing games, etc, due to lack of time, cost and facilities. Advanced researches confirm that sports activity groups have the highest happiness level among many leisure activity groups. As a result of integrating leisure activities and interests for each group of ages the biggest part is assigned to internet games, sports, and health management ;field observations in internet cafes, health clubs and hospitals helped to understand customer types and behaviors for each group of ages. Therefore, it was possible to search a leisure activity service which allows to apply to all group pf ages combination of game, sport and health management. Second, in defining step with all the research databases, users are divided into three user groups which represents high school students in 10s, office workers in 30s and independent businessmen in 50s and for each type`s leisure activity experiences and expected situations are classified by affinity diagram. And designing each age`s persona and user`s itinerary map allows to understand concrete needs of users. In case of high school students in 10s, they can access easily to the leisure activities through internet cafe and internet games but they are not free from many limitations which are made to prevent excessive game immersions. In case of office workers in 30s, their leisure are reflecting Korean young adults and middle-aged people’s lifestyle such as Korean working culture with many overtime works and company dinners and lifestyle with many interests in appearances. In case of independent businessmen in 50s, they are old consumers who definitely have less time for leisure activities and care about their personal health conditions. Third, in developing step, service ideas were derived from analysis and insights. This service defines key words as accessibility, gamification and u-Healthcare, and the system w is designed to conduct the game play and exercise at once to introduce virtual reality game space in the most common place of sports activities; health club. Also, through a wearable device which records athletic performances in real time and send to mobiles or web to draw ideas to allow personal health management whenever and wherever; visual factors such as sketches, each users`s and story boards developed the ideas much more. Fourth, in delivering step, we name this service as ‘VR FIT’ and develop a prototype for service application to send specific service contents visually. So, users gets a temporary password by a Smart Watch for check-in and a locker in the health club by and this Smart Watch senses the starting of exercise and measures the records in real time to make accumulated records into data. Also in ‘VR Room’ inside the health club, users can enjoy game and exercise in the same time through HMD and virtual reality treadmill and users can have exercise records by mobile and web to manage their health systematically. This service is a convergent leisure activity service which allows sports activities, games, health management at once and can provide high satisfaction of leisure activities to customers in all group of age. To commercialize this service, many contents for virtual reality and wearable devices should be developed in advance, and test operations are required to measure sports effect and customer satisfaction by virtual reality and following studies are required to review profitability of business model. There are concerns about leakage of `big data` related to personal information such as life log and etc, which are easily chased by wearable devices and of course, personal information protection policy and security technology in Korea should be enforced more. By suggesting fitness service for sustainable leisure activities, this study expects to improve the people`s satisfaction of leisure activities which is connected to people`s happiness and there is significance as a oncoming business model.",
		"KEYWORD": null
	},
	{
		"ID": 942,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "공공부문의 정보시스템유지보수업체 선정을 위한 평가모델에 관한 실증적 연구 =(An)empirical study of source selection and evaluation model for the maintenance of information systems in the public sector ",
		"AUTHOR": "권기학",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "최근 정보시스템은 스마트 전자정부 구현, 클라우드 컴퓨팅의 발전 및 확산, 빅데이터 등의 신기술을 적용하여 서비스가 고도화되고 복잡화 되는 추세이다. 이러한 정보시스템의 효율적인 서비스를 위해서는 안정적인 유지보수가 필수이다. 중견?중소SI(System Integration)기업들은 대기업군SI기업에 비해 위험관리, 품질관리, 사업관리, 기술지원 등이 한계적이어서 조직적 역량과 기술지원적 역량이 매우 부족하다. 이러한 문제를 해결할 수 있는 방법은 합리적인 평가기준에 따라 최적의 유지보수업체를 선정하는 것이다. 그러나 공공부문의 정보시스템유지보수업체 선정을 위한 평가모델에 관한 연구가 부족한 실정이다. 본 논문의 목적은 공공부문의 정보시스템유지보수업체를 선정하기 위한 평가모델을 제시하는 것이다. 이 논문의 연구범위는 공공부문의 정보시스템유지보수분야이다. 본 논문의 연구방법은 국제 표준을 연구하여 설문의 항목을 도출하고 전문가의 의견 수렴을 통하여 검증하는 것이다. 본 논문의 연구결과를 활용시 합리적인 평가가 가능하므로 공공부문의 정보시스템유지보수업체 선정에 크게 기여할 것이다.",
		"KEYWORD": "정보시스템유지보수업체,평가모텔"
	},
	{
		"ID": 943,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "DANBI :a programming model and runtime for dynamic and scalable stream parallelism :동적 확장가능한 스트림 병렬화를 위한 프로그래밍 모델 및 런타임 ",
		"AUTHOR": "ChangwooMin",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 944,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "SDN/OpenFlow환경에서 Legacy Network와의 연동기술에 관한 연구 =A study on interconnection technology with legacy network in SDN/OpenFlow environment ",
		"AUTHOR": "백동희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최재영",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "소프트웨어 정의 네트워킹(SDN:Sofrware Defined Networking. 이하 SDN)의 핵심은 Legacy Network 장비에서 Hardware와 Software 기능을 분리하여 서비스하는 기술이다. 지금까지 Hardware에 의해 정해진 기능만 수행해오던 Network 장비들이 Software기반의 네트워크 사용을 통해 기존 방식보다 유연하고 효율적으로 Network 환경을 사용할 수 있도록 하는 기술로 예측된다. 다가오는 5G 및 IoT환경, 빅데이터의 시대에서는 사용자가 요구하는 서비스 운영을 위해 SDN이 핵심기술로 자리잡게 될 것으로 예상된다. 주요 기업들은 지속적으로 기술 개발을 추진하고 있으며, SDN을 실제 Network 환경에 적용하고자 활발하게 연구 활동을 진행하고 있다. 그러나 현재 설치되어 있는 네트워크 장비와 SDN과의 연동방안에 대해서는 구체적인 대안이나 사례를 찾아보기 힘들다. 현재 운영중인 Legacy Network 환경에서 SDN 장비를 도입할 경우 많은 문제가 예상되므로, 다양한 각도에서 연구하여 효과적인 SDN 연동 방안이 필요한 시점이다. 본 논문은 기존 Legacy Network과 SDN/OpenFlow을 연구하고 이 둘의 효과적인 연동기술을 제안하고자 한다. 우선 Legacy Network을 이해하고, SDN의 개념과 SDN 구축기술 중 하나인 OpenFlow의 동작원리를 설명한다. 그리고 Legacy Network 장비 동작방식에 SDN/ OpenFlow의 중앙 집중제어 기술을 추가시킨 Hybrid OpenFlow 장비를 설계하며, Legacy Network와 SDN/OpenFlow를 효과적으로 적용시킬 수 있는 Network 구성을 제안한다. 앞으로는 Legacy Network의 구조 별로 SDN을 연동할 수 있는 Network 구성에 대한 가이드라인이나 지침 등이 명시될 수 있도록 많은 연구가 필요하다.",
		"KEYWORD": "Network,OpenFlow,SDN"
	},
	{
		"ID": 945,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 스마트도시과학경영대학원",
		"TITLE": "파라메트릭 기반 사용자 맞춤형 주거모델 자동생성 시스템 구현 :Parametric based, user-customized automatic generative housing model system realization :단독주거 고령 사용자를 대상으로 =focused on the detached house for older users ",
		"AUTHOR": "허준우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 정재희 국·영문초록수록 참고문헌: p. 97-99",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "Until now, both domestic and overseas residential buildings have been mainly systems distributed and designed with planner’s intentions. However, as tastes and styles of the modern users became more diverse, it became difficult to easily and clearly categorize users into few homogenous types. Following this social change, user-customized design is being demanded from industry markets in general, through the rapid development of technology in various fields. For example, the development of user-customized technology by development of information technology based on big-data, the introduction of flexible generative technology through convergence of computer IT technology as design methodology and the change from analog design process to digital design process. Moreover, while the needs for development of user-customized housing is being expanded, research until now has been focused solely on quantitative character analysis of users or has not fully considered the qualitative aspects. However, today there are many researches in progress for user-customized designs in various industry markets. Therefore in this research, based on periodic and sociological background and using IT technology (generative design technology) to match the user’s quantitative and qualitative characteristics, we wish to implement research into flexible service provision technology, to build a user-customization housing model auto-generation system. Moreover, the objective of this research is the creation of a user-customization housing model auto-generation system based on parametric, to suggest a user-customized housing model to the housing market in a effective and economic way. To do this, unlike previous research which unilaterally provided a service from user categorization through unilateral classification, this research will deduct quantitative and qualitative characteristics of each user and make it applicable to the housing model. Through this, we wish to build a system which can automatically generate a customized housing model for each user. Moreover, with creation of aparametric-based user-customized housing model auto-generation system, we hope that the convergence research in architectural design technology and IT technology can be utilized as basic research resource for user-customized housing. To implement a generative system using various variables according to user characteristics factor analysis, the usage for system and various scopes must be set up. Therefore in this research, the usage for system was decided as user-customized housing model generation, and the scope of users was decided as elderly, over 65 years of age. This is because, for generation of user-customized housing model based on parametric, the detailed analysis of user characteristics factor and quantitative and objective values must be extracted. Elderly people over 65 years of age were elected as scope of users, considering that they possess user characteristic factors which stand out compared to other various age groups, and the issue of aging society has been magnified. Moreover, to generate a housing model by combining various variables of user characteristic factors, the specific definition and form about the housing model was necessary. Therefore in this research, the definition of housing model is defined as detached house use, which has architectural space volume, which means space size of external shape and space, and energy usage information according to mass. This is the setting of timely and physical limitation for all types of housing model, to increase the significance of the result value. Lastly, as this research designed and built an architectural design methodology based on generative system theory, the focus was centered on generative design technology based on parametric from the fields of generative systems. For research methodology, first by literature research and analysis of previous works, the comprehensive concept, technology and case studies of generative system and user-customized materialization technology was analyzed. Secondly, as the basic resource for the automatic generation of user-customized housing model, we analyzed characteristics of elderly to set up architectural design variables. Thirdly, architectural design variables from elderly character analysis was indexed and optimized so that it can be used for generative design algorithm. Fourth, the research for generation of algorithm for auto-generation of user-customized housing model was implemented. Lastly, using the deducted design variable process and housing model auto-generation algorithm, the creation for user-customization housing model auto-generated system was implemented. Through this type of research, unlike the existing design processes, generative system was utilized and parameters were applied to the design algorithm, and this was introduced into the user (elderly)-customized housing model generation system. As a result, we were able to observe the generation of many design alternatives, in an effective and economic way, through the generative designs from various parameters. Through this, it was concluded that this system supported the user’s decision making, when he directly generates and selects a housing model. However, with the housing model information of this research such as architectural space volume, size of each space and energy usage information, there will be difficulty to the general user when he perceives an architectural space or selects a housing. Moreover, for the progress of convergence technology such as architecture plus IT technology, expert knowledge will be needed to analyze and understand users’ behavioral pattern and to apply it to design. Furthermore, the completeness of design alternatives and credibility problem of parameters will need to be proven. Additionally, research should be implemented to provide convenience to the user, with interface design focused on user convenience and various applications and IT devices based on IT technology, utilized for the users’ easy usage.",
		"KEYWORD": null
	},
	{
		"ID": 946,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "단국대학교 대학원",
		"TITLE": "옴니채널쇼핑 도입의도와 기대효과에 관한 연구 :(A)study on the intention to adopt omni-channel shopping and expected effects :혁신확산이론과 TOE 프레임워크를 중심으로 =focusing on innovation diffusion theory and TOE framework ",
		"AUTHOR": "김병철",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수:오재인 참고문헌 : p. 103-118",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "With the spread of the Internet and smartphone, the traditional purchase of goods from offline stores is evolving to the purchase of desired goods at the most reasonable price regardless of online/offline. Such an innovation of shopping was started by the name of ‘omni?channel shopping,’ and is introduced as a representative case of online/offline fusion. Recently, firms of distribution business are concentrating their interest on omni?channel shopping in order to overcome the stagnant Revenue growth of individual distribution channels. Omni?channel shopping can take advantage of the strengths of each distribution channel by providing customers with unceasing experiences. In addition, related services are developing gradually through the convergence and fusion of multiple channels and functions based on various information technologies including the Internet, mobile devices, and big data. Now customers have arrived at the age of effortless shopping. Omni?channel shopping is now being tried by a few leading companies, and paid highly-elated attention to by scholars that encourage omni?channel shopping as a future method of shopping. Thus, the purpose of this study was to identify factors affecting firm’s intention to adopt omni?channel shopping and to analyse what significance there is between intention to adopt omni?channel shopping and expected effects. To begin with, in order to identify factors affecting intention to adopt omni?channel shopping, this study explored previous studies and theories that verified the intention of introduction of IT and e?Commerce that are the foundation of omni?channel shopping. Out of them, this study subsequently managed to develope a structural equation research model based on the Innovation Diffusion Theory(IDT) and TOE Framework that were tested exhaustively on a theoretical base. This study applied descriptive statistics, exploratory factor analysis, and CMB testing for each variable using SPSS 20, and performed confirmatory factor analysis, hypothesis testing, and moderating effect analysis using SmartPLS 3. The overall research model was built as a structural equation model for enhancing the explanatory power of the model and explaining the findings reliably. The results of these analyses were as follows. From the revised research model were derived nine hypotheses, and they were tested and seven of them were adopted while two in technological context were rejected. That is, among the independent variables, technical readiness and complexity in technological context were rejected, and the hypotheses that relative advantage, top management support, environmental effect, and external support would have a positive effect on intention to adopt omni?channel shopping were adopted. What is more, the three hypotheses that the adoption of omni?channel shopping would bring positive expected effects to sales, internal operation, and brand image were found to be significant. In the results of analyzing moderating effect by group, significant results were observed partially for major classes of target customers and involvement in major products, but a moderating effect by group was not observed for company size. This study attempted to analyse the intention of introduction of omni?channel shopping and expected effects by using the Innovation Diffusion Theory and TOE Framework. What is more, the findings of this study are meaningful in that they spread the importance of new distribution innovation like the advent of omni?channel shopping to the industry and present the importance of related researches in the academic field.",
		"KEYWORD": null
	},
	{
		"ID": 947,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "전시참관객의 개인화 모바일서비스 사용의도에 미치는 요인에 관한 연구 =(A)study on factors affecting usage intention of exhibition attendees on personalized mobile service ",
		"AUTHOR": "고준용",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 한경석",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "전시산업은 21세기 지식집약, 환경 친화적 고부가가치 산업이며, 고 외화 가득률 산업이다. 엑스포, 코엑스, 킨텍스등 다양한 전시회와 컨벤션행사로 국가 발전에 크게 기여하고 있으며 다양한 주요 행사를 도맡아 함으로서 성공적으로 수행을 했다. 최근 들어 웹3.0, 모바일 3.0, 스마트 2.0시대, MICE산업 3.0등 새로운 시대임을 표현하는 다양한 신종어가 탄생하고 있으며 모바일 기술과 웹기술, 디바이스 기술과 연계된 새로운 제품군이 시장에 태어나고 있다. 이러한 기술을 통해 전시산업에도 위치센서, QR바코드, NFC등과 같은 장치와 모바일과 연결된 서비스로 발전되고 있다. 이러한 기술을 통하여 개인화 맞춤 정보 서비스의 제공으로 참관객들은 전시 공간 내에서 복잡함을 피하고 공간과 시간의 효율적인 관리를 할 수 있는 전시산업으로 발전되고 있다. 개인화 모바일 디바이스의 보급과 개인화의 중요성에 따라 개인화와 모바일 서비스와 연계된 연구 및 개발이 교육, 의료, 의류, 콘텐츠, 관광등 다양한 부분에서 연구가 활발히 진행되고 있다. 하지만 위에서 논한 것처럼 전시산업이 중요한 산업인 것에 반해 전시산업과 IT기술과 연계된 시스템연구와 논문이 많이 부족하다. 전시산업과 연계된 IT기술의 경우 참관객이 웹을 통하여 등록을 하고 전시장에 각종 부스안내, 세미나 안내를 받을 수 있는 모바일 서비스가 독일, 홍콩에서 활발히 진행되고 있으며 한국 전시장에서도 시도를 하고 있다. 위치센서나 QR코드 등을 통하여 좀 더 참관객들에게 맞춤형서비스를 하기 위하여 산·학·연을 중심으로 프로토타입으로도 연구 및 개발되고 있다. 또한 IT발달과 다양한 디바이스의 발달로 새로운 매체로서의 잠재력을 알게 되면서 웹을 보다 더 진화한 형태의 핵심적 마케팅 수단으로 사용하려는 노력을 하였고 연계된 많은 연구가 진행되고 있다. 어떠한 매체보다 효과적이고 뛰어난 인터넷의 쌍방향성과 인터렉티브한 기능을 이용한 개인화 마케팅이 그것이다. 즉. 고객은 대중도 특정집단도 아닌 개인으로 세분화되고, 이러한 개별 단위로 저장이 되는 개인의 정보 데이터베이스를 기반으로 각각의 욕구에 맞도록 차별화된 서비스를 제공받게 되는 것이다. 향후에 개인화모바일 서비스를 통해 기업은 고객 개개인과 의사소통을 하게 되어 그들의 요구가 무엇인지 정확하게 파악하여 제품의 개발이나 마케팅에 활용할 수 있으며 미래의 고객이 어떻게 변화하게 될 것인가를 정확하게 예측하게 되는 것이고 이렇게 수집된 데이터들은 향후 빅데이터분석과 연계되어 더 유용한 자료로 사용될 수 있다. 이러한 IT기술과 개인화모바일 서비스를 개발하고 제품을 발전시키는 것도 중요하지만 이러한 지능형 개인화 모바일 서비스가 전시참관객들에게 어떠한 특징들을 선호하고 어떠한 요인들이 필요한지 연구가 필요하다. 또한 이번 연구 중에 문헌연구와 선행연구를 찾아보면서 전시산업관련 전시참관객의 정보시스템 수용에 대한 연구가 많이 부족함을 느꼈다. 그래서 본 연구를 통한 결과는 향후 전시산업에서의 전시회참관객이 개인화모바일서비스 이용 시 참관객이 필요로 하는 요인 분석으로 효과적인 서비스와 기능을 구현하고 전시산업 정책을 세우는 데 일조할 것으로 기대하여 본다.",
		"KEYWORD": "개인화,모바일서비스,전시,전시참관객"
	},
	{
		"ID": 948,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 공학대학원",
		"TITLE": "전로베어링 감시시스템 구축 프로젝트의 위험관리 방안 =A study on the improvement of risk management process for condition monitoring system for converter bearing ",
		"AUTHOR": "김성진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 강창욱 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 36",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "스마트 팩토리(Smart Factory)는 제 4차 산업혁명으로 불리는 ICT (Information Communication Technology)와 제조업의 융합으로 기계 스스로 시뮬레이션을 통해 자동 생산하는 시스템이 구축된 공장으로 공장 안에 있는 모든 설비와 기계 장비에 무선 네트워크 센서를 부착하여 그 정보를 중앙에서 수집하고 관리하는 시스템을 기반으로서, 한 공장으로 중앙서버에서 빅데이터 기술과 사물 인터넷 기술을 기반으로 현재 공장에 설치된 다양한 기기, 설비 심지어는 작업자의 상태를 파악하여 상황에 따라 빠른 처리를 가능하게 만든 후 이러한 시스템을 통해 제조 과정에서 발생할 수 있는 다양한 변수와 데이터를 예측 가능하도록 만드는 장소라고 정의할 수 있다. 스마트 팩토리 프로젝트의 일환인 전로베어링 감시시스템 구축 프로젝트 성공 확률을 높이기 위해서는 그 위험요인을 확인하고 그 상대적 중요도를 파악 하여야 하는데, 그 위험 요인을 모두 식별하고 관리하기란 쉽지 않다. 현실적으로 프로젝트 진행 시 발생할 수 있는 위험 요인이 매우 많고, 각 전로마다 특성이 있어 그 특성을 반영한 자료가 정리된 경우는 거의 없다. 본 연구에서는 전로베어링 감시시스템 구축 프로젝트의 위험 요인들을 파악하고 효과적인 프로젝트 관리를 위하여 각 위험 요소들 간의 상대적 중요도를 파악 후 이를 활용하여 프로젝트의 성공 확률을 높이는데 그 목적이 있다.",
		"KEYWORD": "생산관리"
	},
	{
		"ID": 949,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 정보과학대학원",
		"TITLE": "멀티코어 프로세서 기반의 ARIA 암호 알고리즘 병렬처리 연구 =(A)study on parallel ARIA cipher algorithm base on multi-core processor ",
		"AUTHOR": "김현승",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 박재표 참고문헌: p. 35",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "현대 사회가 정보화, 통신화롤 접어들면서 강력한 보안을 요구하기 시작했다. 이는 작은 데이터를 다루는 IoT부터 크기가 크고 많은 데이터를 다루는 빅데이터까지 모두 요구되는 사항이다. 하지만 기존의 암호 알고리즘은 멀티코어 프로세서 상에서는 공유자원에 대한 비효율적인 사용으로 성능향상을 기대하기 어려웠다. 본 논문에서는 국산 암호 알고리즘에 대해 정의하고, 멀티코어 프로세서 환경에서 자원 효율성을 극대화 하는 알고리즘 설계를 제안하고자 한다. ARIA 암호 알고리즘의 주요 함수인 치환, 확산, 키 확장에 포함 된 비트연산에 대해 OpenMP로 병렬화 한다. 병렬 처리된 암호 알고리즘에 대해 시간 소요, 시간 복잡도 대소비교, 포맷 지원을 확인하였고 기존의 ARIA 암호 알고리즘에 비해 쿼드코어 기준 처리속도 두 배 향상을 확인하였다. 이러한 병렬화를 통해 IoT, 클라우드, 빅데이터 등 다양한 멀티코어 프로세서 기반의 통신 환경에서 병렬처리 된 암호 알고리즘을 사용할 수 있음을 확인하였다. 하지만 병렬화 시 생기는 잦은 오버헤드와 소형 멀티프로세서에 대한 병렬화에 대한 차후 연구가 필요하다.",
		"KEYWORD": "ARIA,OpenMP,멀티코어 프로세서,병렬처리"
	},
	{
		"ID": 950,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "서울과학기술대학교 NID융합기술대학원",
		"TITLE": "웹3.0 시대 소비재 기업을 위한 웹사이트 디자인 제안 :Suggestions on the website design for consumer-goods producers in the era of web 3.0 :경동나비엔 웹사이트 구축사례를 중심으로 =focused on a website development case of `Kyungdong Na[v]ien` ",
		"AUTHOR": "선경",
		"REGION": "서울",
		"PROFESSOR": "지도교수:홍석기",
		"STORE_LOCATION": "서울과학기술대학교 도서관",
		"ABSTRACT": "정보와 기술이 발전함에 따라 인터넷상에 웹은 꾸준히 진화하고 있다. 현재 웹은 2.0 시대를 넘어 웹 3.0시대까지 도래하였다. 웹 2.0의 특징은 참여, 공유, 개방이 키워드로 사용자에 의해 데이터가 급격하게 증가하였고, 이러한 데이터의 급격한 증가는 필요한 자료가 점점 방대해 지는 것으로 느낄 수 있지만 사용자들은 페이지수가 늘어나고 쓸데없는 자료 또한 넘쳐나는 것에 불편함을 느끼고 있다. 여기서 웹 2.0의 한계가 있었다. 웹 2.0은 참여, 공유, 개방으로 사람들을 연결하여 사회적 연결성은 높지만, 공유된 정보를 연결하는 정보적 연결성에 대한 방법으로 시맨틱 웹을 출현시켰다. 하지만 시맨틱 웹이란 말만 무성할 뿐 딱히 대응책은 없었다. 웹 3.0과 웹2.0시대에 대해 명확히 구분을 짓자면, 웹3.0 시대는 지식기반 사회에서 최적화된 정보를 연결을 중심으로 발전 때문에 정보적 연결성이 매우 높은 것이 특징이라고 할 수 있다. 즉 웹3.0은 웹2.0의 한계를 극복하고 지능화된 웹 환경을 구축하기 위해 출현했다. 웹 3.0의 시맨틱 웹, 실시간 웹, 클라우드 컴퓨팅, 빅데이터의 대응, 모바일에 대한 서비스로 모두 지능형 서비스를 위한 기술력이다. 웹 3.0은 컴퓨터가 정보자원의 뜻을 이해하고 논리적 추론까지 함으로써 이용자의 패턴을 추론해 사용자에게 꼭 맞는 서비스를 제공할 수 있는 지능형 웹은 물론 실시간 웹의 특징인 사용자 참여형 인터넷 환경의 시대로 나아가고 있는 것이다. 시대의 변화에 맞춰 웹에서 제공되는 서비스에 대한 개선은 반드시 이루어 져야한다. 시대가 변한만큼 사용자의 요구도 변했기 때문이다. 사용자의 요구가 변화함에 따라 기업의 웹사이트 디자인도 많은 변화를 거듭하고 있다. 기업은 시대의 변화에 따라 사용자가 원하는 웹사이트 상에 서비스를 제공해야하고, 효율적인 웹사이트 운영을 위해 적극적으로 노력해야한다. 본 연구의 목적은 소비재 기업에서 웹사이트를 제작할 때, 시대에 따라 발전된 기술력을 사용자가 요구하는 콘텐트, 디자인, 기능적 요소에 적용시킴으로써 시대적 변화에 따른 사용자에게 적합한 웹사이트의 디자인을 제안하는 것에 있다. 따라서 본 연구에서는 현재 많은 기업에서 시대의 변화와 사용자의 요구에 적합한 웹사이트 디자인을 하기 위해 앞서 웹3.0시대의 변화에 대한 시대적 특징과 이론을 고찰하여, 웹3.0 시대의 웹사이트가 갖춰야할 요소에 대해 파악한다. 도출된 요소는 콘텐트, 디자인과 기능에 있어 중요한 요소로써 기업 웹사이트 디자인 제안 시 중점적으로 연구한다. 개선할 웹사이트 디자인 제안을 위해 동종업계 중 국내 기업 중 3곳의 실태를 살펴본 후 공통점, 차이점을 비교 분석한다. 그리고 개선대상의 문제점을 파악하기 위해 온라인 게시판과 콜센터로 접수된 사용자 불만사항의 유형을 파악하였다. 사용자 요구사항과 동종업계의 분석 요소는 경동나비엔의 웹사이트 개선 시 키워드로 활용하여 개선한다. 그리고 경동나비엔의 현재 웹사이트 디자인의 문제점을 파악하고, 앞서 도출된 결과를 바탕으로 디자인 콘셉을 기립한 후 콘텐트와 디자인의 방향을 설정하여 웹 사이트 디자인을 제안한다. 디자인 제안에 있어 모바일의 대응을 중점적으로 그리드 디자인을 적용한 반응형 웹사이트를 제작한다. 이와 같은 연구 결과는 소비재 기업이 웹사이트를 통해 시대에 맞는 기술을 적용한 웹사이트를 서비스함으로써 사용자와 커뮤니케이션을 하고 신속하고 정확한 정보 전달과 더불어 기업 이미지를 향상할 수 있을 것이며, 시대에 바람직한 웹사이트로 나아가기 위한 디자인 방안으로 활용할 수 있을 것이다.",
		"KEYWORD": "big data,Cloud Computing,mobile,Semantic,SNS,web3.0,그리드디자인,기업웹사이트,반응형웹,시맨틱웹,웹3.0,웹디자인"
	},
	{
		"ID": 951,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 언론정보대학원",
		"TITLE": "소비자 라이프스타일과 O2O 서비스 특성에 대한 인식에 관한 연구 :(A)study on consumer lifestyle and perception of O2O service characteristics :O2O 서비스 이용빈도와 구전의도를 중심으로 =focusing on the frequency of service use and intention of word of mouth ",
		"AUTHOR": "오용석",
		"REGION": "서울",
		"PROFESSOR": "부록 수록 지도교수: 한미정 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 66-78",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "국문요지 ICT(Information & Communication Technology, 정보통신기술)의 성장으로 소비시장은 새롭게 변화하고 있다. 새로운 변화 중 하나인 O2O 서비스는 스마트폰 등의 디바이스의 발전을 통해 급격히 발전하고 있는 비즈니스이다. O2O 서비스는 온·오프라인의 소비 채널을 유기적으로 융합한 비즈니스라고 개념에 대해 간단하게 설명할 수 있겠다. O2O 시장의 발전은 3C(Consumer, Channel, Community)의 중심을 이동시키고, 이것이 다시 수요자의 요구에 따라서 원하는 형태와 시점에 상품이나 서비스의 공급이 이루어지는 경제 시스템인 ‘온디맨드 이코노미(On-Demand Economy)’의 도래에 영향을 미칠 것으로 전망하고 있다. 모바일 디바이스의 발달로 인해 ‘모바일 온디맨드 경제(Mobile On -Demand Economy)’ 사업 분야가 급성장하면서 실시간 주문, 위치기반서비스 등 다양한 O2O 서비스 모델이 등장했고, 비콘(Beacon), 근거리무선통신(NFC), 빅데이터 분석 등 소비자의 상황을 명확하게 파악하고 분석할 수 있는 기술의 발전이 O2O 확산의 밑거름이 되고 있다. 여기에 모바일 결제기술의 발전이 결합되면서 더 다양한 O2O 모델이 출현할 수 있는 토대를 제공하고 있다. O2O 서비스 유형은 크게 커머스(Commerce) 확장과 플랫폼 비즈니스(Platform Business) 고도화의 2가지 형태로 나눌 수 있으며, 세부적으로는 4가지 유형으로 구분할 수 있다. 첫 번째로, 온라인에서 오프라인으로 비즈니스 채널을 확대하는 유형. 두 번째로, 오프라인에서 온라인으로 비즈니스 채널을 확대하는 유형. 세 번째로, 플랫폼 기반 사업자가 O2O 서비스를 직접 제공하는 유형. 네 번째로, 여러 회사의 서비스를 모아 소비자와 연결해주는 유형(Aggregator) 이다. 본 연구는 O2O 서비스의 발전에 있어 부족한 선행 연구를 대신해 위와 같이 O2O 서비스에 대한 개념과 함께 유형에 대해 정리하고자 했다. 이와 함께 산업화, 정보화가 진전됨에 따라 이전과 다르게 변화하는 라이프스타일에 따른 O2O 서비스 이용빈도 차이와 O2O 서비스 구전의도 차이를 알아보고, O2O 특성에 대한 소비자 인식과 O2O 서비스의 이용빈도 간 상관관계, O2O 특성에 대한 소비자 인식과 O2O 서비스 구전의도의 상관관계를 알아보고자 하는 것이 본 연구의 목적이다. O2O 서비스는 고관여 서비스군으로 부동산, 숙박, 자동차 수리, 렌터카 관련 서비스를 지정했고, 저관여 서비스군으로 배달, 콜택시, 쿠폰, 쇼핑 관련 서비스를 지정했다. 본 연구를 위해 문헌적 연구방법과 실증적 연구 방법이 병행 됐다. 문헌 연구는 국내외 서적, 학술지, 논문, 보고서 등 문헌자료를 통한 이론을 기본으로 O2O 서비스에 대한 개념과 현황, 유형 등을 도출했고, 라이프스타일, O2O 특성에 대한 소비자 인식, 관여도, 구전의도에 대해 이론적 토대로 고찰하였다. 실증적 연구는 이론적 배경을 토대로 국내 O2O 서비스 중 선행연구에서 도출한 서비스의 이용빈도 조사를 실행하면서, O2O 특성에 대한 소비자 인식을 알아보기 위해 선행연구에서 도출되고 검증된 O2O 특성과 문항을 바탕으로 연구를 진행했다. 라이프스타일, 구전의도의 문항들은 선행연구를 통해 도출했다. 그 결과 라이프스타일은 군집분석을 통해 3가지 유형의 군집집단으로 분류하였고, O2O 서비스 이용빈도와 차이는 존재하지 않는 것으로 나타났다. 하지만 O2O 서비스 구전의도에 대해서는 라이프스타일 군집유형에 따른 차이가 분명히 존재했다. O2O 서비스에 대한 소비자 인식과 O2O 서비스 이용빈도 간 상관관계 분석을 통해서는 고관여 서비스군에서는 이용하기 쉽다고 인식할수록 부동산, 숙박 관련 O2O 서비스에서, 오락적이라고 인식할수록 부동산, 숙박, 자동차 수리 관련 O2O 서비스에서, 서로 간 관계한다고 인식할수록 숙박 관련 O2O 서비스에서, 안전하다고 인식할수록 부동산, 숙박 관련 O2O 서비스에서, 경제적이라고 인식할수록 부동산, 숙박, 렌터카 관련 서비스에서 유의미한 상관관계가 있는 것으로 나타났다. 저관여 서비스군에서는 이용하기 쉽다고 인식할수록 배달, 쿠폰 관련 O2O 서비스에서, 오락적이라고 인식할수록 조사한 모든 저관여군 O2O 서비스인 배달, 콜택시, 쿠폰, 쇼핑에서, 서로 간 관계한다고 인식할수록 배달, 콜택시, 쿠폰 관련 O2O 서비스에서, 안전하다고 인식할수록 배달, 쿠폰 관련 O2O 서비스에서, 경제적이라고 인식할수록 쿠폰, 쇼핑 관련 서비스에서 유의미한 상관관계가 있는 것으로 나타났다. O2O 특성에 대한 소비자 인식과 O2O 서비스 구전의도 간에는 모두 유의미한 상관관계를 보이고 있는 것으로 나타났다. 본 연구의 결과를 통해 O2O 서비스를 진행하거나, 진행하고자 하는 기업이나 서비스 실무자는 필요한 부분에 대한 마케팅 효율성과 개선점을 찾는데 도움이 될 것이라 생각한다.",
		"KEYWORD": "광고"
	},
	{
		"ID": 952,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서강대학교 정보통신대학원",
		"TITLE": "네트워크 패킷처리 가속화를 위한 DPDK 패킷 분산처리 어플리케이션의 동적 CPU 할당 기법 설계 및 구현 =(A)design and implementation of dynamic CPU allocation technique for DPDK packet distributor application to accelerate packet processing ",
		"AUTHOR": "심장훈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 낭종호",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "Recent IT environment, network traffic is increasing rapidly by the emerging IT services such as Mobile, Cloud, IoT and Big data. In order to process effectively the traffic increasing rapidly, various high-speed packets processing technologies to overcome the existing limitations of the network packet processing have been introduced. It is an important issue however, to effectively apply such acceleration technology to the actual business. This thesis proposes a dynamic resource allocation　technique to improve the resource allocation method of DPDK (Data Plane Development Kit) which is one of the high-speed network packet processing technologies. The method proposed in this thesis, the state of the overall resource allocation of DPDP applications running in the system are managed by centralized management system. This centralized management system improves the static resource allocation method in the existing DPDK architecture by assigning effective resources to DPDK applications. DPDK application to take advantage of the method proposed in this thesis, to prevent mistakes that can occur in the user`s manual assignment, with the flexibility to adjust the allocation of resources, increase the efficiency of the resources that network applications use. As a result of experiments proposed method in this thesis, it prevents the packet loss occurring in the conventional static allocation technique, at the same time it was possible to improve the efficiency of resource utilization by preventing the user`s mistake; it could be to improve the processing performance of the packet.",
		"KEYWORD": null
	},
	{
		"ID": 953,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 산업·창업경영대학원",
		"TITLE": "고객스포팅기법을 활용한 외식업 상권범위에 관한 연구 :상권유형에 따른 OO설렁탕 기업 사례를 중심으로 ",
		"AUTHOR": "권영산",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박재환 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "본 연구는 설렁탕전문점의 상권 범위를 설정하기 위해서 고객스포팅기법(CST)을 활용했다. 고객스포팅기법(CST)으로 부터 도출한 상권범위를 기반으로 신규매장을 출점하는 근거자료로 사용하고자 함이다. 각 매장의 매출활성화를 위한 마케팅 전략을 마련하고자 고객의 구매형태를 설문조사했다. 고객구매행태를 분석하고, 5개 지점의 상권분석을 시도하여 고객분포범위 등을 추정해 봄에 있어 GIS를 이용하였다. 분석결과 상권유형, 고객의 이용거리, 성별과 연령, 직업, 출발지, 이동수단, 이용요일, 이용시간, 방문이유, 방문목적, 이용횟수, 유동인구와 유입인구, 주변 업종별 점포수, 점포규모, 주차시설, 도로와 교통여건, 교통수단 등에 따라 상권범위와 고객분포 범위가 크게 차이가 남을 알 수 있었다. 기존의 학자들이 주장하는 매출 70% 단위의 반경 500m 이내를 1차 상권이라고 범주화시킨 연구문헌과 비교해 보았을 때, 연구결과는 다음과 같은 큰 차이를 보였다. 고객스포팅기법, 나이스비즈맵의 빅데이터 분석, 비즈 GIS의 지리정보시스템을 활용한 상권유형별 분석결과는 상권범위가 2200∼9187m로 광범위하게 나타났다. 고객구매행태를 분석한 결과 연령비중은 20∼30대, 성별은 여성, 직업은 직장인비중별로 높게 나타났다. 도보비중와 저녁타임 이용비중이 많게 나타났으나, 김포 지점만은 남성고객 비중이 높았고 이동수단으로는 자가용 비중이 높았다. 설렁탕 전문점의 상권범위는 상권 유형에 따라 차이가 나기도 하지만, 대중교통의 발달정도, 주변업종의 점포수, 거주인구수, 주차시설, 점포규모, 고객의 연령층에 따라 상권범위가 달라짐을 알 수 있었다. 특히, 일반적인 고정관념과 달리 설렁탕 전문점의 상권 범위가 광범위할 뿐 아니라 젊은 층 고객이 많고 주차시설이 잘 갖춰진 교외지역도 고객수요가 많은 것을 알 수 있었다. 방문 목적과 이유는 맛과 단순식사가 가장 높게 나타났고, 1개월에 1회 이용하는 비중이 가장 크다는 분석결과를 통해 고객들의 이용 빈도가 낮다는 것을 알 수 있었다. 고객구매행태를 통한 매출향상과 영업활성화를 위해서 타깃마케팅을 통한 지점의 차별화가 필요함을 알 수 있었다. 설렁탕전문점 및 유사한 한식아이템의 신규출점시에는 점포면적이 크고, 주변업종 점포수가 많지 않으며, 주차시설과 도로여건이 좋은 교외지역이 더 성공할 가능성이 클 것이라는 근거를 제시하는데 의의가 있는 분석이었다. 설문 조사의 시간적 제약과 고객들의 부정확한 거주지 주소 기입등의 소극적 설문참여로 인한 연구의 한계가 있었다. 향후 연구방향은 동일상권에 소재한 지점을 선정하여 고객스포팅기법을 활용하는 방법과 상권유형별로 분류해서 얻은 평균치로 좀더 정확한 결과를 도출하는 방향으로 나아가는 것이 바람직 할 것이다.",
		"KEYWORD": null
	},
	{
		"ID": 954,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "한국외국어대학교 대학원",
		"TITLE": "기록관리 대상으로서 SNS 연구 :페이스북, 트위터, 블로그, 유튜브를 중심으로 ",
		"AUTHOR": "송주형",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 노명환 한국외국어대학교 논문은 저작권에 의해 보호 받습니다. 참고문헌 : p. 102-107",
		"STORE_LOCATION": "한국외국어대학교 글로벌캠퍼스 도서관,한국외국어대학교 서울캠퍼스 도서관,한국학중앙연구원 도서관",
		"ABSTRACT": "This study examined the influence and meaning of SNS as the hot topic of our time from the archival perspective and also studied the ‘SNS records management’. The archival value of SNS includes many users, political and economic influences, securing social diversity, formation of collective memory, realization of public sphere, generation of ‘Big data’, meaning of SNS itself and volatility. The many users mean a high accessibility and utilization of SNS, which increase the influence and value of SNS as a record. Politically, SNS is a tool that strengthens the communication among the voters, politicians and the public while economically, it is a window to accept the complaints of the customers and a marketing tool. In addition, the voices of social minorities are also recorded unlike in the traditional media, which makes the SNS record a method to gain the social variety and diversity. SNS is a place of formation of collective memory and collective memory itself. Furthermore, it can play the role of public sphere. It also is a place for generation of ‘big data’ in an archival sense. The history is also the history of the media, which necessitates the record of SNS itself and the volatility of SNS also carries the meaning of SNS records. In addition, this study has classified the SNS records management into primary and secondary management that include record management entities, subjects, periods, methods, and causes. The primary management occurs without discrimination in real-time web setting for the system by the user and the secondary management occurs through evaluations and selections of the database or offline for the tipping points by the experts or the committees in sociocultural ways. This study analyzed the history, status, and the meaning of SNS to assess the values and meanings as the preliminary study for the future SNS record management studies.",
		"KEYWORD": "SNS,SNS 관리,블로그,웹2.0,유튜브,트위터,페이스북"
	},
	{
		"ID": 955,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "기업 마케팅 캠페인 성과 향상을 위한 디지털 마케팅 기법에 관한 실증적 연구 =(An)empirical study on digital marketing tactics for improving enterprise marketing campaign performance ",
		"AUTHOR": "이상호",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이남용",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "한국 기업들이 마케팅 프로세스를 혁신하기 위한 프로젝트를 수행하고 있다. 최근에는 마케팅 혁신이 최고 마케팅 임원뿐 아니라, 기업 최고 경영자의 핵심 과제로 여겨지고 있다. 웹 2.0 기술, 빅 데이터 분석, 소셜 미디어의 발전으로 디지털 마케팅 기법이 활발하게 도입되고 있다. 하지만 기존 전통적 마케팅에 대한 이론적인 연구는 활발하지만, 기업에서 디지털 마케팅 기법을 도입할 때 참조할 수 있는 실증적 연구는 부족한 실정이다. 이에 기업의 마케팅 성과에 영향을 미치는 디지털 마케팅의 핵심 성공 요인에 대한 연구를 수행하였다. 이 논문의 목적은 기업들이 디지털 마케팅 기법들을 도입할 때 참조할 수 있는 성과 모델에 대한 실증적 연구 결과를 제공하는 것이다. 이 논문의 연구 범위는 마케팅 전체 프로세스 중에서 최종 실행 단계인 마케팅 캠페인 관리 분야이다. 관련 연구를 통하여 디지털 캠페인 기법이 기업의 마케팅 성과 향상과 연관성이 있다는 연구 가설을 수립하고, 마케팅 전문가 설문 조사를 통한 과학적 통계 분석을 통해 가설을 검증하였다. 연구 수행 결과 디지털 마케팅 기법 중에서 웹 분석/예측 분석, 온라인/인터랙티브 캠페인 관리, 개인 맞춤형 캠페인 관리, 캠페인 자동화 관리 툴, 소셜 미디어 채널 확장 등의 기법이 기업의 마케팅 캠페인 성과 향상에 긍정적인 영향을 미치는 핵심 성공 요인이라는 것을 실증적으로 검증하였다.",
		"KEYWORD": null
	},
	{
		"ID": 956,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울과학기술대학교 IT정책전문대학원",
		"TITLE": "글로벌 ICT 기업의 개인정보 정책과 국내법과의 정합성에 관한 연구 :A study on the consistency between personal information policy of global ICT firms and Korean domestic law : focused on the Google and Facebook ",
		"AUTHOR": "정주영",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현경",
		"STORE_LOCATION": "서울과학기술대학교 도서관",
		"ABSTRACT": "글로벌 ICT 기업이 개인 맞춤형 서비스 등 신규 산업을 확대함에 따라 이들 기업에 의하여 개인정보가 광범위하게 수집되고 국외로 이전되고 있다. 또한, 빅데이터, 사물인터넷, 클라우드 컴퓨팅 서비스 등의 디지털 기술로 인하여 국경을 넘어 개인정보의 이전이 더욱 가속화될 것으로 예상된다. 이에 따라 특정 국가와 기업에 개인정보가 집중되어 개인의 정보주권이 제한되고, 남용될 가능성이 더욱 증가되고 있다. 본 연구에서는 글로벌 ICT 기업 중 구글과 페이스북이 전 세계적으로 이용자의 개인정보를 수집하여 보유하고 있고, 이용자에게 미치는 영향력이 매우 크다는 점에 주목하여 이들의 개인정보 정책과 국내법의 비교법적 고찰을 통해 현행 법령상 괴리되거나 규정되지 못한 영역을 논의하였다. 구글과 페이스북의 개인정보 관련 정책과 국내 개인정보 보호 관련법과의 정합성을 검토한 결과, 이들 기업이 제공하는 서비스의 특성상 이용자의 개인정보를 광범위하게 수집하고, 이용할수록 기업의 매출과 순이익이 증가하고 있는 반면에 이용자들의 개인정보를 포괄적으로 동의받아 이용하고 있는 등 국내 법률을 적극적으로 준수하지 않고 있어 국내 개인정보 법률의 실효성을 약화시키고 있었다. 따라서, 본 연구에서는 글로벌 ICT 기업의 개인정보 정책과 국내법간 정합성을 제고하고, 서비스 이용자의 개인정보를 보호하기 위하여 적극적으로 개인정보의 역외적용의 필요성에 대해 살펴보았고, 일부 문제가 발생하는 것이 예상됨에도 불구하고 개인정보의 국지화 규정을 정비할 필요성을 제기하였다. 또한, 정보기술 등의 발달에 따라 변화된 환경을 반영하여 정보통신서비스를 이용하는 정보주체가 신규 서비스를 합리적으로 수용할 수 있도록 균형을 유지하면서 이용자들의 개인정보를 보호할 수 있도록 실질적인 방안이 마련되어야 한다.",
		"KEYWORD": null
	},
	{
		"ID": 957,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "배재대학교 대학원",
		"TITLE": "VPN 터널링 QoS를 위한 다중큐잉 실시간 트래픽 쉐이핑에 관한 연구 =(A)study on multi-queuing real-time traffic shaping for VPN tunneling QoS ",
		"AUTHOR": "양승의",
		"REGION": "대전",
		"PROFESSOR": "지도교수: 정회경",
		"STORE_LOCATION": "배재대학교 도서관",
		"ABSTRACT": "Recently, information and communication-based various service technologies, such as cloud, smart devices and IoT (Internet of Things) have been rapidly developed. In addition, platform technologies of network equipment like routers, smart gateways, switches, firewalls which are required for this various technologies are being developed as well. Development of information & communication technology enables users not only to overcome time and space constraints for the use of smart devices, but also to continue what they are doing in any other places including the office, home, school and to provide the same network environment as that of physically remote location. The technology that multiple remote networks can be configured as a local network can be implemented through well-known inter-network VPN (Virtual Private Network) equipment. Commercial VPN equipment has been evolved to provide the application of many advanced functions including not only basic router and tunneling functions, but also intelligent firewall including IDS (Intrusion Detection System) and IPS (Intrusion Protection System), QoS (Quality of Service) technology, multi-line support, and load balancing, etc. This commercial VPN equipment is being used as high-performance products in a dedicated line environment with the support of experts. Moreover, these are expensive and dedicated equipment due to their technical nature so that it is not easy to ensure for them to provide the compatibility between equipment. Also as mentioned earlier, under the situation that small and medium-sized businesses and even the public increasingly require the need for the same network environment such as cloud, IoT (Internet of Things) and multi-screen, the need for the wired/wireless router to support inter-network VPN under general internet environment has been increased because application of dedicated VPN equipment to the expensive leased line environment is not economical. Accordingly, a technology providing reliable VPN environment in a vulnerable network environment which shows relatively less CPU and memory performances than dedicated VPN equipment is required. Although several existing wired/wireless routers to support VPN exist, their simple VPN server functions only provide direct linkage to a PC or a smartphone not a inter-network VPN linkage. Therefore, their utilization is decreased, the machine to support is limited and the speed rate is only in 5Mbps level. In addition, not only that it is not economical to popularize commercial VPN dedicated equipment, but that its operation is not possible without dedicated line. In this study, I propose several solutions to revolve the above problems; First, I propose a platform to support VPN tunneling to the affordable cost hardware; Second, I propose an implementation plan to support at least 20Mbps for VPN tunneling rate for each tunneling algorithm; Third, I propose a method for applying different-features, multi-queuing techniques beyond the simple QoS, ToS (Type of Service) methods by identifying real-time internet line situation even if the change of internet line quality is large, and the measurement results will be presented as well. Historic network-based equipment including routers, firewalls, and VPN equipment have been developed continuously even today. Development of hardware performance itself is required, but development of software technology is further required in recent days not only for the proper responses to a variety of services and environment changes, but also for the need of popularization of associated network equipment to respond against explosive expansion of various services such as cloud, big data, and loT. The hardware, operating system and software platform used in the study are based on OpenWRT which many developers in the various network equipment fields have used for a long time. Thus, the techniques from the study are considered to be applied to VPN tunneling-related solutions as well as a variety of network equipment such as smart gateway application for loT.",
		"KEYWORD": "IoT,OpenWRT,QoS,SSL,VPN,다중큐잉,트래픽 쉐이핑"
	},
	{
		"ID": 958,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "경기대학교 건축전문대학원",
		"TITLE": "스마트 환경에서 공간의 가변적 확장가능성에 관한 연구 ",
		"AUTHOR": "박정식",
		"REGION": "경기도",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수:조택연 참고문헌 : p.110-112",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "본 연구 논문은 네트워크(Network)와 디지털 기술의 발전으로 인해 변화되어 나타나는 인간의 라이프 스타일(Life Style)과 그로인해 변화된 공간이용행태의 속성을 파악한 후, 차세대 환경인 스마트환경(Smart Environment)에서 인간의 행위에 상황별로 가변(可變)하는 지능형 공간 모형의 가능성과 지속성을 통해 진화할 수 있는 지능형공간의 구조를 찾고자한다. 또한 이 과정을 통해 나타나는 현상들을 분석하여 상황에 능동적으로 대응하여 가변되는 지능형 공간구조를 찾는 것을 목적으로 한다. 본 연구에서는 상황에 따라 가변되는 지능형 공간구조를 찾기 위해 다음과 같은 구성을 통하여 기술하였다. 우선 공간의 변화를 이해하고 새로운 변화를 추론하기 위해 인간의 역사에서 정주의 개념이 나타나기 시작하는 농업혁명과 도시 공간의 적층이 이루어지는 시기인 산업혁명에서의 공간의 의미를 파악하고, 파악된 공간의 의미에 사회현상 및 기술적 배경이 미치는 영향을 분석하여 공간의 변화를 이해한다. 두 번 쨰로 정보혁명을 중심으로 정보혁명이전의 물리적 공간과 정보혁명 이후의 물리적 공간을 선연구된 결과물과 문헌을 통해 분석하고 이를 토대로 정보혁명에서 나타난 공간의 속성과 인간의 사용방법을 연구하여 스마트 환경에서 나타날 수 있는 공간을 분석하고 그 지향점을 찾고자 한다. 세 번 째로 마크 와이저(Mark Weiser)에 의해 주창된 유비쿼터스 컴퓨팅(Ubiquitous Computing)이론에서 시작된 디지털 공간의 특성과 지능형 공간구조로서의 가능성을 통해 양방향 소통이 가능한 공간의 지능형 구조를 찾아 스마트 환경에 적용하고자 한다. 마지막으로 스마트 환경에서의 공간의 지능화를 통해 인간행위의 상황에 맞게 가변적으로 변화하는 공간의 적용방법론과 그 방법론을 통해 스마트 환경에서의 공간의 활용방법을 도출함으로서 스마트 환경에서의 가변적 공간의 확장가능성모형을 제시하고자 한다. 이러한 과정을 통해 도출된 내용을 좀 더 자세히 서술하면 다음과 같다. 첫째로 기술의 발전에 따른 사회현상과 문화의 변화는 인간이 사용하고 있는 공간에 많은 영향력을 행사한다. 이러한 영향력은 인간의 행위가 변화함에 따라 공간의 사용방법과 활용방법이 바뀌는 것을 확인 할 수 있다. 기술의 발달은 물리적 한계를 점 점 더 줄여나감으로서 공간과 장소가 가지고 있는 장소성과 영역성의 경계를 무너뜨리고 고정되고 확정되어 사용되어지던 평면에서 변화되는 상황에 능동적으로 대처할 수 있는 유연하고 가변적인 공간으로의 변화를 요구하고 있다. 건축공간은 이제 고정된 평면을 가지는 것이 아니라 시간의 중첩성을 활용 할 수 있는 탄력적이며 동적인 공간으로 변모 될 것이다. 둘째로 네트워크의 발전과 네트워크로 연결된 휴대용 디지털 디바이스의 발전은 장소중심의 공간 활동에서 시간중심의 행위와 공간 활동으로 변화하는 계기를 만들었다. 정보혁명이전의 인간의 행위는 시간과 장소의 제약을 극복하는 방법론으로서 물리적인 기계의 힘을 빌려 물리적인 격차를 줄여나가는 방법을 택하였다. 다시말해 자동차, 비행기, 기차와 같은 기계의 능력을 빌려 장소와 장소를 이동함으로서 물리적인 격차를 줄였다. 그러나 정보혁명이후 탄생한 제3의 공간 즉 디지털 공간은 물리적 장소의 제약을 받지 않으므로 시간을 중첩적으로 사용할 수 있게 되었다. 일예로서 예전엔 은행 업무를 보기위해 은행이라는 물리적 장소에 가서 차례가 될 때 까지 기다려서 업무를 보고 와야 했다, 하지만 인터넷의 발달과 스마트폰의 발달은 은행에 직접 가서 해결해야했던 업무를 다른 행위를 하면서 동 시간에 인터넷이나 스마트폰에 저장된 앱(App, Application)을 통해 물리적 장소의 이동 없이 해결할 수 있게 되었다. 이러한 디지털 장소에서의 시간의 중첩성은 물리적 시간의 한계성으로 인하여 순차적으로 처리하던 인간의 행위를 동시적이며 즉시적으로 해결할 수 있게 하였으며, 하나의 행위가 수행되기 위해 정해진 장소에서 수행하던 행위와 동시간대에 흩어져 있던 장소에서 행해지던 행위를 네트워크로 연결하여 하나의 장소에서 동시다발적으로 동시에 처리 할 수 있게 되었다. 따라서 디지털 공간과 물리적 공간의 결합으로 가능해진 멀티태스킹(Multi-Tasking)멀티태스킹(Multi-Tasking)하나의 컴퓨터가 동시에 여러 개의 작업을 수행하는 일. 다중 프로그래밍과 비슷하지만 뜻이 약간 다르다. 태스크라는 말은 엄밀하게 말하면 프로그램이나 프로세스와는 조금 다른 의미로, 컴퓨터 쪽에서 볼 때의 작업 단위를 이르는 말이나 본 논문에서는 인간이 물리적으로 흩어져 있던 여러 가지 일들을 디지털공간과 의 결합으로 동시다발적으로 해결한다는 의미이다. 을 통해 시간과 공간을 탈장소화 시켰으며, 물리적 한계로 인해 분산되었던 인간의 행위를 사용자 중심의 시간과 장소로 재구성함으로서 시간중심의 공간 조직화가 가능해졌다. 세 번째 로서 유비쿼터스 환경과 스마트 환경의 분석을 통해 지능화된 공간의 속성을 분석하여 지속적으로 공간에 적용 가능한 것인가를 확인한다. 방법론으로서 공간지능화의 기술과 적용사례 그리고 앞으로 적용가능한 방법론을 선연구된 결과물고 추론을 통해 공간지능화를 통한 새로운 공간모형의 적용가능성을 타진해보았다. 넷째로 네트워크 환경이 유선에서 무선으로 급속도로 바뀌는 상황에서 점 점 더 커지는 무선네트워크의 점유율을 통해 바뀌어 지는 공간사용행태를 분석하였으며, 이러한 분석의 토대를 통해 현재 계속 발전중인 기술인 사물인터넷과 사물인터넷에 의해 수집된 정보 즉 빅데이터(Big Data)의 사용방법과 사용되어지는 사례조사를 통해 스마트 환경에서 적용가능한 방법론을 도출하고자 한다. 또한 사용자의 공간사용정보를 공유함으로서 공간의 공유(公有,Share)가능성을 모색함과 동시에 공간을 공유함으로서 가변적으로 사용할 수 있는 공간 모델을 구상할 것이다. 인간의 기술과 생각으로 만들어진 물리적 공간은 현대에 이르기 까지 고정된 평면의 형태를 보여 왔으며, 기술의 발전과 더불어 변화의 방법론을 모색하기는 하였지만 모두 물리적 한계성을 크게 벗어나지 못하였다. 그러나 디지털 공간과 네트워크의 연결은 공간의 물리적 한계성을 극복할 수 있는 새로운 가능성을 제시하였고 더불어 기술의 발달과 함께 나타나는 신풍속도로 인하여 공간의 의미는 많이 변화하였다. 본 논문에서는 기술의 변화와 함께 변화한 인간의 라이프 스타일에 능동적으로 유연하게 대처 할 수 있는 공간을 연구하여 스마트 환경에서 나타날 수 있는 새로운 공간 모형을 제시하고자 한다.",
		"KEYWORD": "가변적공간,스마트환경"
	},
	{
		"ID": 959,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "단국대학교 정책경영대학원",
		"TITLE": "주택 모기지론 이용시 소득계층별 거래은행 선택 요인에 관한 연구 :(A)research on the selection factor for main bank by income bracket in using housing mortgage loan :평택 지역을 중심으로 =focused on Pyungtaek area ",
		"AUTHOR": "한영민",
		"REGION": "경기도",
		"PROFESSOR": "단국대학교 학위논문은 저작권에 의해 보호받습니다. 지도교수:이호병 참고문헌 : 105-108장",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "최근 정부는 전체 금융권을 대상으로 LTV·DTI 규제 비율을 완화하여 2014년 8월부터 시행중에 있고, 한국은행이 8월과 10월 두차례 기준금리를 인하 하여 수년간 저금리가 지속되고 있다. 금번 LTV·DTI 규제 완화는 2013년말 기준 이미 1,000조원을 초과한 가계부채의 질적 구조개선, 그리고 침체된 경기 부양과 주택시장의 거래 활성화에 주된 목적이 있다. 그러나 규제완화 및 기준금리 인하 이후 2014년 3분기말 현재 가계부채는 1060조원을 넘어섰고 이중 주택담보대출이 50%의 비중을 차지하고 있으며, 4분기에도 계속 증가추세에 있고, 10월 가계대출 증가액은 7조 8천억원으로 월별 기준 역대 최고치를 기록했다. 이러한 배경하에 본 연구는 주택모기지론 이용시 거래은행 선택 요인에 관한 연구를 목적으로 크게 두가지 방법으로 나누어 분석을 실시하였다. 첫째, 소득계층별 주택모기지론 이용방식과의 연관성에 대해 살펴 보았고, 분석 결과 거래은행 선택시 고려하는 중요 요소 13개 속성에서는 예상과 달리 모두 유의한 차이가 없었다. 다만, 유의수준을 0.10으로 확대할 경우 그 차이가 인정될 수 있는 수준인 대출금리는 소득수준이 높을수록 중요도를 높게 평가 하는 것으로 나타났다. 둘째, 동일계층 소득 집단 내에서의 중요도 순위와 만족도 순위를 파악하여 어떠한 차이를 보이는지 비교분석을 통하여 중요도가 높은 항목이나 상대적으로 만족도에 있어 평균보다 낮은 수준의 항목들을 중심으로 결과치를 살펴보았다. 먼저 저소득계층의 경우 대출금리(이자율), 중도상환수수료 등 기타비용, 대출자격 요건 등 심사기준의 항목은 중요도가 높은 항목이나 만족도에 있어 평균보다 낮은 수준이므로 다른 항목에 비해 우선적으로 이 부분에 대하여 관심을 집중하고 성과를 개선 할 수 있는 마케팅 전략이 마련되어야 한다. 중소득계층의 경우 우선적으로 관심을 갖고 집중해야할 항목으로 대출금리(이자율), 대출기간, 소득공제 혜택, 대출금리 적용방식, 중도상환수수료 등 기타비용 항목으로 나타났다. 다음으로 고소득계층의 경우 우선적으로 관심을 갖고 집중해야할 항목으로 중도상환수수료 등 기타비용, 대출금리 적용방식, 소득공제 혜택의 항목으로 나타났고, 대출기간은 중요도 및 만족도 순위가 평균치로 나타났다. 각 동일 소득계층별 우선적으로 관심을 갖고 집중해야할 항목 분석시 저소득과 중소득에서는 대출금리(이자율)가 두 집단에 공통으로 속해 있었고, 세 개의 각 동일 계층별 공통적으로 포함된 항목은 중도상환수수료 등 기타비용 항목으로 나타났다. 이러한 동일 계층간 중요도 순위와 만족도 순위의 차이에 대한 비교분석을 통하여 모기지를 판매하는 은행은 단순한 브랜드 이미지를 벗어나 각 소득 계층별 다양한 니즈 분석과 맞춤형 상품 설계로 치열한 금융기관 경쟁시 차별화된 타겟 마케팅 전략을 수립하는데 기초자료로 활용 될 수 있을 것이며 향후 금융업무의 빅데이터로 활용 하기에도 가치가 있을 것으로 기대한다.",
		"KEYWORD": null
	},
	{
		"ID": 960,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2013",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "Study on CMOSFET mobility enhancement by Ge condensation on Si-on-insulator (SOI) =SOI 기판 위 Ge 응축방법에 의한 CMOSFET 이동도 향상에 관한 연구 ",
		"AUTHOR": "김태현",
		"REGION": "서울",
		"PROFESSOR": "지도교수 : 박재근 국문요지, Abstract 수록 참고문헌 : p.121-136",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 빅 데이터 시대를 맞이하여 모바일 컴퓨팅 기기에 대한 수요가 폭발적으로 증가하고 있다. 기가 헤르츠급 프로세서 스피드와 기가 바이트급 저장 장치를 갖춘 최신 스마트폰은 이미 십년 전 하이엔드 데스크탑 컴퓨터급 전력을 소모하는 수준이 되었다. 하지만 더 작고, 더 빠른 컴퓨팅 장치에 대한 수요가 기하급수적으로 증가함에 따라 디바이스칩 내 사용되는 실리콘 기반 기술의 적용이 물리적 측면뿐만 아니라 경제적 측면에서도 점점 무어의 법칙을 유지하기 힘든 상황을 빠르게 도래시키고 있다. ITRS 보고서에 따르면, 2018년 트랜지스터 게이트의 길이가 7 nm까지 축소될 것으로 전망함에 따라 채널 물질로서 실리콘 사용 시 발생할 물리적 한계점이 새롭게 대두 되고 있다. 그러므로 전 세계적으로 차세대 기술을 위한 새로운 솔루션을 요구하고 있다. 이에 대한 솔루션 중 하나가 바로 스트레인드 실리콘, 절연막을 갖는 게르마늄, 원소 3-5족 계열의 물질들을 이용함으로써 실리콘의 한계점을 극복하는 것이다. 그 이유는 이와 같은 물질들이 실리콘이 가지고 있는 전자 및 정공의 이동도보다 훨씬 빠른 특성을 가지고 있기 때문이다. 이와 같은 관점에서 본 학위 논문은 고 이동도(전자 및 정공)를 갖는 기판 제조를 위해 시도했던 다양한 공정 방법과 기판 특성에 대해 다루었다. 첫째, 본딩, 디스로케이션 싱크, 컨덴세이션 방법들에 의해 제조된 스트레인드 실리콘 기판의 스트레인 이완 메카니즘에 대해 연구하였다. 본딩 및 디스로케이션 싱크 방법에 의한 스트레인 이완은 게르마늄 농도의 기울기에 의해 달성된다. 이와는 대조적으로 켄덴세이션 방법에 의한 이완 메카니즘은 산화 공정을 하는 동안 게르마늄 원자의 응축정도에 의해 형성된다. 표면 거칠기와 결함 밀도는 본딩, 디스로케이션 싱크, 컨덴세이션 방식 순으로 각각 2.45, 0.46, 0.40 nm, 5.0×103, 9×103, 0 개의 결과 값을 보여 주었다. 이는 기판의 품질 및 생산 비용 측면에서, 스트레인 실리콘 기판을 제작하는데 켄덴세이션이 다른 두 방법에 비해 월등히 우수한 방법임을 확인시켜 주는 결과이다. 둘째, 앞서 우수한 컨덴세이션의 방식을 이용하면 스트레인 실리콘 기판뿐만 아니라 절연층을 갖는 게르마늄 기판도 제작할 수 있다. 따라서 고품질의 우수한 절연층을 갖는 게르마늄 기판을 제작하기 위해 효과적인 컨덴세이션 공정 기술에 대해 연구하였다. 특히, 본 공정 기술에서 가장 큰 관심인 쓰레딩 디스로케이션과 표면 거칠기를 개선하기 위해 초기 SOI 두께, 초기 Ge농도, 산화 공정 온도, 간헐적 산화막 제거 효과, 열처리 효과 등 여러 공정조건의 최적화에 대해 연구 하였다. 초기 SOI 두께의 경우, 그 두께가 얇을수록 산화 공정 후 실리콘 게르마늄층 내 Ge 농도 프로파일이 기울어지는 현상을 막고 이로 인해 게르마늄 원자가 휘발되는 것을 피할 수 있다. 그리고 초기 실리콘 게르마늄층의 Ge 농도가 높을수록 GOI 기판을 제작하는데 효과적으로 Ge 농도를 증가시킬 수 있었다. 또한, 산화 공정 온도가 높을수록 그 확산 거리가 길어지므로 산화 공정 시 매몰 산화 막으로의 Ge 원자의 확산과 축적 간 균형을 유지하게 되어 효과적으로 표면 거칠기를 개선 할 수 있다. 950도에서 컨덴세이션 된 샘플은 6.05nm의 값을 나타낸 반면, 1100도에서 산화된 샘플의 표면 거칠기는 0.43nm으로 14배 이상 낮은 수치를 실험적으로도 보여주었다. 하지만 이러한 고온 산화 공정은 컨덴세이션 초기 단계에서는 효과적이나, 지속적으로 고온 산화 공정을 진행하는 경우 증가되는 Ge 농도가 50at%를 넘어가면서 녹는점 이상의 고온으로 인하여 오히려 게르마늄의 원자가 녹을 수 있으며, 이로 인해 표면 거칠기가 매우 악화되는 문제가 발생한다. 그러므로 게르마늄 원자가 녹지 않도록 증가되는 Ge 농도를 고려하면서 컨덴세이션 공정온도를 바꾸는 다단계 산화 공정 방법이 효과적이다. 단일 온도에서 산화 공정을 진행한 샘플의 표면 거칠기는 다단계 산화 공정 방법보다 2배 이상 높으며, 그 표면 거칠기의 높이 단차는 8.7배 이상 높은 결과 값을 보였다. 또한, 산화 막의 두께가 증가함에 따라 게르마늄 농도 응축시간이 증가하게 되는 문제가 발생한다. 이는 기판 표면에서 절연막 까지 실리콘 게르마늄 층 내 게르마늄의 농도의 불균형을 가지고 오는 현상을 유발한다. 따라서 산화공정 중 간헐적으로 산화 막을 제거 해줌으로써, 21nm 두께의 품질 좋은 고 농도(95at% 이상) 게르마늄 층을 얻을 수 있었다. 또한 이 공정을 적용함으로써 95 at%이상의 고 농도까지 걸리는 공정 시간 최대 77%까지 감소시킬 수 있었다. 즉, 다단계 산화 공정 중 간헐적 산화 막 제거는 선택이 아닌 필수 공정임을 밝혔다. 더불어, 이러한 컨덴세이션 공정 기술을 적용하여 제작된 기판 위에 Ge 농도 67at%의 p-MOSFET 소자를 제작하였다. 그리고 이 소자의 홀 이동도는 기존 SOI 기판 적용 p-MOSFET 소자대비 2.13배 증가된 결과를 보여 주었다. 마지막으로, 다중파장을 갖는 고 해상도 라만 시스템을 이용하여 스트레인드 실리콘 기판과 절연층을 갖는 게르마늄 기판의 물리적 특성을 관찰하였다. 다중파장 고 해상도 라만 시스템은 서로 다른 4가지의 파장을 이용하여 보다 정밀하게 물리적 특성을 비 파괴적으로 검사 할 수 있는 특징을 가지고 있다. 따라서 스트레인드 실리콘 기판의 경우 하부층과의 스트레인 정도, 층간 구조 및 두께 분석이 가능하며, 절연층을 갖는 게르마늄 기판의 경우 실리콘 게르마늄 층 내 게르마늄의 농도 및 두께 정보를 용이하게 관찰 할 수 있었다. 특히, 산화 공정 시간 증가에 따른 게르마늄 농도 증가를 오제 전자 분석에 의한 결과와 비교 시 비파괴 검사임에도 불구하고 결과 값이 매우 일치함을 보여 주었으며 두께 정보 역시 TEM 분석 결과와 일치함을 확인하였다. 따라서 다중파장 고 해상도 라만 시스템의 비파괴적 분석은 시료 보호뿐만 아니라 비용적인 측면에서도 효과적이다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 961,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "Novel bulletin board system based on document object model and client-side scripting for improved interaction =향상된 인터랙션을 위한 문서 객체 모델 및 클라이언트 사이드 스크립팅 기반 웹게시판 소프트웨어 시스템 ",
		"AUTHOR": "JungUyeHong",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 962,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "가천대학교 대학원",
		"TITLE": "주식 명의신탁 과세제도 개편방안 연구 =(A)study on reorganization of taxation system in the stock trusted nominally ",
		"AUTHOR": "허정준",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 김원배",
		"STORE_LOCATION": "가천대학교 중앙도서관",
		"ABSTRACT": "현행 상속세및증여세법은 2004년부터 포괄 증여를 직접 규정하여 증여세를 과세하고 있다. 따라서 명의신탁 과세의 법률적 특성은 조세정책목적을 용이하게 이행하기 위한 제재목적임이 분명하게 되었다. 그럼에도 과세에 대한 위헌논쟁과 조세법률주의 및 조세공평주의 측면에서의 문제 제기는 늘고 있다. 이는 불분명한 법 규정 및 증여 의제에 의한 증여세도 일반조세라는 법률인식에서 비롯된다고 여겨진다. 이에, 본 연구는 현행 상속세및증여세법 제45조의 2에서 규정하고 있는 명의신탁재산에 대한 증여 의제를 주식을 중심으로 연구하여 합당한 개편방안을 도출하기위하여 진행되었다. 본 연구는 목적달성을 위하여 상속세및증여세법상 명의신탁 과세에 관한 이론적 고찰 및 그간의 변천과정을 검토하였으며 주요외국의 과세제도와 선행연구 및 헌법재판소 결정문, 과세사례 등에 의하여 문제점을 확인하였다. 그리고 국세공무원과 세무대리인 및 명의신탁이해관계인을 대상으로 설문조사를 실시하여 주식을 중심으로 한 현행 과세제도의 문제점과 개편방안에 대하여 실증분석을 하였다. 현행 주식 명의신탁 과세의 문제점에 대한 연구 및 실증분석 결과는 다음과 같다. 첫째 주식 명의신탁에 대한 증여 의제 과세는 부동산 명의신탁에 대한 과징금부과와 비교하여 균형적이지 못하다. 둘째 주식 명의신탁에 대한 과세는 소유 유형별로 균형과세가 되지 못하고 있다. 이는 상당부분이 주주명부상 명의개서를 근거로 하여야 한다는 경직성에서 비롯되는 것으로 여겨진다. 셋째 계속되는 위헌성 논쟁은 포괄증여 및 확장증여(명의신탁) 과세에 대한 인식의 미 전환과 조세법규의 미흡함을 행정집행 과정에서 사실판단이나 판결로서 해결하려는 태도에서 비롯되는 것이다. 행정현황은 이를 잘 나타내고 있는 것이다. 위와 같은 문제점의 축소를 위하여 다음과 같은 개편방안을 제안하였다. 첫째 부동산명의신탁과 비교하여 경제적 실질 측면에서 균형과세가 될 수 있는 입법이 이루어져야 한다. 둘째 명의개서를 과세요건의 기본으로 하는 것 외에도 사실상 타인명의 등에 의한 주식 등의 취득도 과세하는 것으로 개편되어야 할 것이다. 셋째 계속되는 위헌성 논쟁을 줄이기 위하여 명의신탁자(실소유자)에게 포괄증여와 별도과세 하는 방안을 시행하면서 조세정책목적의 과세임을 법률로서 명확히 한다. 넷째 근본적으로 위헌논쟁과 과세에서의 혼란을 해결하기 위해서는 조세회피목적 유무에 대한 판단 단계에서 과세관청에 타인명의 등에 의한 취득사실을 사전에 명시적으로 신고하지 않은 모든 경우는 조세회피목적이 있는 것으로 의제하는 입법이 필요하다. 본 연구의 한계점은 설문의 한계에서 오는 일반화의 문제점과 다양한 태양으로 형성되는 기초사실을 명확하게 확정하기 어려운 부분을 실무적으로 어떻게 결론지을 것인가에 대한 세세한 연구가 부족했다는 점, 명의신탁 재산가액의 평가, 조세회피목적 여부에 대한 입증책임 및 기타재산과의 형평과세 문제점에 대한 연구가 부족한 점이다. 따라서 이들 한계점을 보완하는 후속연구가 계속되기를 기대하며 연구를 마치면서 도출된 문제점들에 대한 개편도 기대해 본다.",
		"KEYWORD": null
	},
	{
		"ID": 963,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "단국대학교 정보미디어대학원",
		"TITLE": "클라우드 시스템에서 효과적인 통합모니터링 도구의 연구 =(A)study on the effective monitoring techniques for cloud systems ",
		"AUTHOR": "한명석",
		"REGION": "경기도",
		"PROFESSOR": "지도교수:박규식",
		"STORE_LOCATION": "단국대학교 율곡기념도서관(천안),단국대학교 퇴계기념도서관(중앙도서관)",
		"ABSTRACT": "본 연구는 클라우드 시스템을 위한 효과적인 통합 모니터링 도구에 대한 연구이다. 최근 IT 서비스 기반이 독립적인 시스템에서 클라우드 시스템으로 변화를 하고 있다. 이러한 변화에 맞추어 서비스 개발과 운영이 모두 변화를 꾀하고 있다. 특히 현재 큰 이슈가 되고 있는 빅 데이터 시스템을 활용하기 위해서 클라우드 시스템에 대한 많은 관심이 있는 상태이다. 오픈소스 기반의 모니터링 도구는 시스템 운영자나 기획자보다는 개발자들에게 활용 하는 모습을 많이 볼 수 있다. 그러한 이유는 오픈소스 자체가 설치가 쉽지 않고 운영 하는데 개발언어나 인터넷에서 검색을 통해서 진행을 하게 되기 때문이다. 기존의 상용 모니터링 도구들의 경우는 설치 메뉴얼에 위해 진행을 하고 진행이 안 될 시에는 엔지니어를 통해서 문제를 바로 해결 할 수 있기 때문이다. 이러한 이유 때문에 중소기업이 아닌 대기업 혹은 서비스 중요도를 많이 생각하는 기업에서 상용 제품을 활용 할 수밖에 없게 되었다. 본 연구에서는 클라우드 시스템 의 개념과 가상화 소프트웨어의 종류와 특장점과 시스템 모니터링의 개념과 필요성에 대해서 알아보고 모니터링 시스템 중 오픈소스 기반의 많은 도구 중 세 가지의 도구를 선정하여 ISO (International Organization for Standardization) 9126의 SW 품질평가 항목의 기준을 활용하여 평가를 위한 항목을 선정한다. 선정된 항목을 기준으로 각종 실험을 진행하여 도구의 차이점을 파악하고 IT 서비스 직군을 대상으로 모니터링 도구의 관심도와 상용제품과의 차이점 그리고 평가항목에 대한 중요도순으로 설문조사를 진행하여 SPSS(Statistical Package for the Social Science)의 빈도 분석을 활용하여 오픈소스 기반의 모니터링 도구에 대한 평가 항목의 가중치를 주어 현업에서 중요로 하는 항목이 무엇인지 살펴보았다. 모니터링 도구 중 NMS 기반의 도구가 독립적인 시스템에서 부터 많은 활용을 하였으며, 또한 계속 진화를 거듭하여 클라우드 환경 및 대용량 파일 시스템 운영을 위해서 변모하고 있다. 본 논문은 IT 서비스 운영자나 기획자에게 오픈소스 모니터링 도구에 대한 인식을 변화 시키고 오픈 소스 모니터링 사용자의 모니터링 도구에 대한 평가를 위한 최초의 논문으로 그 가치가 있다 하겠다.",
		"KEYWORD": "cacti,ganglia,hyperic,모니터링,클라우드,통합 모니터링"
	},
	{
		"ID": 964,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "한국과학기술원",
		"TITLE": "Crowd-sourced information and its application on cultural collections =문화예술기관의 크라우드소싱 정보 활용에 관한 연구 ",
		"AUTHOR": "Chae,Gunho",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 965,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 대학원",
		"TITLE": "교통량 OD를 활용한 상업용지 수요추정 기법에 관한 연구 :(The)estimation of demand for commercial area based on origin-destination traffic volume :5개 신도시를 중심으로 =focused on five new towns Seoul metropolitan area ",
		"AUTHOR": "이유철",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김찬호 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "The appropriate estimation of demand for the commercial area is influential for not only developing a city, but also for management and operation of the city. When the demand of commercial area exceeds the supply, the rental fee will increase and cause inconvenience to the residents’ lives. Also, the vacant ratio and unsold apartments will increase. Thus, the appropriate estimation of demand for the commercial area is crucial for promoting the development of the city and enhancing the city facilities. This paper focused on empirical analysis using the data of commercial demand. The previous methods were diverse in methodology, required excessive number of variables, and were subject to the researcher himself. The reason for using data of commercial demand is because when a city grows over a certain size, the composition of commodity or type of business resembles each other and the impact of total floor area used for commercial purpose outweighs the business sales or space requirement. Especially, such characteristics could also affect the annual average daily traffic volume as well. In the analysis, the independent variable was the sum of shopping traffic volume and leisure·entertainment traffic volume, while the traffic volume of origin and destination was categorized according to four administration units ? dong, new town, city, and metropolitan area. The large scale data of building register was analyzed by a big-data analysis tool named “R,” and the sum of floor area used for commercial purpose was derived. By examining the major origin and destination points, the internal traffic demand of new towns and the relation with higher rank region was analyzed. Also, through the regression analysis, the following conclusions had been derived. First, traffic volume of commercial purpose is more meaningful than the design population. By repeating the analysis under different sample size, the regression model dependent to traffic volume is suitable to macroscopic regional unit such as new town. Secondly, the commercial demand of new town is dependent to the traffic from new town and higher rank, while the commercial demand of each “dong” in the new town is dependent to the internal traffic volume of “dong”. Finally, there were no meaningful regression model for “Jungdong new town” and “Pyeongchon new town.” By examining the control conditions of the analysis, it is estimated that these two areas are respectively subject to Bucheon-si and Anyang-si. Thus, it would be advisable to expand the spatial range of the analysis to city level in order to obtain a meaningful result. Although the spatial range of this paper was limited to new town, it would be positive to derive more meaningful result when the spatial range is expanded. The expansion of spatial range would be necessary for practical uses such as operation and management of cities.",
		"KEYWORD": "OD,교통량,도시계획,상업용지,수요추정"
	},
	{
		"ID": 966,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "NUMA 구조에서 SSD기반 디스크 I/O를 고려한 쓰레드 배치 기법 =(A)SSD-based disk I/O-aware thread placement policy for NUMA architecture ",
		"AUTHOR": "정승재",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박성용 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "최근 빅 데이터나 슈퍼컴퓨터, 사내 가상화 등에 대한 관심이 증가하고, 각종 서버에 고성능, 저비용 하드웨어가 대량으로 공급되면서 기존의 SMP 구조에 비해 하드웨어 확장성이 뛰어난 NUMA 구조 서버의 사용이 증가하고 있다. 이러한 NUMA 구조의 서버는 각 노드와 메모리, 디바이스 등과의 물리적인 배치에 따른 접근성에 의해 성능의 차이가 발생한다. 본 논문은 SSD I/O 디바이스와 메모리의 물리적 위치와 성능의 차이에 따라 쓰레드를 배치하는 기법을 제안한다. 제안된 기법은 쓰레드가 사용하는 I/O가 전체 작업량에서 차지하는 비중과, 노드별 위치에 따른 I/O 성능의 차이, 그리고 노드별 메모리 참조의 양을 이용하여 해당 쓰레드가 배치될 가장 적절한 노드의 위치를 찾아준다. 현대의 많은 서버 환경에서는, I/O 저장장치로부터의 I/O 수행의 양이 증가하고 있기 때문에, I/O의 성능을 향상시키는 것은 전체 시스템의 성능 향상을 위해 꼭 필요하다. 본 논문에서는 Intel 기반의 NUMA 구조의 서버 위에서 디스크 I/O를 고려한 쓰레드 배치 기법을 리눅스에 추가 구현하였고, 제안된 기법이 기본적인 Read와 Write I/O 성능과, 여러 환경에서 성능이 향상되는 것을 보인다.",
		"KEYWORD": null
	},
	{
		"ID": 967,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "연세대학교 대학원",
		"TITLE": "Medium access control for enhanced spatial reuse and QoS support in multi-hop wireless networks =공간 재사용 및 QoS 지원을 위한 무선 다중 홉 네트워크 매체 접속 제어 기법 연구 ",
		"AUTHOR": "MinseokKim",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 968,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "모바일 앱의 사용자 의견을 시스템 요구사항으로 추출 및 정제하기 위한 활동에 관한 연구 =(A)study on system requirements extraction and refinement activities based on mobile app users` opinion ",
		"AUTHOR": "김선빈",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 류성열",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "웹 및 모바일 소프트웨어에 표현한 사용자 의견을 효율적으로 정제 및 확인하기 위한 기법은 빅데이터 기반 연구와 관련이 있다. 또한 이는 사용자 의견에 민감한 소프트웨어의 개선과 유지보수에 매우 중요하다. 본 연구에서는 모바일 애플리케이션에 게시한 사용자 의견을 수집하여, 이를 소프트웨어의 변경 요구사항 또는 시스템 개선 요구사항으로 정제하기 위한 절차를 제안한다. 본 연구에서 제안한 절차는 5단계로 구성되며, 그 내용은 다음과 같다. 1) 애매모호한 사용자 의견을 기본 형식으로 변환하여 사용자 요구사항을 추출하는 단계. 2) 사용자 요구사항을 분석하여 소프트웨어관련 요구사항을 분류하는 단계. 3) 모바일 소프트웨어의 프레임, 페이지 및 GUI를 분석하여 용어사전을 구축하는 단계 4) 소프트웨어관련 요구사항의 적용 대상과 범위를 판단 및 확인하는 단계 5) 그리고 시스템관련 요구사항을 식별 및 추출하기 위한 단계. 각 단계를 수행하기 위하여 12개의 활동과 하위 36개의 태스크를 수행한다. 제안한 절차의 유효성을 검증하기 위하여, 2개 사의 모바일 소프트웨어를 대상으로 조사 분석한 결과, 자동화 가능성을 확인하였다. 또한 이를 분석가/관리자에게 전달한 결과, 유용함을 확인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 969,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "기업의 VOC와 외부채널 데이터 간의 차이점 분석 =Analysis of the differences between the company and external VOC channel data ",
		"AUTHOR": "안상현",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 백동현 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 59-62",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "본 논문은 기업들이 공식적인 채널을 통해 수집하는 VOC(Voice of Customer, 고객의 소리)가 다양한 고객의 의견을 반영하지 못한다는 문제점에서 출발하여 외부채널과의 비교를 통해 VOC가 나아가야 할 올바른 방향성에 대해 연구하였다. 이를 위하여 통계 프로그램 R을 이용, 사회연결망 분석, 모듈성 분석, 감성분석을 각각 활용하여 각각의 채널에서 수집한 자료의 특성과 차이점을 분석하였다.",
		"KEYWORD": "경영전략"
	},
	{
		"ID": 970,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서울시립대학교 대학원",
		"TITLE": "WIM 자료를 이용한 고속도로 화물수송실적 산정 연구 =Estimating truck and freight transportation statistics on expressway using WIM data ",
		"AUTHOR": "주진형",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박동주",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "우리나라는 약 75% 이상의 화물이 도로를 이용하여 수송되고 있으나, 화물 이동, 행태 등 물류활동을 반영하는 성과지표에 대한 연구는 활발히 진행되고 있지 않다. 이에 따라 각 도로등급별, 차종별 화물수송기여도 및 효율성 등을 파악하는데에 어려움이 있다. 또한 우리나라 정부에서는 공공부문의 물류 빅 데이터 이용을 장려하고 있으나, 데이터 수집 및 활용 시 한계점이 많다. 물류 빅 데이터 이용의 한계와 물류행태를 나타내는 지표의 부재로 인해 관련 정책 수립 시 반영이 어려운 실정이다. 본 연구의 목적은 국내화물수송의 핵심인 고속도로를 이용하는 화물자동차를 대상으로 고속도로 교통량 및 하중측정시스템 자료를 이용한 고속도로 화물수송실적(Gross & Net ton-km) 산정 방법을 제시하는 것이다. 본 연구는 크게 5가지 수행과정으로 구성하였다. 첫째, 기존연구 및 사례를 고찰하여 화물수송실적에 대한 정의와 추정 방법론 등을 검토하고, 화물수송실적 산정의 필요성을 규명하였다. 둘째, 화물수송실적을 산정하기 위해 이용가능한 자료를 수집하고, 장·단점 및 한계를 파악하였다. 셋째, 고속도로 화물수송실적 산정 과정에 따라 화물자동차 교통량 추정 및 축중기 중량 추정·보정 방법론, 고속도로 화물수송실적 산정 결과를 제시하였다. 넷째, 본 연구에서 제시한 고속도로 화물수송실적 산정 방법론과 산정 결과에 대한 검증을 통해 타당성을 평가하였다. 마지막으로 본 연구의 결론과 한계점을 기술한 후, 향후 연구방향을 제시하였다. 본 연구의 화물수송실적(톤-km) 산정 방법론은 첫째, 고속도로 교통량 및 하중 측정시스템(TCS, WIM) 자료를 이용한 새로운 시도이며, 둘째, 고속도로 교통량 및 하중 측정시스템 자료(TCS, WIM)의 한계를 Gradient Method, Expectation Maximization Algorithm을 활용하여 보완했다는 점이다. 셋째, 화물의 적재 중량을 고려한 순 화물수송실적(Net ton-km)뿐만 아니라 화물자동차 공차 중량까지 고려한 총 화물수송실적(Gross ton-km)을 산정했다는데에 의의를 가진다.",
		"KEYWORD": "EM Algorithm,TCS,WIM. Gradient Method,고속도로 화물수송실적,화물 지표"
	},
	{
		"ID": 971,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2012",
		"UNIVERSITY": "순천대학교 대학원",
		"TITLE": "객체지향 설계 모델링을 이용한 모바일 클라우드 기반의 상황인식 프로세스 설계 및 구현 ",
		"AUTHOR": "정세훈",
		"REGION": "전라남도",
		"PROFESSOR": "지도교수 :심춘보",
		"STORE_LOCATION": "순천대학교 도서관",
		"ABSTRACT": "수 많은 유비쿼터스 관련 용어들이 홍수처럼 불어나는 정보화 시대에 상황인식과 모바일 및 클라우드 개념은 유비쿼터스 컴퓨팅 환경을 구현하기 위한 하이라이트로 여겨지고 있다. 상황인식 서비스라는 개념은 컴퓨팅과 통신을 기반으로 서비스를 제공 받는자의 주변 상황을 컴퓨터가 인식하고 스스로 판단하여 사용자에게 유용한 정보를 제공하는 서비스이다. 이러한 상황인식 서비스는 컴퓨터가 사용자의 생각을 미리 확인할 수 없지만 사용자의 주변 상황을 인식해서 사용자의 의도에 적합한 수 많은 데이터를 사용자에게 제공할 수 있는 상황인식 프로세스를 가지고 있어야 한다. 현재 상황인식 프로세스는 국내?외적으로 많은 연구가 진행되고 있다. 그러나 기존 연구의 상황인식 서비스는 특정 플랫폼에 종속적으로 배치되어 특정 모바일기기 아닌 불특정 다수의 모바일기기에서 사용할 수 없는 불편함이 단점으로 지적되고 있다. 또한 기존 연구에서는 상황인식 정보를 추론하기 위해 온톨로지 언어인 RDF/OWL을 시멘틱 검색 방식인 SparQL의 질의 형태로 추론 방식을 지향하였다. 그러나 위와 같은 시멘틱 검색 방식은 정보 추론 저작 도구인 Protege에서 상당한 검색 지연 시간을 발생하게 되는 단점이 지적되고 있다. 그리고 단일 형태의 SWRL 규칙으로 상황정보 추론 방식을 대부분 활용하였지만 SWRL의 추론엔진이 존재하지 않아서 외부의 상황 추론 엔진으로 지식베이스에 포함된 Fact와 Rule을 모듈을 통해서 보내는 단점이 있다. 이는 상황인식 추론에 불필요한 응답지연 시간을 포함하게 되는 문제점이기도 하다. 이에 본 논문에서는 특정 플랫폼에 종속되지 않고 다양한 모바일기기에서 상황인식 서비스를 제공받을 수 있도록 PaaS(Platform as a Service)기반의 Google App Engine을 이용한 모바일 클라우드 상황인식 서비스를 제안한다. 아울러 기존 추론 방식인 시멘틱 검색의 SparQL 질의 추론 방식의 단점을 극복하고자 SWRL형태의 규칙 정보인 Class, Property, Individual등의 속성값들을 JessTab 플러그인을 이용하여 Jess 추론 엔진에 연결함으로써 SWRL의 규칙 추론을 Jess 추론 엔진에 매핑하여 상황인식의 서비스 추론 시간을 단축하고자 한다. 마지막으로 상황인식 프로세스의 설계 형태를 사용자 요구사항 분석을 통한 프로세스 모듈간의 상호보완성을 극대화하고자 하며. 이를 위해 객체지향적인 방식을 통하여 각 소프트웨어 설계 산출물을 작성함으로써 추후에 발생할 수 있는 프로세스의 확장성과 재사용성을 최대한 반영하여 프로세스 공정을 개선시킨다.",
		"KEYWORD": "Context-Awareness,Google App Engine,Jess,JessTab,Object-Oriented design modeling,Ontology,SWRL,UML,객체지향 설계 모델링,모바일,상황인식 프로세스,클라우드"
	},
	{
		"ID": 972,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "Under-Sampling과 유전자 알고리즘 기반 앙상블 MSVMs :기업신용등급 예측에의 응용 ",
		"AUTHOR": "박종진",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 전영호 참고문헌: 장 26-29",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "최근 빅 데이터와 머신러닝이 이슈로 떠오르면서 데이터 분석에 대한 수요가 급증하고 있다. 머신러닝의 핵심은 분류를 통한 예측인데 학계에서는 오래전부터 전통적인 이분류 문제에 이어 다분류 문제의 예측과 관련한 다양한 모형들을 연구해 왔다. 최근 연구결과들에 의하면 다양한 분류 알고리즘 중에서도 다분류 SVM이 가장 우수한 예측성과를 보이는 것으로 알려져 있다. 다분류 모형의 예측 성과에는 이와 같이 분류기의 종류에 따른 영향도 있지만 범주 간 데이터의 불균형이 발생하는 경우 또한 매우 큰 장애물이 된다. 따라서 본 연구에서는 다분류 SVM 의 성능 최적화를 위해 유전자 알고리즘(Genetic Algorithm, GA)을 결합하여 파라미터 최적화를 이루고 동시에 데이터 불균형 문제를 해결하기 위해 Under-Sampling 기반 앙상블 MSVM을 설계하여 다분류 문제의 일반화 모형을 제안한다. 제안된 모형을 실제 기업의 신용등급에 적용한 결과 다분류 SVM 의 파라미터 최적화만 이루었을 때 보다 분류성과의 개선이 이루어졌으며 다분류 SVM에 Under-Sampling만을 적용한 경우와 비교해도 견고한 학습성과를 나타냈다.",
		"KEYWORD": null
	},
	{
		"ID": 973,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "딥러닝을 이용한 주가 예측 모델 =Stock price prediction model using deep learning ",
		"AUTHOR": "이지훈",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 정기철 참고문헌: p. 39",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "In 2016, AlphaGo, a Artificial Intelligence developed by Google, won the game against Professional Go player Lee-SeDol. It was the first computer program to win the professional Go Player without handicap. Now, Artificial Intelligence has been used more widely in various fields due to great development of hardware, the emergence of big data and the improvement of algorithms such as computer vision, natural language, processing, robotics and etc, all fields that have been difficult to learn. That also includes investment banking, trading and credit evaluation methods. In this paper, we study how to build a stock price prediction model by analyzing financial data using Multi Layer Perceptron, Convolution Neural Network. Recurrent Neural Network. The model uses data from the top 20 stocks in the KOSPI market between July 2006 and July 2016. Stock data, KOSPI, NIKKEI , S&P500, and NASDAQ were converted into technical indicators and used for neural network learning. Since the neural network assumes that the stock shift patterns will be different for each item, we have created different neural network models.",
		"KEYWORD": "머신러닝"
	},
	{
		"ID": 974,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "충남대학교 대학원",
		"TITLE": "민사소송절차에서 전자적 정보의 증거조사에 관한 연구 ",
		"AUTHOR": "이규철",
		"REGION": "대전",
		"PROFESSOR": "충남대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 金容秦 참고문헌 : p. 207-214",
		"STORE_LOCATION": "충남대학교 도서관",
		"ABSTRACT": "첨단 정보통신기술로 인해 우리의 생활은 유형적 기반에서 무형적 기반으로 바뀌고 있다. 또한 과거 부를 측정하는 단위는 재화나 기술, 인력의 숙련 지수 등이었으나, 현대는 평가단위가 전자적 정보로 대체되어 가고 있을 뿐만 아니라 누가 더 많은 전자적 정보를 가지고 있느냐에 따라 부를 증대시킬 수 있고 그렇지 못할 수 있다. 우리는 전자적 정보가 경제적 자산이 되는 시대에 생활하고 있는 것이다. 민사소송법 제1조의 이념 즉, 법원은 소송절차가 공정하고 신속하며 경제적으로 진행되도록 노력하여야 하고, 신의성실에 따라 소송을 수행하여야 한다는 근본취지에 점차적으로 멀어질 수 있다. 특히, 의료소송, 특허소송 등과 같이 현대형 소송은 전자적 정보가 어느 한쪽에만 편중되어 있어 소송자체를 진행하기 어려운 경우가 적지 않다. 우리나라 문서제출명령제도는 증거방법의 측면도 있지만 활용 여하에 따라서는 증거개시제도로서 기능할 수 있는 여지가 충분하다. 본 논문에서는 전자적 정보를 현행 민사소송절차에 도입하기 위해서 구체적인 방안을 제시한다. 우리나라 기업은 전통적 증거방법에 안주하여 패소하는 경우가 빈번하게 발생하고 있다. 따라서 민사소송법이 갖는 근본적 목적을 확립하기 위한 종합적인 연구가 필요한 시점이다. 우리나라 민사소송에 있어 증거조사, 조사방법 등에 관한 비효율적인 문제점과 미비점을 보완하려는 입법자들의 노력과 함께 전자적 증거방법을 도입하여 우리나라와 세계 각국과의 상호호환이 가능한 전자적 증거방법이 필요할 것으로 생각된다.",
		"KEYWORD": null
	},
	{
		"ID": 975,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "울산대학교 경영대학원",
		"TITLE": "전문가 지식자원의 활용을 위한 지식관리시스템 구축에 대한 연구 =A study on the construction of knowledge management system for utilization of expert knowledge resources ",
		"AUTHOR": "전철호",
		"REGION": "울산",
		"PROFESSOR": "지도교수: 장길상",
		"STORE_LOCATION": "울산대학교 도서관",
		"ABSTRACT": "전문가 지식자원의 활용을 위한 지식관리시스템 구축에 대한 연구 사회와 경제의 패러다임이 지식사회로 변화함에 따라 사회는 지식의 중요성과 지식경영의 필요성을 인식하여 지식경영시스템을 개발하고 운영하기 시작하였다. 그러나 지식경영의 효과는 기대에 미치지 못 하였으며 그 이유는 지식 생성과정이 제대로 이루어지지 않았기 때문이라는 연구 보고가 있다. 그 중에 하나로 기업이나 조직에서 지식 및 기술을 보유한 자들이 생성과정에서 여러 가지 변수로 인하여 지식이전을 하지 못한 채 은퇴를 하는 경우이다. 그 후 이 지식 및 기술들은 방치된 상태에서 자연 소멸되어 국가적으로 지식손실을 가져오며 이는 국가경쟁력을 약화시키기도 한다. 지식생성은 기본적으로 내부 직원들에 의하여 이루어지는 것이 원칙이지만 내부적으로 해결되지 못하는 것은 외부의 지식자원을 활용하여야 한다. 은퇴로 인하여 전문지식과 핵심기술이 이미 외부자원이 되어 버렸지만 이를 지속적이고 효율적으로 활용하기 위한 시스템이 필요한 때라고 본다. 이러한 시스템은 기업은 경영에 필요한 전문지식이나 핵심기술의 공백을 최소화하고, 은퇴자들은 자신들이 보유하고 있는 암묵적 전문지식이나 핵심기술을 현업에 지식이전 할 수 있는 기회를 가질 수 있게 한다. 본 논문에서는 위와 같은 연구문제를 풀어가기 위해 은퇴자를 포함하여 외부에 있는 전문가의 지식자원을 효율적으로 활용하기 위한 전문가지식관리시스템(EKMS : Expert Knowledge Management System) 구축 및 활용 방안을 제시하였다. 구현한 시스템은 기업이나 조직의 외부에 있는 암묵적 전문지식이나 핵심기술들을 일정한 체계를 통하여 분류하고, 전산시스템에 형식화하여 생성, 저장, 공유하여 놓았다가 필요한 기업이나 조직에게 전문지식을 이전하는 외부 지식자원 시스템이다. 전문가지식관리시스템은 각 산업별로 전문지식이나 핵심기술들을 빅데이터로 구축하여 데이터베이스화 하여진다. 테이블 구성으로는 시스템의 중심이 되는 “전문지식 빅데이터” 테이블, 전문지식을 이전하는 프로젝트를 관리하는 “지식이전 프로젝트” 테이블, 전문지식이전 프로젝트를 수행 할 “지식전문가 인력풀” 테이블이 있다. 외부 전문가의 지식자원을 효율적으로 활용하기 위한 전문가지식관리시스템의 기대효과는 다음과 같다. 첫째 기업이나 조직의 경영에 필요한 전문지식이나 핵심기술을 은퇴자들과 지속적인 유대관계를 통하여 유지 보존 할 수 있다. 둘째 은퇴자는 본인이 보유한 전문지식이나 핵심기술을 이용하여 전문지식 관련 사업을 창업하여 평생직업의 기회를 가질 수 있다. 셋째 국가적인 차원으로는 전문지식자원 활성화를 통하여 지식산업의 국가경쟁력 강화 시킬 수 있는 방안을 마련 할 수 있다. 넷째 기업의 퇴직프로그램으로 활용 방안, 국가의 퇴직자들에 대한 일자리창출 정책 수립 방안으로도 활용 할 수 있으리라 본다.",
		"KEYWORD": null
	},
	{
		"ID": 976,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "한성대학교 지식서비스&컨설팅대학원",
		"TITLE": "사물인터넷(IoT) 융합비즈니스 촉진전략에 대한 연구 =(A)study for promotion strategies of the convergence business based on the IoT(Internet of Things) ",
		"AUTHOR": "허진",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 오종택",
		"STORE_LOCATION": "한성대학교 도서관",
		"ABSTRACT": "최근 사물인터넷은 ICT산업의 발전과 빅데이터 시대의 도래 그리고 웨어러블 디바이스의 부상에 따라 다양한 융합비즈니스 모델의 개발과 서비스가 빠르게 확대되고 있다. 최근에 사물인터넷이 다시 주목받기 시작한 것은 국제전기통신연합(ITU)의 ‘모든 기기 및 사물에 근거리 및 원거리 통신 모듈이 탑재되면서 마술과 사람 간 또는 사물 간의 새로운 통신 유형이 등장할 것’이라는 2005년에 사물인터넷 관련 보고서의 발간이 계기가 되었다. 이후 가트너의 ‘2013년 기업이 전략적으로 대응해야 하는 10대 기술 및 트렌드’ 발표 그리고 ‘2020년까지 세계 사물인터넷(IoT, Internet of Things) 기기가 260억대에 이를 것’이란 전망에 따라 사물인터넷에 대한 세계 각국과 IT 선도 기업들의 관심이 증가하고 있다. 사물인터넷의 선도 국가인 미국, EU, 중국 그리고 일본 등은 정부 및 민간 기업의 주도를 통해서 사물인터넷 산업을 발전시키기 위한 다방면의 노력을 하고 있다. 미국에서는 사물인터넷 표준화를 목표로 한 비영리 그룹인 `산업 인터넷 컨소시엄(Industrial Internet Consortium, IIC)`을 창설 되었다. EU는 사물인터넷 연구 협의체 조성 및 액션플랜의 발표를 통해 사물인터넷 산업의 발전을 모색하고 있다. 중국은 ‘사물인터넷 발전 12차 5개년 규획’을 통해서 그리고 일본은 ‘I-Japan 전략 2015’ 등의 수립을 통해 관련 산업에 대한 육성과 지원을 하고 있다. 국내에서는 미래창조과학부 및 관계부처가 합동으로 ‘사물인터넷 기본계획’을 2014년 5월에 발표하면서 각 부처별로 추진되었던 사물인터넷 정책이 통합적으로 추진될 수 있는 기반이 마련되었다. 정부는 사물인터넷 기본계획의 수립을 계기로 생태계 참여자간 협업 강화, 오픈 이노베이션 추진, 글로벌 시장을 겨냥한 서비스의 개발ㆍ확산 그리고 대ㆍ중ㆍ소기업과 스타트업별 맞춤형 전략을 추진전략으로 하여 초연결 디지털 혁명의 선도국가를 실현을 목표하고 있다. 하지만 현재의 사물인터넷 시장을 살펴보면 다양한 사물인터넷과 시장의 활성화 배경과 정부의 강력한 정책적인 지원에도 불구하고 아직은 서비스 중심이 아니라 하드웨어 중심으로 시장이 형성되고 있다. 특히 사물인터넷과 관련한 ICT산업의 발전을 촉진할 수 있는 법과 제도적 토대가 마련되지 않은 이유로 컨텐츠 중심의 서비스 개발과 서비스를 지원하기 위한 구체적인 비전이나 방안들에 대한 논의가 필요한 시점이다. 따라서 본 논문에서는 이를 위한 효과적인 대안으로 회원국들의 정책 사이에 조화를 추구하며 규제, 지침, 결정 등과 같이 법적 구속력을 지닌 도구를 사용하는 전통적인 거버넌스가 아니라 유럽연합이 활용하고 있는 연성법적 접근방식의 개방형 조정방식을 살펴보고자 한다. 효율적인 사물인터넷 생태계가 관련 기관 간 협력체계 구축 및 사업화 지원체계의 강화를 통해서 산업의 발전을 도모하기 위한 방안으로 연성법(Soft Law)적 접근을 통한 자율적인 규제의 도입을 사물인터넷 융합비즈니스의 촉진전략으로 제안하고자 한다.",
		"KEYWORD": "IoE,IoT,M2M,사물만능통신,사물인터넷,사물지능통신"
	},
	{
		"ID": 977,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 교육대학원",
		"TITLE": "정보시각화 이미지를 활용한 통합적 미술수업 방안 연구 ",
		"AUTHOR": "김아름",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김영호 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "With advancing to the era of knowledge-based society, a change was shown even in attitude of accepting information according to a rise in mobile media users. As the big-data age created by excessive information arrives, the media users` desire for the flood of information aims to use the compressed visual information on a small screen with mobile device such as cellular phone. It is not what simply accepts information, but is being demanded ability of analyzing, analyzing and integrating big data. As a means available for approaching the integrated ability of this information, the information visualization is being emerged. Accordingly, this study aims to concentrate on effect and function of being possessed by fine arts in this form through the process of visualizing information. Information has been developed in diverse forms along with mankind. Information began to be visualized from a wall painting by using various symbols. According to the development in printing technology, it is being developed into a printed book of recording it in paper. According to the diffusion of computer, the technology of effectively delivering information even up to visual technology such as photo and image in the media environment has been developed even into the contents of involving information. Information is taking the generally horizontal form that everyone can understand. Owing to the supply of smart phone, the mobile market stretched over the world and is proceeding with developing with sympathizing with people in each country of using different languages. Interactivity in this information shows importance of ability, which stimulates a cognitive desire and analyzes and interprets visual information. However, a research and outcome on education of information visualization were biased to engineering and design field. It is insufficient in the foundation on the specific methodological aspect of art education through applying information visualization. The government is enforcing information visualization on a policy basis in order to be possibly delivered so that many people can easily understand public information. It aims to examine this present situation as a whole and to progress a research of art class with application of information visualization image that can be specific ground and guideline in educational field. Information visualization is a method that can be found easily in life, not a method of being limited to creation. A method of being able to deliver information effectively can be seen what was edited with visual information in all media that we get access to information such as realistic depiction and photo through writing and painting and as image newspaper or book. This information can utilize knowledge that was acquired in textbook. The aim is to research by integrating other curriculums even into art education by using design-based element through diverse visualization methods as for a method of being available for delivering effectively knowledge and information, which were obtained in other diverse curriculums. Firstly, it aims to extract hypothesis on a plan for art education with application of image in information visualization by considering a concept and research trend of information visualization. First of all, it defined terminology on information visualization, defined terms dubbed `information` and `information visualization` because of being likely varied the image of a research on instructional plan with application of information visualization depending on a concept, and progressed a research on merits and demerits of information visualization. Secondly, it examined how the information visualization is being applied now to public agency and design field. It analyzed principle and method of information visualization based on this and examined with which stage the art education needs to be formed by considering a concept of information visualization. Finally, it aims to prove appropriateness of art education with application of image in information visualization based on interactivity and publicness by synthesizing the above contents. The educational objective of art education with application of image in information visualization is to train talents who have creative & analytical thinking, teamwork, and communication skill. According to this educational goal, the scope of forming information includes engineering field, social science field, humanities field, and art field. The aim is to form the instructional process that integrated even the stage of making design image by forming and systemizing information by acquiring the process of utilizing information visualization by integrating it into the stage that understood knowledge in other majors. For this, it aims to research into analysis, too, on curricular subject available for integrating other curriculums, in addition to the analysis of fine arts textbook available for information visualization.",
		"KEYWORD": null
	},
	{
		"ID": 978,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "성균관대학교 대학원",
		"TITLE": "초연결 사회의 Neo-Smart-Human 중심 스마트 프로덕트 기획/개발 프로세스 개발 =Development of smart product design/development process in neo-smart-human centered hyper connected society ",
		"AUTHOR": "김형우",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 최재붕 참고문헌 : p. 85-89",
		"STORE_LOCATION": "성균관대학교 삼성학술정보관,성균관대학교 중앙학술정보관",
		"ABSTRACT": "보편화된 초고속 무선 통신, 소셜 네트워크 서비스, 스마트폰 등으로 인해 새롭게 등장한 초연결사회와 스마트 신인류(Neo-Smart-Human)는 제품과 서비스를 개발하는 과정에 적극적으로 참여하며 새로운 프로세스의 필요성을 발생시켰다. 또한 제품과 서비스가 융합된 스마트 프로덕트라는 카테고리를 등장시켰다. 이러한 환경 변화에서 스마트 프로덕트를 개발함에 있어 기존 방법론을 완전히 적용하기 어렵기에, N.S.H.의 7가지 특성인 연결성, 정보의 신속성, 정보의 전파성, 과시성, 유희성, 공감성, 선의 추구성을 기반으로 분석한 기획/개발 프로세스의 이론화를 위한 연구를 진행하였다. 이를 실제 제품 개발에 적용함으로 시장 검증을 통한 프로세스의 유효성을 검토하였다. 본 논문은 향후 변화된 환경에서의 새로운 제품-서비스 기획 및 개발 생산 기법 연구에 유용하게 사용할 수 있을 것으로 기대 된다.",
		"KEYWORD": "기획/개발 프로세스(Design/Development Process),소셜 네트워크 서비스(Social Network Service),스마트 신인류(Neo-Smart-Human),스마트 프로덕트(Smart Product),스마트폰(Smartphone),초연결사회(Hyper Connected Society)"
	},
	{
		"ID": 979,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "인천대학교 대학원",
		"TITLE": "정보 프라이버시 염려와 신뢰가 개인정보 제공에 미치는 영향 =(The)effect of information privacy concern and trust on the provision of personal information ",
		"AUTHOR": "박천웅",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 김준우",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "인터넷의 등장으로 오프라인에서 진행되던 상거래와 정보 수집 등의 활동이 온라인으로 이동하면서 시간 단축, 비용의 감소 등으로 인해 개인의 생활이 편리해졌다. 특히, 금융업무, 물품 구입 등의 상거래, 민원서류 발급 및 각종 정보 수집 등 대부분의 업무가 정보기기를 활용하기 때문에 개인을 식별할 수 있는 개인정보의 중요성이 더욱 확대되고 있다. 그러나 이러한 개인정보가 유출되면 그 자체로 인해 피해가 발생되며, 또한 유출된 개인정보가 활용되는 2차 피해로 발전 될 수 있다. 따라서 개인정보를 제공하는 소비자들은 개인정보 유출에 대한 우려로 개인정보 제공에 대해 상당한 거부감을 갖게 된다. 따라서 소비자는 개인정보 유출에 대한 염려로 자신의 정보를 쉽게 제공하지 않고 있으며, 오히려 잘못된 정보를 제공하기도 한다. 이처럼 소비자들이 개인정보 제공에 거부감을 갖는 이유는 개인정보를 수집, 취급하는 기업에서 대부분의 개인정보 유출 사고가 발생하고 있기 때문이다. 따라서 본 연구는 개인정보를 수집, 취급하는 기업에 대한 신뢰 회복과 개인정보 제공에 대한 염려를 낮추는데 영향을 주는 요인들을 도출하여 실제로 개인정보 제공행동으로 연결될 수 있도록 하기위해 실증적으로 분석하여 검증하고자 하였다. 이를 위해 기존의 선행연구에서 논의되었던 정보 프라이버시 염려와 신뢰에 대한 4개의 선행변수(위험, 침해경험, 정책, 통제)와의 관계를 분석하여 이를 바탕으로 정보 프라이버시 염려와 신뢰가 개인정보 제공의도와 행동에 어떠한 영향을 미치는지에 대한 영향도를 분석하였으며, 이를 기반으로 정보 프라이버시 염려와 신뢰, 개인정보 제공의도와 행동 영향을 포함하는 연구모형을 수립하였다. 본 연구의 결과는 다음과 같다. 정보 프라이버시 위험과 침해경험, 정책 그리고 통제기능은 염려에 영향을 미치고 결국 행동으로 이루어진다는 것이다. 이러한 연구의 시사점은 소비자에게 정보 프라이버시 염려를 낮추고 신뢰를 높여주는 정책이나 기술을 제공하면 개인정보를 제공할 것이며, 이를 산업적으로 활용할 수도 있을 것이다.",
		"KEYWORD": "개인정보 제공,개인정보 활용,데이터 분석,정보 프라이버시"
	},
	{
		"ID": 980,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "IoT-CBDAC :context-based dynamic access control model using intuitive 5W1H for the Internet of things ",
		"AUTHOR": "JiseongSon",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 981,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "한국외국어대학교 대학원",
		"TITLE": "클라우드 컴퓨팅을 활용한 예측모델링 =Predictive modeling using the cloud computing ",
		"AUTHOR": "김미정",
		"REGION": "서울",
		"PROFESSOR": "한국외국어대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 최대우 참고문헌 : p. 41",
		"STORE_LOCATION": "한국외국어대학교 글로벌캠퍼스 도서관,한국외국어대학교 서울캠퍼스 도서관",
		"ABSTRACT": "최근에 등장하는 CPU들은 싱글코어가 아닌 멀티코어 프로세서로 제작되고 있으며 변화된 컴퓨팅 환경에 맞추어 이들의 성능을 최적화 할 수 있는 효율적인 병렬 프로그래밍 방법론을 개발하는 것이 필수적이다. 또한, 빅데이터를 다룰 수 있는 메모리의 할당량이 충분해야 한다. 본 논문은 멀티코어 CPU 기반의 클러스터 시스템 상에서 효율적인 병렬 프로그래밍을 활용하여 효율적인 예측모델링을 하게 된다. 이를 위해 클라우드 컴퓨팅을 제공하는 아마존웹서비스의 RStudio Web Server를 이용한다. 또한, 예측모델링의 각 단계를 함수화 하여 분석의 일괄적인 처리를 가능하게 한다. 주요용어 : 클라우드 컴퓨팅, 아마존웹서비스, caret 패키지, snow 패키지, 예측모델링",
		"KEYWORD": null
	},
	{
		"ID": 982,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "(An)integrated framework of automatic document summarization and classification ",
		"AUTHOR": "정형일",
		"REGION": "대한민국",
		"PROFESSOR": "지도교수: 서정연",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "In Big Data environment, the number of online news articles has increased significantly. The need to read these using smart phones, smart tablets, smart television, as well as personal computers, continues to grow. This growth makes automatic text summarization and categorization more important. The primary research fields on the solution of information redundancy are automatic document classification and summarization. Automatic document classification is the process to assign a text document to one or more classes or categories, and automatic document summarization is the process to reduce a text document in order to create a summary that retains the most important points of the original document. The purpose of these tasks is to facilitate efficient management of information and reduction of handwork. Traditional automatic document categorization and summarization have been considered as different research fields in this literature. Traditional text summarization systems have not used the category information of documents to be summarized. This has resulted in a data sparseness problem that is generally caused by estimating probabilities from a document and by extracting features from only one sentence for salient sentence extraction. In addition, traditional text categorization systems have not used the summary information of documents to be classified. Traditional document classification represents the weight of term without reflecting the importance of each sentence. However, each sentence in a document has own importance and these importance of sentences influences the importance of each term. In this dissertation, I propose an effective feature-weighting method for document summarization that utilizes category information and solves the problem of data sparseness. This summarization method is comprised of two main features: a category-based smoothing method that employs a language model, and a boosting framework operated by a pseudo-relevance feedback method. In addition, I propose an effective document classification method that uses document summary information. This classification method employs term relevance weight, which reflects the importance of each sentence according to a machine learning method based on both supervised and unsupervised learning. Finally, I propose an integrated framework of the proposed summarization and classification methods. Results of experiments conducted in this study reveal that the proposed summarization method performs 0.614 and 0.664 of F1-measure, and the proposed classification method performs 0.784 and 0.890 of F1-measure via supervised learning, and 0.545 and 0.598 of F1-measure via unsupervised learning, in the KORDIC and AbleNews dataset, respectively. Thus the proposed integrated summarization and classification method perform more efficiently than other statistical methods.",
		"KEYWORD": null
	},
	{
		"ID": 983,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울시립대학교 국제도시과학대학원",
		"TITLE": "통계적분석과 사례기반추론(CBR)을 활용한 경전철 교통수요 증/감 원인분석 및 예측모델에 관한 연구 :국내 경전철사업을 중심으로 ",
		"AUTHOR": "배석환",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김현주",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Private Business Investors are still investing their own capital on the LRT(Light Railway Transit) Public Private Partnership Projects, which are under operation after finish construction. Because actual traffic demands per project are below 70 ~ 80% compared with Implementation Agreement (I.A). Due to this one, every LRT operatin company could not be supported MRG(Mimimum Revenue Guarantee) by government or changed concerned rule. This study was conducted what social/economic factors are influenced traffic demands. The traffic demands is the most basic data to collect private investment. There are 4 types of traditional method for traffic demands measurements; Elasticity of demand Past Trend extension method Direct demand model 4 step demand model (Trip Generation, Trip Distribution, Modal Choice, Trip Assignment) Among these methods, a government office recommends 4 step demand model can be compared objectively. However, with the political, economic, social, cultural conditions are changed rapidly, as our country is very difficult to accurately predict the real traffic demand. In addition, analysts have contradictory results, depending on the technique applied to any material, any differently. This study is aimed to analyze economic and social factors affecting the actual traffic demand and build forecasting model to reflect a study result for the new LRT project. To analyze this study, SPSS(Statistical Package for Social Science) methodology is used to get a weight value and CBR(Case-Based Resoning) is used to develop forecasting model and verify it. Kew words : Traffic demands, Statistical Package for Social Science(SPSS), Case-Based Reasoning(CBR)",
		"KEYWORD": "교통수요"
	},
	{
		"ID": 984,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "Energy disaggregation based on modified FHMM using correlation analysis and its implementation for realtime application system ",
		"AUTHOR": "Choi,Kwang-Soon",
		"REGION": "서울",
		"PROFESSOR": "supervisor : Chung, Habong Includes bibliographical references",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "스마트 그리드 및 AMI (Advanced Metering Infrastructure)의 기술의 발달과 보급으로 기존의 기계식 미터기는 통신이 가능한 디지털 미터기로 점차 교체되고 있으며, 이러한 기술의 발달로 전력 유틸리티 회사에서는 수용가별로 과금을 위해 기존에 검침원이 한 달에 한번 방문하여 검침하는 방법에서 원격지에서의 수시 조회를 통해 과금하는 방식으로 바뀌고 있다. 또한 사용자 스스로의 에너지 절감 의식을 고취시키기 위해 사용자에게 개별 가전기기의 에너지 소비 정보를 실시간으로 피드백 해줄 수 있는 스마트 플러그 기반의 실시간 모니터링 기술이 많이 개발되었으나, 비즈니스 모델의 부재, 사용자의 비용부담 및 보급을 위한 정부 정책 등의 문제로 실용화까지는 아직 해결해야 할 문제가 많이 있다. 하지만 두 가지 기술의 보급을 통해 정부, 전력 유틸리티 회사 및 상당수의 마켓 플레이어들은 기기별 실시간 소비정보의 빅 데이터 수집을 통한 또 다른 비즈니스 기회의 창출을 기대하고 있는 상황이다. 개별 미터링을 통한 후자의 방식은 개별 가전기기의 에너지 소비 특성, 사용자 소비 패턴 분석 등을 위한 다양한 데이터를 직접적으로 제공할 수 있으나, 설치 비용의 부담으로 인한 보급 활성화의 문제를 안고 있어, 전자의 수용가별 총량 미터링을 통해 이러한 서비스를 제공하고자 하는 시도가 전 세계적으로 이루어지고 있다. 수용가별로 취득되는 시간대별 전기 에너지 사용 총량을 가지고 어떠한 가전기기가 어느 시간대에 얼마나 사용되어졌을 지를 역으로 추정해내는 과정을 에너지 분해 (Energy Disaggregation)라고 하며, 본 논문의 2, 3장에서는 FHMM (Factorial Hidden Markov Model)을 변형한 확률 통계 방식 기반으로 에너지 분해를 이론적으로 접근하였으며, 에너지 분해 결과의 정확도를 향상시키기 위해 가전기기간 사용 연관성을 상관 분석 (Correlation Analysis)하여 기존의 FHMM 알고리즘을 변형하였으며, Python을 통한 시뮬레이션을 통해 기존의 방식보다 향상된 에너지 분해 결과를 얻을 수 있었다. 제안된 에너지 분해 기술의 상용화를 위한 실시간 시스템으로의 적용을 목적으로 구현 관점에서의 다양한 고려사항을 도출하여 시뮬레이션을 수행하였으며, 기존의 상용 시스템에 손쉽게 탑재가 가능하도록 소프트웨어 모듈로 구현하여 기존 시스템에 탑재를 통한 실시간 에너지 분해 기능의 검증 또한 성공적으로 수행하였다. 기존의 상용 에너지 미터링 시스템은 운영시 요구되는 사용자의 개입을 통한 설정 변경 등의 불편한 사용자 인터페이스 문제로 인해 에너지 절감 기능 및 다양한 편의 사항을 제공하면서도 사용자의 외면을 받아 왔었다. 이 중 대표적인 것이 시스템 설치 이후 가전기기 위치의 변경 및 교체로 인한 복잡한 재설정 과정, 대기전력 자동차단을 위한 시스템의 대기모드 학습 및 대기모드 재인가를 위한 사용자의 개입 등이 대표적이라 할 수 있다. 이러한 문제를 해결하기 위해 사용자 접근 인지 기반의 자동 전원 제어를 통한 낭비전력 절약 및 대기모드 자동 재인가 알고리즘, 시스템 설정 변경이 필요할시 가전기기 자동인식 알고리즘 기반의 자동 설정 변경 기능, 대기전력 자동차단을 위한 대기전력 학습과정시 사용자의 개입이 필요없는 자동 대기전력 학습 알고리즘에 대해 본 논문의 4장에서 제안한다. 본 논문의 3, 4장에서 제안된 실시간 에너지 분해 기능 및 사용자 편의 기능의 검증을 위해 본 논문의 5장에서는 국제표준 기반의 에너지 절감 시스템의 구조 및 기능 요구사항에 대해 정의하고, 이를 바탕으로 시스템의 기본적인 하드웨어 및 소프트웨어를 구현하였다. 또한 제안한 기능의 기존 시스템 및 상용 시스템으로의 용이한 탑재 및 연동을 위해 소프트웨어 모듈 형태로 개발하였으며, 최종 개발된 시스템에 탑재하여 연동함으로써 성공적인 기능 검증을 완료하였다.",
		"KEYWORD": null
	},
	{
		"ID": 985,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "경기대학교 건설·산업대학원",
		"TITLE": "지방자치단체 재난관리 조직 및 체계의 개선에 관한 연구 ",
		"AUTHOR": "한경복",
		"REGION": "경기도",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수 : 김영철 참고문헌 : p. 91-93",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "2014년 4월 전남 진도군 해상에서 발생한 세월호 사고로 탑승객 476명 가운데 172명만이 구조 되고 300여명이 넘는 사망?실종자가 발생하였다. 이후 정부는 소방방재청과 해양경찰청을 통합하고, 안전행정부와 해양수산부의 일부 기능을 이관하여 통합적 재난컨트롤타워 역할 수행을 위한 재난관리 전담조직인 국민안전처를 신설하였다. 하지만 지방자치단체의 재난관리 조직은 여전히 변화하지 못하고, 과거의 모습을 간직한 채 컨트롤타워로서의 기능을 발휘하지 못하고 있는 것이 현실이다. 이에 본 연구에서는 재난의 예방?점검?대응?복구 등 재난안전관리 업무일체를 재난안전본부로 일원화 하고, 도지사 직속으로 개편한 경기도와 타 시?도의 재난관리체계 및 재난대응사례를 분석함으로써 문제점을 도출하고 이를 개선하기 위한 효율적인 방안을 제시하고자 한다. 첫째, 재난관리업무의 분산운영 방식에 따른 컨트롤타워 부재로 재난대응에 반복적인 실패를 경험하고 있는 지방자치단체의 재난관리 조직체계를 개선해 나가야할 것이다. 이를 위해 재난안전 외부전문가를 영입하고 현장에 강한 소방조직을 중심으로 재난관리 조직을 일원화하여 도지사 직속으로 승격시킨 경기도의 재난관리 조직체계를 표준으로 각 지방자치단체의 환경에 맞게 재난발생시 컨트롤타워 역할을 충실히 수행 할 수 있는 조직체계를 구축해야할 것이다. 둘째, 평상시 재난관련 유관기관 모두가 참여하는 재난유형별 현장대응 훈련은 물론 긴급예산의 편성?집행, 자원관리, 수습복구 등 재난관리 일체를 대상으로 도지사가 관련부처 및 유관기관을 총괄하여 재난대응 전반에 대한 문제점 및 개선방안을 도출해 나가는 재난총괄조정회의 등을 통하여 불시의 재난발생시 대처능력을 향상시켜 나가야할 것이다. 셋째, 민간전문 강사를 양성하고 적극 활용하여 보육시설, 초?중?고등학교, 기업체 등에 체험 위주의 체계적이고 전문화된 안전교육을 실시하여 안전의식 함양을 위한 재난안전교육을 강화해 나가야 할 것이다. 또한, 대형 문화?체육행사, 생활주변 위험시설 및 위험상황에 대한 온라인 안전신고, 안전점검 창구를 개설하여 위험 신고 및 점검 신청 시에 신속하게 현장을 무료로 점검하고, 컨설팅을 실시하여 불의의 안전사고를 미연에 방지해야 할 것이다.",
		"KEYWORD": "재난관리,지방자치단체"
	},
	{
		"ID": 986,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "숭실대학교 소프트웨어특성화대학원",
		"TITLE": "특허 정보와 오픈소스 텍스트 마이닝 도구를 이용한 잠재적 기술수요 발굴 방안 =(A)study on identifying potential technology demand using patent information and open source text-mining tools ",
		"AUTHOR": "지상태",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 신용태 참고문헌: p. 30",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "기술마케팅은 지식기반경제에서 기술이전의 중요한 활동으로 고부가가치를 창출할 수 있는 분야로 주목받고 있다. 특히 기술마케팅에서 정확한 시장수요를 파악하는 일은 기술이전 및 마케팅의 핵심요소로 자리 잡고 있지만, 일부 대기업을 제외한 특허 보유자는 자신의 기술수요를 객관적이고 정확하게 파악하기 어렵다는 문제점이 있다. 이에 본 연구에서는 오픈소스 텍스트 마이닝 도구를 이용하여 대한민국 특허청에 등록된 특정 회사의 특허 정보 데이터를 분석하여 핵심 키워드를 추출하고, 기술마케팅 분석에 필요한 키워드를 추출하는 방법을 제시한다. 본 연구를 통해 국내 기술 특허를 가진 특허 보유자가 빅데이터 분석으로 시간과 비용을 줄여 잠재적 수요자를 파악하고 효과적인 기술이전으로 나아갈 수 있는 가능성을 만들 수 있길 기대한다.",
		"KEYWORD": "Python,R Project,군집화 분석,기술마케팅,기술이전,오픈소스,텍스트 마이닝,특허,형태소 분석"
	},
	{
		"ID": 987,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "운송비 기반 배차 계획 시스템 모델 및 구현 =(An)improved model for vehicle allocation planning system based on logistics cost ",
		"AUTHOR": "강희용",
		"REGION": "서울",
		"PROFESSOR": "숭실대학교 논문은 저작권에 의해 보호받습니다. 지도교수:신용태 참고문헌 수록",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "With the activation of Internet use and the increased amount of online business increase in recent years, the volume of transportation, distribution and logistics is dramatically expanding. As a result, it is getting harder to maintain vehicles and ensure vehicle suppliers’ availability. One of the most important tasks of logistics companies is to manage transportation and its process more efficiently. In this period, there have been a number of studies dealing with the Vehicle Routing Problem(VRP) and the Vehicle Scheduling Problem(VSP) for efficient vehicle routing and allocation planning. This problem has model character in many field of mathematics, computer science, and operation research. Metaheuristics support managers in decision-making with robust that provide high-quality solution to important application in business, engineering, economic and science in reasonable time horizon. But it is difficult to reflect the daily changes in the traffic situation and detailed geographic conditions, and as the number of depots increases, it requires a large scale of database and huge consumption of time for calculations, which can make things very inefficient. Special features of local logistics market totally different from other country logistic business environment. Multi-level marketing conventional practices of cargo logistics industry caused a lot of problems combined with the complexity of live market data does not permit solving the problems exactly. No matter what government has made the best effort to solve the getting worse market problems, many interesting parties in logistics market never have yielded or shared their portion, and nor been co-operative to government policy or campaign either. To solve the vehicle allocation planning problems of Third Party Logistics(3PLs) firms that are faced with various constraints due to transportation cost, this paper proposes an algorithm-based transportation freight/income and new vehicle allocation information system. In addition, this paper shows the results of an actual test applied to a Third Party logistics company. The result shows that vehicle suppliers’ incomes increased by approximately 11 percent when the logistics cost-based vehicle allocation system was applied.",
		"KEYWORD": null
	},
	{
		"ID": 988,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인천대학교 동북아물류대학원",
		"TITLE": "데이터를 기반으로 한 대리점 등급 분류 체계수립 :A study on a agency reclassification system based on data : golf distribution industry standard ",
		"AUTHOR": "박태근",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 신광섭",
		"STORE_LOCATION": "인천대학교 학산도서관",
		"ABSTRACT": "본 연구는 골프기업인 A사와 이에 소속된 대리점의 등급체계를 빅데이터 그룹핑 툴인 K-means Clustering을 통해 재분류하여 A사의 기업경쟁력 강화 및 대리점의 올바른 등급 체계를 구축하는 것에 그 목적이 있다. 본 연구에서는 골프기업 A사에 소속되어 있는 오프라인 대리점과 온라인 대리점 중 오프라인 대리점만을 선별하여 분석하였으며 그 이유는 첫 번째로 대리점 분류체계는 오프라인 대리점에만 적용되고 있으며, 두번째로는 영업활동 촉진을 위한 판매촉진 인센티브 지원과 매출에 따른 미수금 정책이 오프라인 판매점에만 적용되기 때문이다. 본 연구는 거시적으로 국내 최초, 골프 산업 중 용품 기업이 소속된 대리점과의 유통 정책에 대해 조망하는 것이며, 미시적으로 골프 기업 A사의 현행 대리점 분기수금 중심의 1가지 변수-6등급 체계를 7가지 변수-5등급 체계로 정책 변화를 구축하는 것이고, 이를 통해 불필요한 판매 인센티브 절감의 효과와 함께 거래처 등급에 따른 공급제한으로 건강한 유통 생태계를 구성하는 것이다. 아울러 저평가 되어 있는 올바른 대리점의 양성으로 기업 경쟁력 강화에 활용될 수 있다.",
		"KEYWORD": "agency classification,agency reclassification,big data,golf distribution,SCM,골프,골프유통,대리점,대리점 등급 분류,데이터"
	},
	{
		"ID": 989,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "서강대학교 대학원",
		"TITLE": "패킷 버퍼용 메모리 대역폭 이용률 증가를 위한 패킷 매핑 기법과 통합형 메모리 =Improving the bandwidth utilization of packet buffer by packet mapping method and consolidated memory ",
		"AUTHOR": "최동건",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 이혁준 참고문헌수록",
		"STORE_LOCATION": "서강대학교 도서관",
		"ABSTRACT": "네트워크 데이터 트래픽 및 빅데이터 산업의 수요 증가로 인해 네트워크 라우터(Network router) 장비의 처리량 요구가 폭발적으로 증가하고 라우터 장비에서 수행되는 워크로드(Workload) 별 메모리 요구사항이 상이함에 따라 라우터에 최적화된 메모리 솔루션 개발의 필요성이 증대되고 있다. 라우터에서 수행되는 기존의 패킷 버퍼 향 메모리는 상대적으로 더딘 대역폭(Bandwidth) 증가로 인해 라우터의 성능 향상 및 확장의 제약사항이 되어왔다. 이러한 문제를 해결하기 위해 다양한 패킷 매핑(Packet mapping) 기법과 높은 대역폭을 제공하는 메모리를 사용하는 방안이 제시되고 있으며 이들은 메모리 대역폭을 향상시키는 것을 목표로 한다. 라우터에서는 DDR4와 HBM2와 같은 고성능 메모리의 조합으로 메모리 대역폭 향상을 이룰 수 있으나 새로운 고성능 메모리 구조를 효과적으로 사용할 수 있는 패킷 매핑 기법이 필요하다. 또한, 일반적으로 패킷 버퍼 향 메모리로 사용되던 DRAM 버스와 내부 셀 접근속도의 차이도 메모리 대역폭 이용률 감소의 원인이 되므로 이를 보완하는 방안도 필요하다. 지금까지의 연구는 두 가지 원인을 함께 고려한 메모리 솔루션을 제시하지 못했다는 한계를 지니고 있다. 본 논문에서는 메모리 대역폭 이용률을 향상시키기 위해 메모리 시스템 구조 및 환경을 고려해 병렬성을 유지하면서 Row-buffer 지역성을 높이는 패킷 매핑 기법을 제시한다. 또한, 메모리 버스 속도와 내부 셀 접근속도의 차이를 보완할 수 있는 통합형 메모리와 해당 메모리를 사용함에 따른 출력 대기열 큐의 우선순위와 지연시간을 고려한 패킷 매퍼(Packet mapper)의 패킷 배치 기법을 제안한다. 자체 제작한 패킷 제너레이터(Packet Generator)와 수정한 DRAM 시뮬레이터(DRAMSim2)를 사용해 제안한 방법을 증명하였다. 실험 결과 제시된 기법은 단일 DRAM과 기존 패킷 매핑 사용하는 메모리 시스템 대비 메모리 대역폭 이용률이 최대 24.46% 향상됨을 확인하였다.",
		"KEYWORD": null
	},
	{
		"ID": 990,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한양대학교 대학원",
		"TITLE": "차세대 IoT 서비스를 위한 IR-UWB Radar기반의 스마트 센서 구현 =Smart sensor realization based on IR-UWB radar for the next generation of IoT service ",
		"AUTHOR": "장혁",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 조성호 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 31-32",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "본 논문에서는 차세대 Internet of Things (IoT) 서비스를 제공하고자 Impulse radio ultra wide-band (IR-UWB) radar 기반의 스마트 센서를 구현하였으며, 스마트 센서를 적용하여 IoT 환경의 스마트 캠퍼스를 구축하였다. IR-UWB radar기반으로 구현된 IoT 모듈인 스마트 센서는 기존의 단순한 센싱 정보만을 수집했던 반도체 센서와 달리 IR-UWB radar의 특장점을 활용하여 사람의 생체 신호 측정, 측위, 재실 감지, 인원 계수, 방향 판단 등의 다양한 정보를 제공 할 수 있다. 위의 다양한 기능 정보들을 통한 서비스를 제공하기에 앞서 스마트 센서의 현장 적용 가능성을 테스트 하고자 실제 한양대학교 서울 캠퍼스를 테스트베드로 하고 있는 지능형 IoT 플랫폼인 Open-source architecture of semantic IoT service-platform (OASIS 플랫폼) 과 연동하고 있다. OASIS 플랫폼은 빅데이터 기반의 시멘틱한 처리를 해야 하므로 고차원적인 데이터 확보가 가능한 IR-UWB radar기반의 스마트 센서와의 연동이 필수적이다. 따라서, IR-UWB radar기반의 스마트 센서와 OASIS 플랫폼간의 연동을 통해 강의실, 기자재실, 실험실 등의 다양한 장소에 적용하여 스마트 센서의 성능 향상과 적용 범위를 넓혀 나감으로써, 학생들의 캠퍼스 이용에 있어 편의성 등이 증대된 스마트한 환경을 구축 하는 것을 목표로 하였다. 결론적으로, 위에서 언급한 다양한 스마트 센서를 활용한다면 IoT 플랫폼을 통해 제공되는 IoT 서비스의 종류와 질을 높일 수 있게 되며, 이를 통해 캠퍼스 뿐 아니라 점차 실생활 속에서의 광범위한 용도로의 적용하여 차세대 IoT 서비스로의 제공이 가능하게 될 것이다.",
		"KEYWORD": "컴퓨터공학"
	},
	{
		"ID": 991,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2016",
		"UNIVERSITY": "중앙대학교 행정대학원",
		"TITLE": "경찰의 교통사고 조사에 대한 고객만족도 분석을 통한 형사절차 개선방안 ",
		"AUTHOR": "이형주",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 심준섭 참고문헌수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "이 연구의 목적은 현행 교통사고 형사처리절차를 합리적으로 개선하여 신속하고 공정한 업무처리로 신속한 피해회복과 경찰의 수사에 대한 국민의 신뢰를 향상하는데 그 목적이 있다. 따라서 본 연구에서는 기존의 일반형사절차와 교통사고처리절차를 비교 분석하여 어떠한 차이가 있는지 알아보고 이에 따른 현행 교통사고처리절차의 문제점을 분석한다. 이를 위해 본 연구에서는 교통사고처리절차 중 형사사건과 관련되는 인적피해 교통사고에 대하여 사회적으로 문제가 되고 있는 인적피해 조사에 대한 문제를 확인하고 기존의 인적피해에 대한 수사가 오로지 진단서에 의존하여 처리하여 오던 폐단에서 벗어나 보다 객관적인 자료를 제공할 수 있는 세계 여러 나라에서 이미 널리 이용되고 있는 ‘AIS’와 교통안전공단 정부 3.0 정책에 의한 교통사고 빅데이터 구축을 통한 ‘공공데이터’를 이용하여 인적피해에 대한 선행연구를 통해 인적피해에 대한 분류를 보다 객관화 할 수 있는 지표를 제시하였다. 또한 본 연구는 설문조사를 통하여 국민과 경찰 사이의 괴리가 무엇인지 통계를 통하여 분석하고자 하였다. 그동안 교통사고 형사절차에 대한 문제를 인식하고 있으면서도 단 한 번도 이론화 또는 공론화 되지 않았던 교통사고관련 법령의 문제점이 무엇인지 분석하여 경찰수사 및 행정 분야를 보다 합리적으로 개선하여 범죄자를 양산하는 등 기존의 제도를 바로잡아 형사처리 절차를 간소화 하고자 하는 것이 이 연구에 목적이 있다.",
		"KEYWORD": null
	},
	{
		"ID": 992,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "한국항공대학교 대학원",
		"TITLE": "Discovering the characteristic of information for advanced information retrieval, focused on temporal, spatial and human-centric ",
		"AUTHOR": "JunLee",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 993,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "신뢰 네트워크의 연결 속성을 이용한 사용자 모델링 기반의 추천 시스템 ",
		"AUTHOR": "하인애",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:조근식 참고문헌 : p.76-87",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "최근 사용자의 소셜 프로파일, 소셜 네트워크, 그리고 소셜 미디어 등의 정보 활용을 이용한 사용자 정보 기반의 소셜 추천 시스템이 빅데이터 시대의 핵심 전략이 되고 있다. 소셜 네트워크 분석을 통해 소셜 관계를 추론할 수 있으며, 소셜 그룹의 형성을 통해 소셜 이웃 사용자 집단을 구성함으로써 추천의 효율성을 높이고 신뢰성 있는 정보를 제공할 수 있다. 일반적으로 추천 시스템에서 추천의 정확도 및 추천의 질을 향상시키기 위해 어떻게 이웃 사용자 집단을 구성하는지가 중요한 이슈 사항이다. 많은 연구자들이 이웃 사용자 집단을 구성하기 위해 KNN(K-Nearest Neighbor), K-Means 클러스터링 그리고 신뢰 기반의 클러스터링 기법 등을 사용한다. 본 논문에서는 소셜 추천 시스템을 위해 신뢰 기반의 클러스터링 기법을 사용하며, 구체적으로 사용자 신뢰 네트워크에서 연결 속성 정보를 기반으로 한 사용자 모델링을 제안한다. 제안된 방법은 전형적인 사용자 기반의 협업적 여과 방법을 통해 사용자간의 아이템 선호 성향 유사도를 계산하고, 사용자들이 명시적으로 표시한 신뢰 정보를 이용하여 사용자간의 연결 정도를 계산한다. 여기서 사용자들의 신뢰 정보는 링크를 통해 표현하며, 사용자들의 직?간접 연결 정보를 통하여 사용자들의 연결 정도와 연결 강도를 모델링 한다. 사용자들의 아이템 평가 값이 너무 적거나 균형적이지 않은 경우 이웃 사용자 집단을 구성하기 어려워 추천의 정확도가 떨어진다. 이를 해결하기 위해 사용자들의 신뢰 관계 정보를 고려한 사용자 모델링을 통하여 추천의 예측 정확도와 추천의 질을 높이고자 한다. 본 논문에서 제안하는 연결 속성은 크게 2 단계로 나뉜다. 먼저, 연결 정도는 케빈 베이컨의 6 단계 정도(six degrees)를 이용하여 사용자간의 관계를 수치로 표현하며, 연결 정도가 6 이하인 경로 중 최적의 경로를 선택하여 사용자 모델링 구축에 이용한다. 두 번째, 사용자와 직접적으로 연결되어 있는 관계와 간접적으로 연결된 관계 수를 고려하여 연결 강도 가중치를 계산하고 사용자 모델링 구축에 적용한다. 제안된 사용자 모델 기반의 소셜 추천 시스템의 성능을 평가하기 위하여 Epinion.com 데이터를 활용하여 실험하였고, 실험 평가한 결과 벤치마크 알고리즘인 trust_CF의 경우 선호도 예측 정확도가 높은 반면 추천 정확도는 가장 낮은 성능을 보였고, social_CF의 경우 선호도 예측 정확도가 낮은 반면 추천 정확도는 높았다. 즉, 신뢰정보를 이용하는 경우 예측 정확도가 향상이 되고, 사용자 관계를 이용하는 경우 추천 정확도가 향상됨을 알 수 있다. 하지만 본 논문에서 제안하는 LinkAttribute는 신뢰정보와 사용자 관계를 포함하는 연결 속성 기반의 사용자 모델링을 이용함으로써 선호도 예측과 추천 정확도를 모두 향상 시키는 것을 볼 수 있다.",
		"KEYWORD": null
	},
	{
		"ID": 994,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "인하대학교 물류전문대학원",
		"TITLE": "물류기업의 IT 플랫폼 기반 비즈니스 모델 혁신에 관한 사례 연구 :운송 거래 플랫폼 서비스를 중심으로 ",
		"AUTHOR": "최현수",
		"REGION": "인천",
		"PROFESSOR": "지도교수: 민정웅",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "기업의 글로벌 경영 환경이 급속히 변화되면서 물류는 경영의 핵심 요소가 되었다. 물류 산업은 고부가가치를 창출하는 신성장 서비스 산업으로서 새롭게 인식되고 있다. 인터넷 활용이 보편화되고 전자상거래 물동량이 급증함에 따라 국가를 넘나드는 물류서비스에 대한 수요가 늘어나면서 공급망의 범위가 전세계로 넓어졌다. 특히 화물 보관 및 운송에 있어 정확성, 정시성, 신속성, 안전성 등 고객의 기대 수준이 높아짐에 따라 물류 서비스 방식의 혁신이 더욱 중요하게 되었다. 글로벌 물류기업들은 글로벌 물류 수요에 대응하기 위해 차별화된 물류 네트워크 구축과 서비스를 강화할 물류 비즈니스 모델 혁신을 추진하고 있다. 본 사례 연구는 글로벌 물류기업들의 플랫폼 기반 비즈니스 모델 혁신 사례를 분석하여 시사점을 도출한다. 각 기업의 혁신 사례를 파악하기 위해 방문 인터뷰 및 각종 발표 자료를 활용하였다. 연구결과와 시사점은 다음과 같다. 첫째, 글로벌 물류기업들은 운송 거래 플랫폼 기업을 인수ㆍ합병하여 물류서비스의 디지털화를 추진하여 시장 지배력 강화 및 안정적 물량 확보하였다. 글로벌 물류기업들은 비즈니스 프로세스의 디지털화와 전자상거래에 따른 물동량 증가를 새로운 사업 기회로 보았으며, 혁신적인 새로운 서비스를 제공할 최적의 플랫폼을 확보하고 있다. 둘째, 글로벌 물류기업들은 자체 역량과 기술 혁신을 강화하여 물류 서비스 품질 및 신뢰도 확보, 수익성 개선에 노력하고 있다. 글로벌 물류기업들은 물류 관련 정보를 IoT, 빅 데이터, 클라우드 등 ICT(Information and Communications Technologies)를 활용하여 새로운 서비스 모델을 제공하면서 빠르게 혁신하고 있다. 이를 통하여 정보의 신속성, 투명성, 거래 시간 절감, 물류비용의 절감 등 새로운 고객 가치 제공은 시장의 지배력을 강화할 뿐만 아니라 사업 운영 효율성을 놓이고 수익성을 개선할 수 있게 되었다. 셋째, 전략적 협업을 통한 비즈니스 생태계 구축 및 가치 창출은 인수ㆍ합병과 더불어 진행하고 있다. 자체적 역량 확보에 필요한 시간을 단축하고 빠르게 고객의 요구사항에 대응하기 위한 전략적 협업은 비즈니스 생태계를 새롭게 구축하고, 시장 참여자들과 동반 성장하여 비즈니스 생태계의 가치를 높이게 된다. 본 연구를 통해서 글로벌 물류 기업들은 플랫폼 기반의 기술 기업을 인수ㆍ합병하여 서비스 혁신을 추진하고 있는 것을 확인하였다. 또한, 자체 기술 역량 강화 및 전략적 협업을 통한 새로운 비즈니스 모델 혁신도 진행되고 있음을 알았다. 플랫폼 기반 비즈니스 모델 혁신이 새로운 고객 가치 창출 및 물류 산업 생태계 변화에 어떠한 긍정적인 역할을 할 것이지 주목하여야 할 것이다.",
		"KEYWORD": "3PL,글로벌물류기업,비즈니스 모델,비즈니스 모델 캔버스,비즈니스 모델혁신,운송거래플랫폼,운송플랫폼,플랫폼"
	},
	{
		"ID": 995,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "성공회대학교 NGO대학원",
		"TITLE": "자유민주주의 체제 내의 전체주의적 요소들에 대한 연구 :현대 미국의 통치양식을 중심으로 ",
		"AUTHOR": "김필구",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김창진교수",
		"STORE_LOCATION": "성공회대학교 도서관",
		"ABSTRACT": "본 논문은 자유민주주의 체제 내의 전체주의적 요소들에 대한 분석을 목적으로 집필되었으며, 이러한 학술적 작업을 통해 정치 사상가인 후지따 쇼오조오와 슬라보예 지젝의 명제, 즉 `현대의 자유민주주의는 전체주의적이다` 혹은 `전체주의화 되어가고 있다`의 타당성의 반증 또한 그 내용 안에 포함하고 있다. 보다 더 구체적으로 본 논문은, 현대의 자유민주주의는 사람들이 그것에 대해 갖고 있는 일반적인 통념과는 달리, 이전에 등장했던 것들과는 확연히 구별되는 전혀 새로운 형태의 전체주의 체제로 변질되었는가? 혹은 단지 정체 내에 전체주의적 요소들이 모순적인 형태로 통합되어 있는 것일 뿐인가? 현대의 자유민주주의가 새로운 형태의 전체주의 체제로 변질되었다면, 권력의 행사 및 사회지배의 주체는 누구인가? 즉 권력을 독점하고 있는 세력은 누구인가? 만일 자유민주주의 내에 전체주의적 요소들이 모순적인 형태로 통합되어 있을 뿐이라면 이를 `현대` 자유민주주의의 특징으로 간주해야 할 것인가? 아니면 이러한 모순의 기원을 자유 민주주의가 역사에 처음으로 등장한 시점에서 찾아야 할 것인가? 즉 모순으로 인식되는 이러한 자유민주주의 내의 전체주의적 요소들은 보편적인 것들이라고 할 수 있겠는가? 정당정치에 있어서 이데올로기의 부재 혹은 소멸은 특정 이데올로기의 가치독점만큼이나 전체주의적인 것인가? 마지막으로 물리적 테러를 대신해서 현대 대중의 행동과 내면을 폭력 보다 더 효과적으로 통제할 수 있는 수단은 존재하는가? 등의 의문점들을 중심으로 논증을 펼쳐나가고 있다. 특히 본 논문은, 현대 미국의 통치 양식을 중심으로 논증을 펼쳐나가고 있으며, 보다 더 구체적으로 이를 독일 제3제국과 스탈린의 소련, 그리고 1931년에서 1945년 사이의 일본제국의 통치양식과의 비교 및 대조를 통해 그 실제적인 내용을 구성해나가고 있다. 분석틀에 있어서 본 논문은 한나 아렌트의 `전체주의 이론`과 에리히 프롬의 `권위주의 성격유형 이론` 그리고 미셸 푸코의 `파놉티콘 이론`의 유기적인 접목을 시도하고 있으며 이러한 분석틀의 이론적 비판의 대상이 된 요소들은, 미국 정부가 민간 통신 및 IT기업들과의 협약 하에 구축한 디지털 파놉티콘과 미국 저널리즘의 쇠퇴, 그리고 9.11 테러 후 재정된 미 애국자법의 구체적인 조항들이다. 결론적으로 본 논문은 국가의 감시체계는 비단 전체주의에만 해당되는 것이 아니라, 근대 국민국가 전반에 해당되는 요소이며, 이 두 체제의 근본적인 차이는 역시 국가에 의해 주도적으로 행해지는 총체적 테러의 유무에 있음을 확인하게 된다. 또한 이러한 총체적 테러에 정당성을 부여해 주는 전체주의 체제의 근간에는 실리 보다는 이데올로기적 논리에 합한 방향으로 현실 세계의 재구축을 시도하는 전체주의 체제의 독특한 정신구조가 발견되는데, 이러한 점에 있어서 본 논문은, 어디까지나 부국강병을 추구하는 현대 미국의 통치양식과 전체주의의 그것과는 좁혀지지 않는 간극이 존재함을 확인하게 된다. 마지막으로 본 논문은 인터넷과 정보기술의 발달로 인한 미국 저널리즘의 쇠퇴 및 대테러 입법 등으로 말미암은 시민 기본권의 위축 등을 살펴본 후, 이러한 점들이 국가 전략으로서의 파시스트 운동이라든지, 혹은 관료주의적이고도 권위주의적인 정체의 성립으로 귀결될 수는 있으나 미국 내 전체주의 지배체제의 성립으로까지는 이어질 수 없음을 구체적인 요소들을 짚어가며 논증한 후 결론을 맺고 있다.",
		"KEYWORD": null
	},
	{
		"ID": 996,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 신문방송대학원",
		"TITLE": "수용자의 몰아보기 이용동기와 지속적 이용의도에 영향을 미치는 영향 요인에 대한 연구 =Examining motivations & factors Affecting the persistent intention to use Binge-Watching ",
		"AUTHOR": "한순상",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 유홍식",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "2013년 미국의 OTT기업 넷플릭스(Netflix)가 ‘하우스 오브 카드 시즌1’ 13편을 온라인 동시개봉한 후 몰아보기(binge-watching)는 빅뱅을 맞이했다. 한 자리에서 2편이상의 동일 프로그램을 연속으로 이어 보는 몰아보기는 전세계에서 벌어지고 있는 시청행태 변화이자 문화적?사회적 현상이다. 본 연구는 Venkatesh의 확장된 기술수용모델을 이용하여 몰아보기 이용의도에 영향을 미치는 요인과 동기에 대해 알아보았다. 이를 위하여 본 연구는 온라인 설문 조사를 실시하였으며 유효 설문 응답자는 총333명였다. 설문은 총 81문항, 연구가설은 25개였다. 분석결과 몰아보기 동기요인은 모두 5개의 요인군으로 분류되었는데 <프로그램의 화제성>, <본방사수의 어려움>, <몰아보기의 기능성> 요인군은 몰아보기에 대한 지속적 이용의도와 유의미한 관련성(+)을 보인 반면 <몰아보기의 상대적 잇점·재미>, <몰아보기의 경제성 요인>군은 몰아보기에 대한 지속적 이용의도와 부적(-)인 관계를 보였다. 회귀분석 결과이용의도에 영향을 미치는 요인으로 어릴수록, 몰아보기를 자주 할수록, 지각된 유용성을 높게 평가할 수록 몰아보기 이용의도가 높게 나타났다. 또한 부수적으로 하우스 오브 카드 제작과정 분석을 통해 변인 도출의 현실성을 더했고, 몰아보기가 C-P-N-D 콘텐츠 가치사슬 전반에 미치는 영향을 살펴보았다. 본 연구가 차세대 콘텐츠 기획과 관련 영상산업 발전에 기초자료로 활용될 수 있기를 기대해 본다.",
		"KEYWORD": null
	},
	{
		"ID": 997,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "중앙대학교 첨단영상대학원",
		"TITLE": "미디어 아트 3.0 :Media art 3.0 :관객의 다중 상호작용을 위한 인터페이스 연구 =a study on the characteristics of the interface for multi-participants ",
		"AUTHOR": "장윤제",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김형기 참고문헌 수록",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "인터랙티브 아트(Interactive Art)는 관객이 사용자로서 참여하고 소통하면서 완성되는 작품이다. 미디어 아트 중에서 관객의 참여가 전제로 시작되는 인터랙티브 아트는 미디어 기술을 이용하여 종전의 예술에서 나타난 단방향적 소통의 한계점을 극복하는 특성을 제시하였다. 인터랙티브 아트에서의 관객 참여는 직접적인 상호작용을 전제로 하며 관객이 물리적인 관여를 통하여 작품을 완성해나가는 것을 의미한다. 관객은 이와 같은 상호작용에 따라 작품에 몰입할 수도 있으며 더 나아가 작품의 재해석 및 재구성이 가능하다. 따라서 인터랙티브 작품에 대한 참여적 소통의 도구인 인터페이스와 행위자로서 관객 사이의 관계는 밀접하다. 그 중에서도 다수의 관객을 작품에 물리적, 심리적으로 연결하는 것이 다수 참여 인터페이스(multi-user interface)이다. 본 논문에서는 미디어 아트의 유형을 관객의 참여 정도 및 단계에 따라 세 가지로 분류해 보았다. 첫 번째, 미디어 아트 1.0은 미디어 아트의 선구적 작품들이 제시한 시대적 특성으로 일방향적인 소통 구조를 지칭한다. 미디어 아트 2.0은 본격적인 인터랙티브 아트의 특성을 가리키는데, 이 유형의 작품들은 대체로 관객이 작품과 일대일 대응관계를 형성하며 소통해 나간다. 20세기 말 빅 데이터의 중요성이 대두된 환경에서, 작품과 관객의 일대일 소통이 아닌 ‘작품과 다수 관객의 소통’ 또는 ‘다자간의 소통’이라는 집단적 인터랙션을 지향하는 작품들이 나타났다. 미디어 아트 3.0은 이와 같은 다수 관객의 동시 인터랙션이 가능한 시스템 인터페이스를 전제로 두는 새로운 패러다임이다. 본 연구는 세 가지 유형으로 미디어 아트 관객의 참여형태에 따라 참여 관계의 패러다임을 분류하고, 미디어 아트 1.0, 미디어아트 2.0과 비교하여 다수 참여형태인 미디어아트 3.0의 유형적 특징을 도출하였다. 해당 작품들의 사례 분석을 통하여 미디어 아트 3.0의 패러다임에 따라서 나타나는 특징적 요소를 다중 상호작용의 네 가지 유형으로 분류하였다. 관객이 작품에 참여할 때 변화되는 작품의 반응적 결과에 따라 그 경향을 ‘집단 동질적’/‘개별 조합적’으로 구분하였고, 작품에 관객의 참여가 반영되는 경향을 ‘열린 시스템’/‘닫힌 시스템’으로 구분했다. 이에 따라 분류된 다중 상호작용의 네 가지 유형은 닫힌-집단 동질적, 열린-집단 동질적, 닫힌-개별 조합적, 열린-개별 조합적의 4분면이다. 이것을 토대로 상호작용에 관한 인터페이스 분석 요소를 도출하기 위하여 사례 작품의 유형별 요소 분석 및 관계 분석 방법을 적용했다. 작품 사례 분석에서는 관객이 능동적으로 참여하는 작품들을 중심으로 예시를 제시하고 그 특성을 분석하였다. 그 결과 각 유형 별로 다수결형, 무작위형, 분산형, 협력형 관객의 특성이 나타났다. 따라서 다중 관객 사이에서 협력적 관계의 특성을 발현시키기 위해서는 개인을 반영하는 대응성과 함께 관객이 집단으로 작품을 변화시킬 가능성인 ‘가변성’ 동시에 나타나야 한다는 조건이 필요하다.",
		"KEYWORD": null
	},
	{
		"ID": 998,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "중앙대학교 산업·창업경영대학원",
		"TITLE": "주요 메가트렌드(Mega Trend)변화에 따른 미래의 자동차산업 영향요인 분석 ",
		"AUTHOR": "송기석",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 김정인",
		"STORE_LOCATION": "중앙대학교 서울캠퍼스 중앙도서관",
		"ABSTRACT": "This study analyzed the effect of environmental change of auto industry for business performance of enterprise and especially investigated the effect of auto core industry, Mega-Trend. Based on advanced researches, this study studied the effect of environmental change of auto industry for business performance of enterprise. This study is very meaningful in suggesting ways to maximize business outcome of auto industry by analyzing the effect of auto core industry, Mega-Trend. This study conducted questionnaire research on each variable for four weeks from March 10th, 2014 to April 4th, 2014 to test hypothesis, distributing 300 questionnaires and collecting 251. The questionnaire is composed of 58 questions based on 3 measuring criteria. This study sets up two hypothesis and deducted the following research result by analyzing empirical research. First, the environmental change of auto industry has a positive effect on the business performance of auto industry. Factors effecting on the business outcome of auto industry are changes of political, institutional, economical, social, technological situation. Based on the result of correlation analysis, the factor effecting on the sale increase is technological change and the factor on the employment increase is social change. Finally factor on the occupation of market is political and institutional change. This analytical result supports that there are close relationships among the reinforcement of auto safety regulations in global market, regulations on carbon emission of Europe, the reinforcement of auto environment regulations against global warming and climate change, especially imposting cooperative fund for low carbon emitting car, and the business performance of auto industry in the future. Second, auto core industry Mega-Trend has a positive effect on the business performace of auto industry. Factors of Mega-Trend effecting on the business performance of auto industry are echo-friendly factor, high efficiency factor, emerging high sensitive consumers, smart factor and safety reinforcement factor. Based on the result of correlation analysis, the factor effecting on the sale increase is high efficiency and the factor on the employment increase is safety reinforcement. Finally factor on the occupation of market is echo-friendly factor. This analytical result supports that the interests in the development of alternative energy such as hydrogen, electricity, solar heat against exhausting oil and high oil price and regulations on emitting gas. As the oil price is getting higher, the interest on high efficient car is getting increase, this is the result reflecting the effort for improving fuel efficiency and decreasing carbon emission.",
		"KEYWORD": null
	},
	{
		"ID": 999,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2014",
		"UNIVERSITY": "호서대학교 글로벌창업대학원",
		"TITLE": "SNS 및 스마트폰 활용 중소기업 홍보마케팅 사업계획에 관한 연구 =SNS & smartphone marketingPR business plan research for small business ",
		"AUTHOR": "박영만",
		"REGION": "충청남도",
		"PROFESSOR": "지도교수: 전인오",
		"STORE_LOCATION": "호서대학교 중앙도서관,호서대학교 중앙도서관(천안캠퍼스)",
		"ABSTRACT": "SNS, 소셜네트워크서비스, 소셜미디어, 페이스북, 트위터, 유튜브, 블로그, 스마트폰, 모바일, 빅데이터, 클라우드서비스 등 ICT 단어가 많아지고 있는 디지털시대의 중소기업, 소상공인, 자영업자들의 홍보마케팅 애로사항을 해결해 주는 사업계획을 연구하였다. SNS는 관심사에 따라 끼리끼리 모여 있어 타깃 홍보마케팅에도 유리하고 고객인맥 연결효과로 저비용 고효율 홍보마케팅이 가능하다. SNS는 모바일마케팅과 연계되어 실시간 고객 교감 마케팅을 할 수 있다. 창업 및 사업이 성공하려면 고객확보가 중요하고 고객유지와 고객관리를 위해 SNS가 필요하다. 중소기업 및 소상공인은 SNS마케팅을 어떻게 활용할 것인지 절실히 필요해서 고민하고 있지만 조직 내에서 전문가도 없고 전문적인 교육을 받지 못해 해결책이 별로 없었다. 이러한 중소기업 및 소상공인의 SNS마케팅 필요성에 따라 중소기업청 산하 소상공인진흥원의 경영개선교육, 시장경영진흥원의 상인대학, 한국프랜차이즈협회, 대한상공회의소의 강사로 활동하면서 소상공인 및 자영업자들의 SNS와 모바일 및 스마트폰을 활용한 홍보마케팅의 니즈를 파악하게 되었다. 강의 및 컨설팅을 경험하면서 기존의 시스템만으로는 소상공인의 SNS 및 모바일 홍보마케팅 지원에 미흡하다는 생각을 하게 되었으며, 중소기업 및 소상공인들을 위한 SNS 및 모바일 홍보마케팅 전문서비스와 연구를 통한 사업을 기획하였다. 본 사업계획서 연구는 중소기업 및 소상공인의 영업 홍보마케팅 경쟁력 제고 및 지속 가능한 경영을 위해 SNS 및 스마트폰 모바일을 활용한 홍보마케팅 사업화 가능성 검토 및 실제의 사업계획을 작성하였다.",
		"KEYWORD": "SNS,사업계획서,스마트폰,중소기업,홍보마케팅"
	},
	{
		"ID": 1000,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2017",
		"UNIVERSITY": "경기대학교 대학원",
		"TITLE": "도박중독 자녀의 회복과정에 있어 부모 역할의 다의성 :부모와 자녀의 인식 비교를 중심으로 ",
		"AUTHOR": "김호진",
		"REGION": "경기도",
		"PROFESSOR": "경기대학교 논문은 저작권에 의해 보호받습니다. 지도교수: 조원일 참고문헌 : p. 93-96",
		"STORE_LOCATION": "경기대학교 금화도서관(서울캠퍼스),경기대학교 중앙도서관(수원캠퍼스)",
		"ABSTRACT": "본 논문은 도박중독 자녀의 회복과정에 있어 부모 역할의 다의성에 대해 부모와 자녀의 인식을 비교하여 동등한 점과 상이점을 탐색해 보고 그것이 자녀의 치유에 미치는 영향에 대해 현상학적 연구를 통해 알아보고자 하였다. 우리나라의 도박중독 유병률은 OECD 국가들 중에도 매우 높은 수준이며 합법적·불법적 도박의 접근성이 수월해지면서 사회적으로 도박으로 인한 심각한 문제를 일으키고 있다. 도박중독의 폐해 및 부작용이 가져오는 사회적 비용도 상당하지만 도박중독자 가족이 당하는 고통도 매우 크다. 최근 20-30대의 도박으로 인하여 발생한 문제가 사회적으로 심각한 문제가 되고 있다. 자녀의 도박문제를 인지한 부모는 초기에는 문제를 부정하고 자녀에 대한 신뢰를 버리지 않지만 지속되는 도박문제를 겪으면서 그 심각성을 인식하게 되며 치유방안을 탐색하고 자녀와 함께 치유과정에 참여하게 된다. 이처럼 도박중독 자녀의 회복과정에 있어서 부모는 다양한 역할을 수행하게 되는데 이러한 역할에 대해 부모와 자녀의 인식을 탐색, 비교를 통하여 각각 10개 구성요소를 도출하였으며 그 결과를 근거로 아래와 같은 제언을 하였다. 도박문제의 부정이나 심각성을 간과해서는 아니 되며, 도박문제를 인지했을 때는 즉시 전문가를 찾아 치유를 시작해야한다. 부모와 자녀가 겪는 정서적 고통을 치유하는 대책이 필요하며, 자녀 도박문제를 부모가 대리 해결해 주는 것은 치유에 부정적 영향을 끼친다는 사실을 인식해야 한다. 도박중독에 대한 병식을 가지는 것이 중요하고, 치유과정에 부모 자녀가 함께 참석이 중요하다. 치유과정 중에 문제되는 행위를 중단해야 하며, 도박중독의 치유를 위해 다양한 치유 노력을 기울이는 것이 중요하다. 부모의 긍정적 역할에 대해 적극적인 수행이 가능하도록 하는 것이 중요하며, 부정적인 역할에 대해서는 그런 행위를 하지 않도록 예방·홍보하는 것이 중요하다. 그 외에도 20-30대 도박중독 자녀에 대해 온라인 도박에 특화된 별도의 치유프로그램의 수립이 필요하고, 빅데이터를 활용한 온라인 불법 사이트에 대한 방어대책의 수립이 필요하다. 또한 4대 중독 즉 도박, 알코올, 마약, 인터넷 게임에 대한 국가적 통합예방치유시스템이 필요하다는 점도 제언하였다. 주제어 : 도박중독, 회복과정, 부모 역할, 부모 자녀 인식 비교",
		"KEYWORD": "도박중독,부모 역할,부모 자녀 인식 비교,회복과정"
	},
	{
		"ID": 1001,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "한신대학교 대학원",
		"TITLE": "소셜 큐레이션 서비스에 기반한 기록정보서비스 활성화 방안 연구 =A study on archival information service based on social curation service ",
		"AUTHOR": "이상헌",
		"REGION": "경기도",
		"PROFESSOR": "지도교수: 안병우",
		"STORE_LOCATION": "한신대학교 장공도서관,한신대학교 중앙도서관",
		"ABSTRACT": "기록정보의 관리와 보존은 활용을 전제로 행해질 때 그 의미와 가치가 살아난다. 따라서 국내?외 기록관들은 기록정보의 활용을 보다 극대화하기 위하여 기록정보의 검색 및 열람이라는 단순 서비스를 탈피하려고 하며, 기록관을 이용하는 다양한 이용자들의 다양한 정보욕구를 충족시키며, 이용자 중심의 보다 적극적인 기록정보서비스를 제공하기 위하여 많은 노력을 하고 있다. 여기서 이용자 중심의 기록정보서비스를 위한 가장 중요한 부분은 ‘이용자와의 소통’이다. 이용자와의 소통을 통하여 이용자가 원하고 필요로 하는 기록정보서비스가 무엇인지를 확인하고 서비스하는 것이다. 특히 정보과잉의 현시대에서는 이러한 소통을 통하여 이용자가 원하는 선별된 정보의 제공이 더욱 필요하다. 하지만 현재 국내기록관과 이용자와의 소통은 많이 미흡한 편이다. 특히 디지털시대에서 기록정보서비스의 주요한 수단이 되는 소셜 미디어를 통한 이용자와의 소통은 더욱더 그러하다. 본 연구는 소셜 미디어를 활용한 큐레이션 서비스를 제안하려고 한다. 큐레이션 서비스는 미술관 및 박물관의 전시 서비스 개념에서 출발하여, 정보과잉시대가 본격화된 2010년 이후부터는 전자상거래 분야 및 콘텐츠 서비스 분야 등에서 이용자의 선별적 요구에 부응하는 맞춤형 서비스로 발전해 왔다. 이는 이용자와의 소통을 통한 이용자 맞춤형의 정보서비스이다. 이러한 큐레이션 서비스가 소셜 미디어와 결합되어 소셜 큐레이션 서비스가 등장한 것이다. 소셜 미디어가 기록정보서비스의 수단으로써 주목받고 있는 이유는 이용자와의 원활한 소통기능에 있다. 페이스북이나 트위터와 같은 소셜 미디어는 정보가 게시되는 동시에 ‘좋아요, 댓글, 공유’등과 같은 기능으로 이용자들과 실시간 소통할 수 있으며, 이를 통하여 정보에 대한 이용자들의 호응도를 실시간으로 피드백할 수 있는 장점을 갖고 있다. 이러한 소셜 미디어를 수단으로 소통하여 이용자가 원하는 정보서비스를 선별해서 제공해주는 것이 소셜 큐레이션 서비스이다. 또한 이용자가 원하는 정보에 쉽게 접근할 수 있도록 도와주며, 전문적인 기록정보를 쉽게 이해할 수 있도록 내래이션과 스토리텔링 방식을 활용하는 것 또한 소셜 큐레이션 서비스이다. 본 연구에서는 이러한 소셜 큐레이션 서비스에 주목하여, 미국의 국립기록청과 국내의 국가기록원 및 대통령기록관의 기록정보서비스 현황을 연구하였다. 이를 바탕으로 이용자와 소통하여 원하는 정보가 무엇인지를 확인하는 방법으로 소셜 미디어를 통한 소통현황분석, 빅데이터 분석, 소셜 큐레이션 미디어의 활용 방법등을 제시하였고, 기록관과 이용자와의 소통에 중심이 되는 아키비스트의 새로운 역할을 제시하여, 이를 통하여 이용자 중심의 기록정보서비스를 활성화하는 방안을 제안하고자 한다.",
		"KEYWORD": "기록정보서비스,소셜 큐레이션,소셜미디어,이용자중심"
	},
	{
		"ID": 1002,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "인하대학교 대학원",
		"TITLE": "2000년 이후 국내의 정보화 및 전자정부에 대한 연구 동향에 관한 연구 :한국행정학보,한국정책학회보,정보화정책을 중심으로 ",
		"AUTHOR": "이혜원",
		"REGION": "인천",
		"PROFESSOR": "인하대학교 논문은 저작권에 의해 보호받습니다. 지도교수:명승환 참고문헌 : p.82-89",
		"STORE_LOCATION": "인하대학교 도서관",
		"ABSTRACT": "우리나라의 정보화 및 전자정부 분야가 세계에서 주목할 정도로 선구적인 역할을 해왔고 최근 2010년 UN의 전자정부 평가에서 세계 1위를 차지하고 2012년 다시 한번 1위를 차지하면서 전자정부 선도국가로서의 위상을 확립하였다. 이러한 상황 속에서 정보화 및 전자정부와 관련한 연구들은 빠른 변화의 급물살에 휩쓸려 달려왔지만 정보화 및 전자정부의 전반적인 흐름에 대한 성찰은 부족해 보인다. 이러한 문제의식 하에서 본 연구에서는 2000년 이후 행정학 분야의 학술논문을 대상으로 우리나라 정보화 및 전자정부에 대한 연구의 일반적인 경향을 분석하였다. 이를 통해 우리나라의 정보화 및 전자정부에 대한 연구가 향후 고려해야 할 부분들을 살펴보는데 본 연구의 목적이 있다. 본 연구에서는 우리나라의 정보화 및 전자정부의 연구 동향을 살펴보기 위해 한국행정학보, 한국정책학회보, 정보화정책 등 이상의 3개의 학회지에 게재된 학술논문을 대상으로 문헌 연구와 메타 분석 방법을 활용하여 각각의 연구에서 나타나는 연구내용과 연구방법의 두 가지 측면으로 나누어 분석하였다. 본 연구의 주요 연구결과는 다음과 같다. 첫째, 연구방법적인 측면에서 볼 때 정보화 및 전자정부에 대한 연구는 새로운 개념이나 이슈 등을 서술하고 분류하는 연구에서 점차 새로운 모형 혹은 프레임워크를 이용하거나 개발하는 연구방법으로 변화하고 있어 연구 수준이 점차 성숙되어지고 있으며, 양적연구방법보다는 사례연구 등의 질적연구가 많은 비중을 차지하고 있다. 둘째, 연구내용적인 측면에서 볼 때 2000년도 초반에는 정보화 시스템과 거버넌스 관련한 연구가 주를 이루었던 반면, 2000년도 후반으로 갈수록 정보화 서비스, 전자 민주주의, 시민참여, 정보격차, 정보화 연구 등에 관한 연구가 증가하였고, 시스템과 거버넌스에 관련한 연구는 시간의 흐름에 따라 그 주요 패러다임과 내용이 변화하였다. 본 연구의 결과를 통하여 제시하는 정책적 제언은 다음과 같다. 첫째, 연구방법적인 측면에서는 전자정부 1위 국가로서 국제사회에 이바지하고 한국의 정보화를 더욱 발전시키기 위해서 이론 기반 연구가 더욱 많이 이루어져야 할 것이다. 즉, 사례 중심의 질적 연구도 의미 있지만 이론을 정립하여 학술분야로서의 중심을 세울 수 있도록 노력해야 한다. 둘째, 연구내용적인 측면에서는 본 연구결과에서 드러난 전자민주주의, 시민참여, 정보격차 등 최근에 등장한 정보화의 역기능을 해결할 수 있는 연구와 스마트 정부의 등장에 따른 정부신뢰, 빅데이터의 운용, 플래폼정부 등 새로운 패러다임으로의 변화에 대응할 수 있는 연구가 필요하다.",
		"KEYWORD": null
	},
	{
		"ID": 1003,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2016",
		"UNIVERSITY": "과학기술연합대학원대학교",
		"TITLE": "ICT R&D and economic growth :정보통신 연구개발투자와 경제성장 :econometrics and the policy =계량과 정책 ",
		"AUTHOR": "JaePyoHong",
		"REGION": "",
		"PROFESSOR": "",
		"STORE_LOCATION": "",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 1004,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "한양대학교 부동산융합대학원",
		"TITLE": "입지요인이 음식업 매출액에 미치는 영향에 관한 연구 =(A)study on the effects of location factors on the sales of fast-food restaurants, Korean snack bakery shops in Seoul :서울시 패스트푸드점, 분식점, 제과제빵점을 중심으로 ",
		"AUTHOR": "김재홍",
		"REGION": "서울",
		"PROFESSOR": "부록 수록 지도교수: 최창규 권두 국문요지, 권말 Abstract 수록 참고문헌: p. 64-67",
		"STORE_LOCATION": "한양대학교 안산캠퍼스,한양대학교 중앙도서관",
		"ABSTRACT": "최근 우리나라는 베이비붐 세대의 은퇴가 현실화되고, 고용불안 등의 사회적 문제로 인해 창업에 대한 관심이 고조되고 있는 상황이다. 이러한 개인 창업이나 프랜차이즈 점포 창업이 늘면서 신규점포의 입지분석은 그 중요성이 더욱 커지게 되었으며 이에 대한 연구의 필요성도 높아지고 있다. 입지는 매장의 매출과 직결된다는 점에서 상업활성화와 관련하여 가장 중요하게 다루어야 할 요소라고 할 수 있다. 본 연구에서는 빅데이터를 활용하여 서울시 전체지역을 대상으로 점포의 매출액을 결정하는 입지요인에는 어떠한 것들이 있는지에 대해 인구특성, 경제특성, 접근성, 토지이용특성, 업종밀도, 지역특성 등의 측면에서 그 특징들을 다중회귀분석을 통하여 확인하였다. 연구대상 업종은 불황기에도 창업시장에서 꾸준히 관심을 받고 있는 대표적인 업종인 패스트푸드, 분식, 제과제빵업종을 선정하여 연구를 수행하였다. 패스트푸드점은 근린생활상권 지역, 버스정류장거리가 가까운 지역, 용적 률이 높고 큰 건물이 많은 지역 등이 적합한 입지조건으로 분석되었다. 한편, 보행량과는 매출과 유의한 상관관계가 없는 것으로 나타났다. 분식점은 대중교통 접근성이 좋고 유동인구가 많은 역세권 지역, 다양한 용도의 복합도가 높은 지역이, 제과제빵점은 대중교통 접근성이 좋고 유동 인구가 많은 역세권 지역이 유망한 입지조건임을 확인하였다. 3개 업종 모두 유사업종인 음식업종 간의 집적에 의한 매출상승효과가 있고, 대중교통 접근성이 중요하며, 상주인구밀도와 건폐율에 양향을 받지 않는다는 공통점이 있다. 또한 상권을 분석하고 매출을 예측할 경우 중요한 요소로 꼽을 수 있는 보행량과 관련하여 보행량이 업종별 매출액에 미치는 영향관계를 확인하기 위해 음식업 10개 업종을 대상으로 분석한 결과 업종별로 다방/커피, 분식, 제과제빵, 별식/퓨전요리 등의 순으로 보행량과 매출 간의 영향도가 높은 것으로 나타났으며, 반면에 중식의 경우에는 보행량과 매출과의 상관관계가 통계적으로 유의하지 않다는 것을 확인하였다. 보행량과 매출액의 관계는 해당 업종에 따라 그 민감한 정도가 다르게 나타나고 있음을 확인할 수 있었으며, 어떤 업종에서는 보행량과 매출이 상호 연관성을 가지고 있지 않음도 알 수 있었다.",
		"KEYWORD": "부동산"
	},
	{
		"ID": 1005,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2017",
		"UNIVERSITY": "서울시립대학교 도시과학대학원",
		"TITLE": "가스계소화설비의 소화성능 확보를 위한 설계방법 개선에 대한 연구 :A study on design methodology improvement of gas fire extinguishing system : focused on system components ",
		"AUTHOR": "채명희",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤명오",
		"STORE_LOCATION": "서울시립대학교 도서관",
		"ABSTRACT": "Gas system fire extinguishing equipment is applied to the places which have difficulty in applying water-based fire extinguishing system and this kind of difficulty includes uses of space, usage characteristics of space and damage by water etc. The places with water-based fire extinguishing system limitations are normally special places such as electrical room, communication room, room for expensive equipment, document archive and big data center etc. and these places have to secure anti-fire protection performance as a whole. Gas system fire extinguishing equipment installed in this kind of space also has to secure accuracy of operation and reliability of fire extinguishment for early suppression of fire, for which close examination whether it surely secures performance of fire extinguishing in a certain area should be done. Accordingly, the intention of this article is to propose design improvement plan of gas system fire extinguishing equipment for securing its performance and reliability mainly considering components of design improvement plan. First, I will reason out various problems about design, construction, test and maintenance of gas system fire extinguishing equipment through comparison and analysis of relevant laws and technology standard. Second, I will analyze problems caused in the process of the design, construction and maintenance of gas system fire extinguishing equipment by studying failure cases. Third, I will check out the function and performance of each component of applicable facilities technically for the best design of gas system fire extinguishing equipment. Finally, I will propose the design process model for design optimization and the check points by components putting together all the considerations. Each component consisting of gas system fire extinguishing equipment attains its ultimate purpose, fire extinguishment, only if it secures perfomance condition which operates fire extinguishing system organizationally. So it needs to be checked out whether the required performance is secured or not through the decision about how much reliability to secure in the time of design. I am sure that more systematic design and check of gas system fire extinguishing equipment will be possible by using the design process proposed in this article.",
		"KEYWORD": "가스계소화설비,시스템 구성요소 성능개선,청정소화약제,최적화 설계"
	},
	{
		"ID": 1006,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "홍익대학교 국제디자인전문대학원",
		"TITLE": "우리는 감성(감성정보)을 생산하고 소비하는 시대에 살고 있다 =Analysis of sensibility information mechanism of SNS through the angle of the plane mirror changes in Lacan`s mirror stage theory ",
		"AUTHOR": "방채원",
		"REGION": "서울",
		"PROFESSOR": "국·영문초록수록 지도교수: 나건 참고문헌: 장 72-78",
		"STORE_LOCATION": "홍익대학교 중앙도서관",
		"ABSTRACT": "본 연구에서는 최근 소셜 미디어 사용자의 관계형 SNS(페이스북, 카카오스토리 등)에서 관심형 SNS(인스타그램, 핀터레스트 등)로의 이동 양상을 라깡의 거울단계이론 가운데 평면거울의 각도변화로 이론적 관계성을 찾아보았다. 이를 근간으로 각도 변화를 사회 전반의 감성 중심으로의 사회적 움직임으로 바라보면서 기존 실물경제와 온라인의 감성경제(Sensibility Economy)가 서로 점진적으로 닮아가고 있다는 관점에 연구배경을 설정하였다. 이와 같은 감성 중심의 소셜 넷트웍 시대 배경을 뒤에 두고 라깡의 거울단계이론의 메커니즘에서 SNS 사용자 간의 나르시시즘적 요소를 발견하였다. 이 나르시시즘을 중심으로 SNS를 통해 생산되어 비정형 빅데이터로(Unstructured Big Data) 저장된 후, 보다 가치 있는 기준으로 추출 및 분석되는 감성창출이 소셜 넷트웍 시대의 핵심으로 바라보았다. 선행연구에서는 인류문명의 발전에 있어 공공시설로서의 인프라 개념을 연장하여 ‘클라우드 컴퓨팅’을 공공서비스로 바라보았다. 산업사회를 투영으로 기본적 인프라 구축의 다음 단계인 상권 및 상점 형성으로, ‘감성정보(Sensibility Information)’를 기본재로 설정하고 이를 바라보는 관점의 변화와 형태 양상을 둘러보고자하였다. 정보화 시대 이전의 ‘아날로그적 감성’에서부터 사회 패러다임 변화에 따라 농경사회의 ‘일꾼’에게 산업사회에서는 ‘소비자’에게 소비의 극대화를 위해 설계 및 디자인, 마켓팅 및 생산 단계 이전에 제공을 요구받았던 ‘인간공학’, ‘감성디자인‘과 정보화 시대의 사용자(User)로서의 UI/UX 설계 및 디자인을 위한 ‘감성정보’까지 SNS가 활성화되기 이전까지의 ‘감성’의 의미와 형태들을 되짚어보았다. 위와 같은 소셜 네트웍 ‘감성경제(Sensibility Economy)’시대에서 나르시시즘 성향의 증가 양상을 빅데이터 용량의 ‘감성정보’를 생산과 소비시키고자하는 소셜 넷트웍 서비스 프로그래밍(Social Network Service Programming)의 행태로 설정해 바라보며 보다 가치 있는 감성을 보다 기술적인 웹 크롤러(Web Crawler)의 인덱싱(Indexing) 작업으로 추출하여 선점하려는 이익추구집단 혹은 기타의 움직임으로 비유해 보았다. 이론 연구를 통해 라깡의 거울단계이론을 SNS에 증강해 적용해 보았을 때 SNS에 업로드 한 사진이나 동영상 또는 로그인ID 자체가 자아(ego, ID)이고 소타자(other, 친구ID)가 SNS상의 친구에 해당되며 ‘오프라인의 나’는 무의식의 주체인 ‘S`에 해당되고 대타자(Other, 페이스북)를 SNS의 플랫폼으로 설정, 이를 통해 나르시시즘 요소를 발견할 수 있었다. 라깡이 말하는 오프라인의 주체가 만들어 낸 자아상(SNS의 ID)과 타자(SNS의 친구ID, 타ID)의 상이 만나는 상상계적 작용을 하는 상상계의 축이자 소셜 넷트웍 축은 SNS상에서 자신이 업로드 한 이미지에 친구들의 좋아요, 클릭, 댓글 수 등으로 이루어지는 반응행태를 통해 나르시시즘적 요소로서 SNS의 메커니즘으로 볼 수 있었으며 라깡의 대타자(플랫폼이자 페이스북, Other)는 오프라인에서 온라인으로 넘나드는 플랫폼으로써 거울단계이론의 상징계에 해당하면서 이를 SNS에 증강시킨다면, 평면거울의 각도변화에 따른 오프라인의 주체(S)의 움직임을 최근 SNS 사용자들의 페이스북과 카카오스토리에서 인스타그램, 핀터레스트 등으로의 이동 즉, 관계형에서 관심형으로의 이동 양상에 대입해 볼 수 있었다. 이와 같은 축의 이동과 기존 관심에서 감성 중심으로의 전향을 소셜 넷트웍 서비스 프로그래밍 SNSP(Social Network Service Programming)을 사회구조의 기반으로 삼아 움직이는 ‘감성경제(Sensibility economy)’이자 소셜 넷트웍 시대로의 진입으로 바라보며 새로운 사회 패러다임의 변화의 시작으로 바라보았다.",
		"KEYWORD": null
	},
	{
		"ID": 1007,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2015",
		"UNIVERSITY": "숭실대학교 대학원",
		"TITLE": "개인정보의 보호와 이용의 조화에 관한 법제적 연구 =(A)study of the legal system on the balance between protection and use of personal information ",
		"AUTHOR": "김민섭",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 강경근",
		"STORE_LOCATION": "숭실대학교 도서관",
		"ABSTRACT": "오늘날의 고도 정보사회에서는 민간과 공공의 영역을 불문하고 각종 재화나 서비스의 유통과정에서 대량의 개인정보 수집과 이용이 이루어지고 있고, 이는 다양한 사회적 편익을 가져다주고 있다. 하지만 개인정보의 무분별한 수집이나 유출, 오남용으로 인한 피해 또한 크게 증가하고 있고 사회적 관심사로 대두되고 있는 실정이다. 따라서 개인정보 침해의 예방과 방지 그리고 구제 활동은 오늘날의 사회가 시급히 해결해야 할 우선적 과제라고 할 수 있다. 우리나라는 그간 공공 및 민간 각 분야별로 개인정보 보호에 대한 법체계를 구축하여 왔으며, 2011년에는 사회 전 분야를 아우르는 「개인정보 보호법」을 제정함으로써 외견적으로는 선진국형 개인정보보호 법체계를 마련하는데 성공하였다. 그러나 법 제정 이후에도 대량의 개인정보 유출사고가 끊이지 않고 있고, 또 한편으로는 「개인정보 보호법」이 지나치게 과도한 규제 수준을 지니고 있어 정당하게 개인정보를 이용하는 활동마저도 제약을 받고 있다는 목소리가 높아지고 있다. 예를 들어 빅데이터(Big Data)와 같은 혁신적인 산업은 현재의 개인정보 보호 규제 수준 아래에서는 정상적인 서비스가 불가능하다는 우려가 제기되고 있다. 따라서 과연 어디까지 개인정보를 보호해야 할 지, 보호와 이용의 균형은 어떻게 달성해야 할 지는 우리 사회가 반드시 해결해야 할 주요한 기준과 과제라 할 수 있다. 현재의 개인정보 보호 법 체계를 분석하여 보면, 우선 개인정보 보호의 일반법인 「개인정보 보호법」을 제정하였음에도 그 외의 「정보통신망법」등 다른 법률도 난립하고 있어 일원적?체계적 규율이 현실적으로 어렵다. 따라서 향후 이용과 보호의 조화라는 측면에서 타 법령의 폐지를 포함하는 법률 개정이 필요하다. 또한 현재의 개인정보 처리 기준은 지나치게 ‘정보주체의 동의’ 중심으로 해석됨으로써 문제를 야기해 왔으나, 향후에는 기본적인 사회활동에 당연히 수반되는 개인정보의 수집?이용은 이를 허용하는 방향으로 법 해석이 이루어질 필요가 있다. 또한 개인정보 처리기준 위반행위에 대한 지나치게 과도한 형사처벌 위주의 제제수준도 구체적인 법익침해와의 형평성을 감안하여 그 위험성이 적은 위반행위는 비범죄화하는 것을 대안으로 고려해볼 필요가 있다. 의료, 교육, 근로 등 개인정보가 다량으로 수집, 이용되는 각 개별 분야에 대해서는 해당 분야의 특수성을 고려하여 그에 맞는 개인정보 보호의 기준이 정립되어야 한다. 최근 들어 모바일 인터넷 환경을 기반으로 한 이른바 소셜 네트워킹 서비스(SNS)가 널리 이용되고 있으나 이를 통한 개인정보의 원치 않는 노출 및 침해 또한 문제가 되고 있다. 사회 각 분야에서 개인정보의 보호와 이용의 조화를 모색하는 것은 헌법학적으로 중요한 과제라 생각되며 향후에도 지속적인 후속 연구가 필요하리라 생각된다.",
		"KEYWORD": "개인정보,개인정보보호,개인정보보호법,개인정보자기결정권,조화,프라이버시"
	},
	{
		"ID": 1008,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "국민대학교 디자인대학원",
		"TITLE": "기업 홍보관에 나타난 Digital Signage 체험형 인터랙티브 전시 평가 연구 =(A)study on evaluation of digital signage interactive exhibitions of corporate PR centers ",
		"AUTHOR": "이흥주",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 윤재은 참고문헌: p. 115-118",
		"STORE_LOCATION": "국민대학교 성곡도서관",
		"ABSTRACT": "",
		"KEYWORD": null
	},
	{
		"ID": 1009,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2015",
		"UNIVERSITY": "고려대학교 대학원",
		"TITLE": "개인정보 국외이전에 따른 국제법적 과제에 관한 연구 ",
		"AUTHOR": "이세라",
		"REGION": "서울",
		"PROFESSOR": "지도교수: 박노형 참고문헌: p. 92-100",
		"STORE_LOCATION": "고려대학교 도서관",
		"ABSTRACT": "정보통신기술의 발전에 따른 글로벌 네트워크 구축과 국경을 초월한 다국적 기업의 증가로 내국민의 개인정보가 국외로 이전되어 해외에서 처리되는 경우가 증가하고 있다. 또한 클라우드 컴퓨팅(Cloud computing), 빅데이터(Big data), 사물인터넷(IoT 또는 IoE) 등의 등장으로 국경간 개인정보의 이전과 전전유통은 더욱 증가할 것으로 예상되며, 이에 따른 개인정보의 오·남용 피해 및 사생활 침해 가능성도 더 커지고 있다. 그러나 아직 국제적인 차원에서 개인정보 국외이전에 관한 논의는 이루어지지 않고 있다. EU, APEC 등을 중심으로 개인정보 국외이전에 대한 논의가 전혀 없었던 것은 아니지만, 지역적인 한계를 지니고 있어 국제적인 규범으로는 발전하지 못하고 있다. 국제통상법상 개인정보 국외이전은 서비스무역과 관련이 깊다. EU개인정보보호지침(EU data protection directive)은 개인정보 국외이전에 관하여 엄격한 규제를 두고 있는 것으로 평가받고 있는데, EU지침 제25조는 원칙적으로 EU보다 개인정보의 보호수준이 낮은 국가로의 개인정보 국외이전을 금지하고 있다. 따라서 동조는 최혜국대우 의무와 시장접근 약속을 규정한 서비스무역협정(GATS)에 위반된다. 다만, 서비스무역협정의 일반예외 규정에 따라 이 위반이 정당화되고 있다. 그러나 일반예외 규정에 의존하여 개인정보 국외이전을 지나치게 제한하면 무역에 부정적인 영향을 주게 되므로, 국외이전 제한 규정은 국제적인 차원에서 무역을 제한하지 않는 정도의 수준으로 논의될 필요가 있다. 또한 개인정보가 이전되고 나면 각 국의 개인정보보호법에 따른 역외적용 문제가 발생하는데, 개인정보가 국경을 넘나들며 이동하기 때문에 필연적으로 다른 국가와의 관할권 충돌이 발생하게 된다. 따라서 개인정보보호법의 역외적용이 실질적으로 가능하도록 하기 위해서는 다른 국가들과의 논의가 필수적이다. 다른 국가들과의 논의는 궁극적으로 모든 국가를 포섭할 수 있는 국제적인 논의가 되어야 할 것이다. 개인정보 국외이전에 관한 통일적인 국제적 규범을 통해 개인정보 국외이전에 관한 규범의 역외적용 문제를 해결하고 동시에 국제무역에 기여할 수 있는 방향으로 나아가야 할 것이다.",
		"KEYWORD": "개인정보 국외이전,국가관할권,국제규범,국제통상법,역외적용"
	},
	{
		"ID": 1010,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "석사",
		"YEAR": "2013",
		"UNIVERSITY": "충북대학교 대학원",
		"TITLE": "스마트시대의 개인정보보호법제 =(A)study on the legislation of personal information protection in smart era ",
		"AUTHOR": "조민상",
		"REGION": "충청북도",
		"PROFESSOR": "지도교수:윤종민",
		"STORE_LOCATION": "충북대학교 도서관",
		"ABSTRACT": "The recent development and spread of smart device, intellectualized technology, and social service led to the advent of smart era. Smart Era can be defined as a time when information customized to individuals is supplied by internet rapidly and accurately, using products attached with high-tech intelligence. The higher possibility of infringement of personal information by various technologies and media also increased the necessity of personal information protection. Although Personal Information Protection Act, which covers both public and private sector, was enacted and put into action in 2011, it has not been efficient to deal with privacy issues in smart era. Thus, it is imperative to secure the effectiveness of Personal Information Protection Legislation of Korea in step with the upcoming smart era. The purpose of this study lies in reconsidering the status of the Personal Information Protection Act as a fundamental law and protecting personal information in the smart era. Many of the privacy issues occurring in the smart era are correlated with infringement of personal information in the internet that can be regulated by the Personal Information Protection Act and Act on Promotion of Information and Communications Network Utilization and Information Protection. As is often the case with the most of personal information, it is usually processed and regulated by information communication network. Considering that both laws have similar regulations, it is advised to enhance the status as a fundamental law and cope with rapidly changing technologies, letting the issues be taken care of by the Personal Information Protection Act. As more information about individuals is saved in smart devices, the major component of smart era, the portability of smart devices increased the possibility of data spill by loss or theft compared to the existing personal computers. Furthermore, smart devices, which used to be considered the safe zone for viruses and malignant codes, are not safe anymore. There can be unauthorized collection of personal information, in the process of installation or use of application, without any consent of the principals of information. Restructuring of individuals with fragmented information by the rapid growth of information processing and analysis technology such as big data, profiling, and data mining gave birth to the privacy issues. Legal issues on personal information protection in the smart era are presented in a variety of ways according to the media. Inaccuracy of personal information, infringement of location information, and applicability of domestic law are the issues to smart devices. SNS generates the issues related to the protection of personal information of the deceased, protection of voluntarily revealed personal information, and collection of personal information. Meanwhile, cloud computing bears the applicability of the Personal Information Protection Legislation of Korea, when overseas as well as domestic service providers violated any personal information. In this respect, this study inquires into the necessity of personal information protection through the general theories, and looks through `the Right to be Forgotten`. Furthermore, it reviews the overseas legislation cases of personal information protection and speculates upon the way of applying them to the domestic cases, to further analyze the major contents and issues of current system and then suggest measures to settle the issues of infringement on personal information in the smart era.",
		"KEYWORD": null
	},
	{
		"ID": 1011,
		"SEARCH_KEYWORD": "빅데이터",
		"DEGREE": "박사",
		"YEAR": "2014",
		"UNIVERSITY": "홍익대학교 대학원",
		"TITLE": "공유가치 기반 장소 브랜딩 모델에 관한 연구 =(A)study on the place branding model based on the shared value ",
		"AUTHOR": "이경화",
		"REGION": "서울",
		"PROFESSOR": "국, 영문초록수록 부록 : 설문지 지도교수: 김주연 참고문헌( p.269-276)수록 서지적각주수록",
		"STORE_LOCATION": "홍익대학교 세종캠퍼스 문정도서관,홍익대학교 중앙도서관",
		"ABSTRACT": "전 지구적인 환경 변화와 새로운 인류가 직면하고 있는 다각화된 사회 문제 및 경제적 위기 속에, 오늘날 지속가능성을 위한 대안적 개념의 도구로써 공유 (Sharing)가 강조되고 있다. 이 같은 공유에 대한 관심과 가치구현의 시대적 도래로 등장한 공유가치(Shared Value)는 다양한 삶의 사회 윤리적 갈등이 내재되어 있는 장소 브랜딩에 있어, 복잡한 네트워크로 생성되는 미래의 공간 환경 창출에 대한 새로운 방법론적 지침을 제공하는 역할을 수행할 수 있다. 여기서, 이제는 단순히 브랜드의 호의적인 평가를 얻기 위한 소극적인 방법론으로서가 아니라, 브랜드와 사회와의 상호의존성을 인식하여 진화된 사회공헌활동으로써 공유가치성장(Shared Value Growth)을 도모하는 적극적인 관점에서의 장소 브랜딩 디자인이 시대 가치적으로 필요한 시점에 있다. 본 연구는 상기와 같이 미래성장 동력으로서 공유가치의 시대적 패러다임을 이해하고, 지속가능한 장소 브랜딩의 방법론을 도출하기 위한 초기 의도로 시작되었다. 이에, 일차적으로 공유가치의 개념적 범주와 장소 브랜딩의 핵심항목을 통하여 공유가치 평가지표 모형을 도출하고, 이차적으로 장소 브랜드 포지셔닝의 유형 규정 및 가치항목의 평가를 통해 공유가치 기반 장소 브랜딩 모델을 제시하는데 연구의 목적을 두었다. 연구의 범위는 공유가치의 개념을 ‘공공의 이익을 위해 사회공헌활동을 중심으로 경제 및 사회, 환경적 가치 창출을 동시에 지향하는 나눔의 가치’로 규정하고, 장소성의 복잡성과 다차원적인 성격을 이해하기 위한 개념적 범주를 다각화된 세가지 관점에서 접근하였다. 즉, 인문 사회학적 관점으로 공공성(Publiceness) 개념과 공간 환경학적 관점으로 공동체 도시모델, 그리고 디자인 경영학적 관점으로 공유가치창출(Creating Shared Value) 개념과 관련한 이론을 중심으로 공유가치의 개념적 범위를 설정하였다. 연구의 공간적 범위는 장소 브랜딩의 개념이 함축하는 구역, 도시를 포함한 지역을 중심으로 전개하였으며, 시간적 범위는 최초로 도시 브랜드 자산평가 지수(City Brand Index)를 공식화한 사이먼 안홀트(Simon Anholt) 이후 장소 브랜딩 연구가 가장 활발히 이루어졌던 2006년 이후의 문헌을 중심으로 분석하여 진행하였다. 연구의 방법은 이론 및 선행연구와 전문가 인터뷰를 거쳐 상정된 가설에 대한 정량적 검증과, 전문가 설문을 통한 사례 평가의 정성적 방법을 통해 이루어졌다. 연구의 세부적 방법은 장별로 구성하여 체계적으로 적용하였으며, 이 같은 연구 전개 과정 및 내용을 정리하면 다음과 같다. 연구의 1장에서는 공유가치의 시대적 배경과 이에 기반한 장소 브랜딩 방법론을 연구의 목적으로 제시하였으며, 연역적 해석을 통해 연구의 방법 및 범위를 전개하고 선행연구 분석을 통해 차별화된 연구의 논증을 위한 근거를 마련하였다. 연구의 2장에서는 공유가치의 개념을 이해하기 위하여 관련 문헌을 고찰하고, 장소성의 브랜드 이미지 구축 특성과 장소 브랜드 포지셔닝의 전개 유형을 파악한 후, 지속가능한 장소 브랜딩을 위한 공유가치의 개념적 접근에 대한 필요성을 모색하였다. 연구의 3장에서는 공유가치의 개념적 범주와 장소 브랜딩 핵심항목을 상정하고 장소 브랜드 포지셔닝의 유형을 규정하여, 공유가치 기반 장소 브랜딩 모델의 구조(Framework)를 제시하였다. 연구의 4장에서는 일차적으로 전문가 심층 인터뷰와 설문 조사를 통해 상정된 공유가치의 개념적 범주 및 장소 브랜딩의 핵심항목을 정량적으로 검증하였으며, 이차적으로 전문가 사례 분석을 통해 유형별 가치항목을 정성적으로 평가 및 해석하여 공유가치 기반 장소 브랜딩 모델을 제시하였다. 연구의 5장에서는 연구 내용의 종합 및 유용성을 모색하여 공유가치 기반 장소 브랜딩 연구 모델을 규명하고, 향후 지향해야 할 장소 브랜딩 구축의 디자인 방향성과 연구 모형 및 모델의 활용 가능성을 제언하였으며, 마지막으로 연구의 회고와 한계로 마무리하였다. 이상과 같은 진행 과정을 통해 본 연구에서는 공유가치 개념으로 도덕적 윤리가치(Fairness), 잠재적 기회가치(Expandability), 심미적 차이가치(Aesthetics), 유기적 순환가치(Circularity), 포용적 연대가치(Solidarity)와 같은 5가지 범주와 이에 기반한 27가지 장소 브랜딩 핵심항목을 추출 및 검증하였으며, 사례 평가를 통한 상대적 우위 분석으로 유형별 차이 가치를 파악하여 장소 브랜드 포지셔닝의 특성을 도출하였다. 결과적으로 장소성의 브랜드 이미지 구축에 있어 공유가치의 개념적 범주, 주요 핵심항목, 포지셔닝의 특성을 내재한 공유가치 기반 장소 브랜딩 모델은, 근본적으로 공공성을 위한 도덕적 윤리가치 속에서 잠재적 기회의 확장성을 위한 공동체 비지니스(Community Business), 장소자산의 고유성 확보를 위한 창조적 재생(Creative Recycling), 유기적 순환성을 위한 친환경적 조화(Ecological Harmony), 그리고 포용적 연대성을 위한 자발적 참여(Voluntary Participation)라는 공유가치 속성을 함축하며 지속가능한 장소 브랜딩의 방향성을 제언하였다. 첫째, 시민사회의 공론장으로서 브랜드 본연의 ‘차별화’ 가치와 아울러 ‘참여화’의 가치 기준에 보다 무게 중심을 두어, 이해관계자들의 자발적 참여 속에 공공복리를 도모함으로써 장소 브랜딩의 지속성을 모색할 수 있는 디자인에 대한 재고가 보다 적극적으로 이루어져야 한다. 둘째, 소외된 유무형의 장소자산에 새로운 생명을 불어넣을 수 있는 창조적 재생 및 재해석을 통해 보다 다각화된 관점에서의 전략적 접근을 활성화하여, 과거에 투영된 기억을 보존하고 공간에서 새로운 문화적 교류를 생성할 수 있는 장소 브랜딩을 개발해 나가야 한다. 셋째, 장기적인 장소 브랜딩의 경쟁력을 높일 수 있는 수단으로 세계지역화(Glocalization)를 위한 공동체 비즈니스의 활성화를 통해, 차별화된 개성과 가치를 자생적으로 주도해 나갈 수 있는 장소 브랜딩이 지향되어야 할 것이다. 끝으로, 본 연구에서 도출된 장소 브랜딩의 공유가치 평가지표 모형은 장소성의 브랜드 이미지 구축에 있어 공유가치의 개념적 범주와 핵심항목을 평가하여 전략적 디자인의 지침을 마련하는데 활용되어질 수 있다. 또한, 본 연구의 공유가치 기반 장소 브랜딩 모델은 단계별 프로세스를 통한 접근 방법을 제시하여 일관된 포지셔닝 디자인의 방향성을 설정할 수 있고, 향후 체계적으로 누적된 빅 데이터는 공유가치의 초기 포지셔닝 상황진단 도구로써의 역할을 수행할 수 있다. 이렇듯, 공유가치에 기반한 장소 브랜딩 디자인의 세분화된 방법론적 지표 생성의 유용성을 통해, 향후 장소 브랜드 포지셔닝 계획과 집행 전략의 선택과 집중에 있어 판단의 지침을 제공하는데 본 연구의 의의가 있다. 공유가치의 시대적 패러다임에서 공익을 위한 브랜딩은 일방적으로 ‘보여주고 전달하는’ 차원을 넘어 긍정적인 사고의 전환을 통해 행동의 변화를 유도할 수 있으며, 나아가 바람직한 사회문화 창출을 위한 상호 신뢰와 교류의 지속성을 낳는 토대를 제공한다. 갈수록 거대하고 첨단화되어가는 공간 환경의 도시화 이면의 난제 앞에 장소를 브랜딩의 대상으로 설정하여 공유가치의 관점에서 수행된 본 연구는, 단지 장소의 물리적 환경 디자인으로 국한된 것이 아니라 공유를 통해 개개인의 기억과 경험 공간으로의 확장과 사람들 간의 참여와 소통, 그리고 그 속에 살고 있는 주체와 그들이 만들어낼 창의적인 콘텐츠의 생성과 관계적 가치를 지향하는 장소성 실현에 일조할 수 있다. 이렇듯, 오늘날 공유의 형태로 진화되어가는 생활환경의 변화 속에 공유가치를 기반으로 사회적 담론을 형성하고 공간과 사건의 교감을 통해 구축되어지는 장소 브랜딩은, 인간 삶의 문화 및 생활양식 구현에 있어 중심적인 역할을 수행하며 나아가 지속가능한 시공간적 유토피아에 접근할 수 있는 이 시대의 방법론적 대안이 아닌가 한다.",
		"KEYWORD": null
	}
];